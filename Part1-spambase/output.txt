hdf5 not supported (please install/reinstall h5py)
Scipy not supported!
---------------------------------
Run id: 9RS8Y2
Log directory: summaries/
[?25l---------------------------------
Preprocessing... Calculating mean over all dataset (this may take long)...
Mean: 6.15077019107 (To avoid repetitive computation, add it to argument 'mean' of `add_featurewise_zero_center`)
---------------------------------
Preprocessing... Calculating std over all dataset (this may take long)...
STD: 92.4752145995 (To avoid repetitive computation, add it to argument 'std' of `add_featurewise_stdnorm`)
---------------------------------
Training samples: 3680
Validation samples: 921
--
Training Step: 1 
[2K| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/3680
[A[ATraining Step: 2  | total loss: [1m[32m0.62382[0m[0m
[2K| Adam | epoch: 001 | loss: 0.62382 - acc: 0.2812 -- iter: 0064/3680
[A[ATraining Step: 3  | total loss: [1m[32m0.68054[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68054 - acc: 0.4347 -- iter: 0096/3680
[A[ATraining Step: 4  | total loss: [1m[32m0.68943[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68943 - acc: 0.6243 -- iter: 0128/3680
[A[ATraining Step: 5  | total loss: [1m[32m0.69194[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69194 - acc: 0.5382 -- iter: 0160/3680
[A[ATraining Step: 6  | total loss: [1m[32m0.69198[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69198 - acc: 0.5940 -- iter: 0192/3680
[A[ATraining Step: 7  | total loss: [1m[32m0.69130[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69130 - acc: 0.6501 -- iter: 0224/3680
[A[ATraining Step: 8  | total loss: [1m[32m0.69208[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69208 - acc: 0.5832 -- iter: 0256/3680
[A[ATraining Step: 9  | total loss: [1m[32m0.69197[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69197 - acc: 0.5888 -- iter: 0288/3680
[A[ATraining Step: 10  | total loss: [1m[32m0.69179[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69179 - acc: 0.5913 -- iter: 0320/3680
[A[ATraining Step: 11  | total loss: [1m[32m0.69168[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69168 - acc: 0.5924 -- iter: 0352/3680
[A[ATraining Step: 12  | total loss: [1m[32m0.69187[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69187 - acc: 0.5649 -- iter: 0384/3680
[A[ATraining Step: 13  | total loss: [1m[32m0.69203[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69203 - acc: 0.5505 -- iter: 0416/3680
[A[ATraining Step: 14  | total loss: [1m[32m0.69121[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69121 - acc: 0.5938 -- iter: 0448/3680
[A[ATraining Step: 15  | total loss: [1m[32m0.69181[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69181 - acc: 0.5392 -- iter: 0480/3680
[A[ATraining Step: 16  | total loss: [1m[32m0.69181[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69181 - acc: 0.5926 -- iter: 0512/3680
[A[ATraining Step: 17  | total loss: [1m[32m0.69037[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69037 - acc: 0.5926 -- iter: 0544/3680
[A[ATraining Step: 18  | total loss: [1m[32m0.69009[0m[0m
[2K| Adam | epoch: 001 | loss: 0.69009 - acc: 0.6038 -- iter: 0576/3680
[A[ATraining Step: 19  | total loss: [1m[32m0.68941[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68941 - acc: 0.6317 -- iter: 0608/3680
[A[ATraining Step: 20  | total loss: [1m[32m0.68863[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68863 - acc: 0.6496 -- iter: 0640/3680
[A[ATraining Step: 21  | total loss: [1m[32m0.68844[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68844 - acc: 0.6420 -- iter: 0672/3680
[A[ATraining Step: 22  | total loss: [1m[32m0.68781[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68781 - acc: 0.6556 -- iter: 0704/3680
[A[ATraining Step: 23  | total loss: [1m[32m0.68672[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68672 - acc: 0.6921 -- iter: 0736/3680
[A[ATraining Step: 24  | total loss: [1m[32m0.68685[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68685 - acc: 0.6644 -- iter: 0768/3680
[A[ATraining Step: 25  | total loss: [1m[32m0.68572[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68572 - acc: 0.6707 -- iter: 0800/3680
[A[ATraining Step: 26  | total loss: [1m[32m0.68529[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68529 - acc: 0.6669 -- iter: 0832/3680
[A[ATraining Step: 27  | total loss: [1m[32m0.68460[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68460 - acc: 0.6802 -- iter: 0864/3680
[A[ATraining Step: 28  | total loss: [1m[32m0.68490[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68490 - acc: 0.6664 -- iter: 0896/3680
[A[ATraining Step: 29  | total loss: [1m[32m0.68509[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68509 - acc: 0.6563 -- iter: 0928/3680
[A[ATraining Step: 30  | total loss: [1m[32m0.68648[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68648 - acc: 0.6267 -- iter: 0960/3680
[A[ATraining Step: 31  | total loss: [1m[32m0.68719[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68719 - acc: 0.6119 -- iter: 0992/3680
[A[ATraining Step: 32  | total loss: [1m[32m0.68826[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68826 - acc: 0.5938 -- iter: 1024/3680
[A[ATraining Step: 33  | total loss: [1m[32m0.68638[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68638 - acc: 0.6212 -- iter: 1056/3680
[A[ATraining Step: 34  | total loss: [1m[32m0.68452[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68452 - acc: 0.6421 -- iter: 1088/3680
[A[ATraining Step: 35  | total loss: [1m[32m0.68483[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68483 - acc: 0.6320 -- iter: 1120/3680
[A[ATraining Step: 36  | total loss: [1m[32m0.68520[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68520 - acc: 0.6114 -- iter: 1152/3680
[A[ATraining Step: 37  | total loss: [1m[32m0.68431[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68431 - acc: 0.6328 -- iter: 1184/3680
[A[ATraining Step: 38  | total loss: [1m[32m0.68431[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68431 - acc: 0.6252 -- iter: 1216/3680
[A[ATraining Step: 39  | total loss: [1m[32m0.68482[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68482 - acc: 0.6192 -- iter: 1248/3680
[A[ATraining Step: 40  | total loss: [1m[32m0.68287[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68287 - acc: 0.6320 -- iter: 1280/3680
[A[ATraining Step: 41  | total loss: [1m[32m0.68409[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68409 - acc: 0.6135 -- iter: 1312/3680
[A[ATraining Step: 42  | total loss: [1m[32m0.68471[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68471 - acc: 0.5987 -- iter: 1344/3680
[A[ATraining Step: 43  | total loss: [1m[32m0.68352[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68352 - acc: 0.6033 -- iter: 1376/3680
[A[ATraining Step: 44  | total loss: [1m[32m0.68055[0m[0m
[2K| Adam | epoch: 001 | loss: 0.68055 - acc: 0.6287 -- iter: 1408/3680
[A[ATraining Step: 45  | total loss: [1m[32m0.67982[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67982 - acc: 0.6334 -- iter: 1440/3680
[A[ATraining Step: 46  | total loss: [1m[32m0.67930[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67930 - acc: 0.6372 -- iter: 1472/3680
[A[ATraining Step: 47  | total loss: [1m[32m0.67869[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67869 - acc: 0.6454 -- iter: 1504/3680
[A[ATraining Step: 48  | total loss: [1m[32m0.67727[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67727 - acc: 0.6472 -- iter: 1536/3680
[A[ATraining Step: 49  | total loss: [1m[32m0.67651[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67651 - acc: 0.6486 -- iter: 1568/3680
[A[ATraining Step: 50  | total loss: [1m[32m0.67651[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67651 - acc: 0.6401 -- iter: 1600/3680
[A[ATraining Step: 51  | total loss: [1m[32m0.67702[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67702 - acc: 0.6378 -- iter: 1632/3680
[A[ATraining Step: 52  | total loss: [1m[32m0.67553[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67553 - acc: 0.6406 -- iter: 1664/3680
[A[ATraining Step: 53  | total loss: [1m[32m0.67507[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67507 - acc: 0.6318 -- iter: 1696/3680
[A[ATraining Step: 54  | total loss: [1m[32m0.67496[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67496 - acc: 0.6318 -- iter: 1728/3680
[A[ATraining Step: 55  | total loss: [1m[32m0.67073[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67073 - acc: 0.6585 -- iter: 1760/3680
[A[ATraining Step: 56  | total loss: [1m[32m0.67073[0m[0m
[2K| Adam | epoch: 001 | loss: 0.67073 - acc: 0.6585 -- iter: 1792/3680
[A[ATraining Step: 57  | total loss: [1m[32m0.66798[0m[0m
[2K| Adam | epoch: 001 | loss: 0.66798 - acc: 0.6582 -- iter: 1824/3680
[A[ATraining Step: 58  | total loss: [1m[32m0.66911[0m[0m
[2K| Adam | epoch: 001 | loss: 0.66911 - acc: 0.6452 -- iter: 1856/3680
[A[ATraining Step: 59  | total loss: [1m[32m0.66648[0m[0m
[2K| Adam | epoch: 001 | loss: 0.66648 - acc: 0.6593 -- iter: 1888/3680
[A[ATraining Step: 60  | total loss: [1m[32m0.66395[0m[0m
[2K| Adam | epoch: 001 | loss: 0.66395 - acc: 0.6754 -- iter: 1920/3680
[A[ATraining Step: 61  | total loss: [1m[32m0.66214[0m[0m
[2K| Adam | epoch: 001 | loss: 0.66214 - acc: 0.6770 -- iter: 1952/3680
[A[ATraining Step: 62  | total loss: [1m[32m0.66005[0m[0m
[2K| Adam | epoch: 001 | loss: 0.66005 - acc: 0.6823 -- iter: 1984/3680
[A[ATraining Step: 63  | total loss: [1m[32m0.65628[0m[0m
[2K| Adam | epoch: 001 | loss: 0.65628 - acc: 0.6949 -- iter: 2016/3680
[A[ATraining Step: 64  | total loss: [1m[32m0.65427[0m[0m
[2K| Adam | epoch: 001 | loss: 0.65427 - acc: 0.6940 -- iter: 2048/3680
[A[ATraining Step: 65  | total loss: [1m[32m0.65365[0m[0m
[2K| Adam | epoch: 001 | loss: 0.65365 - acc: 0.6932 -- iter: 2080/3680
[A[ATraining Step: 66  | total loss: [1m[32m0.64758[0m[0m
[2K| Adam | epoch: 001 | loss: 0.64758 - acc: 0.7115 -- iter: 2112/3680
[A[ATraining Step: 67  | total loss: [1m[32m0.64203[0m[0m
[2K| Adam | epoch: 001 | loss: 0.64203 - acc: 0.7205 -- iter: 2144/3680
[A[ATraining Step: 68  | total loss: [1m[32m0.64316[0m[0m
[2K| Adam | epoch: 001 | loss: 0.64316 - acc: 0.7130 -- iter: 2176/3680
[A[ATraining Step: 69  | total loss: [1m[32m0.64316[0m[0m
[2K| Adam | epoch: 001 | loss: 0.64316 - acc: 0.7130 -- iter: 2208/3680
[A[ATraining Step: 70  | total loss: [1m[32m0.63727[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63727 - acc: 0.7281 -- iter: 2240/3680
[A[ATraining Step: 71  | total loss: [1m[32m0.63653[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63653 - acc: 0.7235 -- iter: 2272/3680
[A[ATraining Step: 72  | total loss: [1m[32m0.63806[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63806 - acc: 0.7124 -- iter: 2304/3680
[A[ATraining Step: 73  | total loss: [1m[32m0.63794[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63794 - acc: 0.6992 -- iter: 2336/3680
[A[ATraining Step: 74  | total loss: [1m[32m0.63504[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63504 - acc: 0.7048 -- iter: 2368/3680
[A[ATraining Step: 75  | total loss: [1m[32m0.63180[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63180 - acc: 0.7097 -- iter: 2400/3680
[A[ATraining Step: 76  | total loss: [1m[32m0.63435[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63435 - acc: 0.6939 -- iter: 2432/3680
[A[ATraining Step: 77  | total loss: [1m[32m0.63380[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63380 - acc: 0.6932 -- iter: 2464/3680
[A[ATraining Step: 78  | total loss: [1m[32m0.64018[0m[0m
[2K| Adam | epoch: 001 | loss: 0.64018 - acc: 0.6796 -- iter: 2496/3680
[A[ATraining Step: 79  | total loss: [1m[32m0.63523[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63523 - acc: 0.6836 -- iter: 2528/3680
[A[ATraining Step: 80  | total loss: [1m[32m0.62747[0m[0m
[2K| Adam | epoch: 001 | loss: 0.62747 - acc: 0.6936 -- iter: 2560/3680
[A[ATraining Step: 81  | total loss: [1m[32m0.63174[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63174 - acc: 0.6748 -- iter: 2592/3680
[A[ATraining Step: 82  | total loss: [1m[32m0.63032[0m[0m
[2K| Adam | epoch: 001 | loss: 0.63032 - acc: 0.6748 -- iter: 2624/3680
[A[ATraining Step: 83  | total loss: [1m[32m0.62643[0m[0m
[2K| Adam | epoch: 001 | loss: 0.62643 - acc: 0.6823 -- iter: 2656/3680
[A[ATraining Step: 84  | total loss: [1m[32m0.61643[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61643 - acc: 0.6922 -- iter: 2688/3680
[A[ATraining Step: 85  | total loss: [1m[32m0.61661[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61661 - acc: 0.6980 -- iter: 2720/3680
[A[ATraining Step: 86  | total loss: [1m[32m0.61504[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61504 - acc: 0.7001 -- iter: 2752/3680
[A[ATraining Step: 87  | total loss: [1m[32m0.61699[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61699 - acc: 0.6988 -- iter: 2784/3680
[A[ATraining Step: 88  | total loss: [1m[32m0.62202[0m[0m
[2K| Adam | epoch: 001 | loss: 0.62202 - acc: 0.6852 -- iter: 2816/3680
[A[ATraining Step: 89  | total loss: [1m[32m0.61980[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61980 - acc: 0.6792 -- iter: 2848/3680
[A[ATraining Step: 90  | total loss: [1m[32m0.61172[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61172 - acc: 0.6862 -- iter: 2880/3680
[A[ATraining Step: 91  | total loss: [1m[32m0.60506[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60506 - acc: 0.6926 -- iter: 2912/3680
[A[ATraining Step: 92  | total loss: [1m[32m0.59699[0m[0m
[2K| Adam | epoch: 001 | loss: 0.59699 - acc: 0.7015 -- iter: 2944/3680
[A[ATraining Step: 93  | total loss: [1m[32m0.58595[0m[0m
[2K| Adam | epoch: 001 | loss: 0.58595 - acc: 0.7095 -- iter: 2976/3680
[A[ATraining Step: 94  | total loss: [1m[32m0.58671[0m[0m
[2K| Adam | epoch: 001 | loss: 0.58671 - acc: 0.7041 -- iter: 3008/3680
[A[ATraining Step: 95  | total loss: [1m[32m0.58760[0m[0m
[2K| Adam | epoch: 001 | loss: 0.58760 - acc: 0.7087 -- iter: 3040/3680
[A[ATraining Step: 96  | total loss: [1m[32m0.58509[0m[0m
[2K| Adam | epoch: 001 | loss: 0.58509 - acc: 0.7191 -- iter: 3072/3680
[A[ATraining Step: 97  | total loss: [1m[32m0.57587[0m[0m
[2K| Adam | epoch: 001 | loss: 0.57587 - acc: 0.7316 -- iter: 3104/3680
[A[ATraining Step: 98  | total loss: [1m[32m0.58392[0m[0m
[2K| Adam | epoch: 001 | loss: 0.58392 - acc: 0.7240 -- iter: 3136/3680
[A[ATraining Step: 99  | total loss: [1m[32m0.58277[0m[0m
[2K| Adam | epoch: 001 | loss: 0.58277 - acc: 0.7235 -- iter: 3168/3680
[A[ATraining Step: 100  | total loss: [1m[32m0.57420[0m[0m
[2K| Adam | epoch: 001 | loss: 0.57420 - acc: 0.7335 | val_loss: 0.60353 - val_acc: 0.6764 -- iter: 3200/3680
[A[ATraining Step: 100  | total loss: [1m[32m0.57420[0m[0m
[2K| Adam | epoch: 001 | loss: 0.57420 - acc: 0.7335 | val_loss: 0.60353 - val_acc: 0.6764 -- iter: 3200/3680
--
Training Step: 101  | total loss: [1m[32m0.57785[0m[0m
[2K| Adam | epoch: 001 | loss: 0.57785 - acc: 0.7335 -- iter: 3232/3680
[A[ATraining Step: 102  | total loss: [1m[32m0.56996[0m[0m
[2K| Adam | epoch: 001 | loss: 0.56996 - acc: 0.7414 -- iter: 3264/3680
[A[ATraining Step: 103  | total loss: [1m[32m0.57918[0m[0m
[2K| Adam | epoch: 001 | loss: 0.57918 - acc: 0.7298 -- iter: 3296/3680
[A[ATraining Step: 104  | total loss: [1m[32m0.60418[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60418 - acc: 0.7224 -- iter: 3328/3680
[A[ATraining Step: 105  | total loss: [1m[32m0.60453[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60453 - acc: 0.7158 -- iter: 3360/3680
[A[ATraining Step: 106  | total loss: [1m[32m0.61590[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61590 - acc: 0.7036 -- iter: 3392/3680
[A[ATraining Step: 107  | total loss: [1m[32m0.60907[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60907 - acc: 0.7083 -- iter: 3424/3680
[A[ATraining Step: 108  | total loss: [1m[32m0.61254[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61254 - acc: 0.7031 -- iter: 3456/3680
[A[ATraining Step: 109  | total loss: [1m[32m0.60331[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60331 - acc: 0.7140 -- iter: 3488/3680
[A[ATraining Step: 110  | total loss: [1m[32m0.59638[0m[0m
[2K| Adam | epoch: 001 | loss: 0.59638 - acc: 0.7145 -- iter: 3520/3680
[A[ATraining Step: 111  | total loss: [1m[32m0.60413[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60413 - acc: 0.7024 -- iter: 3552/3680
[A[ATraining Step: 112  | total loss: [1m[32m0.61251[0m[0m
[2K| Adam | epoch: 001 | loss: 0.61251 - acc: 0.6978 -- iter: 3584/3680
[A[ATraining Step: 113  | total loss: [1m[32m0.59831[0m[0m
[2K| Adam | epoch: 001 | loss: 0.59831 - acc: 0.7027 -- iter: 3616/3680
[A[ATraining Step: 114  | total loss: [1m[32m0.59831[0m[0m
[2K| Adam | epoch: 001 | loss: 0.59831 - acc: 0.6981 -- iter: 3648/3680
[A[ATraining Step: 115  | total loss: [1m[32m0.60478[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60478 - acc: 0.6981 | val_loss: 0.59828 - val_acc: 0.6873 -- iter: 3680/3680
[A[ATraining Step: 115  | total loss: [1m[32m0.60478[0m[0m
[2K| Adam | epoch: 001 | loss: 0.60478 - acc: 0.6981 | val_loss: 0.59828 - val_acc: 0.6873 -- iter: 3680/3680
--
Training Step: 116  | total loss: [1m[32m0.60096[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60096 - acc: 0.7001 -- iter: 0032/3680
[A[ATraining Step: 117  | total loss: [1m[32m0.59834[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59834 - acc: 0.6989 -- iter: 0064/3680
[A[ATraining Step: 118  | total loss: [1m[32m0.60919[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60919 - acc: 0.6852 -- iter: 0096/3680
[A[ATraining Step: 119  | total loss: [1m[32m0.60298[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60298 - acc: 0.6916 -- iter: 0128/3680
[A[ATraining Step: 120  | total loss: [1m[32m0.60298[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60298 - acc: 0.6916 -- iter: 0160/3680
[A[ATraining Step: 121  | total loss: [1m[32m0.60362[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60362 - acc: 0.6818 -- iter: 0192/3680
[A[ATraining Step: 122  | total loss: [1m[32m0.59645[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59645 - acc: 0.6913 -- iter: 0224/3680
[A[ATraining Step: 123  | total loss: [1m[32m0.59359[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59359 - acc: 0.6913 -- iter: 0256/3680
[A[ATraining Step: 124  | total loss: [1m[32m0.59452[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59452 - acc: 0.6790 -- iter: 0288/3680
[A[ATraining Step: 125  | total loss: [1m[32m0.59606[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59606 - acc: 0.6790 -- iter: 0320/3680
[A[ATraining Step: 126  | total loss: [1m[32m0.59792[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59792 - acc: 0.6830 -- iter: 0352/3680
[A[ATraining Step: 127  | total loss: [1m[32m0.60221[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60221 - acc: 0.6772 -- iter: 0384/3680
[A[ATraining Step: 128  | total loss: [1m[32m0.59681[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59681 - acc: 0.6814 -- iter: 0416/3680
[A[ATraining Step: 129  | total loss: [1m[32m0.59390[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59390 - acc: 0.6882 -- iter: 0448/3680
[A[ATraining Step: 130  | total loss: [1m[32m0.59320[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59320 - acc: 0.6819 -- iter: 0480/3680
[A[ATraining Step: 131  | total loss: [1m[32m0.59403[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59403 - acc: 0.6856 -- iter: 0512/3680
[A[ATraining Step: 132  | total loss: [1m[32m0.58842[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58842 - acc: 0.6920 -- iter: 0544/3680
[A[ATraining Step: 133  | total loss: [1m[32m0.58563[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58563 - acc: 0.6978 -- iter: 0576/3680
[A[ATraining Step: 134  | total loss: [1m[32m0.58169[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58169 - acc: 0.7030 -- iter: 0608/3680
[A[ATraining Step: 135  | total loss: [1m[32m0.59172[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59172 - acc: 0.6921 -- iter: 0640/3680
[A[ATraining Step: 136  | total loss: [1m[32m0.58784[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58784 - acc: 0.7010 -- iter: 0672/3680
[A[ATraining Step: 137  | total loss: [1m[32m0.58242[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58242 - acc: 0.7028 -- iter: 0704/3680
[A[ATraining Step: 138  | total loss: [1m[32m0.58598[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58598 - acc: 0.7013 -- iter: 0736/3680
[A[ATraining Step: 139  | total loss: [1m[32m0.58060[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58060 - acc: 0.7061 -- iter: 0768/3680
[A[ATraining Step: 140  | total loss: [1m[32m0.57001[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57001 - acc: 0.7137 -- iter: 0800/3680
[A[ATraining Step: 141  | total loss: [1m[32m0.56817[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56817 - acc: 0.7204 -- iter: 0832/3680
[A[ATraining Step: 142  | total loss: [1m[32m0.56620[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56620 - acc: 0.7265 -- iter: 0864/3680
[A[ATraining Step: 143  | total loss: [1m[32m0.56788[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56788 - acc: 0.7163 -- iter: 0896/3680
[A[ATraining Step: 144  | total loss: [1m[32m0.56308[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56308 - acc: 0.7166 -- iter: 0928/3680
[A[ATraining Step: 145  | total loss: [1m[32m0.56024[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56024 - acc: 0.7137 -- iter: 0960/3680
[A[ATraining Step: 146  | total loss: [1m[32m0.56229[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56229 - acc: 0.7111 -- iter: 0992/3680
[A[ATraining Step: 147  | total loss: [1m[32m0.56640[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56640 - acc: 0.7056 -- iter: 1024/3680
[A[ATraining Step: 148  | total loss: [1m[32m0.57171[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57171 - acc: 0.7100 -- iter: 1056/3680
[A[ATraining Step: 149  | total loss: [1m[32m0.57225[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57225 - acc: 0.7140 -- iter: 1088/3680
[A[ATraining Step: 150  | total loss: [1m[32m0.56528[0m[0m
[2K| Adam | epoch: 002 | loss: 0.56528 - acc: 0.7176 -- iter: 1120/3680
[A[ATraining Step: 151  | total loss: [1m[32m0.57318[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57318 - acc: 0.7084 -- iter: 1152/3680
[A[ATraining Step: 152  | total loss: [1m[32m0.57686[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57686 - acc: 0.7031 -- iter: 1184/3680
[A[ATraining Step: 153  | total loss: [1m[32m0.57797[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57797 - acc: 0.6953 -- iter: 1216/3680
[A[ATraining Step: 154  | total loss: [1m[32m0.57523[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57523 - acc: 0.6977 -- iter: 1248/3680
[A[ATraining Step: 155  | total loss: [1m[32m0.58661[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58661 - acc: 0.6935 -- iter: 1280/3680
[A[ATraining Step: 156  | total loss: [1m[32m0.61236[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61236 - acc: 0.6804 -- iter: 1312/3680
[A[ATraining Step: 157  | total loss: [1m[32m0.60990[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60990 - acc: 0.6780 -- iter: 1344/3680
[A[ATraining Step: 158  | total loss: [1m[32m0.61401[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61401 - acc: 0.6696 -- iter: 1376/3680
[A[ATraining Step: 159  | total loss: [1m[32m0.61395[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61395 - acc: 0.6714 -- iter: 1408/3680
[A[ATraining Step: 160  | total loss: [1m[32m0.61414[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61414 - acc: 0.6699 -- iter: 1440/3680
[A[ATraining Step: 161  | total loss: [1m[32m0.61331[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61331 - acc: 0.6685 -- iter: 1472/3680
[A[ATraining Step: 162  | total loss: [1m[32m0.60581[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60581 - acc: 0.6798 -- iter: 1504/3680
[A[ATraining Step: 163  | total loss: [1m[32m0.61206[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61206 - acc: 0.6743 -- iter: 1536/3680
[A[ATraining Step: 164  | total loss: [1m[32m0.60366[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60366 - acc: 0.6819 -- iter: 1568/3680
[A[ATraining Step: 165  | total loss: [1m[32m0.59340[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59340 - acc: 0.6918 -- iter: 1600/3680
[A[ATraining Step: 166  | total loss: [1m[32m0.58855[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58855 - acc: 0.6945 -- iter: 1632/3680
[A[ATraining Step: 167  | total loss: [1m[32m0.59705[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59705 - acc: 0.6813 -- iter: 1664/3680
[A[ATraining Step: 168  | total loss: [1m[32m0.59393[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59393 - acc: 0.6913 -- iter: 1696/3680
[A[ATraining Step: 169  | total loss: [1m[32m0.59091[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59091 - acc: 0.6909 -- iter: 1728/3680
[A[ATraining Step: 170  | total loss: [1m[32m0.59303[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59303 - acc: 0.6937 -- iter: 1760/3680
[A[ATraining Step: 171  | total loss: [1m[32m0.58774[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58774 - acc: 0.6962 -- iter: 1792/3680
[A[ATraining Step: 172  | total loss: [1m[32m0.58513[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58513 - acc: 0.6985 -- iter: 1824/3680
[A[ATraining Step: 173  | total loss: [1m[32m0.58864[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58864 - acc: 0.6849 -- iter: 1856/3680
[A[ATraining Step: 174  | total loss: [1m[32m0.58828[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58828 - acc: 0.6883 -- iter: 1888/3680
[A[ATraining Step: 175  | total loss: [1m[32m0.58851[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58851 - acc: 0.6882 -- iter: 1920/3680
[A[ATraining Step: 176  | total loss: [1m[32m0.59562[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59562 - acc: 0.6819 -- iter: 1952/3680
[A[ATraining Step: 177  | total loss: [1m[32m0.59157[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59157 - acc: 0.6824 -- iter: 1984/3680
[A[ATraining Step: 178  | total loss: [1m[32m0.60161[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60161 - acc: 0.6736 -- iter: 2016/3680
[A[ATraining Step: 179  | total loss: [1m[32m0.58645[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58645 - acc: 0.6875 -- iter: 2048/3680
[A[ATraining Step: 180  | total loss: [1m[32m0.58878[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58878 - acc: 0.6843 -- iter: 2080/3680
[A[ATraining Step: 181  | total loss: [1m[32m0.58289[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58289 - acc: 0.6909 -- iter: 2112/3680
[A[ATraining Step: 182  | total loss: [1m[32m0.57793[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57793 - acc: 0.6968 -- iter: 2144/3680
[A[ATraining Step: 183  | total loss: [1m[32m0.58402[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58402 - acc: 0.6928 -- iter: 2176/3680
[A[ATraining Step: 184  | total loss: [1m[32m0.59613[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59613 - acc: 0.6860 -- iter: 2208/3680
[A[ATraining Step: 185  | total loss: [1m[32m0.58877[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58877 - acc: 0.6924 -- iter: 2240/3680
[A[ATraining Step: 186  | total loss: [1m[32m0.59664[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59664 - acc: 0.6919 -- iter: 2272/3680
[A[ATraining Step: 187  | total loss: [1m[32m0.58837[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58837 - acc: 0.7040 -- iter: 2304/3680
[A[ATraining Step: 188  | total loss: [1m[32m0.59545[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59545 - acc: 0.6930 -- iter: 2336/3680
[A[ATraining Step: 189  | total loss: [1m[32m0.59170[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59170 - acc: 0.6930 -- iter: 2368/3680
[A[ATraining Step: 190  | total loss: [1m[32m0.58856[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58856 - acc: 0.6893 -- iter: 2400/3680
[A[ATraining Step: 191  | total loss: [1m[32m0.58071[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58071 - acc: 0.6923 -- iter: 2432/3680
[A[ATraining Step: 192  | total loss: [1m[32m0.57510[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57510 - acc: 0.6918 -- iter: 2464/3680
[A[ATraining Step: 193  | total loss: [1m[32m0.57241[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57241 - acc: 0.7039 -- iter: 2496/3680
[A[ATraining Step: 194  | total loss: [1m[32m0.57493[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57493 - acc: 0.6929 -- iter: 2528/3680
[A[ATraining Step: 195  | total loss: [1m[32m0.58515[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58515 - acc: 0.6736 -- iter: 2560/3680
[A[ATraining Step: 196  | total loss: [1m[32m0.59110[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59110 - acc: 0.6843 -- iter: 2592/3680
[A[ATraining Step: 197  | total loss: [1m[32m0.59045[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59045 - acc: 0.6972 -- iter: 2624/3680
[A[ATraining Step: 198  | total loss: [1m[32m0.58580[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58580 - acc: 0.7024 -- iter: 2656/3680
[A[ATraining Step: 199  | total loss: [1m[32m0.57635[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57635 - acc: 0.7072 -- iter: 2688/3680
[A[ATraining Step: 200  | total loss: [1m[32m0.60336[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60336 - acc: 0.6800 | val_loss: 0.57746 - val_acc: 0.6938 -- iter: 2720/3680
[A[ATraining Step: 200  | total loss: [1m[32m0.60336[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60336 - acc: 0.6800 | val_loss: 0.57746 - val_acc: 0.6938 -- iter: 2720/3680
--
Training Step: 201  | total loss: [1m[32m0.60336[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60336 - acc: 0.6800 -- iter: 2752/3680
[A[ATraining Step: 202  | total loss: [1m[32m0.59007[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59007 - acc: 0.7080 -- iter: 2784/3680
[A[ATraining Step: 203  | total loss: [1m[32m0.57547[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57547 - acc: 0.7080 -- iter: 2816/3680
[A[ATraining Step: 204  | total loss: [1m[32m0.57823[0m[0m
[2K| Adam | epoch: 002 | loss: 0.57823 - acc: 0.6997 -- iter: 2848/3680
[A[ATraining Step: 205  | total loss: [1m[32m0.59622[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59622 - acc: 0.6922 -- iter: 2880/3680
[A[ATraining Step: 206  | total loss: [1m[32m0.59554[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59554 - acc: 0.6918 -- iter: 2912/3680
[A[ATraining Step: 207  | total loss: [1m[32m0.58453[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58453 - acc: 0.7038 -- iter: 2944/3680
[A[ATraining Step: 208  | total loss: [1m[32m0.58991[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58991 - acc: 0.6826 -- iter: 2976/3680
[A[ATraining Step: 209  | total loss: [1m[32m0.58991[0m[0m
[2K| Adam | epoch: 002 | loss: 0.58991 - acc: 0.6831 -- iter: 3008/3680
[A[ATraining Step: 210  | total loss: [1m[32m0.59304[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59304 - acc: 0.6831 -- iter: 3040/3680
[A[ATraining Step: 211  | total loss: [1m[32m0.59350[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59350 - acc: 0.6804 -- iter: 3072/3680
[A[ATraining Step: 212  | total loss: [1m[32m0.59865[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59865 - acc: 0.6717 -- iter: 3104/3680
[A[ATraining Step: 213  | total loss: [1m[32m0.59898[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59898 - acc: 0.6733 -- iter: 3136/3680
[A[ATraining Step: 214  | total loss: [1m[32m0.60689[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60689 - acc: 0.6670 -- iter: 3168/3680
[A[ATraining Step: 215  | total loss: [1m[32m0.60689[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60689 - acc: 0.6670 -- iter: 3200/3680
[A[ATraining Step: 216  | total loss: [1m[32m0.60652[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60652 - acc: 0.6628 -- iter: 3232/3680
[A[ATraining Step: 217  | total loss: [1m[32m0.60860[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60860 - acc: 0.6590 -- iter: 3264/3680
[A[ATraining Step: 218  | total loss: [1m[32m0.62363[0m[0m
[2K| Adam | epoch: 002 | loss: 0.62363 - acc: 0.6556 -- iter: 3296/3680
[A[ATraining Step: 219  | total loss: [1m[32m0.61028[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61028 - acc: 0.6650 -- iter: 3328/3680
[A[ATraining Step: 220  | total loss: [1m[32m0.61346[0m[0m
[2K| Adam | epoch: 002 | loss: 0.61346 - acc: 0.6641 -- iter: 3360/3680
[A[ATraining Step: 221  | total loss: [1m[32m0.60718[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60718 - acc: 0.6696 -- iter: 3392/3680
[A[ATraining Step: 222  | total loss: [1m[32m0.60381[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60381 - acc: 0.6776 -- iter: 3424/3680
[A[ATraining Step: 223  | total loss: [1m[32m0.60497[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60497 - acc: 0.6849 -- iter: 3456/3680
[A[ATraining Step: 224  | total loss: [1m[32m0.59753[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59753 - acc: 0.6914 -- iter: 3488/3680
[A[ATraining Step: 225  | total loss: [1m[32m0.59591[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59591 - acc: 0.6973 -- iter: 3520/3680
[A[ATraining Step: 226  | total loss: [1m[32m0.59162[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59162 - acc: 0.7025 -- iter: 3552/3680
[A[ATraining Step: 227  | total loss: [1m[32m0.59894[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59894 - acc: 0.6948 -- iter: 3584/3680
[A[ATraining Step: 228  | total loss: [1m[32m0.59400[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59400 - acc: 0.7003 -- iter: 3616/3680
[A[ATraining Step: 229  | total loss: [1m[32m0.60190[0m[0m
[2K| Adam | epoch: 002 | loss: 0.60190 - acc: 0.6896 -- iter: 3648/3680
[A[ATraining Step: 230  | total loss: [1m[32m0.59643[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59643 - acc: 0.6914 | val_loss: 0.57554 - val_acc: 0.6949 -- iter: 3680/3680
[A[ATraining Step: 230  | total loss: [1m[32m0.59643[0m[0m
[2K| Adam | epoch: 002 | loss: 0.59643 - acc: 0.6914 | val_loss: 0.57554 - val_acc: 0.6949 -- iter: 3680/3680
--
Training Step: 231  | total loss: [1m[32m0.59643[0m[0m
[2K| Adam | epoch: 003 | loss: 0.59643 - acc: 0.6914 -- iter: 0032/3680
[A[ATraining Step: 232  | total loss: [1m[32m0.60135[0m[0m
[2K| Adam | epoch: 003 | loss: 0.60135 - acc: 0.6848 -- iter: 0064/3680
[A[ATraining Step: 233  | total loss: [1m[32m0.60556[0m[0m
[2K| Adam | epoch: 003 | loss: 0.60556 - acc: 0.6757 -- iter: 0096/3680
[A[ATraining Step: 234  | total loss: [1m[32m0.60161[0m[0m
[2K| Adam | epoch: 003 | loss: 0.60161 - acc: 0.6769 -- iter: 0128/3680
[A[ATraining Step: 235  | total loss: [1m[32m0.59722[0m[0m
[2K| Adam | epoch: 003 | loss: 0.59722 - acc: 0.6842 -- iter: 0160/3680
[A[ATraining Step: 236  | total loss: [1m[32m0.59681[0m[0m
[2K| Adam | epoch: 003 | loss: 0.59681 - acc: 0.6845 -- iter: 0192/3680
[A[ATraining Step: 237  | total loss: [1m[32m0.59029[0m[0m
[2K| Adam | epoch: 003 | loss: 0.59029 - acc: 0.6879 -- iter: 0224/3680
[A[ATraining Step: 238  | total loss: [1m[32m0.59438[0m[0m
[2K| Adam | epoch: 003 | loss: 0.59438 - acc: 0.6910 -- iter: 0256/3680
[A[ATraining Step: 239  | total loss: [1m[32m0.59075[0m[0m
[2K| Adam | epoch: 003 | loss: 0.59075 - acc: 0.7094 -- iter: 0288/3680
[A[ATraining Step: 240  | total loss: [1m[32m0.57218[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57218 - acc: 0.7134 -- iter: 0320/3680
[A[ATraining Step: 241  | total loss: [1m[32m0.57218[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57218 - acc: 0.7134 -- iter: 0352/3680
[A[ATraining Step: 242  | total loss: [1m[32m0.56375[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56375 - acc: 0.7201 -- iter: 0384/3680
[A[ATraining Step: 243  | total loss: [1m[32m0.56382[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56382 - acc: 0.7201 -- iter: 0416/3680
[A[ATraining Step: 244  | total loss: [1m[32m0.56360[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56360 - acc: 0.7199 -- iter: 0448/3680
[A[ATraining Step: 245  | total loss: [1m[32m0.56304[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56304 - acc: 0.7198 -- iter: 0480/3680
[A[ATraining Step: 246  | total loss: [1m[32m0.56879[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56879 - acc: 0.7135 -- iter: 0512/3680
[A[ATraining Step: 247  | total loss: [1m[32m0.57263[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57263 - acc: 0.7077 -- iter: 0544/3680
[A[ATraining Step: 248  | total loss: [1m[32m0.57374[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57374 - acc: 0.7088 -- iter: 0576/3680
[A[ATraining Step: 249  | total loss: [1m[32m0.57312[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57312 - acc: 0.7098 -- iter: 0608/3680
[A[ATraining Step: 250  | total loss: [1m[32m0.56702[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56702 - acc: 0.7107 -- iter: 0640/3680
[A[ATraining Step: 251  | total loss: [1m[32m0.56723[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56723 - acc: 0.7178 -- iter: 0672/3680
[A[ATraining Step: 252  | total loss: [1m[32m0.56620[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56620 - acc: 0.7180 -- iter: 0704/3680
[A[ATraining Step: 253  | total loss: [1m[32m0.56620[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56620 - acc: 0.7180 -- iter: 0736/3680
[A[ATraining Step: 254  | total loss: [1m[32m0.56425[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56425 - acc: 0.7243 -- iter: 0768/3680
[A[ATraining Step: 255  | total loss: [1m[32m0.56254[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56254 - acc: 0.7237 -- iter: 0800/3680
[A[ATraining Step: 256  | total loss: [1m[32m0.56346[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56346 - acc: 0.7137 -- iter: 0832/3680
[A[ATraining Step: 257  | total loss: [1m[32m0.56346[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56346 - acc: 0.7137 -- iter: 0864/3680
[A[ATraining Step: 258  | total loss: [1m[32m0.54888[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54888 - acc: 0.7267 -- iter: 0896/3680
[A[ATraining Step: 259  | total loss: [1m[32m0.54579[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54579 - acc: 0.7322 -- iter: 0928/3680
[A[ATraining Step: 260  | total loss: [1m[32m0.54024[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54024 - acc: 0.7402 -- iter: 0960/3680
[A[ATraining Step: 261  | total loss: [1m[32m0.53792[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53792 - acc: 0.7412 -- iter: 0992/3680
[A[ATraining Step: 262  | total loss: [1m[32m0.53743[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53743 - acc: 0.7421 -- iter: 1024/3680
[A[ATraining Step: 263  | total loss: [1m[32m0.54005[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54005 - acc: 0.7397 -- iter: 1056/3680
[A[ATraining Step: 264  | total loss: [1m[32m0.54866[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54866 - acc: 0.7298 -- iter: 1088/3680
[A[ATraining Step: 265  | total loss: [1m[32m0.55154[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55154 - acc: 0.7298 -- iter: 1120/3680
[A[ATraining Step: 266  | total loss: [1m[32m0.54951[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54951 - acc: 0.7287 -- iter: 1152/3680
[A[ATraining Step: 267  | total loss: [1m[32m0.55188[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55188 - acc: 0.7371 -- iter: 1184/3680
[A[ATraining Step: 268  | total loss: [1m[32m0.55115[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55115 - acc: 0.7452 -- iter: 1216/3680
[A[ATraining Step: 269  | total loss: [1m[32m0.54484[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54484 - acc: 0.7452 -- iter: 1248/3680
[A[ATraining Step: 270  | total loss: [1m[32m0.54432[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54432 - acc: 0.7425 -- iter: 1280/3680
[A[ATraining Step: 271  | total loss: [1m[32m0.54899[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54899 - acc: 0.7339 -- iter: 1312/3680
[A[ATraining Step: 272  | total loss: [1m[32m0.55837[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55837 - acc: 0.7324 -- iter: 1344/3680
[A[ATraining Step: 273  | total loss: [1m[32m0.56507[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56507 - acc: 0.7216 -- iter: 1376/3680
[A[ATraining Step: 274  | total loss: [1m[32m0.55845[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55845 - acc: 0.7214 -- iter: 1408/3680
[A[ATraining Step: 275  | total loss: [1m[32m0.55549[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55549 - acc: 0.7180 -- iter: 1440/3680
[A[ATraining Step: 276  | total loss: [1m[32m0.54965[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54965 - acc: 0.7266 -- iter: 1472/3680
[A[ATraining Step: 277  | total loss: [1m[32m0.56279[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56279 - acc: 0.7266 -- iter: 1504/3680
[A[ATraining Step: 278  | total loss: [1m[32m0.56641[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56641 - acc: 0.7226 -- iter: 1536/3680
[A[ATraining Step: 279  | total loss: [1m[32m0.57409[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57409 - acc: 0.7066 -- iter: 1568/3680
[A[ATraining Step: 280  | total loss: [1m[32m0.57713[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57713 - acc: 0.6985 -- iter: 1600/3680
[A[ATraining Step: 281  | total loss: [1m[32m0.57325[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57325 - acc: 0.7058 -- iter: 1632/3680
[A[ATraining Step: 282  | total loss: [1m[32m0.57325[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57325 - acc: 0.7058 -- iter: 1664/3680
[A[ATraining Step: 283  | total loss: [1m[32m0.56614[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56614 - acc: 0.7133 -- iter: 1696/3680
[A[ATraining Step: 284  | total loss: [1m[32m0.56914[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56914 - acc: 0.7076 -- iter: 1728/3680
[A[ATraining Step: 285  | total loss: [1m[32m0.56513[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56513 - acc: 0.7087 -- iter: 1760/3680
[A[ATraining Step: 286  | total loss: [1m[32m0.56957[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56957 - acc: 0.7035 -- iter: 1792/3680
[A[ATraining Step: 287  | total loss: [1m[32m0.55644[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55644 - acc: 0.7112 -- iter: 1824/3680
[A[ATraining Step: 288  | total loss: [1m[32m0.54892[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54892 - acc: 0.7182 -- iter: 1856/3680
[A[ATraining Step: 289  | total loss: [1m[32m0.54878[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54878 - acc: 0.7183 -- iter: 1888/3680
[A[ATraining Step: 290  | total loss: [1m[32m0.55189[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55189 - acc: 0.7090 -- iter: 1920/3680
[A[ATraining Step: 291  | total loss: [1m[32m0.55245[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55245 - acc: 0.7131 -- iter: 1952/3680
[A[ATraining Step: 292  | total loss: [1m[32m0.54942[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54942 - acc: 0.7230 -- iter: 1984/3680
[A[ATraining Step: 293  | total loss: [1m[32m0.55715[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55715 - acc: 0.7132 -- iter: 2016/3680
[A[ATraining Step: 294  | total loss: [1m[32m0.54724[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54724 - acc: 0.7200 -- iter: 2048/3680
[A[ATraining Step: 295  | total loss: [1m[32m0.54038[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54038 - acc: 0.7293 -- iter: 2080/3680
[A[ATraining Step: 296  | total loss: [1m[32m0.53069[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53069 - acc: 0.7313 -- iter: 2112/3680
[A[ATraining Step: 297  | total loss: [1m[32m0.52940[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52940 - acc: 0.7301 -- iter: 2144/3680
[A[ATraining Step: 298  | total loss: [1m[32m0.52226[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52226 - acc: 0.7352 -- iter: 2176/3680
[A[ATraining Step: 299  | total loss: [1m[32m0.52596[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52596 - acc: 0.7336 -- iter: 2208/3680
[A[ATraining Step: 300  | total loss: [1m[32m0.52236[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52236 - acc: 0.7414 | val_loss: 0.56139 - val_acc: 0.7047 -- iter: 2240/3680
[A[ATraining Step: 300  | total loss: [1m[32m0.52236[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52236 - acc: 0.7414 | val_loss: 0.56139 - val_acc: 0.7047 -- iter: 2240/3680
--
Training Step: 301  | total loss: [1m[32m0.53285[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53285 - acc: 0.7315 -- iter: 2272/3680
[A[ATraining Step: 302  | total loss: [1m[32m0.53330[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53330 - acc: 0.7315 -- iter: 2304/3680
[A[ATraining Step: 303  | total loss: [1m[32m0.53126[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53126 - acc: 0.7302 -- iter: 2336/3680
[A[ATraining Step: 304  | total loss: [1m[32m0.55078[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55078 - acc: 0.7041 -- iter: 2368/3680
[A[ATraining Step: 305  | total loss: [1m[32m0.55412[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55412 - acc: 0.7024 -- iter: 2400/3680
[A[ATraining Step: 306  | total loss: [1m[32m0.55168[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55168 - acc: 0.7072 -- iter: 2432/3680
[A[ATraining Step: 307  | total loss: [1m[32m0.54161[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54161 - acc: 0.7278 -- iter: 2464/3680
[A[ATraining Step: 308  | total loss: [1m[32m0.52621[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52621 - acc: 0.7278 -- iter: 2496/3680
[A[ATraining Step: 309  | total loss: [1m[32m0.51436[0m[0m
[2K| Adam | epoch: 003 | loss: 0.51436 - acc: 0.7425 -- iter: 2528/3680
[A[ATraining Step: 310  | total loss: [1m[32m0.52098[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52098 - acc: 0.7433 -- iter: 2560/3680
[A[ATraining Step: 311  | total loss: [1m[32m0.53081[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53081 - acc: 0.7346 -- iter: 2592/3680
[A[ATraining Step: 312  | total loss: [1m[32m0.53776[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53776 - acc: 0.7236 -- iter: 2624/3680
[A[ATraining Step: 313  | total loss: [1m[32m0.52775[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52775 - acc: 0.7356 -- iter: 2656/3680
[A[ATraining Step: 314  | total loss: [1m[32m0.53689[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53689 - acc: 0.7246 -- iter: 2688/3680
[A[ATraining Step: 315  | total loss: [1m[32m0.52392[0m[0m
[2K| Adam | epoch: 003 | loss: 0.52392 - acc: 0.7302 -- iter: 2720/3680
[A[ATraining Step: 316  | total loss: [1m[32m0.55887[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55887 - acc: 0.7135 -- iter: 2752/3680
[A[ATraining Step: 317  | total loss: [1m[32m0.55999[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55999 - acc: 0.7109 -- iter: 2784/3680
[A[ATraining Step: 318  | total loss: [1m[32m0.55683[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55683 - acc: 0.7149 -- iter: 2816/3680
[A[ATraining Step: 319  | total loss: [1m[32m0.55683[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55683 - acc: 0.7149 -- iter: 2848/3680
[A[ATraining Step: 320  | total loss: [1m[32m0.55828[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55828 - acc: 0.7222 -- iter: 2880/3680
[A[ATraining Step: 321  | total loss: [1m[32m0.55296[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55296 - acc: 0.7222 -- iter: 2912/3680
[A[ATraining Step: 322  | total loss: [1m[32m0.55310[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55310 - acc: 0.7218 -- iter: 2944/3680
[A[ATraining Step: 323  | total loss: [1m[32m0.54876[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54876 - acc: 0.7215 -- iter: 2976/3680
[A[ATraining Step: 324  | total loss: [1m[32m0.54723[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54723 - acc: 0.7244 -- iter: 3008/3680
[A[ATraining Step: 325  | total loss: [1m[32m0.54614[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54614 - acc: 0.7176 -- iter: 3040/3680
[A[ATraining Step: 326  | total loss: [1m[32m0.54563[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54563 - acc: 0.7145 -- iter: 3072/3680
[A[ATraining Step: 327  | total loss: [1m[32m0.55442[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55442 - acc: 0.7056 -- iter: 3104/3680
[A[ATraining Step: 328  | total loss: [1m[32m0.55925[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55925 - acc: 0.6944 -- iter: 3136/3680
[A[ATraining Step: 329  | total loss: [1m[32m0.56210[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56210 - acc: 0.6937 -- iter: 3168/3680
[A[ATraining Step: 330  | total loss: [1m[32m0.57058[0m[0m
[2K| Adam | epoch: 003 | loss: 0.57058 - acc: 0.6837 -- iter: 3200/3680
[A[ATraining Step: 331  | total loss: [1m[32m0.56179[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56179 - acc: 0.7051 -- iter: 3232/3680
[A[ATraining Step: 332  | total loss: [1m[32m0.56417[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56417 - acc: 0.7051 -- iter: 3264/3680
[A[ATraining Step: 333  | total loss: [1m[32m0.55457[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55457 - acc: 0.7158 -- iter: 3296/3680
[A[ATraining Step: 334  | total loss: [1m[32m0.56651[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56651 - acc: 0.7036 -- iter: 3328/3680
[A[ATraining Step: 335  | total loss: [1m[32m0.56192[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56192 - acc: 0.7082 -- iter: 3360/3680
[A[ATraining Step: 336  | total loss: [1m[32m0.56343[0m[0m
[2K| Adam | epoch: 003 | loss: 0.56343 - acc: 0.6999 -- iter: 3392/3680
[A[ATraining Step: 337  | total loss: [1m[32m0.55596[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55596 - acc: 0.7018 -- iter: 3424/3680
[A[ATraining Step: 338  | total loss: [1m[32m0.55910[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55910 - acc: 0.6941 -- iter: 3456/3680
[A[ATraining Step: 339  | total loss: [1m[32m0.55588[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55588 - acc: 0.6935 -- iter: 3488/3680
[A[ATraining Step: 340  | total loss: [1m[32m0.55346[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55346 - acc: 0.6991 -- iter: 3520/3680
[A[ATraining Step: 341  | total loss: [1m[32m0.54619[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54619 - acc: 0.7042 -- iter: 3552/3680
[A[ATraining Step: 342  | total loss: [1m[32m0.55208[0m[0m
[2K| Adam | epoch: 003 | loss: 0.55208 - acc: 0.7025 -- iter: 3584/3680
[A[ATraining Step: 343  | total loss: [1m[32m0.54281[0m[0m
[2K| Adam | epoch: 003 | loss: 0.54281 - acc: 0.7104 -- iter: 3616/3680
[A[ATraining Step: 344  | total loss: [1m[32m0.53429[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53429 - acc: 0.7204 -- iter: 3648/3680
[A[ATraining Step: 345  | total loss: [1m[32m0.53497[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53497 - acc: 0.7204 | val_loss: 0.55299 - val_acc: 0.7025 -- iter: 3680/3680
[A[ATraining Step: 345  | total loss: [1m[32m0.53497[0m[0m
[2K| Adam | epoch: 003 | loss: 0.53497 - acc: 0.7204 | val_loss: 0.55299 - val_acc: 0.7025 -- iter: 3680/3680
--
Training Step: 346  | total loss: [1m[32m0.53404[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53404 - acc: 0.7203 -- iter: 0032/3680
[A[ATraining Step: 347  | total loss: [1m[32m0.52623[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52623 - acc: 0.7326 -- iter: 0064/3680
[A[ATraining Step: 348  | total loss: [1m[32m0.54078[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54078 - acc: 0.7281 -- iter: 0096/3680
[A[ATraining Step: 349  | total loss: [1m[32m0.55360[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55360 - acc: 0.7240 -- iter: 0128/3680
[A[ATraining Step: 350  | total loss: [1m[32m0.55207[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55207 - acc: 0.7235 -- iter: 0160/3680
[A[ATraining Step: 351  | total loss: [1m[32m0.54503[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54503 - acc: 0.7262 -- iter: 0192/3680
[A[ATraining Step: 352  | total loss: [1m[32m0.55134[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55134 - acc: 0.7192 -- iter: 0224/3680
[A[ATraining Step: 353  | total loss: [1m[32m0.54851[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54851 - acc: 0.7160 -- iter: 0256/3680
[A[ATraining Step: 354  | total loss: [1m[32m0.53866[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53866 - acc: 0.7257 -- iter: 0288/3680
[A[ATraining Step: 355  | total loss: [1m[32m0.54011[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54011 - acc: 0.7218 -- iter: 0320/3680
[A[ATraining Step: 356  | total loss: [1m[32m0.53241[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53241 - acc: 0.7247 -- iter: 0352/3680
[A[ATraining Step: 357  | total loss: [1m[32m0.52898[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52898 - acc: 0.7334 -- iter: 0384/3680
[A[ATraining Step: 358  | total loss: [1m[32m0.53292[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53292 - acc: 0.7247 -- iter: 0416/3680
[A[ATraining Step: 359  | total loss: [1m[32m0.53368[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53368 - acc: 0.7241 -- iter: 0448/3680
[A[ATraining Step: 360  | total loss: [1m[32m0.53368[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53368 - acc: 0.7241 -- iter: 0480/3680
[A[ATraining Step: 361  | total loss: [1m[32m0.52456[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52456 - acc: 0.7236 -- iter: 0512/3680
[A[ATraining Step: 362  | total loss: [1m[32m0.52200[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52200 - acc: 0.7262 -- iter: 0544/3680
[A[ATraining Step: 363  | total loss: [1m[32m0.52273[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52273 - acc: 0.7255 -- iter: 0576/3680
[A[ATraining Step: 364  | total loss: [1m[32m0.52539[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52539 - acc: 0.7236 -- iter: 0608/3680
[A[ATraining Step: 365  | total loss: [1m[32m0.52539[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52539 - acc: 0.7236 -- iter: 0640/3680
[A[ATraining Step: 366  | total loss: [1m[32m0.52278[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52278 - acc: 0.7293 -- iter: 0672/3680
[A[ATraining Step: 367  | total loss: [1m[32m0.53268[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53268 - acc: 0.7158 -- iter: 0704/3680
[A[ATraining Step: 368  | total loss: [1m[32m0.53540[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53540 - acc: 0.7005 -- iter: 0736/3680
[A[ATraining Step: 369  | total loss: [1m[32m0.52923[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52923 - acc: 0.7085 -- iter: 0768/3680
[A[ATraining Step: 370  | total loss: [1m[32m0.52948[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52948 - acc: 0.7096 -- iter: 0800/3680
[A[ATraining Step: 371  | total loss: [1m[32m0.52333[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52333 - acc: 0.7230 -- iter: 0832/3680
[A[ATraining Step: 372  | total loss: [1m[32m0.53910[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53910 - acc: 0.7038 -- iter: 0864/3680
[A[ATraining Step: 373  | total loss: [1m[32m0.53629[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53629 - acc: 0.7115 -- iter: 0896/3680
[A[ATraining Step: 374  | total loss: [1m[32m0.55189[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55189 - acc: 0.6966 -- iter: 0928/3680
[A[ATraining Step: 375  | total loss: [1m[32m0.55319[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55319 - acc: 0.6926 -- iter: 0960/3680
[A[ATraining Step: 376  | total loss: [1m[32m0.54698[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54698 - acc: 0.6952 -- iter: 0992/3680
[A[ATraining Step: 377  | total loss: [1m[32m0.54006[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54006 - acc: 0.7038 -- iter: 1024/3680
[A[ATraining Step: 378  | total loss: [1m[32m0.53700[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53700 - acc: 0.7116 -- iter: 1056/3680
[A[ATraining Step: 379  | total loss: [1m[32m0.53243[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53243 - acc: 0.7279 -- iter: 1088/3680
[A[ATraining Step: 380  | total loss: [1m[32m0.53637[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53637 - acc: 0.7301 -- iter: 1120/3680
[A[ATraining Step: 381  | total loss: [1m[32m0.52361[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52361 - acc: 0.7384 -- iter: 1152/3680
[A[ATraining Step: 382  | total loss: [1m[32m0.53704[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53704 - acc: 0.7208 -- iter: 1184/3680
[A[ATraining Step: 383  | total loss: [1m[32m0.53360[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53360 - acc: 0.7206 -- iter: 1216/3680
[A[ATraining Step: 384  | total loss: [1m[32m0.53065[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53065 - acc: 0.7266 -- iter: 1248/3680
[A[ATraining Step: 385  | total loss: [1m[32m0.53637[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53637 - acc: 0.7227 -- iter: 1280/3680
[A[ATraining Step: 386  | total loss: [1m[32m0.55392[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55392 - acc: 0.7129 -- iter: 1312/3680
[A[ATraining Step: 387  | total loss: [1m[32m0.54441[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54441 - acc: 0.7198 -- iter: 1344/3680
[A[ATraining Step: 388  | total loss: [1m[32m0.55878[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55878 - acc: 0.7041 -- iter: 1376/3680
[A[ATraining Step: 389  | total loss: [1m[32m0.55013[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55013 - acc: 0.7055 -- iter: 1408/3680
[A[ATraining Step: 390  | total loss: [1m[32m0.56805[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56805 - acc: 0.6787 -- iter: 1440/3680
[A[ATraining Step: 391  | total loss: [1m[32m0.57148[0m[0m
[2K| Adam | epoch: 004 | loss: 0.57148 - acc: 0.6796 -- iter: 1472/3680
[A[ATraining Step: 392  | total loss: [1m[32m0.56131[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56131 - acc: 0.6929 -- iter: 1504/3680
[A[ATraining Step: 393  | total loss: [1m[32m0.55060[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55060 - acc: 0.7017 -- iter: 1536/3680
[A[ATraining Step: 394  | total loss: [1m[32m0.54703[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54703 - acc: 0.7128 -- iter: 1568/3680
[A[ATraining Step: 395  | total loss: [1m[32m0.55416[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55416 - acc: 0.7103 -- iter: 1600/3680
[A[ATraining Step: 396  | total loss: [1m[32m0.55039[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55039 - acc: 0.7111 -- iter: 1632/3680
[A[ATraining Step: 397  | total loss: [1m[32m0.55333[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55333 - acc: 0.7150 -- iter: 1664/3680
[A[ATraining Step: 398  | total loss: [1m[32m0.55174[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55174 - acc: 0.7088 -- iter: 1696/3680
[A[ATraining Step: 399  | total loss: [1m[32m0.55483[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55483 - acc: 0.7088 -- iter: 1728/3680
[A[ATraining Step: 400  | total loss: [1m[32m0.55169[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55169 - acc: 0.7161 | val_loss: 0.54352 - val_acc: 0.7058 -- iter: 1760/3680
[A[ATraining Step: 400  | total loss: [1m[32m0.55169[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55169 - acc: 0.7161 | val_loss: 0.54352 - val_acc: 0.7058 -- iter: 1760/3680
--
Training Step: 401  | total loss: [1m[32m0.55729[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55729 - acc: 0.7013 -- iter: 1792/3680
[A[ATraining Step: 402  | total loss: [1m[32m0.55729[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55729 - acc: 0.7013 -- iter: 1824/3680
[A[ATraining Step: 403  | total loss: [1m[32m0.56077[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56077 - acc: 0.6893 -- iter: 1856/3680
[A[ATraining Step: 404  | total loss: [1m[32m0.57720[0m[0m
[2K| Adam | epoch: 004 | loss: 0.57720 - acc: 0.6893 -- iter: 1888/3680
[A[ATraining Step: 405  | total loss: [1m[32m0.58235[0m[0m
[2K| Adam | epoch: 004 | loss: 0.58235 - acc: 0.6954 -- iter: 1920/3680
[A[ATraining Step: 406  | total loss: [1m[32m0.58463[0m[0m
[2K| Adam | epoch: 004 | loss: 0.58463 - acc: 0.6946 -- iter: 1952/3680
[A[ATraining Step: 407  | total loss: [1m[32m0.56896[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56896 - acc: 0.7095 -- iter: 1984/3680
[A[ATraining Step: 408  | total loss: [1m[32m0.55742[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55742 - acc: 0.7198 -- iter: 2016/3680
[A[ATraining Step: 409  | total loss: [1m[32m0.55879[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55879 - acc: 0.7228 -- iter: 2048/3680
[A[ATraining Step: 410  | total loss: [1m[32m0.56335[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56335 - acc: 0.7130 -- iter: 2080/3680
[A[ATraining Step: 411  | total loss: [1m[32m0.55910[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55910 - acc: 0.7105 -- iter: 2112/3680
[A[ATraining Step: 412  | total loss: [1m[32m0.56919[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56919 - acc: 0.7019 -- iter: 2144/3680
[A[ATraining Step: 413  | total loss: [1m[32m0.56331[0m[0m
[2K| Adam | epoch: 004 | loss: 0.56331 - acc: 0.7067 -- iter: 2176/3680
[A[ATraining Step: 414  | total loss: [1m[32m0.55677[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55677 - acc: 0.7236 -- iter: 2208/3680
[A[ATraining Step: 415  | total loss: [1m[32m0.55526[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55526 - acc: 0.7286 -- iter: 2240/3680
[A[ATraining Step: 416  | total loss: [1m[32m0.55475[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55475 - acc: 0.7286 -- iter: 2272/3680
[A[ATraining Step: 417  | total loss: [1m[32m0.54955[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54955 - acc: 0.7307 -- iter: 2304/3680
[A[ATraining Step: 418  | total loss: [1m[32m0.55586[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55586 - acc: 0.7264 -- iter: 2336/3680
[A[ATraining Step: 419  | total loss: [1m[32m0.55645[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55645 - acc: 0.7288 -- iter: 2368/3680
[A[ATraining Step: 420  | total loss: [1m[32m0.54863[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54863 - acc: 0.7309 -- iter: 2400/3680
[A[ATraining Step: 421  | total loss: [1m[32m0.54997[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54997 - acc: 0.7172 -- iter: 2432/3680
[A[ATraining Step: 422  | total loss: [1m[32m0.55437[0m[0m
[2K| Adam | epoch: 004 | loss: 0.55437 - acc: 0.7173 -- iter: 2464/3680
[A[ATraining Step: 423  | total loss: [1m[32m0.54773[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54773 - acc: 0.7175 -- iter: 2496/3680
[A[ATraining Step: 424  | total loss: [1m[32m0.53516[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53516 - acc: 0.7301 -- iter: 2528/3680
[A[ATraining Step: 425  | total loss: [1m[32m0.52537[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52537 - acc: 0.7352 -- iter: 2560/3680
[A[ATraining Step: 426  | total loss: [1m[32m0.52301[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52301 - acc: 0.7429 -- iter: 2592/3680
[A[ATraining Step: 427  | total loss: [1m[32m0.53027[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53027 - acc: 0.7515 -- iter: 2624/3680
[A[ATraining Step: 428  | total loss: [1m[32m0.51781[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51781 - acc: 0.7515 -- iter: 2656/3680
[A[ATraining Step: 429  | total loss: [1m[32m0.51320[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51320 - acc: 0.7545 -- iter: 2688/3680
[A[ATraining Step: 430  | total loss: [1m[32m0.51660[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51660 - acc: 0.7603 -- iter: 2720/3680
[A[ATraining Step: 431  | total loss: [1m[32m0.52525[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52525 - acc: 0.7499 -- iter: 2752/3680
[A[ATraining Step: 432  | total loss: [1m[32m0.54595[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54595 - acc: 0.7405 -- iter: 2784/3680
[A[ATraining Step: 433  | total loss: [1m[32m0.54930[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54930 - acc: 0.7383 -- iter: 2816/3680
[A[ATraining Step: 434  | total loss: [1m[32m0.54574[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54574 - acc: 0.7437 -- iter: 2848/3680
[A[ATraining Step: 435  | total loss: [1m[32m0.53712[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53712 - acc: 0.7437 -- iter: 2880/3680
[A[ATraining Step: 436  | total loss: [1m[32m0.53074[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53074 - acc: 0.7443 -- iter: 2912/3680
[A[ATraining Step: 437  | total loss: [1m[32m0.53208[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53208 - acc: 0.7449 -- iter: 2944/3680
[A[ATraining Step: 438  | total loss: [1m[32m0.53227[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53227 - acc: 0.7391 -- iter: 2976/3680
[A[ATraining Step: 439  | total loss: [1m[32m0.53312[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53312 - acc: 0.7402 -- iter: 3008/3680
[A[ATraining Step: 440  | total loss: [1m[32m0.53621[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53621 - acc: 0.7381 -- iter: 3040/3680
[A[ATraining Step: 441  | total loss: [1m[32m0.53658[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53658 - acc: 0.7330 -- iter: 3072/3680
[A[ATraining Step: 442  | total loss: [1m[32m0.53791[0m[0m
[2K| Adam | epoch: 004 | loss: 0.53791 - acc: 0.7316 -- iter: 3104/3680
[A[ATraining Step: 443  | total loss: [1m[32m0.54070[0m[0m
[2K| Adam | epoch: 004 | loss: 0.54070 - acc: 0.7272 -- iter: 3136/3680
[A[ATraining Step: 444  | total loss: [1m[32m0.52595[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52595 - acc: 0.7357 -- iter: 3168/3680
[A[ATraining Step: 445  | total loss: [1m[32m0.51848[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51848 - acc: 0.7371 -- iter: 3200/3680
[A[ATraining Step: 446  | total loss: [1m[32m0.51040[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51040 - acc: 0.7447 -- iter: 3232/3680
[A[ATraining Step: 447  | total loss: [1m[32m0.51106[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51106 - acc: 0.7454 -- iter: 3264/3680
[A[ATraining Step: 448  | total loss: [1m[32m0.51106[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51106 - acc: 0.7454 -- iter: 3296/3680
[A[ATraining Step: 449  | total loss: [1m[32m0.50527[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50527 - acc: 0.7550 -- iter: 3328/3680
[A[ATraining Step: 450  | total loss: [1m[32m0.50424[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50424 - acc: 0.7550 -- iter: 3360/3680
[A[ATraining Step: 451  | total loss: [1m[32m0.50932[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50932 - acc: 0.7483 -- iter: 3392/3680
[A[ATraining Step: 452  | total loss: [1m[32m0.52002[0m[0m
[2K| Adam | epoch: 004 | loss: 0.52002 - acc: 0.7391 -- iter: 3424/3680
[A[ATraining Step: 453  | total loss: [1m[32m0.51697[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51697 - acc: 0.7386 -- iter: 3456/3680
[A[ATraining Step: 454  | total loss: [1m[32m0.51078[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51078 - acc: 0.7386 -- iter: 3488/3680
[A[ATraining Step: 455  | total loss: [1m[32m0.51201[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51201 - acc: 0.7460 -- iter: 3520/3680
[A[ATraining Step: 456  | total loss: [1m[32m0.50882[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50882 - acc: 0.7402 -- iter: 3552/3680
[A[ATraining Step: 457  | total loss: [1m[32m0.50774[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50774 - acc: 0.7318 -- iter: 3584/3680
[A[ATraining Step: 458  | total loss: [1m[32m0.51543[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51543 - acc: 0.7211 -- iter: 3616/3680
[A[ATraining Step: 459  | total loss: [1m[32m0.51230[0m[0m
[2K| Adam | epoch: 004 | loss: 0.51230 - acc: 0.7271 -- iter: 3648/3680
[A[ATraining Step: 460  | total loss: [1m[32m0.50840[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50840 - acc: 0.7294 | val_loss: 0.53650 - val_acc: 0.7253 -- iter: 3680/3680
[A[ATraining Step: 460  | total loss: [1m[32m0.50840[0m[0m
[2K| Adam | epoch: 004 | loss: 0.50840 - acc: 0.7294 | val_loss: 0.53650 - val_acc: 0.7253 -- iter: 3680/3680
--
Training Step: 461  | total loss: [1m[32m0.51863[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51863 - acc: 0.7271 -- iter: 0032/3680
[A[ATraining Step: 462  | total loss: [1m[32m0.51863[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51863 - acc: 0.7271 -- iter: 0064/3680
[A[ATraining Step: 463  | total loss: [1m[32m0.51896[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51896 - acc: 0.7189 -- iter: 0096/3680
[A[ATraining Step: 464  | total loss: [1m[32m0.53048[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53048 - acc: 0.7189 -- iter: 0128/3680
[A[ATraining Step: 465  | total loss: [1m[32m0.53884[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53884 - acc: 0.7101 -- iter: 0160/3680
[A[ATraining Step: 466  | total loss: [1m[32m0.53740[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53740 - acc: 0.7141 -- iter: 0192/3680
[A[ATraining Step: 467  | total loss: [1m[32m0.53663[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53663 - acc: 0.7115 -- iter: 0224/3680
[A[ATraining Step: 468  | total loss: [1m[32m0.53931[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53931 - acc: 0.7115 -- iter: 0256/3680
[A[ATraining Step: 469  | total loss: [1m[32m0.52894[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52894 - acc: 0.7153 -- iter: 0288/3680
[A[ATraining Step: 470  | total loss: [1m[32m0.53865[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53865 - acc: 0.7169 -- iter: 0320/3680
[A[ATraining Step: 471  | total loss: [1m[32m0.53312[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53312 - acc: 0.7169 -- iter: 0352/3680
[A[ATraining Step: 472  | total loss: [1m[32m0.52610[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52610 - acc: 0.7233 -- iter: 0384/3680
[A[ATraining Step: 473  | total loss: [1m[32m0.51866[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51866 - acc: 0.7323 -- iter: 0416/3680
[A[ATraining Step: 474  | total loss: [1m[32m0.54123[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54123 - acc: 0.7150 -- iter: 0448/3680
[A[ATraining Step: 475  | total loss: [1m[32m0.54123[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54123 - acc: 0.7150 -- iter: 0480/3680
[A[ATraining Step: 476  | total loss: [1m[32m0.52205[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52205 - acc: 0.7341 -- iter: 0512/3680
[A[ATraining Step: 477  | total loss: [1m[32m0.51673[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51673 - acc: 0.7295 -- iter: 0544/3680
[A[ATraining Step: 478  | total loss: [1m[32m0.52242[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52242 - acc: 0.7221 -- iter: 0576/3680
[A[ATraining Step: 479  | total loss: [1m[32m0.51257[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51257 - acc: 0.7343 -- iter: 0608/3680
[A[ATraining Step: 480  | total loss: [1m[32m0.51448[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51448 - acc: 0.7359 -- iter: 0640/3680
[A[ATraining Step: 481  | total loss: [1m[32m0.52079[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52079 - acc: 0.7342 -- iter: 0672/3680
[A[ATraining Step: 482  | total loss: [1m[32m0.52362[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52362 - acc: 0.7306 -- iter: 0704/3680
[A[ATraining Step: 483  | total loss: [1m[32m0.52362[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52362 - acc: 0.7306 -- iter: 0736/3680
[A[ATraining Step: 484  | total loss: [1m[32m0.52088[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52088 - acc: 0.7325 -- iter: 0768/3680
[A[ATraining Step: 485  | total loss: [1m[32m0.50953[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50953 - acc: 0.7499 -- iter: 0800/3680
[A[ATraining Step: 486  | total loss: [1m[32m0.50700[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50700 - acc: 0.7593 -- iter: 0832/3680
[A[ATraining Step: 487  | total loss: [1m[32m0.52119[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52119 - acc: 0.7427 -- iter: 0864/3680
[A[ATraining Step: 488  | total loss: [1m[32m0.51479[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51479 - acc: 0.7435 -- iter: 0896/3680
[A[ATraining Step: 489  | total loss: [1m[32m0.52382[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52382 - acc: 0.7410 -- iter: 0928/3680
[A[ATraining Step: 490  | total loss: [1m[32m0.53813[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53813 - acc: 0.7388 -- iter: 0960/3680
[A[ATraining Step: 491  | total loss: [1m[32m0.53785[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53785 - acc: 0.7430 -- iter: 0992/3680
[A[ATraining Step: 492  | total loss: [1m[32m0.53691[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53691 - acc: 0.7437 -- iter: 1024/3680
[A[ATraining Step: 493  | total loss: [1m[32m0.52515[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52515 - acc: 0.7475 -- iter: 1056/3680
[A[ATraining Step: 494  | total loss: [1m[32m0.52970[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52970 - acc: 0.7415 -- iter: 1088/3680
[A[ATraining Step: 495  | total loss: [1m[32m0.51738[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51738 - acc: 0.7455 -- iter: 1120/3680
[A[ATraining Step: 496  | total loss: [1m[32m0.52142[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52142 - acc: 0.7516 -- iter: 1152/3680
[A[ATraining Step: 497  | total loss: [1m[32m0.52142[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52142 - acc: 0.7516 -- iter: 1184/3680
[A[ATraining Step: 498  | total loss: [1m[32m0.51723[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51723 - acc: 0.7515 -- iter: 1216/3680
[A[ATraining Step: 499  | total loss: [1m[32m0.51707[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51707 - acc: 0.7576 -- iter: 1248/3680
[A[ATraining Step: 500  | total loss: [1m[32m0.51764[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51764 - acc: 0.7537 | val_loss: 0.53077 - val_acc: 0.7210 -- iter: 1280/3680
[A[ATraining Step: 500  | total loss: [1m[32m0.51764[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51764 - acc: 0.7537 | val_loss: 0.53077 - val_acc: 0.7210 -- iter: 1280/3680
--
Training Step: 501  | total loss: [1m[32m0.52507[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52507 - acc: 0.7539 -- iter: 1312/3680
[A[ATraining Step: 502  | total loss: [1m[32m0.51571[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51571 - acc: 0.7567 -- iter: 1344/3680
[A[ATraining Step: 503  | total loss: [1m[32m0.51991[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51991 - acc: 0.7567 -- iter: 1376/3680
[A[ATraining Step: 504  | total loss: [1m[32m0.51833[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51833 - acc: 0.7591 -- iter: 1408/3680
[A[ATraining Step: 505  | total loss: [1m[32m0.51775[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51775 - acc: 0.7645 -- iter: 1440/3680
[A[ATraining Step: 506  | total loss: [1m[32m0.51538[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51538 - acc: 0.7630 -- iter: 1472/3680
[A[ATraining Step: 507  | total loss: [1m[32m0.50450[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50450 - acc: 0.7680 -- iter: 1504/3680
[A[ATraining Step: 508  | total loss: [1m[32m0.49919[0m[0m
[2K| Adam | epoch: 005 | loss: 0.49919 - acc: 0.7693 -- iter: 1536/3680
[A[ATraining Step: 509  | total loss: [1m[32m0.50715[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50715 - acc: 0.7611 -- iter: 1568/3680
[A[ATraining Step: 510  | total loss: [1m[32m0.50470[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50470 - acc: 0.7593 -- iter: 1600/3680
[A[ATraining Step: 511  | total loss: [1m[32m0.50567[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50567 - acc: 0.7584 -- iter: 1632/3680
[A[ATraining Step: 512  | total loss: [1m[32m0.51504[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51504 - acc: 0.7584 -- iter: 1664/3680
[A[ATraining Step: 513  | total loss: [1m[32m0.51108[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51108 - acc: 0.7638 -- iter: 1696/3680
[A[ATraining Step: 514  | total loss: [1m[32m0.52689[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52689 - acc: 0.7562 -- iter: 1728/3680
[A[ATraining Step: 515  | total loss: [1m[32m0.54040[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54040 - acc: 0.7368 -- iter: 1760/3680
[A[ATraining Step: 516  | total loss: [1m[32m0.53578[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53578 - acc: 0.7444 -- iter: 1792/3680
[A[ATraining Step: 517  | total loss: [1m[32m0.52929[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52929 - acc: 0.7482 -- iter: 1824/3680
[A[ATraining Step: 518  | total loss: [1m[32m0.52929[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52929 - acc: 0.7482 -- iter: 1856/3680
[A[ATraining Step: 519  | total loss: [1m[32m0.53587[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53587 - acc: 0.7297 -- iter: 1888/3680
[A[ATraining Step: 520  | total loss: [1m[32m0.54812[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54812 - acc: 0.7376 -- iter: 1920/3680
[A[ATraining Step: 521  | total loss: [1m[32m0.53425[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53425 - acc: 0.7376 -- iter: 1952/3680
[A[ATraining Step: 522  | total loss: [1m[32m0.55274[0m[0m
[2K| Adam | epoch: 005 | loss: 0.55274 - acc: 0.7170 -- iter: 1984/3680
[A[ATraining Step: 523  | total loss: [1m[32m0.54849[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54849 - acc: 0.7265 -- iter: 2016/3680
[A[ATraining Step: 524  | total loss: [1m[32m0.55278[0m[0m
[2K| Adam | epoch: 005 | loss: 0.55278 - acc: 0.7257 -- iter: 2048/3680
[A[ATraining Step: 525  | total loss: [1m[32m0.55006[0m[0m
[2K| Adam | epoch: 005 | loss: 0.55006 - acc: 0.7313 -- iter: 2080/3680
[A[ATraining Step: 526  | total loss: [1m[32m0.55639[0m[0m
[2K| Adam | epoch: 005 | loss: 0.55639 - acc: 0.7269 -- iter: 2112/3680
[A[ATraining Step: 527  | total loss: [1m[32m0.54438[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54438 - acc: 0.7261 -- iter: 2144/3680
[A[ATraining Step: 528  | total loss: [1m[32m0.53924[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53924 - acc: 0.7254 -- iter: 2176/3680
[A[ATraining Step: 529  | total loss: [1m[32m0.53971[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53971 - acc: 0.7310 -- iter: 2208/3680
[A[ATraining Step: 530  | total loss: [1m[32m0.52609[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52609 - acc: 0.7391 -- iter: 2240/3680
[A[ATraining Step: 531  | total loss: [1m[32m0.52801[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52801 - acc: 0.7433 -- iter: 2272/3680
[A[ATraining Step: 532  | total loss: [1m[32m0.52717[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52717 - acc: 0.7440 -- iter: 2304/3680
[A[ATraining Step: 533  | total loss: [1m[32m0.51292[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51292 - acc: 0.7571 -- iter: 2336/3680
[A[ATraining Step: 534  | total loss: [1m[32m0.51618[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51618 - acc: 0.7342 -- iter: 2368/3680
[A[ATraining Step: 535  | total loss: [1m[32m0.52659[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52659 - acc: 0.7342 -- iter: 2400/3680
[A[ATraining Step: 536  | total loss: [1m[32m0.52201[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52201 - acc: 0.7358 -- iter: 2432/3680
[A[ATraining Step: 537  | total loss: [1m[32m0.51748[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51748 - acc: 0.7469 -- iter: 2464/3680
[A[ATraining Step: 538  | total loss: [1m[32m0.51748[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51748 - acc: 0.7469 -- iter: 2496/3680
[A[ATraining Step: 539  | total loss: [1m[32m0.52696[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52696 - acc: 0.7316 -- iter: 2528/3680
[A[ATraining Step: 540  | total loss: [1m[32m0.53036[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53036 - acc: 0.7209 -- iter: 2560/3680
[A[ATraining Step: 541  | total loss: [1m[32m0.54768[0m[0m
[2K| Adam | epoch: 005 | loss: 0.54768 - acc: 0.7082 -- iter: 2592/3680
[A[ATraining Step: 542  | total loss: [1m[32m0.55146[0m[0m
[2K| Adam | epoch: 005 | loss: 0.55146 - acc: 0.6999 -- iter: 2624/3680
[A[ATraining Step: 543  | total loss: [1m[32m0.55175[0m[0m
[2K| Adam | epoch: 005 | loss: 0.55175 - acc: 0.6987 -- iter: 2656/3680
[A[ATraining Step: 544  | total loss: [1m[32m0.53125[0m[0m
[2K| Adam | epoch: 005 | loss: 0.53125 - acc: 0.7225 -- iter: 2688/3680
[A[ATraining Step: 545  | total loss: [1m[32m0.52518[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52518 - acc: 0.7225 -- iter: 2720/3680
[A[ATraining Step: 546  | total loss: [1m[32m0.52041[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52041 - acc: 0.7315 -- iter: 2752/3680
[A[ATraining Step: 547  | total loss: [1m[32m0.50884[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50884 - acc: 0.7427 -- iter: 2784/3680
[A[ATraining Step: 548  | total loss: [1m[32m0.51020[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51020 - acc: 0.7497 -- iter: 2816/3680
[A[ATraining Step: 549  | total loss: [1m[32m0.50516[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50516 - acc: 0.7591 -- iter: 2848/3680
[A[ATraining Step: 550  | total loss: [1m[32m0.50618[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50618 - acc: 0.7582 -- iter: 2880/3680
[A[ATraining Step: 551  | total loss: [1m[32m0.51468[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51468 - acc: 0.7582 -- iter: 2912/3680
[A[ATraining Step: 552  | total loss: [1m[32m0.49962[0m[0m
[2K| Adam | epoch: 005 | loss: 0.49962 - acc: 0.7582 -- iter: 2944/3680
[A[ATraining Step: 553  | total loss: [1m[32m0.49775[0m[0m
[2K| Adam | epoch: 005 | loss: 0.49775 - acc: 0.7605 -- iter: 2976/3680
[A[ATraining Step: 554  | total loss: [1m[32m0.49293[0m[0m
[2K| Adam | epoch: 005 | loss: 0.49293 - acc: 0.7688 -- iter: 3008/3680
[A[ATraining Step: 555  | total loss: [1m[32m0.47668[0m[0m
[2K| Adam | epoch: 005 | loss: 0.47668 - acc: 0.7793 -- iter: 3040/3680
[A[ATraining Step: 556  | total loss: [1m[32m0.48067[0m[0m
[2K| Adam | epoch: 005 | loss: 0.48067 - acc: 0.7793 -- iter: 3072/3680
[A[ATraining Step: 557  | total loss: [1m[32m0.47142[0m[0m
[2K| Adam | epoch: 005 | loss: 0.47142 - acc: 0.7920 -- iter: 3104/3680
[A[ATraining Step: 558  | total loss: [1m[32m0.48002[0m[0m
[2K| Adam | epoch: 005 | loss: 0.48002 - acc: 0.7784 -- iter: 3136/3680
[A[ATraining Step: 559  | total loss: [1m[32m0.48366[0m[0m
[2K| Adam | epoch: 005 | loss: 0.48366 - acc: 0.7725 -- iter: 3168/3680
[A[ATraining Step: 560  | total loss: [1m[32m0.47300[0m[0m
[2K| Adam | epoch: 005 | loss: 0.47300 - acc: 0.7733 -- iter: 3200/3680
[A[ATraining Step: 561  | total loss: [1m[32m0.46971[0m[0m
[2K| Adam | epoch: 005 | loss: 0.46971 - acc: 0.7808 -- iter: 3232/3680
[A[ATraining Step: 562  | total loss: [1m[32m0.46971[0m[0m
[2K| Adam | epoch: 005 | loss: 0.46971 - acc: 0.7808 -- iter: 3264/3680
[A[ATraining Step: 563  | total loss: [1m[32m0.47929[0m[0m
[2K| Adam | epoch: 005 | loss: 0.47929 - acc: 0.7715 -- iter: 3296/3680
[A[ATraining Step: 564  | total loss: [1m[32m0.48100[0m[0m
[2K| Adam | epoch: 005 | loss: 0.48100 - acc: 0.7639 -- iter: 3328/3680
[A[ATraining Step: 565  | total loss: [1m[32m0.48902[0m[0m
[2K| Adam | epoch: 005 | loss: 0.48902 - acc: 0.7639 -- iter: 3360/3680
[A[ATraining Step: 566  | total loss: [1m[32m0.49776[0m[0m
[2K| Adam | epoch: 005 | loss: 0.49776 - acc: 0.7563 -- iter: 3392/3680
[A[ATraining Step: 567  | total loss: [1m[32m0.49664[0m[0m
[2K| Adam | epoch: 005 | loss: 0.49664 - acc: 0.7619 -- iter: 3424/3680
[A[ATraining Step: 568  | total loss: [1m[32m0.50661[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50661 - acc: 0.7451 -- iter: 3456/3680
[A[ATraining Step: 569  | total loss: [1m[32m0.50887[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50887 - acc: 0.7456 -- iter: 3488/3680
[A[ATraining Step: 570  | total loss: [1m[32m0.50632[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50632 - acc: 0.7523 -- iter: 3520/3680
[A[ATraining Step: 571  | total loss: [1m[32m0.50328[0m[0m
[2K| Adam | epoch: 005 | loss: 0.50328 - acc: 0.7521 -- iter: 3552/3680
[A[ATraining Step: 572  | total loss: [1m[32m0.52117[0m[0m
[2K| Adam | epoch: 005 | loss: 0.52117 - acc: 0.7425 -- iter: 3584/3680
[A[ATraining Step: 573  | total loss: [1m[32m0.51176[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51176 - acc: 0.7526 -- iter: 3616/3680
[A[ATraining Step: 574  | total loss: [1m[32m0.51806[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51806 - acc: 0.7430 -- iter: 3648/3680
[A[ATraining Step: 575  | total loss: [1m[32m0.51453[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51453 - acc: 0.7405 | val_loss: 0.52176 - val_acc: 0.7383 -- iter: 3680/3680
[A[ATraining Step: 575  | total loss: [1m[32m0.51453[0m[0m
[2K| Adam | epoch: 005 | loss: 0.51453 - acc: 0.7405 | val_loss: 0.52176 - val_acc: 0.7383 -- iter: 3680/3680
--
Training Step: 576  | total loss: [1m[32m0.51575[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51575 - acc: 0.7352 -- iter: 0032/3680
[A[ATraining Step: 577  | total loss: [1m[32m0.49527[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49527 - acc: 0.7523 -- iter: 0064/3680
[A[ATraining Step: 578  | total loss: [1m[32m0.48736[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48736 - acc: 0.7646 -- iter: 0096/3680
[A[ATraining Step: 579  | total loss: [1m[32m0.48557[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48557 - acc: 0.7600 -- iter: 0128/3680
[A[ATraining Step: 580  | total loss: [1m[32m0.48148[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48148 - acc: 0.7621 -- iter: 0160/3680
[A[ATraining Step: 581  | total loss: [1m[32m0.48163[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48163 - acc: 0.7547 -- iter: 0192/3680
[A[ATraining Step: 582  | total loss: [1m[32m0.47699[0m[0m
[2K| Adam | epoch: 006 | loss: 0.47699 - acc: 0.7605 -- iter: 0224/3680
[A[ATraining Step: 583  | total loss: [1m[32m0.48431[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48431 - acc: 0.7469 -- iter: 0256/3680
[A[ATraining Step: 584  | total loss: [1m[32m0.49189[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49189 - acc: 0.7472 -- iter: 0288/3680
[A[ATraining Step: 585  | total loss: [1m[32m0.49825[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49825 - acc: 0.7413 -- iter: 0320/3680
[A[ATraining Step: 586  | total loss: [1m[32m0.49093[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49093 - acc: 0.7453 -- iter: 0352/3680
[A[ATraining Step: 587  | total loss: [1m[32m0.48400[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48400 - acc: 0.7489 -- iter: 0384/3680
[A[ATraining Step: 588  | total loss: [1m[32m0.48530[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48530 - acc: 0.7458 -- iter: 0416/3680
[A[ATraining Step: 589  | total loss: [1m[32m0.50597[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50597 - acc: 0.7275 -- iter: 0448/3680
[A[ATraining Step: 590  | total loss: [1m[32m0.51993[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51993 - acc: 0.7204 -- iter: 0480/3680
[A[ATraining Step: 591  | total loss: [1m[32m0.51977[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51977 - acc: 0.7265 -- iter: 0512/3680
[A[ATraining Step: 592  | total loss: [1m[32m0.50418[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50418 - acc: 0.7382 -- iter: 0544/3680
[A[ATraining Step: 593  | total loss: [1m[32m0.52100[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52100 - acc: 0.7300 -- iter: 0576/3680
[A[ATraining Step: 594  | total loss: [1m[32m0.51165[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51165 - acc: 0.7383 -- iter: 0608/3680
[A[ATraining Step: 595  | total loss: [1m[32m0.52310[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52310 - acc: 0.7332 -- iter: 0640/3680
[A[ATraining Step: 596  | total loss: [1m[32m0.52694[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52694 - acc: 0.7442 -- iter: 0672/3680
[A[ATraining Step: 597  | total loss: [1m[32m0.51852[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51852 - acc: 0.7511 -- iter: 0704/3680
[A[ATraining Step: 598  | total loss: [1m[32m0.52188[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52188 - acc: 0.7447 -- iter: 0736/3680
[A[ATraining Step: 599  | total loss: [1m[32m0.53244[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53244 - acc: 0.7296 -- iter: 0768/3680
[A[ATraining Step: 600  | total loss: [1m[32m0.52388[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52388 - acc: 0.7348 | val_loss: 0.51758 - val_acc: 0.7481 -- iter: 0800/3680
[A[ATraining Step: 600  | total loss: [1m[32m0.52388[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52388 - acc: 0.7348 | val_loss: 0.51758 - val_acc: 0.7481 -- iter: 0800/3680
--
Training Step: 601  | total loss: [1m[32m0.51959[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51959 - acc: 0.7394 -- iter: 0832/3680
[A[ATraining Step: 602  | total loss: [1m[32m0.51838[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51838 - acc: 0.7405 -- iter: 0864/3680
[A[ATraining Step: 603  | total loss: [1m[32m0.52543[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52543 - acc: 0.7446 -- iter: 0896/3680
[A[ATraining Step: 604  | total loss: [1m[32m0.52131[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52131 - acc: 0.7420 -- iter: 0928/3680
[A[ATraining Step: 605  | total loss: [1m[32m0.52339[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52339 - acc: 0.7459 -- iter: 0960/3680
[A[ATraining Step: 606  | total loss: [1m[32m0.52499[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52499 - acc: 0.7526 -- iter: 0992/3680
[A[ATraining Step: 607  | total loss: [1m[32m0.52251[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52251 - acc: 0.7492 -- iter: 1024/3680
[A[ATraining Step: 608  | total loss: [1m[32m0.51956[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51956 - acc: 0.7524 -- iter: 1056/3680
[A[ATraining Step: 609  | total loss: [1m[32m0.50452[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50452 - acc: 0.7709 -- iter: 1088/3680
[A[ATraining Step: 610  | total loss: [1m[32m0.50689[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50689 - acc: 0.7626 -- iter: 1120/3680
[A[ATraining Step: 611  | total loss: [1m[32m0.49812[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49812 - acc: 0.7707 -- iter: 1152/3680
[A[ATraining Step: 612  | total loss: [1m[32m0.49413[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49413 - acc: 0.7780 -- iter: 1184/3680
[A[ATraining Step: 613  | total loss: [1m[32m0.50586[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50586 - acc: 0.7721 -- iter: 1216/3680
[A[ATraining Step: 614  | total loss: [1m[32m0.51683[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51683 - acc: 0.7636 -- iter: 1248/3680
[A[ATraining Step: 615  | total loss: [1m[32m0.52814[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52814 - acc: 0.7529 -- iter: 1280/3680
[A[ATraining Step: 616  | total loss: [1m[32m0.52945[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52945 - acc: 0.7526 -- iter: 1312/3680
[A[ATraining Step: 617  | total loss: [1m[32m0.51737[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51737 - acc: 0.7648 -- iter: 1344/3680
[A[ATraining Step: 618  | total loss: [1m[32m0.51688[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51688 - acc: 0.7651 -- iter: 1376/3680
[A[ATraining Step: 619  | total loss: [1m[32m0.51244[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51244 - acc: 0.7651 -- iter: 1408/3680
[A[ATraining Step: 620  | total loss: [1m[32m0.51783[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51783 - acc: 0.7636 -- iter: 1440/3680
[A[ATraining Step: 621  | total loss: [1m[32m0.52219[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52219 - acc: 0.7623 -- iter: 1472/3680
[A[ATraining Step: 622  | total loss: [1m[32m0.51683[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51683 - acc: 0.7610 -- iter: 1504/3680
[A[ATraining Step: 623  | total loss: [1m[32m0.51837[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51837 - acc: 0.7568 -- iter: 1536/3680
[A[ATraining Step: 624  | total loss: [1m[32m0.52303[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52303 - acc: 0.7530 -- iter: 1568/3680
[A[ATraining Step: 625  | total loss: [1m[32m0.52702[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52702 - acc: 0.7464 -- iter: 1600/3680
[A[ATraining Step: 626  | total loss: [1m[32m0.53031[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53031 - acc: 0.7499 -- iter: 1632/3680
[A[ATraining Step: 627  | total loss: [1m[32m0.54112[0m[0m
[2K| Adam | epoch: 006 | loss: 0.54112 - acc: 0.7437 -- iter: 1664/3680
[A[ATraining Step: 628  | total loss: [1m[32m0.54617[0m[0m
[2K| Adam | epoch: 006 | loss: 0.54617 - acc: 0.7381 -- iter: 1696/3680
[A[ATraining Step: 629  | total loss: [1m[32m0.53272[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53272 - acc: 0.7486 -- iter: 1728/3680
[A[ATraining Step: 630  | total loss: [1m[32m0.52242[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52242 - acc: 0.7581 -- iter: 1760/3680
[A[ATraining Step: 631  | total loss: [1m[32m0.51585[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51585 - acc: 0.7636 -- iter: 1792/3680
[A[ATraining Step: 632  | total loss: [1m[32m0.50400[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50400 - acc: 0.7716 -- iter: 1824/3680
[A[ATraining Step: 633  | total loss: [1m[32m0.50646[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50646 - acc: 0.7663 -- iter: 1856/3680
[A[ATraining Step: 634  | total loss: [1m[32m0.51436[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51436 - acc: 0.7584 -- iter: 1888/3680
[A[ATraining Step: 635  | total loss: [1m[32m0.50690[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50690 - acc: 0.7545 -- iter: 1920/3680
[A[ATraining Step: 636  | total loss: [1m[32m0.50305[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50305 - acc: 0.7603 -- iter: 1952/3680
[A[ATraining Step: 637  | total loss: [1m[32m0.50192[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50192 - acc: 0.7624 -- iter: 1984/3680
[A[ATraining Step: 638  | total loss: [1m[32m0.49912[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49912 - acc: 0.7674 -- iter: 2016/3680
[A[ATraining Step: 639  | total loss: [1m[32m0.50588[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50588 - acc: 0.7625 -- iter: 2048/3680
[A[ATraining Step: 640  | total loss: [1m[32m0.49885[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49885 - acc: 0.7675 -- iter: 2080/3680
[A[ATraining Step: 641  | total loss: [1m[32m0.50446[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50446 - acc: 0.7614 -- iter: 2112/3680
[A[ATraining Step: 642  | total loss: [1m[32m0.50446[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50446 - acc: 0.7614 -- iter: 2144/3680
[A[ATraining Step: 643  | total loss: [1m[32m0.50833[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50833 - acc: 0.7502 -- iter: 2176/3680
[A[ATraining Step: 644  | total loss: [1m[32m0.51160[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51160 - acc: 0.7502 -- iter: 2208/3680
[A[ATraining Step: 645  | total loss: [1m[32m0.49568[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49568 - acc: 0.7626 -- iter: 2240/3680
[A[ATraining Step: 646  | total loss: [1m[32m0.49806[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49806 - acc: 0.7551 -- iter: 2272/3680
[A[ATraining Step: 647  | total loss: [1m[32m0.48772[0m[0m
[2K| Adam | epoch: 006 | loss: 0.48772 - acc: 0.7609 -- iter: 2304/3680
[A[ATraining Step: 648  | total loss: [1m[32m0.49040[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49040 - acc: 0.7566 -- iter: 2336/3680
[A[ATraining Step: 649  | total loss: [1m[32m0.49752[0m[0m
[2K| Adam | epoch: 006 | loss: 0.49752 - acc: 0.7591 -- iter: 2368/3680
[A[ATraining Step: 650  | total loss: [1m[32m0.50643[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50643 - acc: 0.7457 -- iter: 2400/3680
[A[ATraining Step: 651  | total loss: [1m[32m0.51295[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51295 - acc: 0.7461 -- iter: 2432/3680
[A[ATraining Step: 652  | total loss: [1m[32m0.50772[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50772 - acc: 0.7528 -- iter: 2464/3680
[A[ATraining Step: 653  | total loss: [1m[32m0.50642[0m[0m
[2K| Adam | epoch: 006 | loss: 0.50642 - acc: 0.7494 -- iter: 2496/3680
[A[ATraining Step: 654  | total loss: [1m[32m0.51821[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51821 - acc: 0.7494 -- iter: 2528/3680
[A[ATraining Step: 655  | total loss: [1m[32m0.51683[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51683 - acc: 0.7526 -- iter: 2560/3680
[A[ATraining Step: 656  | total loss: [1m[32m0.52846[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52846 - acc: 0.7398 -- iter: 2592/3680
[A[ATraining Step: 657  | total loss: [1m[32m0.52315[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52315 - acc: 0.7409 -- iter: 2624/3680
[A[ATraining Step: 658  | total loss: [1m[32m0.53418[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53418 - acc: 0.7480 -- iter: 2656/3680
[A[ATraining Step: 659  | total loss: [1m[32m0.53804[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53804 - acc: 0.7326 -- iter: 2688/3680
[A[ATraining Step: 660  | total loss: [1m[32m0.53583[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53583 - acc: 0.7375 -- iter: 2720/3680
[A[ATraining Step: 661  | total loss: [1m[32m0.53008[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53008 - acc: 0.7387 -- iter: 2752/3680
[A[ATraining Step: 662  | total loss: [1m[32m0.52429[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52429 - acc: 0.7492 -- iter: 2784/3680
[A[ATraining Step: 663  | total loss: [1m[32m0.52681[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52681 - acc: 0.7462 -- iter: 2816/3680
[A[ATraining Step: 664  | total loss: [1m[32m0.55000[0m[0m
[2K| Adam | epoch: 006 | loss: 0.55000 - acc: 0.7272 -- iter: 2848/3680
[A[ATraining Step: 665  | total loss: [1m[32m0.55000[0m[0m
[2K| Adam | epoch: 006 | loss: 0.55000 - acc: 0.7272 -- iter: 2880/3680
[A[ATraining Step: 666  | total loss: [1m[32m0.55190[0m[0m
[2K| Adam | epoch: 006 | loss: 0.55190 - acc: 0.7264 -- iter: 2912/3680
[A[ATraining Step: 667  | total loss: [1m[32m0.53709[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53709 - acc: 0.7381 -- iter: 2944/3680
[A[ATraining Step: 668  | total loss: [1m[32m0.53963[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53963 - acc: 0.7393 -- iter: 2976/3680
[A[ATraining Step: 669  | total loss: [1m[32m0.55052[0m[0m
[2K| Adam | epoch: 006 | loss: 0.55052 - acc: 0.7372 -- iter: 3008/3680
[A[ATraining Step: 670  | total loss: [1m[32m0.55991[0m[0m
[2K| Adam | epoch: 006 | loss: 0.55991 - acc: 0.7440 -- iter: 3040/3680
[A[ATraining Step: 671  | total loss: [1m[32m0.53669[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53669 - acc: 0.7440 -- iter: 3072/3680
[A[ATraining Step: 672  | total loss: [1m[32m0.53767[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53767 - acc: 0.7384 -- iter: 3104/3680
[A[ATraining Step: 673  | total loss: [1m[32m0.52915[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52915 - acc: 0.7489 -- iter: 3136/3680
[A[ATraining Step: 674  | total loss: [1m[32m0.52438[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52438 - acc: 0.7584 -- iter: 3168/3680
[A[ATraining Step: 675  | total loss: [1m[32m0.52151[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52151 - acc: 0.7607 -- iter: 3200/3680
[A[ATraining Step: 676  | total loss: [1m[32m0.52980[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52980 - acc: 0.7471 -- iter: 3232/3680
[A[ATraining Step: 677  | total loss: [1m[32m0.52337[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52337 - acc: 0.7505 -- iter: 3264/3680
[A[ATraining Step: 678  | total loss: [1m[32m0.52222[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52222 - acc: 0.7536 -- iter: 3296/3680
[A[ATraining Step: 679  | total loss: [1m[32m0.53361[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53361 - acc: 0.7407 -- iter: 3328/3680
[A[ATraining Step: 680  | total loss: [1m[32m0.52651[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52651 - acc: 0.7479 -- iter: 3360/3680
[A[ATraining Step: 681  | total loss: [1m[32m0.52004[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52004 - acc: 0.7575 -- iter: 3392/3680
[A[ATraining Step: 682  | total loss: [1m[32m0.51504[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51504 - acc: 0.7630 -- iter: 3424/3680
[A[ATraining Step: 683  | total loss: [1m[32m0.52262[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52262 - acc: 0.7555 -- iter: 3456/3680
[A[ATraining Step: 684  | total loss: [1m[32m0.51883[0m[0m
[2K| Adam | epoch: 006 | loss: 0.51883 - acc: 0.7580 -- iter: 3488/3680
[A[ATraining Step: 685  | total loss: [1m[32m0.53750[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53750 - acc: 0.7416 -- iter: 3520/3680
[A[ATraining Step: 686  | total loss: [1m[32m0.53532[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53532 - acc: 0.7456 -- iter: 3552/3680
[A[ATraining Step: 687  | total loss: [1m[32m0.53504[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53504 - acc: 0.7398 -- iter: 3584/3680
[A[ATraining Step: 688  | total loss: [1m[32m0.52944[0m[0m
[2K| Adam | epoch: 006 | loss: 0.52944 - acc: 0.7439 -- iter: 3616/3680
[A[ATraining Step: 689  | total loss: [1m[32m0.53599[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53599 - acc: 0.7414 -- iter: 3648/3680
[A[ATraining Step: 690  | total loss: [1m[32m0.53209[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53209 - acc: 0.7329 | val_loss: 0.51632 - val_acc: 0.7535 -- iter: 3680/3680
[A[ATraining Step: 690  | total loss: [1m[32m0.53209[0m[0m
[2K| Adam | epoch: 006 | loss: 0.53209 - acc: 0.7329 | val_loss: 0.51632 - val_acc: 0.7535 -- iter: 3680/3680
--
Training Step: 691  | total loss: [1m[32m0.53291[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53291 - acc: 0.7315 -- iter: 0032/3680
[A[ATraining Step: 692  | total loss: [1m[32m0.52752[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52752 - acc: 0.7333 -- iter: 0064/3680
[A[ATraining Step: 693  | total loss: [1m[32m0.52515[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52515 - acc: 0.7287 -- iter: 0096/3680
[A[ATraining Step: 694  | total loss: [1m[32m0.53091[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53091 - acc: 0.7215 -- iter: 0128/3680
[A[ATraining Step: 695  | total loss: [1m[32m0.53126[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53126 - acc: 0.7300 -- iter: 0160/3680
[A[ATraining Step: 696  | total loss: [1m[32m0.52372[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52372 - acc: 0.7300 -- iter: 0192/3680
[A[ATraining Step: 697  | total loss: [1m[32m0.51963[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51963 - acc: 0.7414 -- iter: 0224/3680
[A[ATraining Step: 698  | total loss: [1m[32m0.52662[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52662 - acc: 0.7374 -- iter: 0256/3680
[A[ATraining Step: 699  | total loss: [1m[32m0.52662[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52662 - acc: 0.7418 -- iter: 0288/3680
[A[ATraining Step: 700  | total loss: [1m[32m0.51699[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51699 - acc: 0.7418 | val_loss: 0.51382 - val_acc: 0.7427 -- iter: 0320/3680
[A[ATraining Step: 700  | total loss: [1m[32m0.51699[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51699 - acc: 0.7418 | val_loss: 0.51382 - val_acc: 0.7427 -- iter: 0320/3680
--
Training Step: 701  | total loss: [1m[32m0.52160[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52160 - acc: 0.7395 -- iter: 0352/3680
[A[ATraining Step: 702  | total loss: [1m[32m0.50851[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50851 - acc: 0.7562 -- iter: 0384/3680
[A[ATraining Step: 703  | total loss: [1m[32m0.50942[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50942 - acc: 0.7524 -- iter: 0416/3680
[A[ATraining Step: 704  | total loss: [1m[32m0.51770[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51770 - acc: 0.7491 -- iter: 0448/3680
[A[ATraining Step: 705  | total loss: [1m[32m0.51952[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51952 - acc: 0.7460 -- iter: 0480/3680
[A[ATraining Step: 706  | total loss: [1m[32m0.51222[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51222 - acc: 0.7527 -- iter: 0512/3680
[A[ATraining Step: 707  | total loss: [1m[32m0.51161[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51161 - acc: 0.7524 -- iter: 0544/3680
[A[ATraining Step: 708  | total loss: [1m[32m0.51209[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51209 - acc: 0.7428 -- iter: 0576/3680
[A[ATraining Step: 709  | total loss: [1m[32m0.50955[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50955 - acc: 0.7466 -- iter: 0608/3680
[A[ATraining Step: 710  | total loss: [1m[32m0.50575[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50575 - acc: 0.7470 -- iter: 0640/3680
[A[ATraining Step: 711  | total loss: [1m[32m0.50728[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50728 - acc: 0.7660 -- iter: 0672/3680
[A[ATraining Step: 712  | total loss: [1m[32m0.50068[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50068 - acc: 0.7660 -- iter: 0704/3680
[A[ATraining Step: 713  | total loss: [1m[32m0.48586[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48586 - acc: 0.7831 -- iter: 0736/3680
[A[ATraining Step: 714  | total loss: [1m[32m0.48660[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48660 - acc: 0.7767 -- iter: 0768/3680
[A[ATraining Step: 715  | total loss: [1m[32m0.48434[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48434 - acc: 0.7772 -- iter: 0800/3680
[A[ATraining Step: 716  | total loss: [1m[32m0.46801[0m[0m
[2K| Adam | epoch: 007 | loss: 0.46801 - acc: 0.7994 -- iter: 0832/3680
[A[ATraining Step: 717  | total loss: [1m[32m0.47370[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47370 - acc: 0.7976 -- iter: 0864/3680
[A[ATraining Step: 718  | total loss: [1m[32m0.45881[0m[0m
[2K| Adam | epoch: 007 | loss: 0.45881 - acc: 0.8085 -- iter: 0896/3680
[A[ATraining Step: 719  | total loss: [1m[32m0.47052[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47052 - acc: 0.8026 -- iter: 0928/3680
[A[ATraining Step: 720  | total loss: [1m[32m0.48762[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48762 - acc: 0.7911 -- iter: 0960/3680
[A[ATraining Step: 721  | total loss: [1m[32m0.48080[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48080 - acc: 0.8026 -- iter: 0992/3680
[A[ATraining Step: 722  | total loss: [1m[32m0.47652[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47652 - acc: 0.8076 -- iter: 1024/3680
[A[ATraining Step: 723  | total loss: [1m[32m0.47475[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47475 - acc: 0.8076 -- iter: 1056/3680
[A[ATraining Step: 724  | total loss: [1m[32m0.47614[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47614 - acc: 0.7987 -- iter: 1088/3680
[A[ATraining Step: 725  | total loss: [1m[32m0.47505[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47505 - acc: 0.7970 -- iter: 1120/3680
[A[ATraining Step: 726  | total loss: [1m[32m0.47498[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47498 - acc: 0.7954 -- iter: 1152/3680
[A[ATraining Step: 727  | total loss: [1m[32m0.46788[0m[0m
[2K| Adam | epoch: 007 | loss: 0.46788 - acc: 0.8003 -- iter: 1184/3680
[A[ATraining Step: 728  | total loss: [1m[32m0.47440[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47440 - acc: 0.7921 -- iter: 1216/3680
[A[ATraining Step: 729  | total loss: [1m[32m0.47668[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47668 - acc: 0.7816 -- iter: 1248/3680
[A[ATraining Step: 730  | total loss: [1m[32m0.47634[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47634 - acc: 0.7785 -- iter: 1280/3680
[A[ATraining Step: 731  | total loss: [1m[32m0.47524[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47524 - acc: 0.7881 -- iter: 1312/3680
[A[ATraining Step: 732  | total loss: [1m[32m0.47512[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47512 - acc: 0.7874 -- iter: 1344/3680
[A[ATraining Step: 733  | total loss: [1m[32m0.49051[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49051 - acc: 0.7681 -- iter: 1376/3680
[A[ATraining Step: 734  | total loss: [1m[32m0.51362[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51362 - acc: 0.7569 -- iter: 1408/3680
[A[ATraining Step: 735  | total loss: [1m[32m0.52143[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52143 - acc: 0.7500 -- iter: 1440/3680
[A[ATraining Step: 736  | total loss: [1m[32m0.50605[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50605 - acc: 0.7593 -- iter: 1472/3680
[A[ATraining Step: 737  | total loss: [1m[32m0.51346[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51346 - acc: 0.7451 -- iter: 1504/3680
[A[ATraining Step: 738  | total loss: [1m[32m0.51833[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51833 - acc: 0.7451 -- iter: 1536/3680
[A[ATraining Step: 739  | total loss: [1m[32m0.51687[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51687 - acc: 0.7487 -- iter: 1568/3680
[A[ATraining Step: 740  | total loss: [1m[32m0.50063[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50063 - acc: 0.7551 -- iter: 1600/3680
[A[ATraining Step: 741  | total loss: [1m[32m0.49860[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49860 - acc: 0.7514 -- iter: 1632/3680
[A[ATraining Step: 742  | total loss: [1m[32m0.50852[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50852 - acc: 0.7482 -- iter: 1664/3680
[A[ATraining Step: 743  | total loss: [1m[32m0.50137[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50137 - acc: 0.7546 -- iter: 1696/3680
[A[ATraining Step: 744  | total loss: [1m[32m0.49915[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49915 - acc: 0.7573 -- iter: 1728/3680
[A[ATraining Step: 745  | total loss: [1m[32m0.48562[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48562 - acc: 0.7722 -- iter: 1760/3680
[A[ATraining Step: 746  | total loss: [1m[32m0.49270[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49270 - acc: 0.7668 -- iter: 1792/3680
[A[ATraining Step: 747  | total loss: [1m[32m0.50678[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50678 - acc: 0.7495 -- iter: 1824/3680
[A[ATraining Step: 748  | total loss: [1m[32m0.51195[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51195 - acc: 0.7468 -- iter: 1856/3680
[A[ATraining Step: 749  | total loss: [1m[32m0.51195[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51195 - acc: 0.7468 -- iter: 1888/3680
[A[ATraining Step: 750  | total loss: [1m[32m0.50860[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50860 - acc: 0.7502 -- iter: 1920/3680
[A[ATraining Step: 751  | total loss: [1m[32m0.50050[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50050 - acc: 0.7533 -- iter: 1952/3680
[A[ATraining Step: 752  | total loss: [1m[32m0.49796[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49796 - acc: 0.7561 -- iter: 1984/3680
[A[ATraining Step: 753  | total loss: [1m[32m0.48674[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48674 - acc: 0.7662 -- iter: 2016/3680
[A[ATraining Step: 754  | total loss: [1m[32m0.48586[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48586 - acc: 0.7662 -- iter: 2048/3680
[A[ATraining Step: 755  | total loss: [1m[32m0.49456[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49456 - acc: 0.7583 -- iter: 2080/3680
[A[ATraining Step: 756  | total loss: [1m[32m0.49158[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49158 - acc: 0.7638 -- iter: 2112/3680
[A[ATraining Step: 757  | total loss: [1m[32m0.50035[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50035 - acc: 0.7624 -- iter: 2144/3680
[A[ATraining Step: 758  | total loss: [1m[32m0.48872[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48872 - acc: 0.7705 -- iter: 2176/3680
[A[ATraining Step: 759  | total loss: [1m[32m0.47896[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47896 - acc: 0.7694 -- iter: 2208/3680
[A[ATraining Step: 760  | total loss: [1m[32m0.48535[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48535 - acc: 0.7694 -- iter: 2240/3680
[A[ATraining Step: 761  | total loss: [1m[32m0.47583[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47583 - acc: 0.7800 -- iter: 2272/3680
[A[ATraining Step: 762  | total loss: [1m[32m0.47860[0m[0m
[2K| Adam | epoch: 007 | loss: 0.47860 - acc: 0.7770 -- iter: 2304/3680
[A[ATraining Step: 763  | total loss: [1m[32m0.48119[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48119 - acc: 0.7775 -- iter: 2336/3680
[A[ATraining Step: 764  | total loss: [1m[32m0.48442[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48442 - acc: 0.7810 -- iter: 2368/3680
[A[ATraining Step: 765  | total loss: [1m[32m0.48156[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48156 - acc: 0.7810 -- iter: 2400/3680
[A[ATraining Step: 766  | total loss: [1m[32m0.48226[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48226 - acc: 0.7685 -- iter: 2432/3680
[A[ATraining Step: 767  | total loss: [1m[32m0.48604[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48604 - acc: 0.7573 -- iter: 2464/3680
[A[ATraining Step: 768  | total loss: [1m[32m0.49972[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49972 - acc: 0.7503 -- iter: 2496/3680
[A[ATraining Step: 769  | total loss: [1m[32m0.49901[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49901 - acc: 0.7440 -- iter: 2528/3680
[A[ATraining Step: 770  | total loss: [1m[32m0.48792[0m[0m
[2K| Adam | epoch: 007 | loss: 0.48792 - acc: 0.7571 -- iter: 2560/3680
[A[ATraining Step: 771  | total loss: [1m[32m0.49078[0m[0m
[2K| Adam | epoch: 007 | loss: 0.49078 - acc: 0.7564 -- iter: 2592/3680
[A[ATraining Step: 772  | total loss: [1m[32m0.50388[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50388 - acc: 0.7464 -- iter: 2624/3680
[A[ATraining Step: 773  | total loss: [1m[32m0.50771[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50771 - acc: 0.7468 -- iter: 2656/3680
[A[ATraining Step: 774  | total loss: [1m[32m0.50327[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50327 - acc: 0.7502 -- iter: 2688/3680
[A[ATraining Step: 775  | total loss: [1m[32m0.50995[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50995 - acc: 0.7439 -- iter: 2720/3680
[A[ATraining Step: 776  | total loss: [1m[32m0.51734[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51734 - acc: 0.7320 -- iter: 2752/3680
[A[ATraining Step: 777  | total loss: [1m[32m0.52678[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52678 - acc: 0.7307 -- iter: 2784/3680
[A[ATraining Step: 778  | total loss: [1m[32m0.53246[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53246 - acc: 0.7264 -- iter: 2816/3680
[A[ATraining Step: 779  | total loss: [1m[32m0.51368[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51368 - acc: 0.7413 -- iter: 2848/3680
[A[ATraining Step: 780  | total loss: [1m[32m0.55372[0m[0m
[2K| Adam | epoch: 007 | loss: 0.55372 - acc: 0.7265 -- iter: 2880/3680
[A[ATraining Step: 781  | total loss: [1m[32m0.54782[0m[0m
[2K| Adam | epoch: 007 | loss: 0.54782 - acc: 0.7320 -- iter: 2912/3680
[A[ATraining Step: 782  | total loss: [1m[32m0.54387[0m[0m
[2K| Adam | epoch: 007 | loss: 0.54387 - acc: 0.7369 -- iter: 2944/3680
[A[ATraining Step: 783  | total loss: [1m[32m0.53997[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53997 - acc: 0.7445 -- iter: 2976/3680
[A[ATraining Step: 784  | total loss: [1m[32m0.53867[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53867 - acc: 0.7421 -- iter: 3008/3680
[A[ATraining Step: 785  | total loss: [1m[32m0.53800[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53800 - acc: 0.7421 -- iter: 3040/3680
[A[ATraining Step: 786  | total loss: [1m[32m0.52758[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52758 - acc: 0.7460 -- iter: 3072/3680
[A[ATraining Step: 787  | total loss: [1m[32m0.52228[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52228 - acc: 0.7558 -- iter: 3104/3680
[A[ATraining Step: 788  | total loss: [1m[32m0.52915[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52915 - acc: 0.7458 -- iter: 3136/3680
[A[ATraining Step: 789  | total loss: [1m[32m0.53732[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53732 - acc: 0.7462 -- iter: 3168/3680
[A[ATraining Step: 790  | total loss: [1m[32m0.52304[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52304 - acc: 0.7529 -- iter: 3200/3680
[A[ATraining Step: 791  | total loss: [1m[32m0.51731[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51731 - acc: 0.7588 -- iter: 3232/3680
[A[ATraining Step: 792  | total loss: [1m[32m0.52443[0m[0m
[2K| Adam | epoch: 007 | loss: 0.52443 - acc: 0.7579 -- iter: 3264/3680
[A[ATraining Step: 793  | total loss: [1m[32m0.53416[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53416 - acc: 0.7509 -- iter: 3296/3680
[A[ATraining Step: 794  | total loss: [1m[32m0.53033[0m[0m
[2K| Adam | epoch: 007 | loss: 0.53033 - acc: 0.7571 -- iter: 3328/3680
[A[ATraining Step: 795  | total loss: [1m[32m0.51920[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51920 - acc: 0.7626 -- iter: 3360/3680
[A[ATraining Step: 796  | total loss: [1m[32m0.51944[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51944 - acc: 0.7551 -- iter: 3392/3680
[A[ATraining Step: 797  | total loss: [1m[32m0.51323[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51323 - acc: 0.7608 -- iter: 3424/3680
[A[ATraining Step: 798  | total loss: [1m[32m0.51053[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51053 - acc: 0.7660 -- iter: 3456/3680
[A[ATraining Step: 799  | total loss: [1m[32m0.51914[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51914 - acc: 0.7519 -- iter: 3488/3680
[A[ATraining Step: 800  | total loss: [1m[32m0.51049[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51049 - acc: 0.7548 | val_loss: 0.50628 - val_acc: 0.7503 -- iter: 3520/3680
[A[ATraining Step: 800  | total loss: [1m[32m0.51049[0m[0m
[2K| Adam | epoch: 007 | loss: 0.51049 - acc: 0.7548 | val_loss: 0.50628 - val_acc: 0.7503 -- iter: 3520/3680
--
Training Step: 801  | total loss: [1m[32m0.50499[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50499 - acc: 0.7575 -- iter: 3552/3680
[A[ATraining Step: 802  | total loss: [1m[32m0.50717[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50717 - acc: 0.7599 -- iter: 3584/3680
[A[ATraining Step: 803  | total loss: [1m[32m0.50945[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50945 - acc: 0.7589 -- iter: 3616/3680
[A[ATraining Step: 804  | total loss: [1m[32m0.50742[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50742 - acc: 0.7580 -- iter: 3648/3680
[A[ATraining Step: 805  | total loss: [1m[32m0.50188[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50188 - acc: 0.7527 | val_loss: 0.50661 - val_acc: 0.7470 -- iter: 3680/3680
[A[ATraining Step: 805  | total loss: [1m[32m0.50188[0m[0m
[2K| Adam | epoch: 007 | loss: 0.50188 - acc: 0.7527 | val_loss: 0.50661 - val_acc: 0.7470 -- iter: 3680/3680
--
Training Step: 806  | total loss: [1m[32m0.50059[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50059 - acc: 0.7527 -- iter: 0032/3680
[A[ATraining Step: 807  | total loss: [1m[32m0.51071[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51071 - acc: 0.7438 -- iter: 0064/3680
[A[ATraining Step: 808  | total loss: [1m[32m0.50707[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50707 - acc: 0.7438 -- iter: 0096/3680
[A[ATraining Step: 809  | total loss: [1m[32m0.50614[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50614 - acc: 0.7444 -- iter: 0128/3680
[A[ATraining Step: 810  | total loss: [1m[32m0.49846[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49846 - acc: 0.7574 -- iter: 0160/3680
[A[ATraining Step: 811  | total loss: [1m[32m0.49249[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49249 - acc: 0.7567 -- iter: 0192/3680
[A[ATraining Step: 812  | total loss: [1m[32m0.48539[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48539 - acc: 0.7654 -- iter: 0224/3680
[A[ATraining Step: 813  | total loss: [1m[32m0.48311[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48311 - acc: 0.7764 -- iter: 0256/3680
[A[ATraining Step: 814  | total loss: [1m[32m0.48232[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48232 - acc: 0.7720 -- iter: 0288/3680
[A[ATraining Step: 815  | total loss: [1m[32m0.48089[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48089 - acc: 0.7720 -- iter: 0320/3680
[A[ATraining Step: 816  | total loss: [1m[32m0.49256[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49256 - acc: 0.7573 -- iter: 0352/3680
[A[ATraining Step: 817  | total loss: [1m[32m0.48816[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48816 - acc: 0.7597 -- iter: 0384/3680
[A[ATraining Step: 818  | total loss: [1m[32m0.49235[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49235 - acc: 0.7493 -- iter: 0416/3680
[A[ATraining Step: 819  | total loss: [1m[32m0.51369[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51369 - acc: 0.7400 -- iter: 0448/3680
[A[ATraining Step: 820  | total loss: [1m[32m0.51337[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51337 - acc: 0.7379 -- iter: 0480/3680
[A[ATraining Step: 821  | total loss: [1m[32m0.50995[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50995 - acc: 0.7485 -- iter: 0512/3680
[A[ATraining Step: 822  | total loss: [1m[32m0.51048[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51048 - acc: 0.7518 -- iter: 0544/3680
[A[ATraining Step: 823  | total loss: [1m[32m0.52032[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52032 - acc: 0.7391 -- iter: 0576/3680
[A[ATraining Step: 824  | total loss: [1m[32m0.51495[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51495 - acc: 0.7402 -- iter: 0608/3680
[A[ATraining Step: 825  | total loss: [1m[32m0.51321[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51321 - acc: 0.7380 -- iter: 0640/3680
[A[ATraining Step: 826  | total loss: [1m[32m0.50588[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50588 - acc: 0.7486 -- iter: 0672/3680
[A[ATraining Step: 827  | total loss: [1m[32m0.49897[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49897 - acc: 0.7550 -- iter: 0704/3680
[A[ATraining Step: 828  | total loss: [1m[32m0.49966[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49966 - acc: 0.7576 -- iter: 0736/3680
[A[ATraining Step: 829  | total loss: [1m[32m0.49489[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49489 - acc: 0.7569 -- iter: 0768/3680
[A[ATraining Step: 830  | total loss: [1m[32m0.51324[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51324 - acc: 0.7431 -- iter: 0800/3680
[A[ATraining Step: 831  | total loss: [1m[32m0.51324[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51324 - acc: 0.7431 -- iter: 0832/3680
[A[ATraining Step: 832  | total loss: [1m[32m0.50980[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50980 - acc: 0.7438 -- iter: 0864/3680
[A[ATraining Step: 833  | total loss: [1m[32m0.51151[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51151 - acc: 0.7506 -- iter: 0896/3680
[A[ATraining Step: 834  | total loss: [1m[32m0.50524[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50524 - acc: 0.7568 -- iter: 0928/3680
[A[ATraining Step: 835  | total loss: [1m[32m0.50552[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50552 - acc: 0.7624 -- iter: 0960/3680
[A[ATraining Step: 836  | total loss: [1m[32m0.49900[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49900 - acc: 0.7674 -- iter: 0992/3680
[A[ATraining Step: 837  | total loss: [1m[32m0.49074[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49074 - acc: 0.7657 -- iter: 1024/3680
[A[ATraining Step: 838  | total loss: [1m[32m0.50315[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50315 - acc: 0.7547 -- iter: 1056/3680
[A[ATraining Step: 839  | total loss: [1m[32m0.50044[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50044 - acc: 0.7542 -- iter: 1088/3680
[A[ATraining Step: 840  | total loss: [1m[32m0.50417[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50417 - acc: 0.7538 -- iter: 1120/3680
[A[ATraining Step: 841  | total loss: [1m[32m0.50530[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50530 - acc: 0.7503 -- iter: 1152/3680
[A[ATraining Step: 842  | total loss: [1m[32m0.50145[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50145 - acc: 0.7565 -- iter: 1184/3680
[A[ATraining Step: 843  | total loss: [1m[32m0.49162[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49162 - acc: 0.7621 -- iter: 1216/3680
[A[ATraining Step: 844  | total loss: [1m[32m0.50676[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50676 - acc: 0.7453 -- iter: 1248/3680
[A[ATraining Step: 845  | total loss: [1m[32m0.49660[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49660 - acc: 0.7458 -- iter: 1280/3680
[A[ATraining Step: 846  | total loss: [1m[32m0.48659[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48659 - acc: 0.7493 -- iter: 1312/3680
[A[ATraining Step: 847  | total loss: [1m[32m0.47222[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47222 - acc: 0.7650 -- iter: 1344/3680
[A[ATraining Step: 848  | total loss: [1m[32m0.47586[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47586 - acc: 0.7698 -- iter: 1376/3680
[A[ATraining Step: 849  | total loss: [1m[32m0.47744[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47744 - acc: 0.7772 -- iter: 1408/3680
[A[ATraining Step: 850  | total loss: [1m[32m0.47578[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47578 - acc: 0.7807 -- iter: 1440/3680
[A[ATraining Step: 851  | total loss: [1m[32m0.47079[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47079 - acc: 0.7776 -- iter: 1472/3680
[A[ATraining Step: 852  | total loss: [1m[32m0.48093[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48093 - acc: 0.7624 -- iter: 1504/3680
[A[ATraining Step: 853  | total loss: [1m[32m0.47514[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47514 - acc: 0.7674 -- iter: 1536/3680
[A[ATraining Step: 854  | total loss: [1m[32m0.47972[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47972 - acc: 0.7656 -- iter: 1568/3680
[A[ATraining Step: 855  | total loss: [1m[32m0.48222[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48222 - acc: 0.7672 -- iter: 1600/3680
[A[ATraining Step: 856  | total loss: [1m[32m0.47485[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47485 - acc: 0.7717 -- iter: 1632/3680
[A[ATraining Step: 857  | total loss: [1m[32m0.48966[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48966 - acc: 0.7539 -- iter: 1664/3680
[A[ATraining Step: 858  | total loss: [1m[32m0.49153[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49153 - acc: 0.7535 -- iter: 1696/3680
[A[ATraining Step: 859  | total loss: [1m[32m0.49994[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49994 - acc: 0.7501 -- iter: 1728/3680
[A[ATraining Step: 860  | total loss: [1m[32m0.49134[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49134 - acc: 0.7594 -- iter: 1760/3680
[A[ATraining Step: 861  | total loss: [1m[32m0.48439[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48439 - acc: 0.7647 -- iter: 1792/3680
[A[ATraining Step: 862  | total loss: [1m[32m0.48597[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48597 - acc: 0.7601 -- iter: 1824/3680
[A[ATraining Step: 863  | total loss: [1m[32m0.50724[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50724 - acc: 0.7466 -- iter: 1856/3680
[A[ATraining Step: 864  | total loss: [1m[32m0.49928[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49928 - acc: 0.7501 -- iter: 1888/3680
[A[ATraining Step: 865  | total loss: [1m[32m0.50161[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50161 - acc: 0.7438 -- iter: 1920/3680
[A[ATraining Step: 866  | total loss: [1m[32m0.51344[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51344 - acc: 0.7319 -- iter: 1952/3680
[A[ATraining Step: 867  | total loss: [1m[32m0.51424[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51424 - acc: 0.7306 -- iter: 1984/3680
[A[ATraining Step: 868  | total loss: [1m[32m0.50276[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50276 - acc: 0.7357 -- iter: 2016/3680
[A[ATraining Step: 869  | total loss: [1m[32m0.50655[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50655 - acc: 0.7465 -- iter: 2048/3680
[A[ATraining Step: 870  | total loss: [1m[32m0.51620[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51620 - acc: 0.7500 -- iter: 2080/3680
[A[ATraining Step: 871  | total loss: [1m[32m0.51772[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51772 - acc: 0.7468 -- iter: 2112/3680
[A[ATraining Step: 872  | total loss: [1m[32m0.52490[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52490 - acc: 0.7409 -- iter: 2144/3680
[A[ATraining Step: 873  | total loss: [1m[32m0.51659[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51659 - acc: 0.7481 -- iter: 2176/3680
[A[ATraining Step: 874  | total loss: [1m[32m0.52471[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52471 - acc: 0.7514 -- iter: 2208/3680
[A[ATraining Step: 875  | total loss: [1m[32m0.52679[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52679 - acc: 0.7419 -- iter: 2240/3680
[A[ATraining Step: 876  | total loss: [1m[32m0.51875[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51875 - acc: 0.7521 -- iter: 2272/3680
[A[ATraining Step: 877  | total loss: [1m[32m0.51019[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51019 - acc: 0.7612 -- iter: 2304/3680
[A[ATraining Step: 878  | total loss: [1m[32m0.51104[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51104 - acc: 0.7539 -- iter: 2336/3680
[A[ATraining Step: 879  | total loss: [1m[32m0.50480[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50480 - acc: 0.7494 -- iter: 2368/3680
[A[ATraining Step: 880  | total loss: [1m[32m0.51109[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51109 - acc: 0.7494 -- iter: 2400/3680
[A[ATraining Step: 881  | total loss: [1m[32m0.51340[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51340 - acc: 0.7494 -- iter: 2432/3680
[A[ATraining Step: 882  | total loss: [1m[32m0.50892[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50892 - acc: 0.7557 -- iter: 2464/3680
[A[ATraining Step: 883  | total loss: [1m[32m0.52183[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52183 - acc: 0.7552 -- iter: 2496/3680
[A[ATraining Step: 884  | total loss: [1m[32m0.52288[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52288 - acc: 0.7484 -- iter: 2528/3680
[A[ATraining Step: 885  | total loss: [1m[32m0.53256[0m[0m
[2K| Adam | epoch: 008 | loss: 0.53256 - acc: 0.7517 -- iter: 2560/3680
[A[ATraining Step: 886  | total loss: [1m[32m0.52705[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52705 - acc: 0.7515 -- iter: 2592/3680
[A[ATraining Step: 887  | total loss: [1m[32m0.52717[0m[0m
[2K| Adam | epoch: 008 | loss: 0.52717 - acc: 0.7576 -- iter: 2624/3680
[A[ATraining Step: 888  | total loss: [1m[32m0.51326[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51326 - acc: 0.7662 -- iter: 2656/3680
[A[ATraining Step: 889  | total loss: [1m[32m0.49565[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49565 - acc: 0.7716 -- iter: 2688/3680
[A[ATraining Step: 890  | total loss: [1m[32m0.49565[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49565 - acc: 0.7716 -- iter: 2720/3680
[A[ATraining Step: 891  | total loss: [1m[32m0.49200[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49200 - acc: 0.7726 -- iter: 2752/3680
[A[ATraining Step: 892  | total loss: [1m[32m0.49640[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49640 - acc: 0.7765 -- iter: 2784/3680
[A[ATraining Step: 893  | total loss: [1m[32m0.49997[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49997 - acc: 0.7833 -- iter: 2816/3680
[A[ATraining Step: 894  | total loss: [1m[32m0.50269[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50269 - acc: 0.7768 -- iter: 2848/3680
[A[ATraining Step: 895  | total loss: [1m[32m0.48420[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48420 - acc: 0.7866 -- iter: 2880/3680
[A[ATraining Step: 896  | total loss: [1m[32m0.47976[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47976 - acc: 0.7923 -- iter: 2912/3680
[A[ATraining Step: 897  | total loss: [1m[32m0.47742[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47742 - acc: 0.7944 -- iter: 2944/3680
[A[ATraining Step: 898  | total loss: [1m[32m0.49464[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49464 - acc: 0.7837 -- iter: 2976/3680
[A[ATraining Step: 899  | total loss: [1m[32m0.49597[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49597 - acc: 0.7772 -- iter: 3008/3680
[A[ATraining Step: 900  | total loss: [1m[32m0.51507[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51507 - acc: 0.7588 | val_loss: 0.51069 - val_acc: 0.7481 -- iter: 3040/3680
[A[ATraining Step: 900  | total loss: [1m[32m0.51507[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51507 - acc: 0.7588 | val_loss: 0.51069 - val_acc: 0.7481 -- iter: 3040/3680
--
Training Step: 901  | total loss: [1m[32m0.51896[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51896 - acc: 0.7580 -- iter: 3072/3680
[A[ATraining Step: 902  | total loss: [1m[32m0.51453[0m[0m
[2K| Adam | epoch: 008 | loss: 0.51453 - acc: 0.7634 -- iter: 3104/3680
[A[ATraining Step: 903  | total loss: [1m[32m0.50597[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50597 - acc: 0.7777 -- iter: 3136/3680
[A[ATraining Step: 904  | total loss: [1m[32m0.49592[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49592 - acc: 0.7812 -- iter: 3168/3680
[A[ATraining Step: 905  | total loss: [1m[32m0.48912[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48912 - acc: 0.7749 -- iter: 3200/3680
[A[ATraining Step: 906  | total loss: [1m[32m0.48504[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48504 - acc: 0.7758 -- iter: 3232/3680
[A[ATraining Step: 907  | total loss: [1m[32m0.50002[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50002 - acc: 0.7758 -- iter: 3264/3680
[A[ATraining Step: 908  | total loss: [1m[32m0.50742[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50742 - acc: 0.7701 -- iter: 3296/3680
[A[ATraining Step: 909  | total loss: [1m[32m0.50286[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50286 - acc: 0.7744 -- iter: 3328/3680
[A[ATraining Step: 910  | total loss: [1m[32m0.49191[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49191 - acc: 0.7844 -- iter: 3360/3680
[A[ATraining Step: 911  | total loss: [1m[32m0.48404[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48404 - acc: 0.7810 -- iter: 3392/3680
[A[ATraining Step: 912  | total loss: [1m[32m0.47648[0m[0m
[2K| Adam | epoch: 008 | loss: 0.47648 - acc: 0.7873 -- iter: 3424/3680
[A[ATraining Step: 913  | total loss: [1m[32m0.48031[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48031 - acc: 0.7867 -- iter: 3456/3680
[A[ATraining Step: 914  | total loss: [1m[32m0.48462[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48462 - acc: 0.7736 -- iter: 3488/3680
[A[ATraining Step: 915  | total loss: [1m[32m0.48698[0m[0m
[2K| Adam | epoch: 008 | loss: 0.48698 - acc: 0.7681 -- iter: 3520/3680
[A[ATraining Step: 916  | total loss: [1m[32m0.49472[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49472 - acc: 0.7663 -- iter: 3552/3680
[A[ATraining Step: 917  | total loss: [1m[32m0.49815[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49815 - acc: 0.7647 -- iter: 3584/3680
[A[ATraining Step: 918  | total loss: [1m[32m0.49536[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49536 - acc: 0.7494 -- iter: 3616/3680
[A[ATraining Step: 919  | total loss: [1m[32m0.50302[0m[0m
[2K| Adam | epoch: 008 | loss: 0.50302 - acc: 0.7494 -- iter: 3648/3680
[A[ATraining Step: 920  | total loss: [1m[32m0.49496[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49496 - acc: 0.7620 | val_loss: 0.49874 - val_acc: 0.7611 -- iter: 3680/3680
[A[ATraining Step: 920  | total loss: [1m[32m0.49496[0m[0m
[2K| Adam | epoch: 008 | loss: 0.49496 - acc: 0.7620 | val_loss: 0.49874 - val_acc: 0.7611 -- iter: 3680/3680
--
Training Step: 921  | total loss: [1m[32m0.49013[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49013 - acc: 0.7608 -- iter: 0032/3680
[A[ATraining Step: 922  | total loss: [1m[32m0.49124[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49124 - acc: 0.7584 -- iter: 0064/3680
[A[ATraining Step: 923  | total loss: [1m[32m0.49237[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49237 - acc: 0.7584 -- iter: 0096/3680
[A[ATraining Step: 924  | total loss: [1m[32m0.48713[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48713 - acc: 0.7576 -- iter: 0128/3680
[A[ATraining Step: 925  | total loss: [1m[32m0.50063[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50063 - acc: 0.7381 -- iter: 0160/3680
[A[ATraining Step: 926  | total loss: [1m[32m0.50432[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50432 - acc: 0.7361 -- iter: 0192/3680
[A[ATraining Step: 927  | total loss: [1m[32m0.49898[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49898 - acc: 0.7375 -- iter: 0224/3680
[A[ATraining Step: 928  | total loss: [1m[32m0.49744[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49744 - acc: 0.7356 -- iter: 0256/3680
[A[ATraining Step: 929  | total loss: [1m[32m0.49640[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49640 - acc: 0.7371 -- iter: 0288/3680
[A[ATraining Step: 930  | total loss: [1m[32m0.50003[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50003 - acc: 0.7352 -- iter: 0320/3680
[A[ATraining Step: 931  | total loss: [1m[32m0.49203[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49203 - acc: 0.7367 -- iter: 0352/3680
[A[ATraining Step: 932  | total loss: [1m[32m0.48997[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48997 - acc: 0.7380 -- iter: 0384/3680
[A[ATraining Step: 933  | total loss: [1m[32m0.49697[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49697 - acc: 0.7392 -- iter: 0416/3680
[A[ATraining Step: 934  | total loss: [1m[32m0.49082[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49082 - acc: 0.7434 -- iter: 0448/3680
[A[ATraining Step: 935  | total loss: [1m[32m0.48937[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48937 - acc: 0.7472 -- iter: 0480/3680
[A[ATraining Step: 936  | total loss: [1m[32m0.48715[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48715 - acc: 0.7475 -- iter: 0512/3680
[A[ATraining Step: 937  | total loss: [1m[32m0.49248[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49248 - acc: 0.7477 -- iter: 0544/3680
[A[ATraining Step: 938  | total loss: [1m[32m0.49762[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49762 - acc: 0.7448 -- iter: 0576/3680
[A[ATraining Step: 939  | total loss: [1m[32m0.50736[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50736 - acc: 0.7422 -- iter: 0608/3680
[A[ATraining Step: 940  | total loss: [1m[32m0.50637[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50637 - acc: 0.7336 -- iter: 0640/3680
[A[ATraining Step: 941  | total loss: [1m[32m0.52343[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52343 - acc: 0.7290 -- iter: 0672/3680
[A[ATraining Step: 942  | total loss: [1m[32m0.51994[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51994 - acc: 0.7342 -- iter: 0704/3680
[A[ATraining Step: 943  | total loss: [1m[32m0.52296[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52296 - acc: 0.7233 -- iter: 0736/3680
[A[ATraining Step: 944  | total loss: [1m[32m0.50904[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50904 - acc: 0.7416 -- iter: 0768/3680
[A[ATraining Step: 945  | total loss: [1m[32m0.50823[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50823 - acc: 0.7425 -- iter: 0800/3680
[A[ATraining Step: 946  | total loss: [1m[32m0.50120[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50120 - acc: 0.7588 -- iter: 0832/3680
[A[ATraining Step: 947  | total loss: [1m[32m0.52138[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52138 - acc: 0.7517 -- iter: 0864/3680
[A[ATraining Step: 948  | total loss: [1m[32m0.51477[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51477 - acc: 0.7547 -- iter: 0896/3680
[A[ATraining Step: 949  | total loss: [1m[32m0.51291[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51291 - acc: 0.7573 -- iter: 0928/3680
[A[ATraining Step: 950  | total loss: [1m[32m0.50220[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50220 - acc: 0.7628 -- iter: 0960/3680
[A[ATraining Step: 951  | total loss: [1m[32m0.49453[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49453 - acc: 0.7678 -- iter: 0992/3680
[A[ATraining Step: 952  | total loss: [1m[32m0.49675[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49675 - acc: 0.7629 -- iter: 1024/3680
[A[ATraining Step: 953  | total loss: [1m[32m0.50136[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50136 - acc: 0.7616 -- iter: 1056/3680
[A[ATraining Step: 954  | total loss: [1m[32m0.50681[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50681 - acc: 0.7604 -- iter: 1088/3680
[A[ATraining Step: 955  | total loss: [1m[32m0.50353[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50353 - acc: 0.7688 -- iter: 1120/3680
[A[ATraining Step: 956  | total loss: [1m[32m0.50470[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50470 - acc: 0.7700 -- iter: 1152/3680
[A[ATraining Step: 957  | total loss: [1m[32m0.50201[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50201 - acc: 0.7649 -- iter: 1184/3680
[A[ATraining Step: 958  | total loss: [1m[32m0.49558[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49558 - acc: 0.7665 -- iter: 1216/3680
[A[ATraining Step: 959  | total loss: [1m[32m0.49933[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49933 - acc: 0.7711 -- iter: 1248/3680
[A[ATraining Step: 960  | total loss: [1m[32m0.50597[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50597 - acc: 0.7628 -- iter: 1280/3680
[A[ATraining Step: 961  | total loss: [1m[32m0.51862[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51862 - acc: 0.7584 -- iter: 1312/3680
[A[ATraining Step: 962  | total loss: [1m[32m0.51680[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51680 - acc: 0.7544 -- iter: 1344/3680
[A[ATraining Step: 963  | total loss: [1m[32m0.50770[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50770 - acc: 0.7508 -- iter: 1376/3680
[A[ATraining Step: 964  | total loss: [1m[32m0.49096[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49096 - acc: 0.7601 -- iter: 1408/3680
[A[ATraining Step: 965  | total loss: [1m[32m0.48225[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48225 - acc: 0.7685 -- iter: 1440/3680
[A[ATraining Step: 966  | total loss: [1m[32m0.48684[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48684 - acc: 0.7635 -- iter: 1472/3680
[A[ATraining Step: 967  | total loss: [1m[32m0.49331[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49331 - acc: 0.7528 -- iter: 1504/3680
[A[ATraining Step: 968  | total loss: [1m[32m0.48729[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48729 - acc: 0.7588 -- iter: 1536/3680
[A[ATraining Step: 969  | total loss: [1m[32m0.48595[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48595 - acc: 0.7641 -- iter: 1568/3680
[A[ATraining Step: 970  | total loss: [1m[32m0.49133[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49133 - acc: 0.7627 -- iter: 1600/3680
[A[ATraining Step: 971  | total loss: [1m[32m0.49387[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49387 - acc: 0.7739 -- iter: 1632/3680
[A[ATraining Step: 972  | total loss: [1m[32m0.50136[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50136 - acc: 0.7653 -- iter: 1664/3680
[A[ATraining Step: 973  | total loss: [1m[32m0.49179[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49179 - acc: 0.7763 -- iter: 1696/3680
[A[ATraining Step: 974  | total loss: [1m[32m0.51168[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51168 - acc: 0.7611 -- iter: 1728/3680
[A[ATraining Step: 975  | total loss: [1m[32m0.51973[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51973 - acc: 0.7569 -- iter: 1760/3680
[A[ATraining Step: 976  | total loss: [1m[32m0.51858[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51858 - acc: 0.7625 -- iter: 1792/3680
[A[ATraining Step: 977  | total loss: [1m[32m0.50732[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50732 - acc: 0.7643 -- iter: 1824/3680
[A[ATraining Step: 978  | total loss: [1m[32m0.49524[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49524 - acc: 0.7723 -- iter: 1856/3680
[A[ATraining Step: 979  | total loss: [1m[32m0.49241[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49241 - acc: 0.7794 -- iter: 1888/3680
[A[ATraining Step: 980  | total loss: [1m[32m0.50175[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50175 - acc: 0.7546 -- iter: 1920/3680
[A[ATraining Step: 981  | total loss: [1m[32m0.51283[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51283 - acc: 0.7417 -- iter: 1952/3680
[A[ATraining Step: 982  | total loss: [1m[32m0.51187[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51187 - acc: 0.7487 -- iter: 1984/3680
[A[ATraining Step: 983  | total loss: [1m[32m0.51374[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51374 - acc: 0.7457 -- iter: 2016/3680
[A[ATraining Step: 984  | total loss: [1m[32m0.51335[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51335 - acc: 0.7503 -- iter: 2048/3680
[A[ATraining Step: 985  | total loss: [1m[32m0.49651[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49651 - acc: 0.7503 -- iter: 2080/3680
[A[ATraining Step: 986  | total loss: [1m[32m0.49790[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49790 - acc: 0.7503 -- iter: 2112/3680
[A[ATraining Step: 987  | total loss: [1m[32m0.49479[0m[0m
[2K| Adam | epoch: 009 | loss: 0.49479 - acc: 0.7534 -- iter: 2144/3680
[A[ATraining Step: 988  | total loss: [1m[32m0.50463[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50463 - acc: 0.7499 -- iter: 2176/3680
[A[ATraining Step: 989  | total loss: [1m[32m0.51280[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51280 - acc: 0.7405 -- iter: 2208/3680
[A[ATraining Step: 990  | total loss: [1m[32m0.50587[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50587 - acc: 0.7446 -- iter: 2240/3680
[A[ATraining Step: 991  | total loss: [1m[32m0.48917[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48917 - acc: 0.7576 -- iter: 2272/3680
[A[ATraining Step: 992  | total loss: [1m[32m0.48005[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48005 - acc: 0.7663 -- iter: 2304/3680
[A[ATraining Step: 993  | total loss: [1m[32m0.47161[0m[0m
[2K| Adam | epoch: 009 | loss: 0.47161 - acc: 0.7709 -- iter: 2336/3680
[A[ATraining Step: 994  | total loss: [1m[32m0.46691[0m[0m
[2K| Adam | epoch: 009 | loss: 0.46691 - acc: 0.7688 -- iter: 2368/3680
[A[ATraining Step: 995  | total loss: [1m[32m0.47575[0m[0m
[2K| Adam | epoch: 009 | loss: 0.47575 - acc: 0.7607 -- iter: 2400/3680
[A[ATraining Step: 996  | total loss: [1m[32m0.46256[0m[0m
[2K| Adam | epoch: 009 | loss: 0.46256 - acc: 0.7752 -- iter: 2432/3680
[A[ATraining Step: 997  | total loss: [1m[32m0.48295[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48295 - acc: 0.7571 -- iter: 2464/3680
[A[ATraining Step: 998  | total loss: [1m[32m0.48245[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48245 - acc: 0.7626 -- iter: 2496/3680
[A[ATraining Step: 999  | total loss: [1m[32m0.48449[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48449 - acc: 0.7520 -- iter: 2528/3680
[A[ATraining Step: 1000  | total loss: [1m[32m0.48712[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48712 - acc: 0.7518 | val_loss: 0.49508 - val_acc: 0.7557 -- iter: 2560/3680
[A[ATraining Step: 1000  | total loss: [1m[32m0.48712[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48712 - acc: 0.7518 | val_loss: 0.49508 - val_acc: 0.7557 -- iter: 2560/3680
--
Training Step: 1001  | total loss: [1m[32m0.48319[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48319 - acc: 0.7579 -- iter: 2592/3680
[A[ATraining Step: 1002  | total loss: [1m[32m0.47189[0m[0m
[2K| Adam | epoch: 009 | loss: 0.47189 - acc: 0.7696 -- iter: 2624/3680
[A[ATraining Step: 1003  | total loss: [1m[32m0.47700[0m[0m
[2K| Adam | epoch: 009 | loss: 0.47700 - acc: 0.7707 -- iter: 2656/3680
[A[ATraining Step: 1004  | total loss: [1m[32m0.46650[0m[0m
[2K| Adam | epoch: 009 | loss: 0.46650 - acc: 0.7749 -- iter: 2688/3680
[A[ATraining Step: 1005  | total loss: [1m[32m0.47537[0m[0m
[2K| Adam | epoch: 009 | loss: 0.47537 - acc: 0.7599 -- iter: 2720/3680
[A[ATraining Step: 1006  | total loss: [1m[32m0.48439[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48439 - acc: 0.7558 -- iter: 2752/3680
[A[ATraining Step: 1007  | total loss: [1m[32m0.48180[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48180 - acc: 0.7615 -- iter: 2784/3680
[A[ATraining Step: 1008  | total loss: [1m[32m0.47566[0m[0m
[2K| Adam | epoch: 009 | loss: 0.47566 - acc: 0.7603 -- iter: 2816/3680
[A[ATraining Step: 1009  | total loss: [1m[32m0.46644[0m[0m
[2K| Adam | epoch: 009 | loss: 0.46644 - acc: 0.7709 -- iter: 2848/3680
[A[ATraining Step: 1010  | total loss: [1m[32m0.46644[0m[0m
[2K| Adam | epoch: 009 | loss: 0.46644 - acc: 0.7709 -- iter: 2880/3680
[A[ATraining Step: 1011  | total loss: [1m[32m0.48131[0m[0m
[2K| Adam | epoch: 009 | loss: 0.48131 - acc: 0.7657 -- iter: 2912/3680
[A[ATraining Step: 1012  | total loss: [1m[32m0.51945[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51945 - acc: 0.7516 -- iter: 2944/3680
[A[ATraining Step: 1013  | total loss: [1m[32m0.52166[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52166 - acc: 0.7514 -- iter: 2976/3680
[A[ATraining Step: 1014  | total loss: [1m[32m0.52976[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52976 - acc: 0.7388 -- iter: 3008/3680
[A[ATraining Step: 1015  | total loss: [1m[32m0.51270[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51270 - acc: 0.7506 -- iter: 3040/3680
[A[ATraining Step: 1016  | total loss: [1m[32m0.51270[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51270 - acc: 0.7506 -- iter: 3072/3680
[A[ATraining Step: 1017  | total loss: [1m[32m0.52910[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52910 - acc: 0.7537 -- iter: 3104/3680
[A[ATraining Step: 1018  | total loss: [1m[32m0.52873[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52873 - acc: 0.7471 -- iter: 3136/3680
[A[ATraining Step: 1019  | total loss: [1m[32m0.51565[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51565 - acc: 0.7598 -- iter: 3168/3680
[A[ATraining Step: 1020  | total loss: [1m[32m0.50073[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50073 - acc: 0.7682 -- iter: 3200/3680
[A[ATraining Step: 1021  | total loss: [1m[32m0.50072[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50072 - acc: 0.7570 -- iter: 3232/3680
[A[ATraining Step: 1022  | total loss: [1m[32m0.50262[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50262 - acc: 0.7532 -- iter: 3264/3680
[A[ATraining Step: 1023  | total loss: [1m[32m0.50669[0m[0m
[2K| Adam | epoch: 009 | loss: 0.50669 - acc: 0.7529 -- iter: 3296/3680
[A[ATraining Step: 1024  | total loss: [1m[32m0.51422[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51422 - acc: 0.7432 -- iter: 3328/3680
[A[ATraining Step: 1025  | total loss: [1m[32m0.51920[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51920 - acc: 0.7439 -- iter: 3360/3680
[A[ATraining Step: 1026  | total loss: [1m[32m0.51677[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51677 - acc: 0.7476 -- iter: 3392/3680
[A[ATraining Step: 1027  | total loss: [1m[32m0.51483[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51483 - acc: 0.7356 -- iter: 3424/3680
[A[ATraining Step: 1028  | total loss: [1m[32m0.52138[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52138 - acc: 0.7356 -- iter: 3456/3680
[A[ATraining Step: 1029  | total loss: [1m[32m0.51504[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51504 - acc: 0.7433 -- iter: 3488/3680
[A[ATraining Step: 1030  | total loss: [1m[32m0.52025[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52025 - acc: 0.7471 -- iter: 3520/3680
[A[ATraining Step: 1031  | total loss: [1m[32m0.51561[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51561 - acc: 0.7536 -- iter: 3552/3680
[A[ATraining Step: 1032  | total loss: [1m[32m0.51986[0m[0m
[2K| Adam | epoch: 009 | loss: 0.51986 - acc: 0.7439 -- iter: 3584/3680
[A[ATraining Step: 1033  | total loss: [1m[32m0.52100[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52100 - acc: 0.7445 -- iter: 3616/3680
[A[ATraining Step: 1034  | total loss: [1m[32m0.52732[0m[0m
[2K| Adam | epoch: 009 | loss: 0.52732 - acc: 0.7419 -- iter: 3648/3680
[A[ATraining Step: 1035  | total loss: [1m[32m0.54027[0m[0m
[2K| Adam | epoch: 009 | loss: 0.54027 - acc: 0.7288 | val_loss: 0.49066 - val_acc: 0.7666 -- iter: 3680/3680
[A[ATraining Step: 1035  | total loss: [1m[32m0.54027[0m[0m
[2K| Adam | epoch: 009 | loss: 0.54027 - acc: 0.7288 | val_loss: 0.49066 - val_acc: 0.7666 -- iter: 3680/3680
--
Training Step: 1036  | total loss: [1m[32m0.54027[0m[0m
[2K| Adam | epoch: 010 | loss: 0.54027 - acc: 0.7288 -- iter: 0032/3680
[A[ATraining Step: 1037  | total loss: [1m[32m0.53426[0m[0m
[2K| Adam | epoch: 010 | loss: 0.53426 - acc: 0.7309 -- iter: 0064/3680
[A[ATraining Step: 1038  | total loss: [1m[32m0.53090[0m[0m
[2K| Adam | epoch: 010 | loss: 0.53090 - acc: 0.7359 -- iter: 0096/3680
[A[ATraining Step: 1039  | total loss: [1m[32m0.52232[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52232 - acc: 0.7405 -- iter: 0128/3680
[A[ATraining Step: 1040  | total loss: [1m[32m0.52006[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52006 - acc: 0.7477 -- iter: 0160/3680
[A[ATraining Step: 1041  | total loss: [1m[32m0.51332[0m[0m
[2K| Adam | epoch: 010 | loss: 0.51332 - acc: 0.7541 -- iter: 0192/3680
[A[ATraining Step: 1042  | total loss: [1m[32m0.52303[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52303 - acc: 0.7537 -- iter: 0224/3680
[A[ATraining Step: 1043  | total loss: [1m[32m0.52056[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52056 - acc: 0.7565 -- iter: 0256/3680
[A[ATraining Step: 1044  | total loss: [1m[32m0.52901[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52901 - acc: 0.7465 -- iter: 0288/3680
[A[ATraining Step: 1045  | total loss: [1m[32m0.54083[0m[0m
[2K| Adam | epoch: 010 | loss: 0.54083 - acc: 0.7406 -- iter: 0320/3680
[A[ATraining Step: 1046  | total loss: [1m[32m0.52045[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52045 - acc: 0.7483 -- iter: 0352/3680
[A[ATraining Step: 1047  | total loss: [1m[32m0.52045[0m[0m
[2K| Adam | epoch: 010 | loss: 0.52045 - acc: 0.7483 -- iter: 0384/3680
[A[ATraining Step: 1048  | total loss: [1m[32m0.51285[0m[0m
[2K| Adam | epoch: 010 | loss: 0.51285 - acc: 0.7547 -- iter: 0416/3680
[A[ATraining Step: 1049  | total loss: [1m[32m0.49789[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49789 - acc: 0.7667 -- iter: 0448/3680
[A[ATraining Step: 1050  | total loss: [1m[32m0.49362[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49362 - acc: 0.7619 -- iter: 0480/3680
[A[ATraining Step: 1051  | total loss: [1m[32m0.47653[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47653 - acc: 0.7765 -- iter: 0512/3680
[A[ATraining Step: 1052  | total loss: [1m[32m0.48035[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48035 - acc: 0.7765 -- iter: 0544/3680
[A[ATraining Step: 1053  | total loss: [1m[32m0.49489[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49489 - acc: 0.7614 -- iter: 0576/3680
[A[ATraining Step: 1054  | total loss: [1m[32m0.51066[0m[0m
[2K| Adam | epoch: 010 | loss: 0.51066 - acc: 0.7571 -- iter: 0608/3680
[A[ATraining Step: 1055  | total loss: [1m[32m0.49972[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49972 - acc: 0.7627 -- iter: 0640/3680
[A[ATraining Step: 1056  | total loss: [1m[32m0.49362[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49362 - acc: 0.7614 -- iter: 0672/3680
[A[ATraining Step: 1057  | total loss: [1m[32m0.49050[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49050 - acc: 0.7624 -- iter: 0704/3680
[A[ATraining Step: 1058  | total loss: [1m[32m0.49626[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49626 - acc: 0.7624 -- iter: 0736/3680
[A[ATraining Step: 1059  | total loss: [1m[32m0.49299[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49299 - acc: 0.7705 -- iter: 0768/3680
[A[ATraining Step: 1060  | total loss: [1m[32m0.48515[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48515 - acc: 0.7716 -- iter: 0800/3680
[A[ATraining Step: 1061  | total loss: [1m[32m0.48193[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48193 - acc: 0.7694 -- iter: 0832/3680
[A[ATraining Step: 1062  | total loss: [1m[32m0.48609[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48609 - acc: 0.7737 -- iter: 0864/3680
[A[ATraining Step: 1063  | total loss: [1m[32m0.49277[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49277 - acc: 0.7651 -- iter: 0896/3680
[A[ATraining Step: 1064  | total loss: [1m[32m0.49778[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49778 - acc: 0.7636 -- iter: 0928/3680
[A[ATraining Step: 1065  | total loss: [1m[32m0.48941[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48941 - acc: 0.7716 -- iter: 0960/3680
[A[ATraining Step: 1066  | total loss: [1m[32m0.49473[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49473 - acc: 0.7772 -- iter: 0992/3680
[A[ATraining Step: 1067  | total loss: [1m[32m0.48468[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48468 - acc: 0.7772 -- iter: 1024/3680
[A[ATraining Step: 1068  | total loss: [1m[32m0.47617[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47617 - acc: 0.7838 -- iter: 1056/3680
[A[ATraining Step: 1069  | total loss: [1m[32m0.47012[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47012 - acc: 0.7930 -- iter: 1088/3680
[A[ATraining Step: 1070  | total loss: [1m[32m0.47795[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47795 - acc: 0.7730 -- iter: 1120/3680
[A[ATraining Step: 1071  | total loss: [1m[32m0.50089[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50089 - acc: 0.7582 -- iter: 1152/3680
[A[ATraining Step: 1072  | total loss: [1m[32m0.49520[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49520 - acc: 0.7637 -- iter: 1184/3680
[A[ATraining Step: 1073  | total loss: [1m[32m0.49649[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49649 - acc: 0.7560 -- iter: 1216/3680
[A[ATraining Step: 1074  | total loss: [1m[32m0.49625[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49625 - acc: 0.7586 -- iter: 1248/3680
[A[ATraining Step: 1075  | total loss: [1m[32m0.49309[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49309 - acc: 0.7640 -- iter: 1280/3680
[A[ATraining Step: 1076  | total loss: [1m[32m0.50543[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50543 - acc: 0.7501 -- iter: 1312/3680
[A[ATraining Step: 1077  | total loss: [1m[32m0.50009[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50009 - acc: 0.7501 -- iter: 1344/3680
[A[ATraining Step: 1078  | total loss: [1m[32m0.51144[0m[0m
[2K| Adam | epoch: 010 | loss: 0.51144 - acc: 0.7344 -- iter: 1376/3680
[A[ATraining Step: 1079  | total loss: [1m[32m0.50774[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50774 - acc: 0.7422 -- iter: 1408/3680
[A[ATraining Step: 1080  | total loss: [1m[32m0.50678[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50678 - acc: 0.7493 -- iter: 1440/3680
[A[ATraining Step: 1081  | total loss: [1m[32m0.50764[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50764 - acc: 0.7525 -- iter: 1472/3680
[A[ATraining Step: 1082  | total loss: [1m[32m0.50266[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50266 - acc: 0.7553 -- iter: 1504/3680
[A[ATraining Step: 1083  | total loss: [1m[32m0.49498[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49498 - acc: 0.7642 -- iter: 1536/3680
[A[ATraining Step: 1084  | total loss: [1m[32m0.50319[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50319 - acc: 0.7534 -- iter: 1568/3680
[A[ATraining Step: 1085  | total loss: [1m[32m0.49387[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49387 - acc: 0.7593 -- iter: 1600/3680
[A[ATraining Step: 1086  | total loss: [1m[32m0.49099[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49099 - acc: 0.7552 -- iter: 1632/3680
[A[ATraining Step: 1087  | total loss: [1m[32m0.49544[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49544 - acc: 0.7485 -- iter: 1664/3680
[A[ATraining Step: 1088  | total loss: [1m[32m0.49091[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49091 - acc: 0.7549 -- iter: 1696/3680
[A[ATraining Step: 1089  | total loss: [1m[32m0.47932[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47932 - acc: 0.7606 -- iter: 1728/3680
[A[ATraining Step: 1090  | total loss: [1m[32m0.48547[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48547 - acc: 0.7627 -- iter: 1760/3680
[A[ATraining Step: 1091  | total loss: [1m[32m0.47315[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47315 - acc: 0.7677 -- iter: 1792/3680
[A[ATraining Step: 1092  | total loss: [1m[32m0.46927[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46927 - acc: 0.7722 -- iter: 1824/3680
[A[ATraining Step: 1093  | total loss: [1m[32m0.49687[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49687 - acc: 0.7543 -- iter: 1856/3680
[A[ATraining Step: 1094  | total loss: [1m[32m0.49311[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49311 - acc: 0.7601 -- iter: 1888/3680
[A[ATraining Step: 1095  | total loss: [1m[32m0.51096[0m[0m
[2K| Adam | epoch: 010 | loss: 0.51096 - acc: 0.7529 -- iter: 1920/3680
[A[ATraining Step: 1096  | total loss: [1m[32m0.49374[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49374 - acc: 0.7651 -- iter: 1952/3680
[A[ATraining Step: 1097  | total loss: [1m[32m0.48424[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48424 - acc: 0.7636 -- iter: 1984/3680
[A[ATraining Step: 1098  | total loss: [1m[32m0.47539[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47539 - acc: 0.7716 -- iter: 2016/3680
[A[ATraining Step: 1099  | total loss: [1m[32m0.46708[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46708 - acc: 0.7726 -- iter: 2048/3680
[A[ATraining Step: 1100  | total loss: [1m[32m0.46376[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46376 - acc: 0.7703 | val_loss: 0.48781 - val_acc: 0.7535 -- iter: 2080/3680
[A[ATraining Step: 1100  | total loss: [1m[32m0.46376[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46376 - acc: 0.7703 | val_loss: 0.48781 - val_acc: 0.7535 -- iter: 2080/3680
--
Training Step: 1101  | total loss: [1m[32m0.46851[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46851 - acc: 0.7714 -- iter: 2112/3680
[A[ATraining Step: 1102  | total loss: [1m[32m0.47117[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47117 - acc: 0.7599 -- iter: 2144/3680
[A[ATraining Step: 1103  | total loss: [1m[32m0.46899[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46899 - acc: 0.7651 -- iter: 2176/3680
[A[ATraining Step: 1104  | total loss: [1m[32m0.46903[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46903 - acc: 0.7636 -- iter: 2208/3680
[A[ATraining Step: 1105  | total loss: [1m[32m0.46468[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46468 - acc: 0.7716 -- iter: 2240/3680
[A[ATraining Step: 1106  | total loss: [1m[32m0.46860[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46860 - acc: 0.7664 -- iter: 2272/3680
[A[ATraining Step: 1107  | total loss: [1m[32m0.46955[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46955 - acc: 0.7678 -- iter: 2304/3680
[A[ATraining Step: 1108  | total loss: [1m[32m0.48501[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48501 - acc: 0.7692 -- iter: 2336/3680
[A[ATraining Step: 1109  | total loss: [1m[32m0.47360[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47360 - acc: 0.7766 -- iter: 2368/3680
[A[ATraining Step: 1110  | total loss: [1m[32m0.47382[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47382 - acc: 0.7709 -- iter: 2400/3680
[A[ATraining Step: 1111  | total loss: [1m[32m0.46198[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46198 - acc: 0.7781 -- iter: 2432/3680
[A[ATraining Step: 1112  | total loss: [1m[32m0.46198[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46198 - acc: 0.7878 -- iter: 2464/3680
[A[ATraining Step: 1113  | total loss: [1m[32m0.46517[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46517 - acc: 0.7840 -- iter: 2496/3680
[A[ATraining Step: 1114  | total loss: [1m[32m0.47158[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47158 - acc: 0.7838 -- iter: 2528/3680
[A[ATraining Step: 1115  | total loss: [1m[32m0.46437[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46437 - acc: 0.7898 -- iter: 2560/3680
[A[ATraining Step: 1116  | total loss: [1m[32m0.48087[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48087 - acc: 0.7702 -- iter: 2592/3680
[A[ATraining Step: 1117  | total loss: [1m[32m0.48200[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48200 - acc: 0.7650 -- iter: 2624/3680
[A[ATraining Step: 1118  | total loss: [1m[32m0.45710[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45710 - acc: 0.7729 -- iter: 2656/3680
[A[ATraining Step: 1119  | total loss: [1m[32m0.45710[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45710 - acc: 0.7706 -- iter: 2688/3680
[A[ATraining Step: 1120  | total loss: [1m[32m0.44859[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44859 - acc: 0.7870 -- iter: 2720/3680
[A[ATraining Step: 1121  | total loss: [1m[32m0.44647[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44647 - acc: 0.7989 -- iter: 2752/3680
[A[ATraining Step: 1122  | total loss: [1m[32m0.44034[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44034 - acc: 0.7989 -- iter: 2784/3680
[A[ATraining Step: 1123  | total loss: [1m[32m0.44343[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44343 - acc: 0.7972 -- iter: 2816/3680
[A[ATraining Step: 1124  | total loss: [1m[32m0.43572[0m[0m
[2K| Adam | epoch: 010 | loss: 0.43572 - acc: 0.7924 -- iter: 2848/3680
[A[ATraining Step: 1125  | total loss: [1m[32m0.43871[0m[0m
[2K| Adam | epoch: 010 | loss: 0.43871 - acc: 0.7944 -- iter: 2880/3680
[A[ATraining Step: 1126  | total loss: [1m[32m0.42997[0m[0m
[2K| Adam | epoch: 010 | loss: 0.42997 - acc: 0.7994 -- iter: 2912/3680
[A[ATraining Step: 1127  | total loss: [1m[32m0.44273[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44273 - acc: 0.7882 -- iter: 2944/3680
[A[ATraining Step: 1128  | total loss: [1m[32m0.42726[0m[0m
[2K| Adam | epoch: 010 | loss: 0.42726 - acc: 0.8000 -- iter: 2976/3680
[A[ATraining Step: 1129  | total loss: [1m[32m0.42216[0m[0m
[2K| Adam | epoch: 010 | loss: 0.42216 - acc: 0.8044 -- iter: 3008/3680
[A[ATraining Step: 1130  | total loss: [1m[32m0.42383[0m[0m
[2K| Adam | epoch: 010 | loss: 0.42383 - acc: 0.8083 -- iter: 3040/3680
[A[ATraining Step: 1131  | total loss: [1m[32m0.43878[0m[0m
[2K| Adam | epoch: 010 | loss: 0.43878 - acc: 0.8056 -- iter: 3072/3680
[A[ATraining Step: 1132  | total loss: [1m[32m0.44800[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44800 - acc: 0.7969 -- iter: 3104/3680
[A[ATraining Step: 1133  | total loss: [1m[32m0.44750[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44750 - acc: 0.7891 -- iter: 3136/3680
[A[ATraining Step: 1134  | total loss: [1m[32m0.44926[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44926 - acc: 0.7852 -- iter: 3168/3680
[A[ATraining Step: 1135  | total loss: [1m[32m0.44893[0m[0m
[2K| Adam | epoch: 010 | loss: 0.44893 - acc: 0.7817 -- iter: 3200/3680
[A[ATraining Step: 1136  | total loss: [1m[32m0.45842[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45842 - acc: 0.7754 -- iter: 3232/3680
[A[ATraining Step: 1137  | total loss: [1m[32m0.45965[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45965 - acc: 0.7824 -- iter: 3264/3680
[A[ATraining Step: 1138  | total loss: [1m[32m0.45965[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45965 - acc: 0.7824 -- iter: 3296/3680
[A[ATraining Step: 1139  | total loss: [1m[32m0.45320[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45320 - acc: 0.7886 -- iter: 3328/3680
[A[ATraining Step: 1140  | total loss: [1m[32m0.46022[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46022 - acc: 0.7816 -- iter: 3360/3680
[A[ATraining Step: 1141  | total loss: [1m[32m0.46143[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46143 - acc: 0.7690 -- iter: 3392/3680
[A[ATraining Step: 1142  | total loss: [1m[32m0.45615[0m[0m
[2K| Adam | epoch: 010 | loss: 0.45615 - acc: 0.7703 -- iter: 3424/3680
[A[ATraining Step: 1143  | total loss: [1m[32m0.47616[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47616 - acc: 0.7651 -- iter: 3456/3680
[A[ATraining Step: 1144  | total loss: [1m[32m0.46868[0m[0m
[2K| Adam | epoch: 010 | loss: 0.46868 - acc: 0.7699 -- iter: 3488/3680
[A[ATraining Step: 1145  | total loss: [1m[32m0.47223[0m[0m
[2K| Adam | epoch: 010 | loss: 0.47223 - acc: 0.7567 -- iter: 3520/3680
[A[ATraining Step: 1146  | total loss: [1m[32m0.48496[0m[0m
[2K| Adam | epoch: 010 | loss: 0.48496 - acc: 0.7567 -- iter: 3552/3680
[A[ATraining Step: 1147  | total loss: [1m[32m0.50682[0m[0m
[2K| Adam | epoch: 010 | loss: 0.50682 - acc: 0.7557 -- iter: 3584/3680
[A[ATraining Step: 1148  | total loss: [1m[32m0.49979[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49979 - acc: 0.7557 -- iter: 3616/3680
[A[ATraining Step: 1149  | total loss: [1m[32m0.49428[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49428 - acc: 0.7512 -- iter: 3648/3680
[A[ATraining Step: 1150  | total loss: [1m[32m0.49428[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49428 - acc: 0.7512 | val_loss: 0.48351 - val_acc: 0.7676 -- iter: 3680/3680
[A[ATraining Step: 1150  | total loss: [1m[32m0.49428[0m[0m
[2K| Adam | epoch: 010 | loss: 0.49428 - acc: 0.7512 | val_loss: 0.48351 - val_acc: 0.7676 -- iter: 3680/3680
--
Training Step: 1151  | total loss: [1m[32m0.50622[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50622 - acc: 0.7480 -- iter: 0032/3680
[A[ATraining Step: 1152  | total loss: [1m[32m0.50514[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50514 - acc: 0.7421 -- iter: 0064/3680
[A[ATraining Step: 1153  | total loss: [1m[32m0.50514[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50514 - acc: 0.7421 -- iter: 0096/3680
[A[ATraining Step: 1154  | total loss: [1m[32m0.50419[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50419 - acc: 0.7398 -- iter: 0128/3680
[A[ATraining Step: 1155  | total loss: [1m[32m0.49933[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49933 - acc: 0.7470 -- iter: 0160/3680
[A[ATraining Step: 1156  | total loss: [1m[32m0.49403[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49403 - acc: 0.7473 -- iter: 0192/3680
[A[ATraining Step: 1157  | total loss: [1m[32m0.48541[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48541 - acc: 0.7570 -- iter: 0224/3680
[A[ATraining Step: 1158  | total loss: [1m[32m0.47500[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47500 - acc: 0.7707 -- iter: 0256/3680
[A[ATraining Step: 1159  | total loss: [1m[32m0.46543[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46543 - acc: 0.7707 -- iter: 0288/3680
[A[ATraining Step: 1160  | total loss: [1m[32m0.47072[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47072 - acc: 0.7780 -- iter: 0320/3680
[A[ATraining Step: 1161  | total loss: [1m[32m0.46516[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46516 - acc: 0.7808 -- iter: 0352/3680
[A[ATraining Step: 1162  | total loss: [1m[32m0.46516[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46516 - acc: 0.7808 -- iter: 0384/3680
[A[ATraining Step: 1163  | total loss: [1m[32m0.45980[0m[0m
[2K| Adam | epoch: 011 | loss: 0.45980 - acc: 0.7839 -- iter: 0416/3680
[A[ATraining Step: 1164  | total loss: [1m[32m0.45991[0m[0m
[2K| Adam | epoch: 011 | loss: 0.45991 - acc: 0.7868 -- iter: 0448/3680
[A[ATraining Step: 1165  | total loss: [1m[32m0.45016[0m[0m
[2K| Adam | epoch: 011 | loss: 0.45016 - acc: 0.7894 -- iter: 0480/3680
[A[ATraining Step: 1166  | total loss: [1m[32m0.46076[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46076 - acc: 0.7881 -- iter: 0512/3680
[A[ATraining Step: 1167  | total loss: [1m[32m0.46198[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46198 - acc: 0.7906 -- iter: 0544/3680
[A[ATraining Step: 1168  | total loss: [1m[32m0.46198[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46198 - acc: 0.7906 -- iter: 0576/3680
[A[ATraining Step: 1169  | total loss: [1m[32m0.46566[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46566 - acc: 0.7896 -- iter: 0608/3680
[A[ATraining Step: 1170  | total loss: [1m[32m0.49641[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49641 - acc: 0.7712 -- iter: 0640/3680
[A[ATraining Step: 1171  | total loss: [1m[32m0.49328[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49328 - acc: 0.7712 -- iter: 0672/3680
[A[ATraining Step: 1172  | total loss: [1m[32m0.48514[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48514 - acc: 0.7722 -- iter: 0704/3680
[A[ATraining Step: 1173  | total loss: [1m[32m0.48630[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48630 - acc: 0.7731 -- iter: 0736/3680
[A[ATraining Step: 1174  | total loss: [1m[32m0.50536[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50536 - acc: 0.7739 -- iter: 0768/3680
[A[ATraining Step: 1175  | total loss: [1m[32m0.50572[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50572 - acc: 0.7778 -- iter: 0800/3680
[A[ATraining Step: 1176  | total loss: [1m[32m0.49216[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49216 - acc: 0.7812 -- iter: 0832/3680
[A[ATraining Step: 1177  | total loss: [1m[32m0.49142[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49142 - acc: 0.7812 -- iter: 0864/3680
[A[ATraining Step: 1178  | total loss: [1m[32m0.49912[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49912 - acc: 0.7750 -- iter: 0896/3680
[A[ATraining Step: 1179  | total loss: [1m[32m0.49495[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49495 - acc: 0.7725 -- iter: 0928/3680
[A[ATraining Step: 1180  | total loss: [1m[32m0.50677[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50677 - acc: 0.7640 -- iter: 0960/3680
[A[ATraining Step: 1181  | total loss: [1m[32m0.50721[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50721 - acc: 0.7563 -- iter: 0992/3680
[A[ATraining Step: 1182  | total loss: [1m[32m0.51134[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51134 - acc: 0.7463 -- iter: 1024/3680
[A[ATraining Step: 1183  | total loss: [1m[32m0.51455[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51455 - acc: 0.7530 -- iter: 1056/3680
[A[ATraining Step: 1184  | total loss: [1m[32m0.51759[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51759 - acc: 0.7558 -- iter: 1088/3680
[A[ATraining Step: 1185  | total loss: [1m[32m0.51638[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51638 - acc: 0.7615 -- iter: 1120/3680
[A[ATraining Step: 1186  | total loss: [1m[32m0.51879[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51879 - acc: 0.7655 -- iter: 1152/3680
[A[ATraining Step: 1187  | total loss: [1m[32m0.51518[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51518 - acc: 0.7655 -- iter: 1184/3680
[A[ATraining Step: 1188  | total loss: [1m[32m0.52566[0m[0m
[2K| Adam | epoch: 011 | loss: 0.52566 - acc: 0.7546 -- iter: 1216/3680
[A[ATraining Step: 1189  | total loss: [1m[32m0.52387[0m[0m
[2K| Adam | epoch: 011 | loss: 0.52387 - acc: 0.7510 -- iter: 1248/3680
[A[ATraining Step: 1190  | total loss: [1m[32m0.53331[0m[0m
[2K| Adam | epoch: 011 | loss: 0.53331 - acc: 0.7415 -- iter: 1280/3680
[A[ATraining Step: 1191  | total loss: [1m[32m0.51224[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51224 - acc: 0.7638 -- iter: 1312/3680
[A[ATraining Step: 1192  | total loss: [1m[32m0.49937[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49937 - acc: 0.7638 -- iter: 1344/3680
[A[ATraining Step: 1193  | total loss: [1m[32m0.49267[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49267 - acc: 0.7718 -- iter: 1376/3680
[A[ATraining Step: 1194  | total loss: [1m[32m0.48989[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48989 - acc: 0.7696 -- iter: 1408/3680
[A[ATraining Step: 1195  | total loss: [1m[32m0.48858[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48858 - acc: 0.7739 -- iter: 1440/3680
[A[ATraining Step: 1196  | total loss: [1m[32m0.48772[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48772 - acc: 0.7684 -- iter: 1472/3680
[A[ATraining Step: 1197  | total loss: [1m[32m0.48258[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48258 - acc: 0.7759 -- iter: 1504/3680
[A[ATraining Step: 1198  | total loss: [1m[32m0.48028[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48028 - acc: 0.7827 -- iter: 1536/3680
[A[ATraining Step: 1199  | total loss: [1m[32m0.48431[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48431 - acc: 0.7830 -- iter: 1568/3680
[A[ATraining Step: 1200  | total loss: [1m[32m0.48141[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48141 - acc: 0.7830 | val_loss: 0.49817 - val_acc: 0.7524 -- iter: 1600/3680
[A[ATraining Step: 1200  | total loss: [1m[32m0.48141[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48141 - acc: 0.7830 | val_loss: 0.49817 - val_acc: 0.7524 -- iter: 1600/3680
--
Training Step: 1201  | total loss: [1m[32m0.46918[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46918 - acc: 0.7891 -- iter: 1632/3680
[A[ATraining Step: 1202  | total loss: [1m[32m0.46785[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46785 - acc: 0.7817 -- iter: 1664/3680
[A[ATraining Step: 1203  | total loss: [1m[32m0.46701[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46701 - acc: 0.7817 -- iter: 1696/3680
[A[ATraining Step: 1204  | total loss: [1m[32m0.46970[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46970 - acc: 0.7816 -- iter: 1728/3680
[A[ATraining Step: 1205  | total loss: [1m[32m0.47657[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47657 - acc: 0.7785 -- iter: 1760/3680
[A[ATraining Step: 1206  | total loss: [1m[32m0.48484[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48484 - acc: 0.7694 -- iter: 1792/3680
[A[ATraining Step: 1207  | total loss: [1m[32m0.48457[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48457 - acc: 0.7737 -- iter: 1824/3680
[A[ATraining Step: 1208  | total loss: [1m[32m0.48228[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48228 - acc: 0.7744 -- iter: 1856/3680
[A[ATraining Step: 1209  | total loss: [1m[32m0.49640[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49640 - acc: 0.7611 -- iter: 1888/3680
[A[ATraining Step: 1210  | total loss: [1m[32m0.49640[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49640 - acc: 0.7611 -- iter: 1920/3680
[A[ATraining Step: 1211  | total loss: [1m[32m0.48573[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48573 - acc: 0.7662 -- iter: 1952/3680
[A[ATraining Step: 1212  | total loss: [1m[32m0.50277[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50277 - acc: 0.7583 -- iter: 1984/3680
[A[ATraining Step: 1213  | total loss: [1m[32m0.50242[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50242 - acc: 0.7637 -- iter: 2016/3680
[A[ATraining Step: 1214  | total loss: [1m[32m0.50852[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50852 - acc: 0.7624 -- iter: 2048/3680
[A[ATraining Step: 1215  | total loss: [1m[32m0.50471[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50471 - acc: 0.7643 -- iter: 2080/3680
[A[ATraining Step: 1216  | total loss: [1m[32m0.50566[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50566 - acc: 0.7628 -- iter: 2112/3680
[A[ATraining Step: 1217  | total loss: [1m[32m0.50441[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50441 - acc: 0.7647 -- iter: 2144/3680
[A[ATraining Step: 1218  | total loss: [1m[32m0.50293[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50293 - acc: 0.7632 -- iter: 2176/3680
[A[ATraining Step: 1219  | total loss: [1m[32m0.49482[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49482 - acc: 0.7681 -- iter: 2208/3680
[A[ATraining Step: 1220  | total loss: [1m[32m0.49432[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49432 - acc: 0.7632 -- iter: 2240/3680
[A[ATraining Step: 1221  | total loss: [1m[32m0.49065[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49065 - acc: 0.7681 -- iter: 2272/3680
[A[ATraining Step: 1222  | total loss: [1m[32m0.52339[0m[0m
[2K| Adam | epoch: 011 | loss: 0.52339 - acc: 0.7569 -- iter: 2304/3680
[A[ATraining Step: 1223  | total loss: [1m[32m0.51929[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51929 - acc: 0.7625 -- iter: 2336/3680
[A[ATraining Step: 1224  | total loss: [1m[32m0.51563[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51563 - acc: 0.7612 -- iter: 2368/3680
[A[ATraining Step: 1225  | total loss: [1m[32m0.50563[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50563 - acc: 0.7664 -- iter: 2400/3680
[A[ATraining Step: 1226  | total loss: [1m[32m0.50213[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50213 - acc: 0.7679 -- iter: 2432/3680
[A[ATraining Step: 1227  | total loss: [1m[32m0.51345[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51345 - acc: 0.7567 -- iter: 2464/3680
[A[ATraining Step: 1228  | total loss: [1m[32m0.51081[0m[0m
[2K| Adam | epoch: 011 | loss: 0.51081 - acc: 0.7623 -- iter: 2496/3680
[A[ATraining Step: 1229  | total loss: [1m[32m0.50405[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50405 - acc: 0.7642 -- iter: 2528/3680
[A[ATraining Step: 1230  | total loss: [1m[32m0.50247[0m[0m
[2K| Adam | epoch: 011 | loss: 0.50247 - acc: 0.7565 -- iter: 2560/3680
[A[ATraining Step: 1231  | total loss: [1m[32m0.49387[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49387 - acc: 0.7590 -- iter: 2592/3680
[A[ATraining Step: 1232  | total loss: [1m[32m0.49085[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49085 - acc: 0.7581 -- iter: 2624/3680
[A[ATraining Step: 1233  | total loss: [1m[32m0.49475[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49475 - acc: 0.7542 -- iter: 2656/3680
[A[ATraining Step: 1234  | total loss: [1m[32m0.47678[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47678 - acc: 0.7725 -- iter: 2688/3680
[A[ATraining Step: 1235  | total loss: [1m[32m0.47434[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47434 - acc: 0.7796 -- iter: 2720/3680
[A[ATraining Step: 1236  | total loss: [1m[32m0.48628[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48628 - acc: 0.7735 -- iter: 2752/3680
[A[ATraining Step: 1237  | total loss: [1m[32m0.48152[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48152 - acc: 0.7743 -- iter: 2784/3680
[A[ATraining Step: 1238  | total loss: [1m[32m0.47688[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47688 - acc: 0.7781 -- iter: 2816/3680
[A[ATraining Step: 1239  | total loss: [1m[32m0.46604[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46604 - acc: 0.7847 -- iter: 2848/3680
[A[ATraining Step: 1240  | total loss: [1m[32m0.47310[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47310 - acc: 0.7718 -- iter: 2880/3680
[A[ATraining Step: 1241  | total loss: [1m[32m0.46218[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46218 - acc: 0.7822 -- iter: 2912/3680
[A[ATraining Step: 1242  | total loss: [1m[32m0.45681[0m[0m
[2K| Adam | epoch: 011 | loss: 0.45681 - acc: 0.7914 -- iter: 2944/3680
[A[ATraining Step: 1243  | total loss: [1m[32m0.46457[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46457 - acc: 0.7842 -- iter: 2976/3680
[A[ATraining Step: 1244  | total loss: [1m[32m0.48833[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48833 - acc: 0.7776 -- iter: 3008/3680
[A[ATraining Step: 1245  | total loss: [1m[32m0.49154[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49154 - acc: 0.7686 -- iter: 3040/3680
[A[ATraining Step: 1246  | total loss: [1m[32m0.46996[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46996 - acc: 0.7824 -- iter: 3072/3680
[A[ATraining Step: 1247  | total loss: [1m[32m0.47015[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47015 - acc: 0.7729 -- iter: 3104/3680
[A[ATraining Step: 1248  | total loss: [1m[32m0.46195[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46195 - acc: 0.7769 -- iter: 3136/3680
[A[ATraining Step: 1249  | total loss: [1m[32m0.47904[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47904 - acc: 0.7648 -- iter: 3168/3680
[A[ATraining Step: 1250  | total loss: [1m[32m0.46304[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46304 - acc: 0.7758 -- iter: 3200/3680
[A[ATraining Step: 1251  | total loss: [1m[32m0.46580[0m[0m
[2K| Adam | epoch: 011 | loss: 0.46580 - acc: 0.7701 -- iter: 3232/3680
[A[ATraining Step: 1252  | total loss: [1m[32m0.48234[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48234 - acc: 0.7587 -- iter: 3264/3680
[A[ATraining Step: 1253  | total loss: [1m[32m0.49413[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49413 - acc: 0.7578 -- iter: 3296/3680
[A[ATraining Step: 1254  | total loss: [1m[32m0.49079[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49079 - acc: 0.7626 -- iter: 3328/3680
[A[ATraining Step: 1255  | total loss: [1m[32m0.48563[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48563 - acc: 0.7613 -- iter: 3360/3680
[A[ATraining Step: 1256  | total loss: [1m[32m0.48433[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48433 - acc: 0.7613 -- iter: 3392/3680
[A[ATraining Step: 1257  | total loss: [1m[32m0.49485[0m[0m
[2K| Adam | epoch: 011 | loss: 0.49485 - acc: 0.7571 -- iter: 3424/3680
[A[ATraining Step: 1258  | total loss: [1m[32m0.48867[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48867 - acc: 0.7658 -- iter: 3456/3680
[A[ATraining Step: 1259  | total loss: [1m[32m0.48168[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48168 - acc: 0.7704 -- iter: 3488/3680
[A[ATraining Step: 1260  | total loss: [1m[32m0.47383[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47383 - acc: 0.7809 -- iter: 3520/3680
[A[ATraining Step: 1261  | total loss: [1m[32m0.47848[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47848 - acc: 0.7809 -- iter: 3552/3680
[A[ATraining Step: 1262  | total loss: [1m[32m0.47911[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47911 - acc: 0.7810 -- iter: 3584/3680
[A[ATraining Step: 1263  | total loss: [1m[32m0.48022[0m[0m
[2K| Adam | epoch: 011 | loss: 0.48022 - acc: 0.7841 -- iter: 3616/3680
[A[ATraining Step: 1264  | total loss: [1m[32m0.47356[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47356 - acc: 0.7838 -- iter: 3648/3680
[A[ATraining Step: 1265  | total loss: [1m[32m0.47762[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47762 - acc: 0.7773 | val_loss: 0.47714 - val_acc: 0.7622 -- iter: 3680/3680
[A[ATraining Step: 1265  | total loss: [1m[32m0.47762[0m[0m
[2K| Adam | epoch: 011 | loss: 0.47762 - acc: 0.7773 | val_loss: 0.47714 - val_acc: 0.7622 -- iter: 3680/3680
--
Training Step: 1266  | total loss: [1m[32m0.46681[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46681 - acc: 0.7871 -- iter: 0032/3680
[A[ATraining Step: 1267  | total loss: [1m[32m0.46672[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46672 - acc: 0.7896 -- iter: 0064/3680
[A[ATraining Step: 1268  | total loss: [1m[32m0.46873[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46873 - acc: 0.7888 -- iter: 0096/3680
[A[ATraining Step: 1269  | total loss: [1m[32m0.47156[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47156 - acc: 0.7849 -- iter: 0128/3680
[A[ATraining Step: 1270  | total loss: [1m[32m0.46545[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46545 - acc: 0.7745 -- iter: 0160/3680
[A[ATraining Step: 1271  | total loss: [1m[32m0.48155[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48155 - acc: 0.7745 -- iter: 0192/3680
[A[ATraining Step: 1272  | total loss: [1m[32m0.49504[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49504 - acc: 0.7689 -- iter: 0224/3680
[A[ATraining Step: 1273  | total loss: [1m[32m0.48685[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48685 - acc: 0.7764 -- iter: 0256/3680
[A[ATraining Step: 1274  | total loss: [1m[32m0.46399[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46399 - acc: 0.7948 -- iter: 0288/3680
[A[ATraining Step: 1275  | total loss: [1m[32m0.46399[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46399 - acc: 0.7948 -- iter: 0320/3680
[A[ATraining Step: 1276  | total loss: [1m[32m0.49450[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49450 - acc: 0.7713 -- iter: 0352/3680
[A[ATraining Step: 1277  | total loss: [1m[32m0.49450[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49450 - acc: 0.7713 -- iter: 0384/3680
[A[ATraining Step: 1278  | total loss: [1m[32m0.48793[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48793 - acc: 0.7692 -- iter: 0416/3680
[A[ATraining Step: 1279  | total loss: [1m[32m0.49350[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49350 - acc: 0.7610 -- iter: 0448/3680
[A[ATraining Step: 1280  | total loss: [1m[32m0.49948[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49948 - acc: 0.7599 -- iter: 0480/3680
[A[ATraining Step: 1281  | total loss: [1m[32m0.50605[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50605 - acc: 0.7527 -- iter: 0512/3680
[A[ATraining Step: 1282  | total loss: [1m[32m0.50481[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50481 - acc: 0.7587 -- iter: 0544/3680
[A[ATraining Step: 1283  | total loss: [1m[32m0.48834[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48834 - acc: 0.7734 -- iter: 0576/3680
[A[ATraining Step: 1284  | total loss: [1m[32m0.47625[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47625 - acc: 0.7836 -- iter: 0608/3680
[A[ATraining Step: 1285  | total loss: [1m[32m0.47943[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47943 - acc: 0.7771 -- iter: 0640/3680
[A[ATraining Step: 1286  | total loss: [1m[32m0.46689[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46689 - acc: 0.7863 -- iter: 0672/3680
[A[ATraining Step: 1287  | total loss: [1m[32m0.46689[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46689 - acc: 0.7863 -- iter: 0704/3680
[A[ATraining Step: 1288  | total loss: [1m[32m0.46018[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46018 - acc: 0.7952 -- iter: 0736/3680
[A[ATraining Step: 1289  | total loss: [1m[32m0.46706[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46706 - acc: 0.7782 -- iter: 0768/3680
[A[ATraining Step: 1290  | total loss: [1m[32m0.46658[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46658 - acc: 0.7847 -- iter: 0800/3680
[A[ATraining Step: 1291  | total loss: [1m[32m0.46831[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46831 - acc: 0.7844 -- iter: 0832/3680
[A[ATraining Step: 1292  | total loss: [1m[32m0.46689[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46689 - acc: 0.7841 -- iter: 0864/3680
[A[ATraining Step: 1293  | total loss: [1m[32m0.47359[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47359 - acc: 0.7713 -- iter: 0896/3680
[A[ATraining Step: 1294  | total loss: [1m[32m0.46606[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46606 - acc: 0.7785 -- iter: 0928/3680
[A[ATraining Step: 1295  | total loss: [1m[32m0.46304[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46304 - acc: 0.7540 -- iter: 0960/3680
[A[ATraining Step: 1296  | total loss: [1m[32m0.48422[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48422 - acc: 0.7540 -- iter: 0992/3680
[A[ATraining Step: 1297  | total loss: [1m[32m0.46823[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46823 - acc: 0.7599 -- iter: 1024/3680
[A[ATraining Step: 1298  | total loss: [1m[32m0.46478[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46478 - acc: 0.7683 -- iter: 1056/3680
[A[ATraining Step: 1299  | total loss: [1m[32m0.46305[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46305 - acc: 0.7633 -- iter: 1088/3680
[A[ATraining Step: 1300  | total loss: [1m[32m0.48243[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48243 - acc: 0.7526 | val_loss: 0.48054 - val_acc: 0.7720 -- iter: 1120/3680
[A[ATraining Step: 1300  | total loss: [1m[32m0.48243[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48243 - acc: 0.7526 | val_loss: 0.48054 - val_acc: 0.7720 -- iter: 1120/3680
--
Training Step: 1301  | total loss: [1m[32m0.47331[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47331 - acc: 0.7617 -- iter: 1152/3680
[A[ATraining Step: 1302  | total loss: [1m[32m0.46427[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46427 - acc: 0.7699 -- iter: 1184/3680
[A[ATraining Step: 1303  | total loss: [1m[32m0.46007[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46007 - acc: 0.7648 -- iter: 1216/3680
[A[ATraining Step: 1304  | total loss: [1m[32m0.47981[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47981 - acc: 0.7571 -- iter: 1248/3680
[A[ATraining Step: 1305  | total loss: [1m[32m0.48122[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48122 - acc: 0.7564 -- iter: 1280/3680
[A[ATraining Step: 1306  | total loss: [1m[32m0.47141[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47141 - acc: 0.7651 -- iter: 1312/3680
[A[ATraining Step: 1307  | total loss: [1m[32m0.46452[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46452 - acc: 0.7824 -- iter: 1344/3680
[A[ATraining Step: 1308  | total loss: [1m[32m0.45791[0m[0m
[2K| Adam | epoch: 012 | loss: 0.45791 - acc: 0.7916 -- iter: 1376/3680
[A[ATraining Step: 1309  | total loss: [1m[32m0.45760[0m[0m
[2K| Adam | epoch: 012 | loss: 0.45760 - acc: 0.7906 -- iter: 1408/3680
[A[ATraining Step: 1310  | total loss: [1m[32m0.45004[0m[0m
[2K| Adam | epoch: 012 | loss: 0.45004 - acc: 0.8021 -- iter: 1440/3680
[A[ATraining Step: 1311  | total loss: [1m[32m0.46506[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46506 - acc: 0.7938 -- iter: 1472/3680
[A[ATraining Step: 1312  | total loss: [1m[32m0.46191[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46191 - acc: 0.7974 -- iter: 1504/3680
[A[ATraining Step: 1313  | total loss: [1m[32m0.45996[0m[0m
[2K| Adam | epoch: 012 | loss: 0.45996 - acc: 0.7974 -- iter: 1536/3680
[A[ATraining Step: 1314  | total loss: [1m[32m0.46978[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46978 - acc: 0.7849 -- iter: 1568/3680
[A[ATraining Step: 1315  | total loss: [1m[32m0.46630[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46630 - acc: 0.7877 -- iter: 1600/3680
[A[ATraining Step: 1316  | total loss: [1m[32m0.46630[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46630 - acc: 0.7877 -- iter: 1632/3680
[A[ATraining Step: 1317  | total loss: [1m[32m0.47386[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47386 - acc: 0.7777 -- iter: 1664/3680
[A[ATraining Step: 1318  | total loss: [1m[32m0.46988[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46988 - acc: 0.7874 -- iter: 1696/3680
[A[ATraining Step: 1319  | total loss: [1m[32m0.48506[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48506 - acc: 0.7743 -- iter: 1728/3680
[A[ATraining Step: 1320  | total loss: [1m[32m0.48927[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48927 - acc: 0.7562 -- iter: 1760/3680
[A[ATraining Step: 1321  | total loss: [1m[32m0.48072[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48072 - acc: 0.7700 -- iter: 1792/3680
[A[ATraining Step: 1322  | total loss: [1m[32m0.48072[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48072 - acc: 0.7700 -- iter: 1824/3680
[A[ATraining Step: 1323  | total loss: [1m[32m0.48760[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48760 - acc: 0.7743 -- iter: 1856/3680
[A[ATraining Step: 1324  | total loss: [1m[32m0.47370[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47370 - acc: 0.7781 -- iter: 1888/3680
[A[ATraining Step: 1325  | total loss: [1m[32m0.48111[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48111 - acc: 0.7753 -- iter: 1920/3680
[A[ATraining Step: 1326  | total loss: [1m[32m0.49836[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49836 - acc: 0.7571 -- iter: 1952/3680
[A[ATraining Step: 1327  | total loss: [1m[32m0.48898[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48898 - acc: 0.7592 -- iter: 1984/3680
[A[ATraining Step: 1328  | total loss: [1m[32m0.48898[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48898 - acc: 0.7489 -- iter: 2016/3680
[A[ATraining Step: 1329  | total loss: [1m[32m0.49951[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49951 - acc: 0.7489 -- iter: 2048/3680
[A[ATraining Step: 1330  | total loss: [1m[32m0.49297[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49297 - acc: 0.7647 -- iter: 2080/3680
[A[ATraining Step: 1331  | total loss: [1m[32m0.49525[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49525 - acc: 0.7476 -- iter: 2112/3680
[A[ATraining Step: 1332  | total loss: [1m[32m0.50067[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50067 - acc: 0.7416 -- iter: 2144/3680
[A[ATraining Step: 1333  | total loss: [1m[32m0.48781[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48781 - acc: 0.7487 -- iter: 2176/3680
[A[ATraining Step: 1334  | total loss: [1m[32m0.47890[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47890 - acc: 0.7580 -- iter: 2208/3680
[A[ATraining Step: 1335  | total loss: [1m[32m0.47890[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47890 - acc: 0.7580 -- iter: 2240/3680
[A[ATraining Step: 1336  | total loss: [1m[32m0.47678[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47678 - acc: 0.7666 -- iter: 2272/3680
[A[ATraining Step: 1337  | total loss: [1m[32m0.48508[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48508 - acc: 0.7649 -- iter: 2304/3680
[A[ATraining Step: 1338  | total loss: [1m[32m0.47877[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47877 - acc: 0.7759 -- iter: 2336/3680
[A[ATraining Step: 1339  | total loss: [1m[32m0.48175[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48175 - acc: 0.7796 -- iter: 2368/3680
[A[ATraining Step: 1340  | total loss: [1m[32m0.47550[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47550 - acc: 0.7766 -- iter: 2400/3680
[A[ATraining Step: 1341  | total loss: [1m[32m0.47365[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47365 - acc: 0.7833 -- iter: 2432/3680
[A[ATraining Step: 1342  | total loss: [1m[32m0.46927[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46927 - acc: 0.7831 -- iter: 2464/3680
[A[ATraining Step: 1343  | total loss: [1m[32m0.46882[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46882 - acc: 0.7861 -- iter: 2496/3680
[A[ATraining Step: 1344  | total loss: [1m[32m0.48764[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48764 - acc: 0.7668 -- iter: 2528/3680
[A[ATraining Step: 1345  | total loss: [1m[32m0.47924[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47924 - acc: 0.7683 -- iter: 2560/3680
[A[ATraining Step: 1346  | total loss: [1m[32m0.49111[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49111 - acc: 0.7571 -- iter: 2592/3680
[A[ATraining Step: 1347  | total loss: [1m[32m0.48344[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48344 - acc: 0.7720 -- iter: 2624/3680
[A[ATraining Step: 1348  | total loss: [1m[32m0.50361[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50361 - acc: 0.7667 -- iter: 2656/3680
[A[ATraining Step: 1349  | total loss: [1m[32m0.50939[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50939 - acc: 0.7681 -- iter: 2688/3680
[A[ATraining Step: 1350  | total loss: [1m[32m0.51987[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51987 - acc: 0.7663 -- iter: 2720/3680
[A[ATraining Step: 1351  | total loss: [1m[32m0.51926[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51926 - acc: 0.7741 -- iter: 2752/3680
[A[ATraining Step: 1352  | total loss: [1m[32m0.51889[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51889 - acc: 0.7685 -- iter: 2784/3680
[A[ATraining Step: 1353  | total loss: [1m[32m0.51551[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51551 - acc: 0.7698 -- iter: 2816/3680
[A[ATraining Step: 1354  | total loss: [1m[32m0.51501[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51501 - acc: 0.7678 -- iter: 2848/3680
[A[ATraining Step: 1355  | total loss: [1m[32m0.50488[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50488 - acc: 0.7754 -- iter: 2880/3680
[A[ATraining Step: 1356  | total loss: [1m[32m0.50730[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50730 - acc: 0.7697 -- iter: 2912/3680
[A[ATraining Step: 1357  | total loss: [1m[32m0.50314[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50314 - acc: 0.7678 -- iter: 2944/3680
[A[ATraining Step: 1358  | total loss: [1m[32m0.50119[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50119 - acc: 0.7754 -- iter: 2976/3680
[A[ATraining Step: 1359  | total loss: [1m[32m0.49547[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49547 - acc: 0.7853 -- iter: 3008/3680
[A[ATraining Step: 1360  | total loss: [1m[32m0.51458[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51458 - acc: 0.7662 -- iter: 3040/3680
[A[ATraining Step: 1361  | total loss: [1m[32m0.52323[0m[0m
[2K| Adam | epoch: 012 | loss: 0.52323 - acc: 0.7583 -- iter: 3072/3680
[A[ATraining Step: 1362  | total loss: [1m[32m0.51241[0m[0m
[2K| Adam | epoch: 012 | loss: 0.51241 - acc: 0.7606 -- iter: 3104/3680
[A[ATraining Step: 1363  | total loss: [1m[32m0.50521[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50521 - acc: 0.7533 -- iter: 3136/3680
[A[ATraining Step: 1364  | total loss: [1m[32m0.49498[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49498 - acc: 0.7623 -- iter: 3168/3680
[A[ATraining Step: 1365  | total loss: [1m[32m0.48813[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48813 - acc: 0.7611 -- iter: 3200/3680
[A[ATraining Step: 1366  | total loss: [1m[32m0.48224[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48224 - acc: 0.7725 -- iter: 3232/3680
[A[ATraining Step: 1367  | total loss: [1m[32m0.48783[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48783 - acc: 0.7734 -- iter: 3264/3680
[A[ATraining Step: 1368  | total loss: [1m[32m0.50849[0m[0m
[2K| Adam | epoch: 012 | loss: 0.50849 - acc: 0.7742 -- iter: 3296/3680
[A[ATraining Step: 1369  | total loss: [1m[32m0.49912[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49912 - acc: 0.7811 -- iter: 3328/3680
[A[ATraining Step: 1370  | total loss: [1m[32m0.49519[0m[0m
[2K| Adam | epoch: 012 | loss: 0.49519 - acc: 0.7780 -- iter: 3360/3680
[A[ATraining Step: 1371  | total loss: [1m[32m0.47916[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47916 - acc: 0.7846 -- iter: 3392/3680
[A[ATraining Step: 1372  | total loss: [1m[32m0.47413[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47413 - acc: 0.7842 -- iter: 3424/3680
[A[ATraining Step: 1373  | total loss: [1m[32m0.48863[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48863 - acc: 0.7683 -- iter: 3456/3680
[A[ATraining Step: 1374  | total loss: [1m[32m0.48708[0m[0m
[2K| Adam | epoch: 012 | loss: 0.48708 - acc: 0.7665 -- iter: 3488/3680
[A[ATraining Step: 1375  | total loss: [1m[32m0.47748[0m[0m
[2K| Adam | epoch: 012 | loss: 0.47748 - acc: 0.7742 -- iter: 3520/3680
[A[ATraining Step: 1376  | total loss: [1m[32m0.46577[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46577 - acc: 0.7905 -- iter: 3552/3680
[A[ATraining Step: 1377  | total loss: [1m[32m0.46459[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46459 - acc: 0.7834 -- iter: 3584/3680
[A[ATraining Step: 1378  | total loss: [1m[32m0.46246[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46246 - acc: 0.7769 -- iter: 3616/3680
[A[ATraining Step: 1379  | total loss: [1m[32m0.46387[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46387 - acc: 0.7773 -- iter: 3648/3680
[A[ATraining Step: 1380  | total loss: [1m[32m0.46224[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46224 - acc: 0.7809 | val_loss: 0.47708 - val_acc: 0.7622 -- iter: 3680/3680
[A[ATraining Step: 1380  | total loss: [1m[32m0.46224[0m[0m
[2K| Adam | epoch: 012 | loss: 0.46224 - acc: 0.7809 | val_loss: 0.47708 - val_acc: 0.7622 -- iter: 3680/3680
--
Training Step: 1381  | total loss: [1m[32m0.46594[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46594 - acc: 0.7809 -- iter: 0032/3680
[A[ATraining Step: 1382  | total loss: [1m[32m0.46384[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46384 - acc: 0.7809 -- iter: 0064/3680
[A[ATraining Step: 1383  | total loss: [1m[32m0.48019[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48019 - acc: 0.7716 -- iter: 0096/3680
[A[ATraining Step: 1384  | total loss: [1m[32m0.49341[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49341 - acc: 0.7569 -- iter: 0128/3680
[A[ATraining Step: 1385  | total loss: [1m[32m0.48987[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48987 - acc: 0.7656 -- iter: 0160/3680
[A[ATraining Step: 1386  | total loss: [1m[32m0.48920[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48920 - acc: 0.7609 -- iter: 0192/3680
[A[ATraining Step: 1387  | total loss: [1m[32m0.48405[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48405 - acc: 0.7661 -- iter: 0224/3680
[A[ATraining Step: 1388  | total loss: [1m[32m0.46815[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46815 - acc: 0.7740 -- iter: 0256/3680
[A[ATraining Step: 1389  | total loss: [1m[32m0.47255[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47255 - acc: 0.7684 -- iter: 0288/3680
[A[ATraining Step: 1390  | total loss: [1m[32m0.47797[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47797 - acc: 0.7684 -- iter: 0320/3680
[A[ATraining Step: 1391  | total loss: [1m[32m0.46270[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46270 - acc: 0.7791 -- iter: 0352/3680
[A[ATraining Step: 1392  | total loss: [1m[32m0.46360[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46360 - acc: 0.7945 -- iter: 0384/3680
[A[ATraining Step: 1393  | total loss: [1m[32m0.45878[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45878 - acc: 0.7945 -- iter: 0416/3680
[A[ATraining Step: 1394  | total loss: [1m[32m0.46905[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46905 - acc: 0.7776 -- iter: 0448/3680
[A[ATraining Step: 1395  | total loss: [1m[32m0.46456[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46456 - acc: 0.7811 -- iter: 0480/3680
[A[ATraining Step: 1396  | total loss: [1m[32m0.47575[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47575 - acc: 0.7748 -- iter: 0512/3680
[A[ATraining Step: 1397  | total loss: [1m[32m0.47286[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47286 - acc: 0.7520 -- iter: 0544/3680
[A[ATraining Step: 1398  | total loss: [1m[32m0.48825[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48825 - acc: 0.7520 -- iter: 0576/3680
[A[ATraining Step: 1399  | total loss: [1m[32m0.47938[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47938 - acc: 0.7610 -- iter: 0608/3680
[A[ATraining Step: 1400  | total loss: [1m[32m0.47938[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47938 - acc: 0.7443 | val_loss: 0.47272 - val_acc: 0.7818 -- iter: 0640/3680
[A[ATraining Step: 1400  | total loss: [1m[32m0.47938[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47938 - acc: 0.7443 | val_loss: 0.47272 - val_acc: 0.7818 -- iter: 0640/3680
--
Training Step: 1401  | total loss: [1m[32m0.49231[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49231 - acc: 0.7443 -- iter: 0672/3680
[A[ATraining Step: 1402  | total loss: [1m[32m0.49024[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49024 - acc: 0.7480 -- iter: 0704/3680
[A[ATraining Step: 1403  | total loss: [1m[32m0.48849[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48849 - acc: 0.7513 -- iter: 0736/3680
[A[ATraining Step: 1404  | total loss: [1m[32m0.48164[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48164 - acc: 0.7668 -- iter: 0768/3680
[A[ATraining Step: 1405  | total loss: [1m[32m0.48447[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48447 - acc: 0.7620 -- iter: 0800/3680
[A[ATraining Step: 1406  | total loss: [1m[32m0.50463[0m[0m
[2K| Adam | epoch: 013 | loss: 0.50463 - acc: 0.7514 -- iter: 0832/3680
[A[ATraining Step: 1407  | total loss: [1m[32m0.51284[0m[0m
[2K| Adam | epoch: 013 | loss: 0.51284 - acc: 0.7513 -- iter: 0864/3680
[A[ATraining Step: 1408  | total loss: [1m[32m0.50258[0m[0m
[2K| Adam | epoch: 013 | loss: 0.50258 - acc: 0.7591 -- iter: 0896/3680
[A[ATraining Step: 1409  | total loss: [1m[32m0.50601[0m[0m
[2K| Adam | epoch: 013 | loss: 0.50601 - acc: 0.7591 -- iter: 0928/3680
[A[ATraining Step: 1410  | total loss: [1m[32m0.49941[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49941 - acc: 0.7812 -- iter: 0960/3680
[A[ATraining Step: 1411  | total loss: [1m[32m0.48702[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48702 - acc: 0.7718 -- iter: 0992/3680
[A[ATraining Step: 1412  | total loss: [1m[32m0.48702[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48702 - acc: 0.7718 -- iter: 1024/3680
[A[ATraining Step: 1413  | total loss: [1m[32m0.47652[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47652 - acc: 0.7852 -- iter: 1056/3680
[A[ATraining Step: 1414  | total loss: [1m[32m0.49054[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49054 - acc: 0.7786 -- iter: 1088/3680
[A[ATraining Step: 1415  | total loss: [1m[32m0.48608[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48608 - acc: 0.7851 -- iter: 1120/3680
[A[ATraining Step: 1416  | total loss: [1m[32m0.48570[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48570 - acc: 0.7878 -- iter: 1152/3680
[A[ATraining Step: 1417  | total loss: [1m[32m0.47393[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47393 - acc: 0.8028 -- iter: 1184/3680
[A[ATraining Step: 1418  | total loss: [1m[32m0.47204[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47204 - acc: 0.8132 -- iter: 1216/3680
[A[ATraining Step: 1419  | total loss: [1m[32m0.46184[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46184 - acc: 0.8193 -- iter: 1248/3680
[A[ATraining Step: 1420  | total loss: [1m[32m0.45405[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45405 - acc: 0.8249 -- iter: 1280/3680
[A[ATraining Step: 1421  | total loss: [1m[32m0.44662[0m[0m
[2K| Adam | epoch: 013 | loss: 0.44662 - acc: 0.8362 -- iter: 1312/3680
[A[ATraining Step: 1422  | total loss: [1m[32m0.44238[0m[0m
[2K| Adam | epoch: 013 | loss: 0.44238 - acc: 0.8369 -- iter: 1344/3680
[A[ATraining Step: 1423  | total loss: [1m[32m0.46152[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46152 - acc: 0.8189 -- iter: 1376/3680
[A[ATraining Step: 1424  | total loss: [1m[32m0.47153[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47153 - acc: 0.8088 -- iter: 1408/3680
[A[ATraining Step: 1425  | total loss: [1m[32m0.47523[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47523 - acc: 0.8061 -- iter: 1440/3680
[A[ATraining Step: 1426  | total loss: [1m[32m0.46603[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46603 - acc: 0.8067 -- iter: 1472/3680
[A[ATraining Step: 1427  | total loss: [1m[32m0.46595[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46595 - acc: 0.8042 -- iter: 1504/3680
[A[ATraining Step: 1428  | total loss: [1m[32m0.46170[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46170 - acc: 0.8019 -- iter: 1536/3680
[A[ATraining Step: 1429  | total loss: [1m[32m0.46731[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46731 - acc: 0.7936 -- iter: 1568/3680
[A[ATraining Step: 1430  | total loss: [1m[32m0.46188[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46188 - acc: 0.7892 -- iter: 1600/3680
[A[ATraining Step: 1431  | total loss: [1m[32m0.46519[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46519 - acc: 0.7884 -- iter: 1632/3680
[A[ATraining Step: 1432  | total loss: [1m[32m0.47357[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47357 - acc: 0.7877 -- iter: 1664/3680
[A[ATraining Step: 1433  | total loss: [1m[32m0.47044[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47044 - acc: 0.7871 -- iter: 1696/3680
[A[ATraining Step: 1434  | total loss: [1m[32m0.46792[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46792 - acc: 0.7896 -- iter: 1728/3680
[A[ATraining Step: 1435  | total loss: [1m[32m0.47105[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47105 - acc: 0.7888 -- iter: 1760/3680
[A[ATraining Step: 1436  | total loss: [1m[32m0.46783[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46783 - acc: 0.7911 -- iter: 1792/3680
[A[ATraining Step: 1437  | total loss: [1m[32m0.48377[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48377 - acc: 0.7808 -- iter: 1824/3680
[A[ATraining Step: 1438  | total loss: [1m[32m0.49168[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49168 - acc: 0.7683 -- iter: 1856/3680
[A[ATraining Step: 1439  | total loss: [1m[32m0.49331[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49331 - acc: 0.7634 -- iter: 1888/3680
[A[ATraining Step: 1440  | total loss: [1m[32m0.48903[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48903 - acc: 0.7652 -- iter: 1920/3680
[A[ATraining Step: 1441  | total loss: [1m[32m0.48544[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48544 - acc: 0.7668 -- iter: 1952/3680
[A[ATraining Step: 1442  | total loss: [1m[32m0.49217[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49217 - acc: 0.7588 -- iter: 1984/3680
[A[ATraining Step: 1443  | total loss: [1m[32m0.48600[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48600 - acc: 0.7673 -- iter: 2016/3680
[A[ATraining Step: 1444  | total loss: [1m[32m0.48659[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48659 - acc: 0.7625 -- iter: 2048/3680
[A[ATraining Step: 1445  | total loss: [1m[32m0.47358[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47358 - acc: 0.7737 -- iter: 2080/3680
[A[ATraining Step: 1446  | total loss: [1m[32m0.46504[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46504 - acc: 0.7807 -- iter: 2112/3680
[A[ATraining Step: 1447  | total loss: [1m[32m0.47428[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47428 - acc: 0.7777 -- iter: 2144/3680
[A[ATraining Step: 1448  | total loss: [1m[32m0.46545[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46545 - acc: 0.7749 -- iter: 2176/3680
[A[ATraining Step: 1449  | total loss: [1m[32m0.47208[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47208 - acc: 0.7693 -- iter: 2208/3680
[A[ATraining Step: 1450  | total loss: [1m[32m0.48088[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48088 - acc: 0.7580 -- iter: 2240/3680
[A[ATraining Step: 1451  | total loss: [1m[32m0.47784[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47784 - acc: 0.7572 -- iter: 2272/3680
[A[ATraining Step: 1452  | total loss: [1m[32m0.46370[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46370 - acc: 0.7658 -- iter: 2304/3680
[A[ATraining Step: 1453  | total loss: [1m[32m0.45854[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45854 - acc: 0.7767 -- iter: 2336/3680
[A[ATraining Step: 1454  | total loss: [1m[32m0.45414[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45414 - acc: 0.7834 -- iter: 2368/3680
[A[ATraining Step: 1455  | total loss: [1m[32m0.45771[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45771 - acc: 0.7895 -- iter: 2400/3680
[A[ATraining Step: 1456  | total loss: [1m[32m0.46130[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46130 - acc: 0.7918 -- iter: 2432/3680
[A[ATraining Step: 1457  | total loss: [1m[32m0.47036[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47036 - acc: 0.7782 -- iter: 2464/3680
[A[ATraining Step: 1458  | total loss: [1m[32m0.45672[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45672 - acc: 0.7910 -- iter: 2496/3680
[A[ATraining Step: 1459  | total loss: [1m[32m0.45867[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45867 - acc: 0.7901 -- iter: 2528/3680
[A[ATraining Step: 1460  | total loss: [1m[32m0.44769[0m[0m
[2K| Adam | epoch: 013 | loss: 0.44769 - acc: 0.7923 -- iter: 2560/3680
[A[ATraining Step: 1461  | total loss: [1m[32m0.45756[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45756 - acc: 0.7881 -- iter: 2592/3680
[A[ATraining Step: 1462  | total loss: [1m[32m0.45668[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45668 - acc: 0.7843 -- iter: 2624/3680
[A[ATraining Step: 1463  | total loss: [1m[32m0.45918[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45918 - acc: 0.7808 -- iter: 2656/3680
[A[ATraining Step: 1464  | total loss: [1m[32m0.46083[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46083 - acc: 0.7840 -- iter: 2688/3680
[A[ATraining Step: 1465  | total loss: [1m[32m0.46642[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46642 - acc: 0.7835 -- iter: 2720/3680
[A[ATraining Step: 1466  | total loss: [1m[32m0.46823[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46823 - acc: 0.7835 -- iter: 2752/3680
[A[ATraining Step: 1467  | total loss: [1m[32m0.46677[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46677 - acc: 0.7771 -- iter: 2784/3680
[A[ATraining Step: 1468  | total loss: [1m[32m0.47214[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47214 - acc: 0.7771 -- iter: 2816/3680
[A[ATraining Step: 1469  | total loss: [1m[32m0.46741[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46741 - acc: 0.7838 -- iter: 2848/3680
[A[ATraining Step: 1470  | total loss: [1m[32m0.46861[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46861 - acc: 0.7804 -- iter: 2880/3680
[A[ATraining Step: 1471  | total loss: [1m[32m0.46999[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46999 - acc: 0.7711 -- iter: 2912/3680
[A[ATraining Step: 1472  | total loss: [1m[32m0.47048[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47048 - acc: 0.7753 -- iter: 2944/3680
[A[ATraining Step: 1473  | total loss: [1m[32m0.46531[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46531 - acc: 0.7727 -- iter: 2976/3680
[A[ATraining Step: 1474  | total loss: [1m[32m0.43439[0m[0m
[2K| Adam | epoch: 013 | loss: 0.43439 - acc: 0.7984 -- iter: 3008/3680
[A[ATraining Step: 1475  | total loss: [1m[32m0.43439[0m[0m
[2K| Adam | epoch: 013 | loss: 0.43439 - acc: 0.7779 -- iter: 3040/3680
[A[ATraining Step: 1476  | total loss: [1m[32m0.45186[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45186 - acc: 0.7779 -- iter: 3072/3680
[A[ATraining Step: 1477  | total loss: [1m[32m0.45760[0m[0m
[2K| Adam | epoch: 013 | loss: 0.45760 - acc: 0.7751 -- iter: 3104/3680
[A[ATraining Step: 1478  | total loss: [1m[32m0.46963[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46963 - acc: 0.7695 -- iter: 3136/3680
[A[ATraining Step: 1479  | total loss: [1m[32m0.46506[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46506 - acc: 0.7769 -- iter: 3168/3680
[A[ATraining Step: 1480  | total loss: [1m[32m0.46667[0m[0m
[2K| Adam | epoch: 013 | loss: 0.46667 - acc: 0.7711 -- iter: 3200/3680
[A[ATraining Step: 1481  | total loss: [1m[32m0.47223[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47223 - acc: 0.7628 -- iter: 3232/3680
[A[ATraining Step: 1482  | total loss: [1m[32m0.47597[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47597 - acc: 0.7677 -- iter: 3264/3680
[A[ATraining Step: 1483  | total loss: [1m[32m0.48491[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48491 - acc: 0.7597 -- iter: 3296/3680
[A[ATraining Step: 1484  | total loss: [1m[32m0.49082[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49082 - acc: 0.7587 -- iter: 3328/3680
[A[ATraining Step: 1485  | total loss: [1m[32m0.49098[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49098 - acc: 0.7610 -- iter: 3360/3680
[A[ATraining Step: 1486  | total loss: [1m[32m0.49177[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49177 - acc: 0.7599 -- iter: 3392/3680
[A[ATraining Step: 1487  | total loss: [1m[32m0.48973[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48973 - acc: 0.7651 -- iter: 3424/3680
[A[ATraining Step: 1488  | total loss: [1m[32m0.48995[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48995 - acc: 0.7605 -- iter: 3456/3680
[A[ATraining Step: 1489  | total loss: [1m[32m0.48437[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48437 - acc: 0.7657 -- iter: 3488/3680
[A[ATraining Step: 1490  | total loss: [1m[32m0.47555[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47555 - acc: 0.7735 -- iter: 3520/3680
[A[ATraining Step: 1491  | total loss: [1m[32m0.47259[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47259 - acc: 0.7743 -- iter: 3552/3680
[A[ATraining Step: 1492  | total loss: [1m[32m0.49447[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49447 - acc: 0.7484 -- iter: 3584/3680
[A[ATraining Step: 1493  | total loss: [1m[32m0.49447[0m[0m
[2K| Adam | epoch: 013 | loss: 0.49447 - acc: 0.7484 -- iter: 3616/3680
[A[ATraining Step: 1494  | total loss: [1m[32m0.47796[0m[0m
[2K| Adam | epoch: 013 | loss: 0.47796 - acc: 0.7642 -- iter: 3648/3680
[A[ATraining Step: 1495  | total loss: [1m[32m0.48057[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48057 - acc: 0.7503 | val_loss: 0.46231 - val_acc: 0.7948 -- iter: 3680/3680
[A[ATraining Step: 1495  | total loss: [1m[32m0.48057[0m[0m
[2K| Adam | epoch: 013 | loss: 0.48057 - acc: 0.7503 | val_loss: 0.46231 - val_acc: 0.7948 -- iter: 3680/3680
--
Training Step: 1496  | total loss: [1m[32m0.49180[0m[0m
[2K| Adam | epoch: 014 | loss: 0.49180 - acc: 0.7471 -- iter: 0032/3680
[A[ATraining Step: 1497  | total loss: [1m[32m0.48495[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48495 - acc: 0.7474 -- iter: 0064/3680
[A[ATraining Step: 1498  | total loss: [1m[32m0.48314[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48314 - acc: 0.7539 -- iter: 0096/3680
[A[ATraining Step: 1499  | total loss: [1m[32m0.48645[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48645 - acc: 0.7504 -- iter: 0128/3680
[A[ATraining Step: 1500  | total loss: [1m[32m0.46910[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46910 - acc: 0.7691 | val_loss: 0.46907 - val_acc: 0.8046 -- iter: 0160/3680
[A[ATraining Step: 1500  | total loss: [1m[32m0.46910[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46910 - acc: 0.7691 | val_loss: 0.46907 - val_acc: 0.8046 -- iter: 0160/3680
--
Training Step: 1501  | total loss: [1m[32m0.47078[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47078 - acc: 0.7703 -- iter: 0192/3680
[A[ATraining Step: 1502  | total loss: [1m[32m0.45835[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45835 - acc: 0.7839 -- iter: 0224/3680
[A[ATraining Step: 1503  | total loss: [1m[32m0.45434[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45434 - acc: 0.7868 -- iter: 0256/3680
[A[ATraining Step: 1504  | total loss: [1m[32m0.45016[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45016 - acc: 0.7987 -- iter: 0288/3680
[A[ATraining Step: 1505  | total loss: [1m[32m0.45704[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45704 - acc: 0.7970 -- iter: 0320/3680
[A[ATraining Step: 1506  | total loss: [1m[32m0.45555[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45555 - acc: 0.7954 -- iter: 0352/3680
[A[ATraining Step: 1507  | total loss: [1m[32m0.45654[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45654 - acc: 0.7971 -- iter: 0384/3680
[A[ATraining Step: 1508  | total loss: [1m[32m0.45769[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45769 - acc: 0.7955 -- iter: 0416/3680
[A[ATraining Step: 1509  | total loss: [1m[32m0.45494[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45494 - acc: 0.7956 -- iter: 0448/3680
[A[ATraining Step: 1510  | total loss: [1m[32m0.45208[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45208 - acc: 0.7956 -- iter: 0480/3680
[A[ATraining Step: 1511  | total loss: [1m[32m0.44311[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44311 - acc: 0.7942 -- iter: 0512/3680
[A[ATraining Step: 1512  | total loss: [1m[32m0.45550[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45550 - acc: 0.7804 -- iter: 0544/3680
[A[ATraining Step: 1513  | total loss: [1m[32m0.46457[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46457 - acc: 0.7805 -- iter: 0576/3680
[A[ATraining Step: 1514  | total loss: [1m[32m0.48125[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48125 - acc: 0.7681 -- iter: 0608/3680
[A[ATraining Step: 1515  | total loss: [1m[32m0.48899[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48899 - acc: 0.7631 -- iter: 0640/3680
[A[ATraining Step: 1516  | total loss: [1m[32m0.49138[0m[0m
[2K| Adam | epoch: 014 | loss: 0.49138 - acc: 0.7556 -- iter: 0672/3680
[A[ATraining Step: 1517  | total loss: [1m[32m0.49274[0m[0m
[2K| Adam | epoch: 014 | loss: 0.49274 - acc: 0.7550 -- iter: 0704/3680
[A[ATraining Step: 1518  | total loss: [1m[32m0.48952[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48952 - acc: 0.7608 -- iter: 0736/3680
[A[ATraining Step: 1519  | total loss: [1m[32m0.48729[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48729 - acc: 0.7628 -- iter: 0768/3680
[A[ATraining Step: 1520  | total loss: [1m[32m0.48352[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48352 - acc: 0.7694 -- iter: 0800/3680
[A[ATraining Step: 1521  | total loss: [1m[32m0.48352[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48352 - acc: 0.7694 -- iter: 0832/3680
[A[ATraining Step: 1522  | total loss: [1m[32m0.48274[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48274 - acc: 0.7800 -- iter: 0864/3680
[A[ATraining Step: 1523  | total loss: [1m[32m0.47622[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47622 - acc: 0.7864 -- iter: 0896/3680
[A[ATraining Step: 1524  | total loss: [1m[32m0.45750[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45750 - acc: 0.8015 -- iter: 0928/3680
[A[ATraining Step: 1525  | total loss: [1m[32m0.47191[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47191 - acc: 0.7932 -- iter: 0960/3680
[A[ATraining Step: 1526  | total loss: [1m[32m0.45966[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45966 - acc: 0.8014 -- iter: 0992/3680
[A[ATraining Step: 1527  | total loss: [1m[32m0.45447[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45447 - acc: 0.8025 -- iter: 1024/3680
[A[ATraining Step: 1528  | total loss: [1m[32m0.46203[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46203 - acc: 0.7879 -- iter: 1056/3680
[A[ATraining Step: 1529  | total loss: [1m[32m0.45508[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45508 - acc: 0.7997 -- iter: 1088/3680
[A[ATraining Step: 1530  | total loss: [1m[32m0.44653[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44653 - acc: 0.8104 -- iter: 1120/3680
[A[ATraining Step: 1531  | total loss: [1m[32m0.45709[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45709 - acc: 0.8043 -- iter: 1152/3680
[A[ATraining Step: 1532  | total loss: [1m[32m0.44773[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44773 - acc: 0.8114 -- iter: 1184/3680
[A[ATraining Step: 1533  | total loss: [1m[32m0.43617[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43617 - acc: 0.8240 -- iter: 1216/3680
[A[ATraining Step: 1534  | total loss: [1m[32m0.44130[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44130 - acc: 0.8135 -- iter: 1248/3680
[A[ATraining Step: 1535  | total loss: [1m[32m0.44450[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44450 - acc: 0.8071 -- iter: 1280/3680
[A[ATraining Step: 1536  | total loss: [1m[32m0.44309[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44309 - acc: 0.8108 -- iter: 1312/3680
[A[ATraining Step: 1537  | total loss: [1m[32m0.43815[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43815 - acc: 0.8110 -- iter: 1344/3680
[A[ATraining Step: 1538  | total loss: [1m[32m0.43548[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43548 - acc: 0.8111 -- iter: 1376/3680
[A[ATraining Step: 1539  | total loss: [1m[32m0.43630[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43630 - acc: 0.8050 -- iter: 1408/3680
[A[ATraining Step: 1540  | total loss: [1m[32m0.43645[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43645 - acc: 0.8058 -- iter: 1440/3680
[A[ATraining Step: 1541  | total loss: [1m[32m0.42794[0m[0m
[2K| Adam | epoch: 014 | loss: 0.42794 - acc: 0.8158 -- iter: 1472/3680
[A[ATraining Step: 1542  | total loss: [1m[32m0.43228[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43228 - acc: 0.8155 -- iter: 1504/3680
[A[ATraining Step: 1543  | total loss: [1m[32m0.42298[0m[0m
[2K| Adam | epoch: 014 | loss: 0.42298 - acc: 0.8152 -- iter: 1536/3680
[A[ATraining Step: 1544  | total loss: [1m[32m0.42308[0m[0m
[2K| Adam | epoch: 014 | loss: 0.42308 - acc: 0.8149 -- iter: 1568/3680
[A[ATraining Step: 1545  | total loss: [1m[32m0.43622[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43622 - acc: 0.8053 -- iter: 1600/3680
[A[ATraining Step: 1546  | total loss: [1m[32m0.42682[0m[0m
[2K| Adam | epoch: 014 | loss: 0.42682 - acc: 0.8185 -- iter: 1632/3680
[A[ATraining Step: 1547  | total loss: [1m[32m0.42664[0m[0m
[2K| Adam | epoch: 014 | loss: 0.42664 - acc: 0.8179 -- iter: 1664/3680
[A[ATraining Step: 1548  | total loss: [1m[32m0.44362[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44362 - acc: 0.8111 -- iter: 1696/3680
[A[ATraining Step: 1549  | total loss: [1m[32m0.43721[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43721 - acc: 0.8144 -- iter: 1728/3680
[A[ATraining Step: 1550  | total loss: [1m[32m0.43229[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43229 - acc: 0.8142 -- iter: 1760/3680
[A[ATraining Step: 1551  | total loss: [1m[32m0.43145[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43145 - acc: 0.8078 -- iter: 1792/3680
[A[ATraining Step: 1552  | total loss: [1m[32m0.41786[0m[0m
[2K| Adam | epoch: 014 | loss: 0.41786 - acc: 0.8239 -- iter: 1824/3680
[A[ATraining Step: 1553  | total loss: [1m[32m0.41997[0m[0m
[2K| Adam | epoch: 014 | loss: 0.41997 - acc: 0.8165 -- iter: 1856/3680
[A[ATraining Step: 1554  | total loss: [1m[32m0.41812[0m[0m
[2K| Adam | epoch: 014 | loss: 0.41812 - acc: 0.8161 -- iter: 1888/3680
[A[ATraining Step: 1555  | total loss: [1m[32m0.43054[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43054 - acc: 0.8126 -- iter: 1920/3680
[A[ATraining Step: 1556  | total loss: [1m[32m0.42978[0m[0m
[2K| Adam | epoch: 014 | loss: 0.42978 - acc: 0.8188 -- iter: 1952/3680
[A[ATraining Step: 1557  | total loss: [1m[32m0.43737[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43737 - acc: 0.8088 -- iter: 1984/3680
[A[ATraining Step: 1558  | total loss: [1m[32m0.44233[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44233 - acc: 0.8030 -- iter: 2016/3680
[A[ATraining Step: 1559  | total loss: [1m[32m0.43963[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43963 - acc: 0.8039 -- iter: 2048/3680
[A[ATraining Step: 1560  | total loss: [1m[32m0.45128[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45128 - acc: 0.8048 -- iter: 2080/3680
[A[ATraining Step: 1561  | total loss: [1m[32m0.45917[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45917 - acc: 0.8055 -- iter: 2112/3680
[A[ATraining Step: 1562  | total loss: [1m[32m0.45258[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45258 - acc: 0.8031 -- iter: 2144/3680
[A[ATraining Step: 1563  | total loss: [1m[32m0.46062[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46062 - acc: 0.7868 -- iter: 2176/3680
[A[ATraining Step: 1564  | total loss: [1m[32m0.46159[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46159 - acc: 0.7868 -- iter: 2208/3680
[A[ATraining Step: 1565  | total loss: [1m[32m0.46265[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46265 - acc: 0.7800 -- iter: 2240/3680
[A[ATraining Step: 1566  | total loss: [1m[32m0.44512[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44512 - acc: 0.7926 -- iter: 2272/3680
[A[ATraining Step: 1567  | total loss: [1m[32m0.45145[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45145 - acc: 0.7946 -- iter: 2304/3680
[A[ATraining Step: 1568  | total loss: [1m[32m0.43782[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43782 - acc: 0.8026 -- iter: 2336/3680
[A[ATraining Step: 1569  | total loss: [1m[32m0.43475[0m[0m
[2K| Adam | epoch: 014 | loss: 0.43475 - acc: 0.7974 -- iter: 2368/3680
[A[ATraining Step: 1570  | total loss: [1m[32m0.44789[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44789 - acc: 0.7958 -- iter: 2400/3680
[A[ATraining Step: 1571  | total loss: [1m[32m0.45563[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45563 - acc: 0.7912 -- iter: 2432/3680
[A[ATraining Step: 1572  | total loss: [1m[32m0.44816[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44816 - acc: 0.7902 -- iter: 2464/3680
[A[ATraining Step: 1573  | total loss: [1m[32m0.45164[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45164 - acc: 0.7924 -- iter: 2496/3680
[A[ATraining Step: 1574  | total loss: [1m[32m0.46376[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46376 - acc: 0.7850 -- iter: 2528/3680
[A[ATraining Step: 1575  | total loss: [1m[32m0.46343[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46343 - acc: 0.7909 -- iter: 2560/3680
[A[ATraining Step: 1576  | total loss: [1m[32m0.46986[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46986 - acc: 0.7900 -- iter: 2592/3680
[A[ATraining Step: 1577  | total loss: [1m[32m0.46431[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46431 - acc: 0.7922 -- iter: 2624/3680
[A[ATraining Step: 1578  | total loss: [1m[32m0.46505[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46505 - acc: 0.7880 -- iter: 2656/3680
[A[ATraining Step: 1579  | total loss: [1m[32m0.45600[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45600 - acc: 0.7936 -- iter: 2688/3680
[A[ATraining Step: 1580  | total loss: [1m[32m0.45653[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45653 - acc: 0.7861 -- iter: 2720/3680
[A[ATraining Step: 1581  | total loss: [1m[32m0.46486[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46486 - acc: 0.7793 -- iter: 2752/3680
[A[ATraining Step: 1582  | total loss: [1m[32m0.47955[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47955 - acc: 0.7670 -- iter: 2784/3680
[A[ATraining Step: 1583  | total loss: [1m[32m0.48501[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48501 - acc: 0.7747 -- iter: 2816/3680
[A[ATraining Step: 1584  | total loss: [1m[32m0.48106[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48106 - acc: 0.7691 -- iter: 2848/3680
[A[ATraining Step: 1585  | total loss: [1m[32m0.46232[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46232 - acc: 0.7828 -- iter: 2880/3680
[A[ATraining Step: 1586  | total loss: [1m[32m0.46795[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46795 - acc: 0.7764 -- iter: 2912/3680
[A[ATraining Step: 1587  | total loss: [1m[32m0.48235[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48235 - acc: 0.7675 -- iter: 2944/3680
[A[ATraining Step: 1588  | total loss: [1m[32m0.48261[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48261 - acc: 0.7658 -- iter: 2976/3680
[A[ATraining Step: 1589  | total loss: [1m[32m0.47828[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47828 - acc: 0.7590 -- iter: 3008/3680
[A[ATraining Step: 1590  | total loss: [1m[32m0.47847[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47847 - acc: 0.7612 -- iter: 3040/3680
[A[ATraining Step: 1591  | total loss: [1m[32m0.47847[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47847 - acc: 0.7612 -- iter: 3072/3680
[A[ATraining Step: 1592  | total loss: [1m[32m0.50084[0m[0m
[2K| Adam | epoch: 014 | loss: 0.50084 - acc: 0.7601 -- iter: 3104/3680
[A[ATraining Step: 1593  | total loss: [1m[32m0.49590[0m[0m
[2K| Adam | epoch: 014 | loss: 0.49590 - acc: 0.7654 -- iter: 3136/3680
[A[ATraining Step: 1594  | total loss: [1m[32m0.48829[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48829 - acc: 0.7701 -- iter: 3168/3680
[A[ATraining Step: 1595  | total loss: [1m[32m0.47207[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47207 - acc: 0.7806 -- iter: 3200/3680
[A[ATraining Step: 1596  | total loss: [1m[32m0.46525[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46525 - acc: 0.7806 -- iter: 3232/3680
[A[ATraining Step: 1597  | total loss: [1m[32m0.46508[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46508 - acc: 0.7776 -- iter: 3264/3680
[A[ATraining Step: 1598  | total loss: [1m[32m0.45811[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45811 - acc: 0.7842 -- iter: 3296/3680
[A[ATraining Step: 1599  | total loss: [1m[32m0.44910[0m[0m
[2K| Adam | epoch: 014 | loss: 0.44910 - acc: 0.7933 -- iter: 3328/3680
[A[ATraining Step: 1600  | total loss: [1m[32m0.45242[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45242 - acc: 0.7858 | val_loss: 0.45910 - val_acc: 0.7948 -- iter: 3360/3680
[A[ATraining Step: 1600  | total loss: [1m[32m0.45242[0m[0m
[2K| Adam | epoch: 014 | loss: 0.45242 - acc: 0.7858 | val_loss: 0.45910 - val_acc: 0.7948 -- iter: 3360/3680
--
Training Step: 1601  | total loss: [1m[32m0.46847[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46847 - acc: 0.7791 -- iter: 3392/3680
[A[ATraining Step: 1602  | total loss: [1m[32m0.48084[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48084 - acc: 0.7731 -- iter: 3424/3680
[A[ATraining Step: 1603  | total loss: [1m[32m0.48125[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48125 - acc: 0.7614 -- iter: 3456/3680
[A[ATraining Step: 1604  | total loss: [1m[32m0.47290[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47290 - acc: 0.7665 -- iter: 3488/3680
[A[ATraining Step: 1605  | total loss: [1m[32m0.46970[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46970 - acc: 0.7711 -- iter: 3520/3680
[A[ATraining Step: 1606  | total loss: [1m[32m0.46473[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46473 - acc: 0.7721 -- iter: 3552/3680
[A[ATraining Step: 1607  | total loss: [1m[32m0.46125[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46125 - acc: 0.7699 -- iter: 3584/3680
[A[ATraining Step: 1608  | total loss: [1m[32m0.46726[0m[0m
[2K| Adam | epoch: 014 | loss: 0.46726 - acc: 0.7658 -- iter: 3616/3680
[A[ATraining Step: 1609  | total loss: [1m[32m0.48267[0m[0m
[2K| Adam | epoch: 014 | loss: 0.48267 - acc: 0.7658 -- iter: 3648/3680
[A[ATraining Step: 1610  | total loss: [1m[32m0.47769[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47769 - acc: 0.7642 | val_loss: 0.45912 - val_acc: 0.8024 -- iter: 3680/3680
[A[ATraining Step: 1610  | total loss: [1m[32m0.47769[0m[0m
[2K| Adam | epoch: 014 | loss: 0.47769 - acc: 0.7642 | val_loss: 0.45912 - val_acc: 0.8024 -- iter: 3680/3680
--
Training Step: 1611  | total loss: [1m[32m0.49590[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49590 - acc: 0.7566 -- iter: 0032/3680
[A[ATraining Step: 1612  | total loss: [1m[32m0.49305[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49305 - acc: 0.7590 -- iter: 0064/3680
[A[ATraining Step: 1613  | total loss: [1m[32m0.49574[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49574 - acc: 0.7581 -- iter: 0096/3680
[A[ATraining Step: 1614  | total loss: [1m[32m0.48896[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48896 - acc: 0.7667 -- iter: 0128/3680
[A[ATraining Step: 1615  | total loss: [1m[32m0.49292[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49292 - acc: 0.7650 -- iter: 0160/3680
[A[ATraining Step: 1616  | total loss: [1m[32m0.48886[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48886 - acc: 0.7635 -- iter: 0192/3680
[A[ATraining Step: 1617  | total loss: [1m[32m0.49235[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49235 - acc: 0.7653 -- iter: 0224/3680
[A[ATraining Step: 1618  | total loss: [1m[32m0.48801[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48801 - acc: 0.7638 -- iter: 0256/3680
[A[ATraining Step: 1619  | total loss: [1m[32m0.48577[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48577 - acc: 0.7624 -- iter: 0288/3680
[A[ATraining Step: 1620  | total loss: [1m[32m0.47975[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47975 - acc: 0.7705 -- iter: 0320/3680
[A[ATraining Step: 1621  | total loss: [1m[32m0.49633[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49633 - acc: 0.7622 -- iter: 0352/3680
[A[ATraining Step: 1622  | total loss: [1m[32m0.48998[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48998 - acc: 0.7735 -- iter: 0384/3680
[A[ATraining Step: 1623  | total loss: [1m[32m0.49442[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49442 - acc: 0.7711 -- iter: 0416/3680
[A[ATraining Step: 1624  | total loss: [1m[32m0.49353[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49353 - acc: 0.7690 -- iter: 0448/3680
[A[ATraining Step: 1625  | total loss: [1m[32m0.49253[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49253 - acc: 0.7703 -- iter: 0480/3680
[A[ATraining Step: 1626  | total loss: [1m[32m0.48301[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48301 - acc: 0.7714 -- iter: 0512/3680
[A[ATraining Step: 1627  | total loss: [1m[32m0.48392[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48392 - acc: 0.7661 -- iter: 0544/3680
[A[ATraining Step: 1628  | total loss: [1m[32m0.50337[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50337 - acc: 0.7520 -- iter: 0576/3680
[A[ATraining Step: 1629  | total loss: [1m[32m0.50639[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50639 - acc: 0.7580 -- iter: 0608/3680
[A[ATraining Step: 1630  | total loss: [1m[32m0.50079[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50079 - acc: 0.7604 -- iter: 0640/3680
[A[ATraining Step: 1631  | total loss: [1m[32m0.51105[0m[0m
[2K| Adam | epoch: 015 | loss: 0.51105 - acc: 0.7656 -- iter: 0672/3680
[A[ATraining Step: 1632  | total loss: [1m[32m0.51224[0m[0m
[2K| Adam | epoch: 015 | loss: 0.51224 - acc: 0.7609 -- iter: 0704/3680
[A[ATraining Step: 1633  | total loss: [1m[32m0.50947[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50947 - acc: 0.7629 -- iter: 0736/3680
[A[ATraining Step: 1634  | total loss: [1m[32m0.49934[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49934 - acc: 0.7710 -- iter: 0768/3680
[A[ATraining Step: 1635  | total loss: [1m[32m0.49233[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49233 - acc: 0.7752 -- iter: 0800/3680
[A[ATraining Step: 1636  | total loss: [1m[32m0.49087[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49087 - acc: 0.7766 -- iter: 0832/3680
[A[ATraining Step: 1637  | total loss: [1m[32m0.49287[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49287 - acc: 0.7766 -- iter: 0864/3680
[A[ATraining Step: 1638  | total loss: [1m[32m0.49403[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49403 - acc: 0.7771 -- iter: 0896/3680
[A[ATraining Step: 1639  | total loss: [1m[32m0.48011[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48011 - acc: 0.7838 -- iter: 0928/3680
[A[ATraining Step: 1640  | total loss: [1m[32m0.49150[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49150 - acc: 0.7679 -- iter: 0960/3680
[A[ATraining Step: 1641  | total loss: [1m[32m0.47989[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47989 - acc: 0.7755 -- iter: 0992/3680
[A[ATraining Step: 1642  | total loss: [1m[32m0.48302[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48302 - acc: 0.7698 -- iter: 1024/3680
[A[ATraining Step: 1643  | total loss: [1m[32m0.47991[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47991 - acc: 0.7741 -- iter: 1056/3680
[A[ATraining Step: 1644  | total loss: [1m[32m0.47750[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47750 - acc: 0.7810 -- iter: 1088/3680
[A[ATraining Step: 1645  | total loss: [1m[32m0.47410[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47410 - acc: 0.7779 -- iter: 1120/3680
[A[ATraining Step: 1646  | total loss: [1m[32m0.48356[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48356 - acc: 0.7626 -- iter: 1152/3680
[A[ATraining Step: 1647  | total loss: [1m[32m0.48331[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48331 - acc: 0.7582 -- iter: 1184/3680
[A[ATraining Step: 1648  | total loss: [1m[32m0.47047[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47047 - acc: 0.7699 -- iter: 1216/3680
[A[ATraining Step: 1649  | total loss: [1m[32m0.46364[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46364 - acc: 0.7742 -- iter: 1248/3680
[A[ATraining Step: 1650  | total loss: [1m[32m0.44759[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44759 - acc: 0.7905 -- iter: 1280/3680
[A[ATraining Step: 1651  | total loss: [1m[32m0.44289[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44289 - acc: 0.7958 -- iter: 1312/3680
[A[ATraining Step: 1652  | total loss: [1m[32m0.44444[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44444 - acc: 0.7975 -- iter: 1344/3680
[A[ATraining Step: 1653  | total loss: [1m[32m0.43074[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43074 - acc: 0.8053 -- iter: 1376/3680
[A[ATraining Step: 1654  | total loss: [1m[32m0.42629[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42629 - acc: 0.8060 -- iter: 1408/3680
[A[ATraining Step: 1655  | total loss: [1m[32m0.42087[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42087 - acc: 0.8098 -- iter: 1440/3680
[A[ATraining Step: 1656  | total loss: [1m[32m0.42336[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42336 - acc: 0.8038 -- iter: 1472/3680
[A[ATraining Step: 1657  | total loss: [1m[32m0.41973[0m[0m
[2K| Adam | epoch: 015 | loss: 0.41973 - acc: 0.8015 -- iter: 1504/3680
[A[ATraining Step: 1658  | total loss: [1m[32m0.43398[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43398 - acc: 0.7995 -- iter: 1536/3680
[A[ATraining Step: 1659  | total loss: [1m[32m0.42794[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42794 - acc: 0.8070 -- iter: 1568/3680
[A[ATraining Step: 1660  | total loss: [1m[32m0.43551[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43551 - acc: 0.7982 -- iter: 1600/3680
[A[ATraining Step: 1661  | total loss: [1m[32m0.43754[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43754 - acc: 0.7903 -- iter: 1632/3680
[A[ATraining Step: 1662  | total loss: [1m[32m0.45379[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45379 - acc: 0.7894 -- iter: 1664/3680
[A[ATraining Step: 1663  | total loss: [1m[32m0.46821[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46821 - acc: 0.7792 -- iter: 1696/3680
[A[ATraining Step: 1664  | total loss: [1m[32m0.46548[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46548 - acc: 0.7731 -- iter: 1728/3680
[A[ATraining Step: 1665  | total loss: [1m[32m0.46042[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46042 - acc: 0.7833 -- iter: 1760/3680
[A[ATraining Step: 1666  | total loss: [1m[32m0.45735[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45735 - acc: 0.7894 -- iter: 1792/3680
[A[ATraining Step: 1667  | total loss: [1m[32m0.46597[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46597 - acc: 0.7761 -- iter: 1824/3680
[A[ATraining Step: 1668  | total loss: [1m[32m0.45999[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45999 - acc: 0.7797 -- iter: 1856/3680
[A[ATraining Step: 1669  | total loss: [1m[32m0.45800[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45800 - acc: 0.7861 -- iter: 1888/3680
[A[ATraining Step: 1670  | total loss: [1m[32m0.47083[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47083 - acc: 0.7794 -- iter: 1920/3680
[A[ATraining Step: 1671  | total loss: [1m[32m0.47433[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47433 - acc: 0.7733 -- iter: 1952/3680
[A[ATraining Step: 1672  | total loss: [1m[32m0.47946[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47946 - acc: 0.7647 -- iter: 1984/3680
[A[ATraining Step: 1673  | total loss: [1m[32m0.49510[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49510 - acc: 0.7570 -- iter: 2016/3680
[A[ATraining Step: 1674  | total loss: [1m[32m0.49637[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49637 - acc: 0.7532 -- iter: 2048/3680
[A[ATraining Step: 1675  | total loss: [1m[32m0.48573[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48573 - acc: 0.7654 -- iter: 2080/3680
[A[ATraining Step: 1676  | total loss: [1m[32m0.50107[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50107 - acc: 0.7540 -- iter: 2112/3680
[A[ATraining Step: 1677  | total loss: [1m[32m0.50107[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50107 - acc: 0.7540 -- iter: 2144/3680
[A[ATraining Step: 1678  | total loss: [1m[32m0.49471[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49471 - acc: 0.7630 -- iter: 2176/3680
[A[ATraining Step: 1679  | total loss: [1m[32m0.49689[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49689 - acc: 0.7617 -- iter: 2208/3680
[A[ATraining Step: 1680  | total loss: [1m[32m0.49370[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49370 - acc: 0.7699 -- iter: 2240/3680
[A[ATraining Step: 1681  | total loss: [1m[32m0.49256[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49256 - acc: 0.7648 -- iter: 2272/3680
[A[ATraining Step: 1682  | total loss: [1m[32m0.50963[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50963 - acc: 0.7602 -- iter: 2304/3680
[A[ATraining Step: 1683  | total loss: [1m[32m0.49469[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49469 - acc: 0.7717 -- iter: 2336/3680
[A[ATraining Step: 1684  | total loss: [1m[32m0.48662[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48662 - acc: 0.7789 -- iter: 2368/3680
[A[ATraining Step: 1685  | total loss: [1m[32m0.47778[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47778 - acc: 0.7822 -- iter: 2400/3680
[A[ATraining Step: 1686  | total loss: [1m[32m0.46273[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46273 - acc: 0.7884 -- iter: 2432/3680
[A[ATraining Step: 1687  | total loss: [1m[32m0.47505[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47505 - acc: 0.7752 -- iter: 2464/3680
[A[ATraining Step: 1688  | total loss: [1m[32m0.47977[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47977 - acc: 0.7664 -- iter: 2496/3680
[A[ATraining Step: 1689  | total loss: [1m[32m0.47232[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47232 - acc: 0.7741 -- iter: 2528/3680
[A[ATraining Step: 1690  | total loss: [1m[32m0.45994[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45994 - acc: 0.7811 -- iter: 2560/3680
[A[ATraining Step: 1691  | total loss: [1m[32m0.45186[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45186 - acc: 0.7905 -- iter: 2592/3680
[A[ATraining Step: 1692  | total loss: [1m[32m0.45120[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45120 - acc: 0.7927 -- iter: 2624/3680
[A[ATraining Step: 1693  | total loss: [1m[32m0.44111[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44111 - acc: 0.7978 -- iter: 2656/3680
[A[ATraining Step: 1694  | total loss: [1m[32m0.44309[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44309 - acc: 0.7993 -- iter: 2688/3680
[A[ATraining Step: 1695  | total loss: [1m[32m0.44196[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44196 - acc: 0.8037 -- iter: 2720/3680
[A[ATraining Step: 1696  | total loss: [1m[32m0.43065[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43065 - acc: 0.8077 -- iter: 2752/3680
[A[ATraining Step: 1697  | total loss: [1m[32m0.42510[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42510 - acc: 0.8176 -- iter: 2784/3680
[A[ATraining Step: 1698  | total loss: [1m[32m0.43267[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43267 - acc: 0.8171 -- iter: 2816/3680
[A[ATraining Step: 1699  | total loss: [1m[32m0.44011[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44011 - acc: 0.8135 -- iter: 2848/3680
[A[ATraining Step: 1700  | total loss: [1m[32m0.43448[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43448 - acc: 0.8165 | val_loss: 0.45712 - val_acc: 0.7915 -- iter: 2880/3680
[A[ATraining Step: 1700  | total loss: [1m[32m0.43448[0m[0m
[2K| Adam | epoch: 015 | loss: 0.43448 - acc: 0.8165 | val_loss: 0.45712 - val_acc: 0.7915 -- iter: 2880/3680
--
Training Step: 1701  | total loss: [1m[32m0.42575[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42575 - acc: 0.8224 -- iter: 2912/3680
[A[ATraining Step: 1702  | total loss: [1m[32m0.42809[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42809 - acc: 0.8151 -- iter: 2944/3680
[A[ATraining Step: 1703  | total loss: [1m[32m0.42489[0m[0m
[2K| Adam | epoch: 015 | loss: 0.42489 - acc: 0.8180 -- iter: 2976/3680
[A[ATraining Step: 1704  | total loss: [1m[32m0.44202[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44202 - acc: 0.8018 -- iter: 3008/3680
[A[ATraining Step: 1705  | total loss: [1m[32m0.44811[0m[0m
[2K| Adam | epoch: 015 | loss: 0.44811 - acc: 0.7966 -- iter: 3040/3680
[A[ATraining Step: 1706  | total loss: [1m[32m0.45695[0m[0m
[2K| Adam | epoch: 015 | loss: 0.45695 - acc: 0.7920 -- iter: 3072/3680
[A[ATraining Step: 1707  | total loss: [1m[32m0.46097[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46097 - acc: 0.7878 -- iter: 3104/3680
[A[ATraining Step: 1708  | total loss: [1m[32m0.51249[0m[0m
[2K| Adam | epoch: 015 | loss: 0.51249 - acc: 0.7590 -- iter: 3136/3680
[A[ATraining Step: 1709  | total loss: [1m[32m0.49710[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49710 - acc: 0.7768 -- iter: 3168/3680
[A[ATraining Step: 1710  | total loss: [1m[32m0.50041[0m[0m
[2K| Adam | epoch: 015 | loss: 0.50041 - acc: 0.7742 -- iter: 3200/3680
[A[ATraining Step: 1711  | total loss: [1m[32m0.49267[0m[0m
[2K| Adam | epoch: 015 | loss: 0.49267 - acc: 0.7811 -- iter: 3232/3680
[A[ATraining Step: 1712  | total loss: [1m[32m0.48988[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48988 - acc: 0.7843 -- iter: 3264/3680
[A[ATraining Step: 1713  | total loss: [1m[32m0.47732[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47732 - acc: 0.7965 -- iter: 3296/3680
[A[ATraining Step: 1714  | total loss: [1m[32m0.47677[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47677 - acc: 0.7918 -- iter: 3328/3680
[A[ATraining Step: 1715  | total loss: [1m[32m0.47744[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47744 - acc: 0.7908 -- iter: 3360/3680
[A[ATraining Step: 1716  | total loss: [1m[32m0.46891[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46891 - acc: 0.7961 -- iter: 3392/3680
[A[ATraining Step: 1717  | total loss: [1m[32m0.47372[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47372 - acc: 0.7946 -- iter: 3424/3680
[A[ATraining Step: 1718  | total loss: [1m[32m0.47975[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47975 - acc: 0.7901 -- iter: 3456/3680
[A[ATraining Step: 1719  | total loss: [1m[32m0.47235[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47235 - acc: 0.7955 -- iter: 3488/3680
[A[ATraining Step: 1720  | total loss: [1m[32m0.48149[0m[0m
[2K| Adam | epoch: 015 | loss: 0.48149 - acc: 0.7847 -- iter: 3520/3680
[A[ATraining Step: 1721  | total loss: [1m[32m0.47111[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47111 - acc: 0.7875 -- iter: 3552/3680
[A[ATraining Step: 1722  | total loss: [1m[32m0.46485[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46485 - acc: 0.7931 -- iter: 3584/3680
[A[ATraining Step: 1723  | total loss: [1m[32m0.46483[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46483 - acc: 0.7888 -- iter: 3616/3680
[A[ATraining Step: 1724  | total loss: [1m[32m0.46335[0m[0m
[2K| Adam | epoch: 015 | loss: 0.46335 - acc: 0.7912 -- iter: 3648/3680
[A[ATraining Step: 1725  | total loss: [1m[32m0.47286[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47286 - acc: 0.7808 | val_loss: 0.45494 - val_acc: 0.8078 -- iter: 3680/3680
[A[ATraining Step: 1725  | total loss: [1m[32m0.47286[0m[0m
[2K| Adam | epoch: 015 | loss: 0.47286 - acc: 0.7808 | val_loss: 0.45494 - val_acc: 0.8078 -- iter: 3680/3680
--
Training Step: 1726  | total loss: [1m[32m0.47059[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47059 - acc: 0.7746 -- iter: 0032/3680
[A[ATraining Step: 1727  | total loss: [1m[32m0.46771[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46771 - acc: 0.7912 -- iter: 0064/3680
[A[ATraining Step: 1728  | total loss: [1m[32m0.46771[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46771 - acc: 0.7912 -- iter: 0096/3680
[A[ATraining Step: 1729  | total loss: [1m[32m0.46170[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46170 - acc: 0.7964 -- iter: 0128/3680
[A[ATraining Step: 1730  | total loss: [1m[32m0.45862[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45862 - acc: 0.8012 -- iter: 0160/3680
[A[ATraining Step: 1731  | total loss: [1m[32m0.45936[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45936 - acc: 0.7929 -- iter: 0192/3680
[A[ATraining Step: 1732  | total loss: [1m[32m0.45272[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45272 - acc: 0.8042 -- iter: 0224/3680
[A[ATraining Step: 1733  | total loss: [1m[32m0.45656[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45656 - acc: 0.8019 -- iter: 0256/3680
[A[ATraining Step: 1734  | total loss: [1m[32m0.46131[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46131 - acc: 0.7968 -- iter: 0288/3680
[A[ATraining Step: 1735  | total loss: [1m[32m0.46099[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46099 - acc: 0.7890 -- iter: 0320/3680
[A[ATraining Step: 1736  | total loss: [1m[32m0.46877[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46877 - acc: 0.7851 -- iter: 0352/3680
[A[ATraining Step: 1737  | total loss: [1m[32m0.46893[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46893 - acc: 0.7784 -- iter: 0384/3680
[A[ATraining Step: 1738  | total loss: [1m[32m0.47810[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47810 - acc: 0.7850 -- iter: 0416/3680
[A[ATraining Step: 1739  | total loss: [1m[32m0.48242[0m[0m
[2K| Adam | epoch: 016 | loss: 0.48242 - acc: 0.7815 -- iter: 0448/3680
[A[ATraining Step: 1740  | total loss: [1m[32m0.48508[0m[0m
[2K| Adam | epoch: 016 | loss: 0.48508 - acc: 0.7752 -- iter: 0480/3680
[A[ATraining Step: 1741  | total loss: [1m[32m0.47715[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47715 - acc: 0.7758 -- iter: 0512/3680
[A[ATraining Step: 1742  | total loss: [1m[32m0.46720[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46720 - acc: 0.7795 -- iter: 0544/3680
[A[ATraining Step: 1743  | total loss: [1m[32m0.48614[0m[0m
[2K| Adam | epoch: 016 | loss: 0.48614 - acc: 0.7692 -- iter: 0576/3680
[A[ATraining Step: 1744  | total loss: [1m[32m0.47674[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47674 - acc: 0.7692 -- iter: 0608/3680
[A[ATraining Step: 1745  | total loss: [1m[32m0.47632[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47632 - acc: 0.7735 -- iter: 0640/3680
[A[ATraining Step: 1746  | total loss: [1m[32m0.47577[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47577 - acc: 0.7712 -- iter: 0672/3680
[A[ATraining Step: 1747  | total loss: [1m[32m0.46793[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46793 - acc: 0.7846 -- iter: 0704/3680
[A[ATraining Step: 1748  | total loss: [1m[32m0.46487[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46487 - acc: 0.7846 -- iter: 0736/3680
[A[ATraining Step: 1749  | total loss: [1m[32m0.46844[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46844 - acc: 0.7812 -- iter: 0768/3680
[A[ATraining Step: 1750  | total loss: [1m[32m0.46539[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46539 - acc: 0.7812 -- iter: 0800/3680
[A[ATraining Step: 1751  | total loss: [1m[32m0.47083[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47083 - acc: 0.7781 -- iter: 0832/3680
[A[ATraining Step: 1752  | total loss: [1m[32m0.47268[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47268 - acc: 0.7721 -- iter: 0864/3680
[A[ATraining Step: 1753  | total loss: [1m[32m0.46634[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46634 - acc: 0.7793 -- iter: 0896/3680
[A[ATraining Step: 1754  | total loss: [1m[32m0.45905[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45905 - acc: 0.7826 -- iter: 0928/3680
[A[ATraining Step: 1755  | total loss: [1m[32m0.47767[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47767 - acc: 0.7637 -- iter: 0960/3680
[A[ATraining Step: 1756  | total loss: [1m[32m0.46386[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46386 - acc: 0.7749 -- iter: 0992/3680
[A[ATraining Step: 1757  | total loss: [1m[32m0.47438[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47438 - acc: 0.7692 -- iter: 1024/3680
[A[ATraining Step: 1758  | total loss: [1m[32m0.46698[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46698 - acc: 0.7673 -- iter: 1056/3680
[A[ATraining Step: 1759  | total loss: [1m[32m0.45312[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45312 - acc: 0.7812 -- iter: 1088/3680
[A[ATraining Step: 1760  | total loss: [1m[32m0.44340[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44340 - acc: 0.7843 -- iter: 1120/3680
[A[ATraining Step: 1761  | total loss: [1m[32m0.44874[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44874 - acc: 0.7872 -- iter: 1152/3680
[A[ATraining Step: 1762  | total loss: [1m[32m0.45291[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45291 - acc: 0.7866 -- iter: 1184/3680
[A[ATraining Step: 1763  | total loss: [1m[32m0.45463[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45463 - acc: 0.7892 -- iter: 1216/3680
[A[ATraining Step: 1764  | total loss: [1m[32m0.45016[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45016 - acc: 0.7977 -- iter: 1248/3680
[A[ATraining Step: 1765  | total loss: [1m[32m0.45845[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45845 - acc: 0.7961 -- iter: 1280/3680
[A[ATraining Step: 1766  | total loss: [1m[32m0.45918[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45918 - acc: 0.7946 -- iter: 1312/3680
[A[ATraining Step: 1767  | total loss: [1m[32m0.44641[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44641 - acc: 0.7995 -- iter: 1344/3680
[A[ATraining Step: 1768  | total loss: [1m[32m0.44360[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44360 - acc: 0.8071 -- iter: 1376/3680
[A[ATraining Step: 1769  | total loss: [1m[32m0.45214[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45214 - acc: 0.7982 -- iter: 1408/3680
[A[ATraining Step: 1770  | total loss: [1m[32m0.45442[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45442 - acc: 0.7903 -- iter: 1440/3680
[A[ATraining Step: 1771  | total loss: [1m[32m0.43906[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43906 - acc: 0.7988 -- iter: 1472/3680
[A[ATraining Step: 1772  | total loss: [1m[32m0.43416[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43416 - acc: 0.8001 -- iter: 1504/3680
[A[ATraining Step: 1773  | total loss: [1m[32m0.42490[0m[0m
[2K| Adam | epoch: 016 | loss: 0.42490 - acc: 0.8014 -- iter: 1536/3680
[A[ATraining Step: 1774  | total loss: [1m[32m0.44029[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44029 - acc: 0.8056 -- iter: 1568/3680
[A[ATraining Step: 1775  | total loss: [1m[32m0.44758[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44758 - acc: 0.7969 -- iter: 1600/3680
[A[ATraining Step: 1776  | total loss: [1m[32m0.44003[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44003 - acc: 0.8016 -- iter: 1632/3680
[A[ATraining Step: 1777  | total loss: [1m[32m0.45801[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45801 - acc: 0.7964 -- iter: 1664/3680
[A[ATraining Step: 1778  | total loss: [1m[32m0.44721[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44721 - acc: 0.7981 -- iter: 1696/3680
[A[ATraining Step: 1779  | total loss: [1m[32m0.45593[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45593 - acc: 0.7870 -- iter: 1728/3680
[A[ATraining Step: 1780  | total loss: [1m[32m0.45366[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45366 - acc: 0.7833 -- iter: 1760/3680
[A[ATraining Step: 1781  | total loss: [1m[32m0.43954[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43954 - acc: 0.7925 -- iter: 1792/3680
[A[ATraining Step: 1782  | total loss: [1m[32m0.45305[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45305 - acc: 0.7913 -- iter: 1824/3680
[A[ATraining Step: 1783  | total loss: [1m[32m0.45153[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45153 - acc: 0.7903 -- iter: 1856/3680
[A[ATraining Step: 1784  | total loss: [1m[32m0.46118[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46118 - acc: 0.7801 -- iter: 1888/3680
[A[ATraining Step: 1785  | total loss: [1m[32m0.45999[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45999 - acc: 0.7833 -- iter: 1920/3680
[A[ATraining Step: 1786  | total loss: [1m[32m0.45509[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45509 - acc: 0.7893 -- iter: 1952/3680
[A[ATraining Step: 1787  | total loss: [1m[32m0.44972[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44972 - acc: 0.7948 -- iter: 1984/3680
[A[ATraining Step: 1788  | total loss: [1m[32m0.45537[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45537 - acc: 0.7872 -- iter: 2016/3680
[A[ATraining Step: 1789  | total loss: [1m[32m0.44552[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44552 - acc: 0.7960 -- iter: 2048/3680
[A[ATraining Step: 1790  | total loss: [1m[32m0.44689[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44689 - acc: 0.7976 -- iter: 2080/3680
[A[ATraining Step: 1791  | total loss: [1m[32m0.45872[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45872 - acc: 0.7866 -- iter: 2112/3680
[A[ATraining Step: 1792  | total loss: [1m[32m0.45591[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45591 - acc: 0.7861 -- iter: 2144/3680
[A[ATraining Step: 1793  | total loss: [1m[32m0.45590[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45590 - acc: 0.7856 -- iter: 2176/3680
[A[ATraining Step: 1794  | total loss: [1m[32m0.46785[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46785 - acc: 0.7789 -- iter: 2208/3680
[A[ATraining Step: 1795  | total loss: [1m[32m0.47786[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47786 - acc: 0.7760 -- iter: 2240/3680
[A[ATraining Step: 1796  | total loss: [1m[32m0.48973[0m[0m
[2K| Adam | epoch: 016 | loss: 0.48973 - acc: 0.7734 -- iter: 2272/3680
[A[ATraining Step: 1797  | total loss: [1m[32m0.47474[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47474 - acc: 0.7867 -- iter: 2304/3680
[A[ATraining Step: 1798  | total loss: [1m[32m0.47186[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47186 - acc: 0.7924 -- iter: 2336/3680
[A[ATraining Step: 1799  | total loss: [1m[32m0.47211[0m[0m
[2K| Adam | epoch: 016 | loss: 0.47211 - acc: 0.7913 -- iter: 2368/3680
[A[ATraining Step: 1800  | total loss: [1m[32m0.46056[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46056 - acc: 0.7934 | val_loss: 0.46637 - val_acc: 0.7666 -- iter: 2400/3680
[A[ATraining Step: 1800  | total loss: [1m[32m0.46056[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46056 - acc: 0.7934 | val_loss: 0.46637 - val_acc: 0.7666 -- iter: 2400/3680
--
Training Step: 1801  | total loss: [1m[32m0.46493[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46493 - acc: 0.7859 -- iter: 2432/3680
[A[ATraining Step: 1802  | total loss: [1m[32m0.46055[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46055 - acc: 0.7886 -- iter: 2464/3680
[A[ATraining Step: 1803  | total loss: [1m[32m0.46534[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46534 - acc: 0.7847 -- iter: 2496/3680
[A[ATraining Step: 1804  | total loss: [1m[32m0.45834[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45834 - acc: 0.7813 -- iter: 2528/3680
[A[ATraining Step: 1805  | total loss: [1m[32m0.46760[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46760 - acc: 0.7813 -- iter: 2560/3680
[A[ATraining Step: 1806  | total loss: [1m[32m0.45100[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45100 - acc: 0.8000 -- iter: 2592/3680
[A[ATraining Step: 1807  | total loss: [1m[32m0.45457[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45457 - acc: 0.7950 -- iter: 2624/3680
[A[ATraining Step: 1808  | total loss: [1m[32m0.45952[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45952 - acc: 0.7936 -- iter: 2656/3680
[A[ATraining Step: 1809  | total loss: [1m[32m0.45879[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45879 - acc: 0.7955 -- iter: 2688/3680
[A[ATraining Step: 1810  | total loss: [1m[32m0.45964[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45964 - acc: 0.7910 -- iter: 2720/3680
[A[ATraining Step: 1811  | total loss: [1m[32m0.44613[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44613 - acc: 0.7962 -- iter: 2752/3680
[A[ATraining Step: 1812  | total loss: [1m[32m0.46589[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46589 - acc: 0.7760 -- iter: 2784/3680
[A[ATraining Step: 1813  | total loss: [1m[32m0.46436[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46436 - acc: 0.7796 -- iter: 2816/3680
[A[ATraining Step: 1814  | total loss: [1m[32m0.45932[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45932 - acc: 0.7861 -- iter: 2848/3680
[A[ATraining Step: 1815  | total loss: [1m[32m0.45068[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45068 - acc: 0.7887 -- iter: 2880/3680
[A[ATraining Step: 1816  | total loss: [1m[32m0.44586[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44586 - acc: 0.8005 -- iter: 2912/3680
[A[ATraining Step: 1817  | total loss: [1m[32m0.44417[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44417 - acc: 0.7985 -- iter: 2944/3680
[A[ATraining Step: 1818  | total loss: [1m[32m0.43300[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43300 - acc: 0.8062 -- iter: 2976/3680
[A[ATraining Step: 1819  | total loss: [1m[32m0.42685[0m[0m
[2K| Adam | epoch: 016 | loss: 0.42685 - acc: 0.8099 -- iter: 3008/3680
[A[ATraining Step: 1820  | total loss: [1m[32m0.43272[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43272 - acc: 0.8071 -- iter: 3040/3680
[A[ATraining Step: 1821  | total loss: [1m[32m0.43458[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43458 - acc: 0.7982 -- iter: 3072/3680
[A[ATraining Step: 1822  | total loss: [1m[32m0.43635[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43635 - acc: 0.8059 -- iter: 3104/3680
[A[ATraining Step: 1823  | total loss: [1m[32m0.43790[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43790 - acc: 0.8128 -- iter: 3136/3680
[A[ATraining Step: 1824  | total loss: [1m[32m0.45896[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45896 - acc: 0.8034 -- iter: 3168/3680
[A[ATraining Step: 1825  | total loss: [1m[32m0.45720[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45720 - acc: 0.7981 -- iter: 3200/3680
[A[ATraining Step: 1826  | total loss: [1m[32m0.44810[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44810 - acc: 0.8058 -- iter: 3232/3680
[A[ATraining Step: 1827  | total loss: [1m[32m0.44820[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44820 - acc: 0.8017 -- iter: 3264/3680
[A[ATraining Step: 1828  | total loss: [1m[32m0.43830[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43830 - acc: 0.8017 -- iter: 3296/3680
[A[ATraining Step: 1829  | total loss: [1m[32m0.44659[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44659 - acc: 0.7997 -- iter: 3328/3680
[A[ATraining Step: 1830  | total loss: [1m[32m0.46293[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46293 - acc: 0.7791 -- iter: 3360/3680
[A[ATraining Step: 1831  | total loss: [1m[32m0.44669[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44669 - acc: 0.7949 -- iter: 3392/3680
[A[ATraining Step: 1832  | total loss: [1m[32m0.45391[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45391 - acc: 0.7926 -- iter: 3424/3680
[A[ATraining Step: 1833  | total loss: [1m[32m0.44842[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44842 - acc: 0.7926 -- iter: 3456/3680
[A[ATraining Step: 1834  | total loss: [1m[32m0.44584[0m[0m
[2K| Adam | epoch: 016 | loss: 0.44584 - acc: 0.7853 -- iter: 3488/3680
[A[ATraining Step: 1835  | total loss: [1m[32m0.43369[0m[0m
[2K| Adam | epoch: 016 | loss: 0.43369 - acc: 0.8036 -- iter: 3520/3680
[A[ATraining Step: 1836  | total loss: [1m[32m0.45399[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45399 - acc: 0.7795 -- iter: 3552/3680
[A[ATraining Step: 1837  | total loss: [1m[32m0.46726[0m[0m
[2K| Adam | epoch: 016 | loss: 0.46726 - acc: 0.7734 -- iter: 3584/3680
[A[ATraining Step: 1838  | total loss: [1m[32m0.45900[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45900 - acc: 0.7805 -- iter: 3616/3680
[A[ATraining Step: 1839  | total loss: [1m[32m0.45844[0m[0m
[2K| Adam | epoch: 016 | loss: 0.45844 - acc: 0.7805 -- iter: 3648/3680
[A[ATraining Step: 1840  | total loss: [1m[32m0.48294[0m[0m
[2K| Adam | epoch: 016 | loss: 0.48294 - acc: 0.7587 | val_loss: 0.44953 - val_acc: 0.8187 -- iter: 3680/3680
[A[ATraining Step: 1840  | total loss: [1m[32m0.48294[0m[0m
[2K| Adam | epoch: 016 | loss: 0.48294 - acc: 0.7587 | val_loss: 0.44953 - val_acc: 0.8187 -- iter: 3680/3680
--
Training Step: 1841  | total loss: [1m[32m0.46645[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46645 - acc: 0.7704 -- iter: 0032/3680
[A[ATraining Step: 1842  | total loss: [1m[32m0.45465[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45465 - acc: 0.7808 -- iter: 0064/3680
[A[ATraining Step: 1843  | total loss: [1m[32m0.46041[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46041 - acc: 0.7715 -- iter: 0096/3680
[A[ATraining Step: 1844  | total loss: [1m[32m0.46088[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46088 - acc: 0.7725 -- iter: 0128/3680
[A[ATraining Step: 1845  | total loss: [1m[32m0.46068[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46068 - acc: 0.7732 -- iter: 0160/3680
[A[ATraining Step: 1846  | total loss: [1m[32m0.46609[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46609 - acc: 0.7732 -- iter: 0192/3680
[A[ATraining Step: 1847  | total loss: [1m[32m0.46477[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46477 - acc: 0.7803 -- iter: 0224/3680
[A[ATraining Step: 1848  | total loss: [1m[32m0.45963[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45963 - acc: 0.7835 -- iter: 0256/3680
[A[ATraining Step: 1849  | total loss: [1m[32m0.47648[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47648 - acc: 0.7739 -- iter: 0288/3680
[A[ATraining Step: 1850  | total loss: [1m[32m0.49753[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49753 - acc: 0.7590 -- iter: 0320/3680
[A[ATraining Step: 1851  | total loss: [1m[32m0.49187[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49187 - acc: 0.7550 -- iter: 0352/3680
[A[ATraining Step: 1852  | total loss: [1m[32m0.47305[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47305 - acc: 0.7732 -- iter: 0384/3680
[A[ATraining Step: 1853  | total loss: [1m[32m0.46437[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46437 - acc: 0.7803 -- iter: 0416/3680
[A[ATraining Step: 1854  | total loss: [1m[32m0.46052[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46052 - acc: 0.7897 -- iter: 0448/3680
[A[ATraining Step: 1855  | total loss: [1m[32m0.46425[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46425 - acc: 0.7795 -- iter: 0480/3680
[A[ATraining Step: 1856  | total loss: [1m[32m0.47677[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47677 - acc: 0.7672 -- iter: 0512/3680
[A[ATraining Step: 1857  | total loss: [1m[32m0.48824[0m[0m
[2K| Adam | epoch: 017 | loss: 0.48824 - acc: 0.7561 -- iter: 0544/3680
[A[ATraining Step: 1858  | total loss: [1m[32m0.49832[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49832 - acc: 0.7617 -- iter: 0576/3680
[A[ATraining Step: 1859  | total loss: [1m[32m0.49185[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49185 - acc: 0.7699 -- iter: 0608/3680
[A[ATraining Step: 1860  | total loss: [1m[32m0.47795[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47795 - acc: 0.7804 -- iter: 0640/3680
[A[ATraining Step: 1861  | total loss: [1m[32m0.47779[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47779 - acc: 0.7868 -- iter: 0672/3680
[A[ATraining Step: 1862  | total loss: [1m[32m0.48772[0m[0m
[2K| Adam | epoch: 017 | loss: 0.48772 - acc: 0.7893 -- iter: 0704/3680
[A[ATraining Step: 1863  | total loss: [1m[32m0.49693[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49693 - acc: 0.7792 -- iter: 0736/3680
[A[ATraining Step: 1864  | total loss: [1m[32m0.50192[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50192 - acc: 0.7669 -- iter: 0768/3680
[A[ATraining Step: 1865  | total loss: [1m[32m0.51667[0m[0m
[2K| Adam | epoch: 017 | loss: 0.51667 - acc: 0.7621 -- iter: 0800/3680
[A[ATraining Step: 1866  | total loss: [1m[32m0.50839[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50839 - acc: 0.7577 -- iter: 0832/3680
[A[ATraining Step: 1867  | total loss: [1m[32m0.49990[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49990 - acc: 0.7709 -- iter: 0864/3680
[A[ATraining Step: 1868  | total loss: [1m[32m0.49150[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49150 - acc: 0.7709 -- iter: 0896/3680
[A[ATraining Step: 1869  | total loss: [1m[32m0.50318[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50318 - acc: 0.7564 -- iter: 0928/3680
[A[ATraining Step: 1870  | total loss: [1m[32m0.49264[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49264 - acc: 0.7651 -- iter: 0960/3680
[A[ATraining Step: 1871  | total loss: [1m[32m0.49041[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49041 - acc: 0.7698 -- iter: 0992/3680
[A[ATraining Step: 1872  | total loss: [1m[32m0.47745[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47745 - acc: 0.7772 -- iter: 1024/3680
[A[ATraining Step: 1873  | total loss: [1m[32m0.45753[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45753 - acc: 0.7870 -- iter: 1056/3680
[A[ATraining Step: 1874  | total loss: [1m[32m0.45135[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45135 - acc: 0.7864 -- iter: 1088/3680
[A[ATraining Step: 1875  | total loss: [1m[32m0.45266[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45266 - acc: 0.7859 -- iter: 1120/3680
[A[ATraining Step: 1876  | total loss: [1m[32m0.46613[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46613 - acc: 0.7823 -- iter: 1152/3680
[A[ATraining Step: 1877  | total loss: [1m[32m0.46471[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46471 - acc: 0.7791 -- iter: 1184/3680
[A[ATraining Step: 1878  | total loss: [1m[32m0.47405[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47405 - acc: 0.7762 -- iter: 1216/3680
[A[ATraining Step: 1879  | total loss: [1m[32m0.45456[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45456 - acc: 0.7829 -- iter: 1248/3680
[A[ATraining Step: 1880  | total loss: [1m[32m0.44890[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44890 - acc: 0.7921 -- iter: 1280/3680
[A[ATraining Step: 1881  | total loss: [1m[32m0.43952[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43952 - acc: 0.7973 -- iter: 1312/3680
[A[ATraining Step: 1882  | total loss: [1m[32m0.44717[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44717 - acc: 0.7988 -- iter: 1344/3680
[A[ATraining Step: 1883  | total loss: [1m[32m0.44374[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44374 - acc: 0.7971 -- iter: 1376/3680
[A[ATraining Step: 1884  | total loss: [1m[32m0.43929[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43929 - acc: 0.8080 -- iter: 1408/3680
[A[ATraining Step: 1885  | total loss: [1m[32m0.44097[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44097 - acc: 0.7991 -- iter: 1440/3680
[A[ATraining Step: 1886  | total loss: [1m[32m0.45582[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45582 - acc: 0.7879 -- iter: 1472/3680
[A[ATraining Step: 1887  | total loss: [1m[32m0.45735[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45735 - acc: 0.7872 -- iter: 1504/3680
[A[ATraining Step: 1888  | total loss: [1m[32m0.43832[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43832 - acc: 0.8054 -- iter: 1536/3680
[A[ATraining Step: 1889  | total loss: [1m[32m0.44446[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44446 - acc: 0.7967 -- iter: 1568/3680
[A[ATraining Step: 1890  | total loss: [1m[32m0.45901[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45901 - acc: 0.7921 -- iter: 1600/3680
[A[ATraining Step: 1891  | total loss: [1m[32m0.44888[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44888 - acc: 0.8003 -- iter: 1632/3680
[A[ATraining Step: 1892  | total loss: [1m[32m0.45076[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45076 - acc: 0.8016 -- iter: 1664/3680
[A[ATraining Step: 1893  | total loss: [1m[32m0.44885[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44885 - acc: 0.8089 -- iter: 1696/3680
[A[ATraining Step: 1894  | total loss: [1m[32m0.45988[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45988 - acc: 0.7968 -- iter: 1728/3680
[A[ATraining Step: 1895  | total loss: [1m[32m0.45151[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45151 - acc: 0.8046 -- iter: 1760/3680
[A[ATraining Step: 1896  | total loss: [1m[32m0.45527[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45527 - acc: 0.8023 -- iter: 1792/3680
[A[ATraining Step: 1897  | total loss: [1m[32m0.45141[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45141 - acc: 0.8095 -- iter: 1824/3680
[A[ATraining Step: 1898  | total loss: [1m[32m0.44784[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44784 - acc: 0.8098 -- iter: 1856/3680
[A[ATraining Step: 1899  | total loss: [1m[32m0.43957[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43957 - acc: 0.8163 -- iter: 1888/3680
[A[ATraining Step: 1900  | total loss: [1m[32m0.42974[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42974 - acc: 0.8285 | val_loss: 0.44500 - val_acc: 0.8122 -- iter: 1920/3680
[A[ATraining Step: 1900  | total loss: [1m[32m0.42974[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42974 - acc: 0.8285 | val_loss: 0.44500 - val_acc: 0.8122 -- iter: 1920/3680
--
Training Step: 1901  | total loss: [1m[32m0.43791[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43791 - acc: 0.8144 -- iter: 1952/3680
[A[ATraining Step: 1902  | total loss: [1m[32m0.43277[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43277 - acc: 0.8173 -- iter: 1984/3680
[A[ATraining Step: 1903  | total loss: [1m[32m0.43924[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43924 - acc: 0.8106 -- iter: 2016/3680
[A[ATraining Step: 1904  | total loss: [1m[32m0.43001[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43001 - acc: 0.8139 -- iter: 2048/3680
[A[ATraining Step: 1905  | total loss: [1m[32m0.42758[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42758 - acc: 0.8231 -- iter: 2080/3680
[A[ATraining Step: 1906  | total loss: [1m[32m0.42536[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42536 - acc: 0.8252 -- iter: 2112/3680
[A[ATraining Step: 1907  | total loss: [1m[32m0.41836[0m[0m
[2K| Adam | epoch: 017 | loss: 0.41836 - acc: 0.8134 -- iter: 2144/3680
[A[ATraining Step: 1908  | total loss: [1m[32m0.41993[0m[0m
[2K| Adam | epoch: 017 | loss: 0.41993 - acc: 0.8134 -- iter: 2176/3680
[A[ATraining Step: 1909  | total loss: [1m[32m0.41591[0m[0m
[2K| Adam | epoch: 017 | loss: 0.41591 - acc: 0.8164 -- iter: 2208/3680
[A[ATraining Step: 1910  | total loss: [1m[32m0.42138[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42138 - acc: 0.8129 -- iter: 2240/3680
[A[ATraining Step: 1911  | total loss: [1m[32m0.42530[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42530 - acc: 0.8098 -- iter: 2272/3680
[A[ATraining Step: 1912  | total loss: [1m[32m0.43410[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43410 - acc: 0.8007 -- iter: 2304/3680
[A[ATraining Step: 1913  | total loss: [1m[32m0.43582[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43582 - acc: 0.7987 -- iter: 2336/3680
[A[ATraining Step: 1914  | total loss: [1m[32m0.42057[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42057 - acc: 0.8126 -- iter: 2368/3680
[A[ATraining Step: 1915  | total loss: [1m[32m0.42672[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42672 - acc: 0.8163 -- iter: 2400/3680
[A[ATraining Step: 1916  | total loss: [1m[32m0.40796[0m[0m
[2K| Adam | epoch: 017 | loss: 0.40796 - acc: 0.8163 -- iter: 2432/3680
[A[ATraining Step: 1917  | total loss: [1m[32m0.43716[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43716 - acc: 0.7947 -- iter: 2464/3680
[A[ATraining Step: 1918  | total loss: [1m[32m0.43716[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43716 - acc: 0.7947 -- iter: 2496/3680
[A[ATraining Step: 1919  | total loss: [1m[32m0.43042[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43042 - acc: 0.7996 -- iter: 2528/3680
[A[ATraining Step: 1920  | total loss: [1m[32m0.42641[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42641 - acc: 0.8040 -- iter: 2560/3680
[A[ATraining Step: 1921  | total loss: [1m[32m0.43184[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43184 - acc: 0.7986 -- iter: 2592/3680
[A[ATraining Step: 1922  | total loss: [1m[32m0.43365[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43365 - acc: 0.7906 -- iter: 2624/3680
[A[ATraining Step: 1923  | total loss: [1m[32m0.43946[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43946 - acc: 0.7865 -- iter: 2656/3680
[A[ATraining Step: 1924  | total loss: [1m[32m0.43791[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43791 - acc: 0.7954 -- iter: 2688/3680
[A[ATraining Step: 1925  | total loss: [1m[32m0.43094[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43094 - acc: 0.7971 -- iter: 2720/3680
[A[ATraining Step: 1926  | total loss: [1m[32m0.42189[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42189 - acc: 0.8080 -- iter: 2752/3680
[A[ATraining Step: 1927  | total loss: [1m[32m0.41991[0m[0m
[2K| Adam | epoch: 017 | loss: 0.41991 - acc: 0.8053 -- iter: 2784/3680
[A[ATraining Step: 1928  | total loss: [1m[32m0.42076[0m[0m
[2K| Adam | epoch: 017 | loss: 0.42076 - acc: 0.8061 -- iter: 2816/3680
[A[ATraining Step: 1929  | total loss: [1m[32m0.43258[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43258 - acc: 0.8067 -- iter: 2848/3680
[A[ATraining Step: 1930  | total loss: [1m[32m0.45048[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45048 - acc: 0.8010 -- iter: 2880/3680
[A[ATraining Step: 1931  | total loss: [1m[32m0.44979[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44979 - acc: 0.8022 -- iter: 2912/3680
[A[ATraining Step: 1932  | total loss: [1m[32m0.44965[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44965 - acc: 0.8032 -- iter: 2944/3680
[A[ATraining Step: 1933  | total loss: [1m[32m0.44365[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44365 - acc: 0.8073 -- iter: 2976/3680
[A[ATraining Step: 1934  | total loss: [1m[32m0.43976[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43976 - acc: 0.8140 -- iter: 3008/3680
[A[ATraining Step: 1935  | total loss: [1m[32m0.43903[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43903 - acc: 0.8170 -- iter: 3040/3680
[A[ATraining Step: 1936  | total loss: [1m[32m0.43518[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43518 - acc: 0.8134 -- iter: 3072/3680
[A[ATraining Step: 1937  | total loss: [1m[32m0.44350[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44350 - acc: 0.8133 -- iter: 3104/3680
[A[ATraining Step: 1938  | total loss: [1m[32m0.43689[0m[0m
[2K| Adam | epoch: 017 | loss: 0.43689 - acc: 0.8195 -- iter: 3136/3680
[A[ATraining Step: 1939  | total loss: [1m[32m0.45349[0m[0m
[2K| Adam | epoch: 017 | loss: 0.45349 - acc: 0.8063 -- iter: 3168/3680
[A[ATraining Step: 1940  | total loss: [1m[32m0.50739[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50739 - acc: 0.7850 -- iter: 3200/3680
[A[ATraining Step: 1941  | total loss: [1m[32m0.51447[0m[0m
[2K| Adam | epoch: 017 | loss: 0.51447 - acc: 0.7847 -- iter: 3232/3680
[A[ATraining Step: 1942  | total loss: [1m[32m0.50422[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50422 - acc: 0.7843 -- iter: 3264/3680
[A[ATraining Step: 1943  | total loss: [1m[32m0.50864[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50864 - acc: 0.7778 -- iter: 3296/3680
[A[ATraining Step: 1944  | total loss: [1m[32m0.50180[0m[0m
[2K| Adam | epoch: 017 | loss: 0.50180 - acc: 0.7781 -- iter: 3328/3680
[A[ATraining Step: 1945  | total loss: [1m[32m0.49648[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49648 - acc: 0.7816 -- iter: 3360/3680
[A[ATraining Step: 1946  | total loss: [1m[32m0.49061[0m[0m
[2K| Adam | epoch: 017 | loss: 0.49061 - acc: 0.7847 -- iter: 3392/3680
[A[ATraining Step: 1947  | total loss: [1m[32m0.48302[0m[0m
[2K| Adam | epoch: 017 | loss: 0.48302 - acc: 0.7906 -- iter: 3424/3680
[A[ATraining Step: 1948  | total loss: [1m[32m0.47726[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47726 - acc: 0.7928 -- iter: 3456/3680
[A[ATraining Step: 1949  | total loss: [1m[32m0.47015[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47015 - acc: 0.7916 -- iter: 3488/3680
[A[ATraining Step: 1950  | total loss: [1m[32m0.47708[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47708 - acc: 0.7874 -- iter: 3520/3680
[A[ATraining Step: 1951  | total loss: [1m[32m0.47157[0m[0m
[2K| Adam | epoch: 017 | loss: 0.47157 - acc: 0.7931 -- iter: 3552/3680
[A[ATraining Step: 1952  | total loss: [1m[32m0.46152[0m[0m
[2K| Adam | epoch: 017 | loss: 0.46152 - acc: 0.7950 -- iter: 3584/3680
[A[ATraining Step: 1953  | total loss: [1m[32m0.44772[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44772 - acc: 0.7999 -- iter: 3616/3680
[A[ATraining Step: 1954  | total loss: [1m[32m0.44941[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44941 - acc: 0.7949 -- iter: 3648/3680
[A[ATraining Step: 1955  | total loss: [1m[32m0.44065[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44065 - acc: 0.7998 | val_loss: 0.43980 - val_acc: 0.8100 -- iter: 3680/3680
[A[ATraining Step: 1955  | total loss: [1m[32m0.44065[0m[0m
[2K| Adam | epoch: 017 | loss: 0.44065 - acc: 0.7998 | val_loss: 0.43980 - val_acc: 0.8100 -- iter: 3680/3680
--
Training Step: 1956  | total loss: [1m[32m0.44451[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44451 - acc: 0.7917 -- iter: 0032/3680
[A[ATraining Step: 1957  | total loss: [1m[32m0.45611[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45611 - acc: 0.7813 -- iter: 0064/3680
[A[ATraining Step: 1958  | total loss: [1m[32m0.43961[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43961 - acc: 0.7938 -- iter: 0096/3680
[A[ATraining Step: 1959  | total loss: [1m[32m0.44902[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44902 - acc: 0.7863 -- iter: 0128/3680
[A[ATraining Step: 1960  | total loss: [1m[32m0.45125[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45125 - acc: 0.7858 -- iter: 0160/3680
[A[ATraining Step: 1961  | total loss: [1m[32m0.44207[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44207 - acc: 0.7884 -- iter: 0192/3680
[A[ATraining Step: 1962  | total loss: [1m[32m0.43454[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43454 - acc: 0.7877 -- iter: 0224/3680
[A[ATraining Step: 1963  | total loss: [1m[32m0.42819[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42819 - acc: 0.7933 -- iter: 0256/3680
[A[ATraining Step: 1964  | total loss: [1m[32m0.43668[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43668 - acc: 0.7952 -- iter: 0288/3680
[A[ATraining Step: 1965  | total loss: [1m[32m0.43827[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43827 - acc: 0.7938 -- iter: 0320/3680
[A[ATraining Step: 1966  | total loss: [1m[32m0.44369[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44369 - acc: 0.7801 -- iter: 0352/3680
[A[ATraining Step: 1967  | total loss: [1m[32m0.43742[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43742 - acc: 0.7802 -- iter: 0384/3680
[A[ATraining Step: 1968  | total loss: [1m[32m0.44531[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44531 - acc: 0.7803 -- iter: 0416/3680
[A[ATraining Step: 1969  | total loss: [1m[32m0.45071[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45071 - acc: 0.7811 -- iter: 0448/3680
[A[ATraining Step: 1970  | total loss: [1m[32m0.45298[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45298 - acc: 0.7811 -- iter: 0480/3680
[A[ATraining Step: 1971  | total loss: [1m[32m0.46771[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46771 - acc: 0.7717 -- iter: 0512/3680
[A[ATraining Step: 1972  | total loss: [1m[32m0.45676[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45676 - acc: 0.7789 -- iter: 0544/3680
[A[ATraining Step: 1973  | total loss: [1m[32m0.44974[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44974 - acc: 0.7917 -- iter: 0576/3680
[A[ATraining Step: 1974  | total loss: [1m[32m0.43972[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43972 - acc: 0.7969 -- iter: 0608/3680
[A[ATraining Step: 1975  | total loss: [1m[32m0.43301[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43301 - acc: 0.7905 -- iter: 0640/3680
[A[ATraining Step: 1976  | total loss: [1m[32m0.46472[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46472 - acc: 0.7905 -- iter: 0672/3680
[A[ATraining Step: 1977  | total loss: [1m[32m0.46208[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46208 - acc: 0.7864 -- iter: 0704/3680
[A[ATraining Step: 1978  | total loss: [1m[32m0.46518[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46518 - acc: 0.7890 -- iter: 0736/3680
[A[ATraining Step: 1979  | total loss: [1m[32m0.44561[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44561 - acc: 0.8008 -- iter: 0768/3680
[A[ATraining Step: 1980  | total loss: [1m[32m0.45413[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45413 - acc: 0.7926 -- iter: 0800/3680
[A[ATraining Step: 1981  | total loss: [1m[32m0.45275[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45275 - acc: 0.7914 -- iter: 0832/3680
[A[ATraining Step: 1982  | total loss: [1m[32m0.45555[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45555 - acc: 0.7904 -- iter: 0864/3680
[A[ATraining Step: 1983  | total loss: [1m[32m0.46155[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46155 - acc: 0.7909 -- iter: 0896/3680
[A[ATraining Step: 1984  | total loss: [1m[32m0.46155[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46155 - acc: 0.7909 -- iter: 0928/3680
[A[ATraining Step: 1985  | total loss: [1m[32m0.45823[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45823 - acc: 0.7862 -- iter: 0960/3680
[A[ATraining Step: 1986  | total loss: [1m[32m0.44778[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44778 - acc: 0.7862 -- iter: 0992/3680
[A[ATraining Step: 1987  | total loss: [1m[32m0.44206[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44206 - acc: 0.7920 -- iter: 1024/3680
[A[ATraining Step: 1988  | total loss: [1m[32m0.44189[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44189 - acc: 0.7878 -- iter: 1056/3680
[A[ATraining Step: 1989  | total loss: [1m[32m0.43517[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43517 - acc: 0.7996 -- iter: 1088/3680
[A[ATraining Step: 1990  | total loss: [1m[32m0.42359[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42359 - acc: 0.8103 -- iter: 1120/3680
[A[ATraining Step: 1991  | total loss: [1m[32m0.43067[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43067 - acc: 0.8020 -- iter: 1152/3680
[A[ATraining Step: 1992  | total loss: [1m[32m0.44373[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44373 - acc: 0.8020 -- iter: 1184/3680
[A[ATraining Step: 1993  | total loss: [1m[32m0.46006[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46006 - acc: 0.7874 -- iter: 1216/3680
[A[ATraining Step: 1994  | total loss: [1m[32m0.44793[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44793 - acc: 0.7961 -- iter: 1248/3680
[A[ATraining Step: 1995  | total loss: [1m[32m0.45344[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45344 - acc: 0.7822 -- iter: 1280/3680
[A[ATraining Step: 1996  | total loss: [1m[32m0.45795[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45795 - acc: 0.7758 -- iter: 1312/3680
[A[ATraining Step: 1997  | total loss: [1m[32m0.44765[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44765 - acc: 0.7795 -- iter: 1344/3680
[A[ATraining Step: 1998  | total loss: [1m[32m0.43978[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43978 - acc: 0.7859 -- iter: 1376/3680
[A[ATraining Step: 1999  | total loss: [1m[32m0.45467[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45467 - acc: 0.7698 -- iter: 1408/3680
[A[ATraining Step: 2000  | total loss: [1m[32m0.47084[0m[0m
[2K| Adam | epoch: 018 | loss: 0.47084 - acc: 0.7616 | val_loss: 0.43408 - val_acc: 0.8132 -- iter: 1440/3680
[A[ATraining Step: 2000  | total loss: [1m[32m0.47084[0m[0m
[2K| Adam | epoch: 018 | loss: 0.47084 - acc: 0.7616 | val_loss: 0.43408 - val_acc: 0.8132 -- iter: 1440/3680
--
Training Step: 2001  | total loss: [1m[32m0.46841[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46841 - acc: 0.7636 -- iter: 1472/3680
[A[ATraining Step: 2002  | total loss: [1m[32m0.45130[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45130 - acc: 0.7809 -- iter: 1504/3680
[A[ATraining Step: 2003  | total loss: [1m[32m0.44841[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44841 - acc: 0.7841 -- iter: 1536/3680
[A[ATraining Step: 2004  | total loss: [1m[32m0.45048[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45048 - acc: 0.7807 -- iter: 1568/3680
[A[ATraining Step: 2005  | total loss: [1m[32m0.44508[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44508 - acc: 0.7839 -- iter: 1600/3680
[A[ATraining Step: 2006  | total loss: [1m[32m0.43830[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43830 - acc: 0.7805 -- iter: 1632/3680
[A[ATraining Step: 2007  | total loss: [1m[32m0.44527[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44527 - acc: 0.7743 -- iter: 1664/3680
[A[ATraining Step: 2008  | total loss: [1m[32m0.45321[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45321 - acc: 0.7688 -- iter: 1696/3680
[A[ATraining Step: 2009  | total loss: [1m[32m0.44063[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44063 - acc: 0.7763 -- iter: 1728/3680
[A[ATraining Step: 2010  | total loss: [1m[32m0.43303[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43303 - acc: 0.7830 -- iter: 1760/3680
[A[ATraining Step: 2011  | total loss: [1m[32m0.43598[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43598 - acc: 0.7797 -- iter: 1792/3680
[A[ATraining Step: 2012  | total loss: [1m[32m0.42826[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42826 - acc: 0.7830 -- iter: 1824/3680
[A[ATraining Step: 2013  | total loss: [1m[32m0.42711[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42711 - acc: 0.7859 -- iter: 1856/3680
[A[ATraining Step: 2014  | total loss: [1m[32m0.42195[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42195 - acc: 0.7948 -- iter: 1888/3680
[A[ATraining Step: 2015  | total loss: [1m[32m0.43494[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43494 - acc: 0.7894 -- iter: 1920/3680
[A[ATraining Step: 2016  | total loss: [1m[32m0.43494[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43494 - acc: 0.7894 -- iter: 1952/3680
[A[ATraining Step: 2017  | total loss: [1m[32m0.43635[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43635 - acc: 0.7824 -- iter: 1984/3680
[A[ATraining Step: 2018  | total loss: [1m[32m0.44026[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44026 - acc: 0.7791 -- iter: 2016/3680
[A[ATraining Step: 2019  | total loss: [1m[32m0.42725[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42725 - acc: 0.7919 -- iter: 2048/3680
[A[ATraining Step: 2020  | total loss: [1m[32m0.43329[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43329 - acc: 0.7814 -- iter: 2080/3680
[A[ATraining Step: 2021  | total loss: [1m[32m0.43299[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43299 - acc: 0.7876 -- iter: 2112/3680
[A[ATraining Step: 2022  | total loss: [1m[32m0.43696[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43696 - acc: 0.7808 -- iter: 2144/3680
[A[ATraining Step: 2023  | total loss: [1m[32m0.44798[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44798 - acc: 0.7746 -- iter: 2176/3680
[A[ATraining Step: 2024  | total loss: [1m[32m0.45518[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45518 - acc: 0.7721 -- iter: 2208/3680
[A[ATraining Step: 2025  | total loss: [1m[32m0.46202[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46202 - acc: 0.7668 -- iter: 2240/3680
[A[ATraining Step: 2026  | total loss: [1m[32m0.45461[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45461 - acc: 0.7776 -- iter: 2272/3680
[A[ATraining Step: 2027  | total loss: [1m[32m0.45308[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45308 - acc: 0.7748 -- iter: 2304/3680
[A[ATraining Step: 2028  | total loss: [1m[32m0.45371[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45371 - acc: 0.7723 -- iter: 2336/3680
[A[ATraining Step: 2029  | total loss: [1m[32m0.46393[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46393 - acc: 0.7800 -- iter: 2368/3680
[A[ATraining Step: 2030  | total loss: [1m[32m0.46553[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46553 - acc: 0.7800 -- iter: 2400/3680
[A[ATraining Step: 2031  | total loss: [1m[32m0.46132[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46132 - acc: 0.7832 -- iter: 2432/3680
[A[ATraining Step: 2032  | total loss: [1m[32m0.45920[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45920 - acc: 0.7893 -- iter: 2464/3680
[A[ATraining Step: 2033  | total loss: [1m[32m0.45580[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45580 - acc: 0.7916 -- iter: 2496/3680
[A[ATraining Step: 2034  | total loss: [1m[32m0.44901[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44901 - acc: 0.7968 -- iter: 2528/3680
[A[ATraining Step: 2035  | total loss: [1m[32m0.45028[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45028 - acc: 0.7953 -- iter: 2560/3680
[A[ATraining Step: 2036  | total loss: [1m[32m0.44943[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44943 - acc: 0.7907 -- iter: 2592/3680
[A[ATraining Step: 2037  | total loss: [1m[32m0.44731[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44731 - acc: 0.7898 -- iter: 2624/3680
[A[ATraining Step: 2038  | total loss: [1m[32m0.44399[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44399 - acc: 0.7913 -- iter: 2656/3680
[A[ATraining Step: 2039  | total loss: [1m[32m0.44218[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44218 - acc: 0.7913 -- iter: 2688/3680
[A[ATraining Step: 2040  | total loss: [1m[32m0.42024[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42024 - acc: 0.8122 -- iter: 2720/3680
[A[ATraining Step: 2041  | total loss: [1m[32m0.42353[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42353 - acc: 0.8091 -- iter: 2752/3680
[A[ATraining Step: 2042  | total loss: [1m[32m0.43415[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43415 - acc: 0.8032 -- iter: 2784/3680
[A[ATraining Step: 2043  | total loss: [1m[32m0.42050[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42050 - acc: 0.8103 -- iter: 2816/3680
[A[ATraining Step: 2044  | total loss: [1m[32m0.42824[0m[0m
[2K| Adam | epoch: 018 | loss: 0.42824 - acc: 0.8012 -- iter: 2848/3680
[A[ATraining Step: 2045  | total loss: [1m[32m0.43368[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43368 - acc: 0.7929 -- iter: 2880/3680
[A[ATraining Step: 2046  | total loss: [1m[32m0.44217[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44217 - acc: 0.7886 -- iter: 2912/3680
[A[ATraining Step: 2047  | total loss: [1m[32m0.45621[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45621 - acc: 0.7848 -- iter: 2944/3680
[A[ATraining Step: 2048  | total loss: [1m[32m0.46236[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46236 - acc: 0.7813 -- iter: 2976/3680
[A[ATraining Step: 2049  | total loss: [1m[32m0.46617[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46617 - acc: 0.7750 -- iter: 3008/3680
[A[ATraining Step: 2050  | total loss: [1m[32m0.46341[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46341 - acc: 0.7819 -- iter: 3040/3680
[A[ATraining Step: 2051  | total loss: [1m[32m0.46090[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46090 - acc: 0.7819 -- iter: 3072/3680
[A[ATraining Step: 2052  | total loss: [1m[32m0.44617[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44617 - acc: 0.7943 -- iter: 3104/3680
[A[ATraining Step: 2053  | total loss: [1m[32m0.44239[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44239 - acc: 0.7961 -- iter: 3136/3680
[A[ATraining Step: 2054  | total loss: [1m[32m0.43309[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43309 - acc: 0.8040 -- iter: 3168/3680
[A[ATraining Step: 2055  | total loss: [1m[32m0.41903[0m[0m
[2K| Adam | epoch: 018 | loss: 0.41903 - acc: 0.8205 -- iter: 3200/3680
[A[ATraining Step: 2056  | total loss: [1m[32m0.46578[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46578 - acc: 0.7978 -- iter: 3232/3680
[A[ATraining Step: 2057  | total loss: [1m[32m0.47718[0m[0m
[2K| Adam | epoch: 018 | loss: 0.47718 - acc: 0.7930 -- iter: 3264/3680
[A[ATraining Step: 2058  | total loss: [1m[32m0.47080[0m[0m
[2K| Adam | epoch: 018 | loss: 0.47080 - acc: 0.8012 -- iter: 3296/3680
[A[ATraining Step: 2059  | total loss: [1m[32m0.46029[0m[0m
[2K| Adam | epoch: 018 | loss: 0.46029 - acc: 0.8117 -- iter: 3328/3680
[A[ATraining Step: 2060  | total loss: [1m[32m0.44670[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44670 - acc: 0.8212 -- iter: 3360/3680
[A[ATraining Step: 2061  | total loss: [1m[32m0.45121[0m[0m
[2K| Adam | epoch: 018 | loss: 0.45121 - acc: 0.8109 -- iter: 3392/3680
[A[ATraining Step: 2062  | total loss: [1m[32m0.44141[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44141 - acc: 0.8142 -- iter: 3424/3680
[A[ATraining Step: 2063  | total loss: [1m[32m0.43700[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43700 - acc: 0.8203 -- iter: 3456/3680
[A[ATraining Step: 2064  | total loss: [1m[32m0.43014[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43014 - acc: 0.8289 -- iter: 3488/3680
[A[ATraining Step: 2065  | total loss: [1m[32m0.43177[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43177 - acc: 0.8273 -- iter: 3520/3680
[A[ATraining Step: 2066  | total loss: [1m[32m0.43203[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43203 - acc: 0.8227 -- iter: 3552/3680
[A[ATraining Step: 2067  | total loss: [1m[32m0.44526[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44526 - acc: 0.8091 -- iter: 3584/3680
[A[ATraining Step: 2068  | total loss: [1m[32m0.44532[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44532 - acc: 0.8126 -- iter: 3616/3680
[A[ATraining Step: 2069  | total loss: [1m[32m0.44516[0m[0m
[2K| Adam | epoch: 018 | loss: 0.44516 - acc: 0.8095 -- iter: 3648/3680
[A[ATraining Step: 2070  | total loss: [1m[32m0.43829[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43829 - acc: 0.8160 | val_loss: 0.43468 - val_acc: 0.8002 -- iter: 3680/3680
[A[ATraining Step: 2070  | total loss: [1m[32m0.43829[0m[0m
[2K| Adam | epoch: 018 | loss: 0.43829 - acc: 0.8160 | val_loss: 0.43468 - val_acc: 0.8002 -- iter: 3680/3680
--
Training Step: 2071  | total loss: [1m[32m0.43824[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43824 - acc: 0.8188 -- iter: 0032/3680
[A[ATraining Step: 2072  | total loss: [1m[32m0.44605[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44605 - acc: 0.8150 -- iter: 0064/3680
[A[ATraining Step: 2073  | total loss: [1m[32m0.43285[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43285 - acc: 0.8242 -- iter: 0096/3680
[A[ATraining Step: 2074  | total loss: [1m[32m0.43834[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43834 - acc: 0.8199 -- iter: 0128/3680
[A[ATraining Step: 2075  | total loss: [1m[32m0.44235[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44235 - acc: 0.8254 -- iter: 0160/3680
[A[ATraining Step: 2076  | total loss: [1m[32m0.44033[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44033 - acc: 0.8178 -- iter: 0192/3680
[A[ATraining Step: 2077  | total loss: [1m[32m0.45594[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45594 - acc: 0.8173 -- iter: 0224/3680
[A[ATraining Step: 2078  | total loss: [1m[32m0.46067[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46067 - acc: 0.8075 -- iter: 0256/3680
[A[ATraining Step: 2079  | total loss: [1m[32m0.44789[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44789 - acc: 0.8142 -- iter: 0288/3680
[A[ATraining Step: 2080  | total loss: [1m[32m0.45067[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45067 - acc: 0.8078 -- iter: 0320/3680
[A[ATraining Step: 2081  | total loss: [1m[32m0.44544[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44544 - acc: 0.8114 -- iter: 0352/3680
[A[ATraining Step: 2082  | total loss: [1m[32m0.43136[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43136 - acc: 0.8146 -- iter: 0384/3680
[A[ATraining Step: 2083  | total loss: [1m[32m0.43085[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43085 - acc: 0.8113 -- iter: 0416/3680
[A[ATraining Step: 2084  | total loss: [1m[32m0.45030[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45030 - acc: 0.7927 -- iter: 0448/3680
[A[ATraining Step: 2085  | total loss: [1m[32m0.45105[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45105 - acc: 0.7915 -- iter: 0480/3680
[A[ATraining Step: 2086  | total loss: [1m[32m0.45786[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45786 - acc: 0.7905 -- iter: 0512/3680
[A[ATraining Step: 2087  | total loss: [1m[32m0.44571[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44571 - acc: 0.7958 -- iter: 0544/3680
[A[ATraining Step: 2088  | total loss: [1m[32m0.46491[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46491 - acc: 0.7787 -- iter: 0576/3680
[A[ATraining Step: 2089  | total loss: [1m[32m0.47188[0m[0m
[2K| Adam | epoch: 019 | loss: 0.47188 - acc: 0.7696 -- iter: 0608/3680
[A[ATraining Step: 2090  | total loss: [1m[32m0.49310[0m[0m
[2K| Adam | epoch: 019 | loss: 0.49310 - acc: 0.7645 -- iter: 0640/3680
[A[ATraining Step: 2091  | total loss: [1m[32m0.49529[0m[0m
[2K| Adam | epoch: 019 | loss: 0.49529 - acc: 0.7599 -- iter: 0672/3680
[A[ATraining Step: 2092  | total loss: [1m[32m0.48514[0m[0m
[2K| Adam | epoch: 019 | loss: 0.48514 - acc: 0.7715 -- iter: 0704/3680
[A[ATraining Step: 2093  | total loss: [1m[32m0.47003[0m[0m
[2K| Adam | epoch: 019 | loss: 0.47003 - acc: 0.7849 -- iter: 0736/3680
[A[ATraining Step: 2094  | total loss: [1m[32m0.46951[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46951 - acc: 0.7783 -- iter: 0768/3680
[A[ATraining Step: 2095  | total loss: [1m[32m0.47410[0m[0m
[2K| Adam | epoch: 019 | loss: 0.47410 - acc: 0.7786 -- iter: 0800/3680
[A[ATraining Step: 2096  | total loss: [1m[32m0.46082[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46082 - acc: 0.7914 -- iter: 0832/3680
[A[ATraining Step: 2097  | total loss: [1m[32m0.46016[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46016 - acc: 0.7872 -- iter: 0864/3680
[A[ATraining Step: 2098  | total loss: [1m[32m0.44748[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44748 - acc: 0.7960 -- iter: 0896/3680
[A[ATraining Step: 2099  | total loss: [1m[32m0.45608[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45608 - acc: 0.7914 -- iter: 0928/3680
[A[ATraining Step: 2100  | total loss: [1m[32m0.44010[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44010 - acc: 0.8029 | val_loss: 0.42559 - val_acc: 0.8208 -- iter: 0960/3680
[A[ATraining Step: 2100  | total loss: [1m[32m0.44010[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44010 - acc: 0.8029 | val_loss: 0.42559 - val_acc: 0.8208 -- iter: 0960/3680
--
Training Step: 2101  | total loss: [1m[32m0.44250[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44250 - acc: 0.8007 -- iter: 0992/3680
[A[ATraining Step: 2102  | total loss: [1m[32m0.43884[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43884 - acc: 0.8050 -- iter: 1024/3680
[A[ATraining Step: 2103  | total loss: [1m[32m0.44512[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44512 - acc: 0.8027 -- iter: 1056/3680
[A[ATraining Step: 2104  | total loss: [1m[32m0.43733[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43733 - acc: 0.8036 -- iter: 1088/3680
[A[ATraining Step: 2105  | total loss: [1m[32m0.42954[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42954 - acc: 0.8045 -- iter: 1120/3680
[A[ATraining Step: 2106  | total loss: [1m[32m0.41795[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41795 - acc: 0.8116 -- iter: 1152/3680
[A[ATraining Step: 2107  | total loss: [1m[32m0.42852[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42852 - acc: 0.8117 -- iter: 1184/3680
[A[ATraining Step: 2108  | total loss: [1m[32m0.43468[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43468 - acc: 0.8149 -- iter: 1216/3680
[A[ATraining Step: 2109  | total loss: [1m[32m0.45446[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45446 - acc: 0.7928 -- iter: 1248/3680
[A[ATraining Step: 2110  | total loss: [1m[32m0.44486[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44486 - acc: 0.7979 -- iter: 1280/3680
[A[ATraining Step: 2111  | total loss: [1m[32m0.44086[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44086 - acc: 0.8024 -- iter: 1312/3680
[A[ATraining Step: 2112  | total loss: [1m[32m0.45327[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45327 - acc: 0.8003 -- iter: 1344/3680
[A[ATraining Step: 2113  | total loss: [1m[32m0.46006[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46006 - acc: 0.7953 -- iter: 1376/3680
[A[ATraining Step: 2114  | total loss: [1m[32m0.45191[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45191 - acc: 0.8001 -- iter: 1408/3680
[A[ATraining Step: 2115  | total loss: [1m[32m0.44869[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44869 - acc: 0.8014 -- iter: 1440/3680
[A[ATraining Step: 2116  | total loss: [1m[32m0.44308[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44308 - acc: 0.8056 -- iter: 1472/3680
[A[ATraining Step: 2117  | total loss: [1m[32m0.44537[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44537 - acc: 0.8032 -- iter: 1504/3680
[A[ATraining Step: 2118  | total loss: [1m[32m0.44218[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44218 - acc: 0.8041 -- iter: 1536/3680
[A[ATraining Step: 2119  | total loss: [1m[32m0.43516[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43516 - acc: 0.8112 -- iter: 1568/3680
[A[ATraining Step: 2120  | total loss: [1m[32m0.43685[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43685 - acc: 0.8113 -- iter: 1600/3680
[A[ATraining Step: 2121  | total loss: [1m[32m0.44142[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44142 - acc: 0.8083 -- iter: 1632/3680
[A[ATraining Step: 2122  | total loss: [1m[32m0.44437[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44437 - acc: 0.8056 -- iter: 1664/3680
[A[ATraining Step: 2123  | total loss: [1m[32m0.43923[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43923 - acc: 0.8063 -- iter: 1696/3680
[A[ATraining Step: 2124  | total loss: [1m[32m0.45719[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45719 - acc: 0.8007 -- iter: 1728/3680
[A[ATraining Step: 2125  | total loss: [1m[32m0.44929[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44929 - acc: 0.8019 -- iter: 1760/3680
[A[ATraining Step: 2126  | total loss: [1m[32m0.45751[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45751 - acc: 0.7967 -- iter: 1792/3680
[A[ATraining Step: 2127  | total loss: [1m[32m0.45531[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45531 - acc: 0.7951 -- iter: 1824/3680
[A[ATraining Step: 2128  | total loss: [1m[32m0.43793[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43793 - acc: 0.8016 -- iter: 1856/3680
[A[ATraining Step: 2129  | total loss: [1m[32m0.43793[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43793 - acc: 0.8016 -- iter: 1888/3680
[A[ATraining Step: 2130  | total loss: [1m[32m0.42616[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42616 - acc: 0.8120 -- iter: 1920/3680
[A[ATraining Step: 2131  | total loss: [1m[32m0.42846[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42846 - acc: 0.8058 -- iter: 1952/3680
[A[ATraining Step: 2132  | total loss: [1m[32m0.43218[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43218 - acc: 0.8034 -- iter: 1984/3680
[A[ATraining Step: 2133  | total loss: [1m[32m0.43029[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43029 - acc: 0.8043 -- iter: 2016/3680
[A[ATraining Step: 2134  | total loss: [1m[32m0.42699[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42699 - acc: 0.8020 -- iter: 2048/3680
[A[ATraining Step: 2135  | total loss: [1m[32m0.42877[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42877 - acc: 0.8030 -- iter: 2080/3680
[A[ATraining Step: 2136  | total loss: [1m[32m0.42704[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42704 - acc: 0.8071 -- iter: 2112/3680
[A[ATraining Step: 2137  | total loss: [1m[32m0.41868[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41868 - acc: 0.8045 -- iter: 2144/3680
[A[ATraining Step: 2138  | total loss: [1m[32m0.41224[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41224 - acc: 0.8084 -- iter: 2176/3680
[A[ATraining Step: 2139  | total loss: [1m[32m0.41544[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41544 - acc: 0.8120 -- iter: 2208/3680
[A[ATraining Step: 2140  | total loss: [1m[32m0.42150[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42150 - acc: 0.8120 -- iter: 2240/3680
[A[ATraining Step: 2141  | total loss: [1m[32m0.41394[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41394 - acc: 0.8183 -- iter: 2272/3680
[A[ATraining Step: 2142  | total loss: [1m[32m0.40886[0m[0m
[2K| Adam | epoch: 019 | loss: 0.40886 - acc: 0.8209 -- iter: 2304/3680
[A[ATraining Step: 2143  | total loss: [1m[32m0.41679[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41679 - acc: 0.8044 -- iter: 2336/3680
[A[ATraining Step: 2144  | total loss: [1m[32m0.42617[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42617 - acc: 0.7896 -- iter: 2368/3680
[A[ATraining Step: 2145  | total loss: [1m[32m0.41453[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41453 - acc: 0.8013 -- iter: 2400/3680
[A[ATraining Step: 2146  | total loss: [1m[32m0.42093[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42093 - acc: 0.7993 -- iter: 2432/3680
[A[ATraining Step: 2147  | total loss: [1m[32m0.42746[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42746 - acc: 0.7975 -- iter: 2464/3680
[A[ATraining Step: 2148  | total loss: [1m[32m0.42940[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42940 - acc: 0.7990 -- iter: 2496/3680
[A[ATraining Step: 2149  | total loss: [1m[32m0.43227[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43227 - acc: 0.7972 -- iter: 2528/3680
[A[ATraining Step: 2150  | total loss: [1m[32m0.43466[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43466 - acc: 0.7862 -- iter: 2560/3680
[A[ATraining Step: 2151  | total loss: [1m[32m0.41478[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41478 - acc: 0.8045 -- iter: 2592/3680
[A[ATraining Step: 2152  | total loss: [1m[32m0.41269[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41269 - acc: 0.8053 -- iter: 2624/3680
[A[ATraining Step: 2153  | total loss: [1m[32m0.42360[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42360 - acc: 0.8038 -- iter: 2656/3680
[A[ATraining Step: 2154  | total loss: [1m[32m0.42360[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42360 - acc: 0.8038 -- iter: 2688/3680
[A[ATraining Step: 2155  | total loss: [1m[32m0.42545[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42545 - acc: 0.8047 -- iter: 2720/3680
[A[ATraining Step: 2156  | total loss: [1m[32m0.44046[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44046 - acc: 0.7961 -- iter: 2752/3680
[A[ATraining Step: 2157  | total loss: [1m[32m0.43494[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43494 - acc: 0.8040 -- iter: 2784/3680
[A[ATraining Step: 2158  | total loss: [1m[32m0.44928[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44928 - acc: 0.7986 -- iter: 2816/3680
[A[ATraining Step: 2159  | total loss: [1m[32m0.46773[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46773 - acc: 0.7719 -- iter: 2848/3680
[A[ATraining Step: 2160  | total loss: [1m[32m0.46878[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46878 - acc: 0.7666 -- iter: 2880/3680
[A[ATraining Step: 2161  | total loss: [1m[32m0.48539[0m[0m
[2K| Adam | epoch: 019 | loss: 0.48539 - acc: 0.7524 -- iter: 2912/3680
[A[ATraining Step: 2162  | total loss: [1m[32m0.46721[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46721 - acc: 0.7709 -- iter: 2944/3680
[A[ATraining Step: 2163  | total loss: [1m[32m0.45047[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45047 - acc: 0.7844 -- iter: 2976/3680
[A[ATraining Step: 2164  | total loss: [1m[32m0.44950[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44950 - acc: 0.7841 -- iter: 3008/3680
[A[ATraining Step: 2165  | total loss: [1m[32m0.45048[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45048 - acc: 0.7838 -- iter: 3040/3680
[A[ATraining Step: 2166  | total loss: [1m[32m0.46565[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46565 - acc: 0.7711 -- iter: 3072/3680
[A[ATraining Step: 2167  | total loss: [1m[32m0.45725[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45725 - acc: 0.7721 -- iter: 3104/3680
[A[ATraining Step: 2168  | total loss: [1m[32m0.47425[0m[0m
[2K| Adam | epoch: 019 | loss: 0.47425 - acc: 0.7699 -- iter: 3136/3680
[A[ATraining Step: 2169  | total loss: [1m[32m0.47417[0m[0m
[2K| Adam | epoch: 019 | loss: 0.47417 - acc: 0.7741 -- iter: 3168/3680
[A[ATraining Step: 2170  | total loss: [1m[32m0.46625[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46625 - acc: 0.7749 -- iter: 3200/3680
[A[ATraining Step: 2171  | total loss: [1m[32m0.46341[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46341 - acc: 0.7786 -- iter: 3232/3680
[A[ATraining Step: 2172  | total loss: [1m[32m0.46627[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46627 - acc: 0.7820 -- iter: 3264/3680
[A[ATraining Step: 2173  | total loss: [1m[32m0.45865[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45865 - acc: 0.7851 -- iter: 3296/3680
[A[ATraining Step: 2174  | total loss: [1m[32m0.44986[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44986 - acc: 0.7878 -- iter: 3328/3680
[A[ATraining Step: 2175  | total loss: [1m[32m0.45466[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45466 - acc: 0.7840 -- iter: 3360/3680
[A[ATraining Step: 2176  | total loss: [1m[32m0.45069[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45069 - acc: 0.7869 -- iter: 3392/3680
[A[ATraining Step: 2177  | total loss: [1m[32m0.46589[0m[0m
[2K| Adam | epoch: 019 | loss: 0.46589 - acc: 0.7832 -- iter: 3424/3680
[A[ATraining Step: 2178  | total loss: [1m[32m0.45897[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45897 - acc: 0.7892 -- iter: 3456/3680
[A[ATraining Step: 2179  | total loss: [1m[32m0.45562[0m[0m
[2K| Adam | epoch: 019 | loss: 0.45562 - acc: 0.7853 -- iter: 3488/3680
[A[ATraining Step: 2180  | total loss: [1m[32m0.44502[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44502 - acc: 0.7974 -- iter: 3520/3680
[A[ATraining Step: 2181  | total loss: [1m[32m0.44719[0m[0m
[2K| Adam | epoch: 019 | loss: 0.44719 - acc: 0.7989 -- iter: 3552/3680
[A[ATraining Step: 2182  | total loss: [1m[32m0.43807[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43807 - acc: 0.8003 -- iter: 3584/3680
[A[ATraining Step: 2183  | total loss: [1m[32m0.43332[0m[0m
[2K| Adam | epoch: 019 | loss: 0.43332 - acc: 0.8046 -- iter: 3616/3680
[A[ATraining Step: 2184  | total loss: [1m[32m0.42438[0m[0m
[2K| Adam | epoch: 019 | loss: 0.42438 - acc: 0.8054 -- iter: 3648/3680
[A[ATraining Step: 2185  | total loss: [1m[32m0.41943[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41943 - acc: 0.8061 | val_loss: 0.42820 - val_acc: 0.8089 -- iter: 3680/3680
[A[ATraining Step: 2185  | total loss: [1m[32m0.41943[0m[0m
[2K| Adam | epoch: 019 | loss: 0.41943 - acc: 0.8061 | val_loss: 0.42820 - val_acc: 0.8089 -- iter: 3680/3680
--
Training Step: 2186  | total loss: [1m[32m0.42418[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42418 - acc: 0.8068 -- iter: 0032/3680
[A[ATraining Step: 2187  | total loss: [1m[32m0.42461[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42461 - acc: 0.8073 -- iter: 0064/3680
[A[ATraining Step: 2188  | total loss: [1m[32m0.41674[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41674 - acc: 0.8110 -- iter: 0096/3680
[A[ATraining Step: 2189  | total loss: [1m[32m0.40442[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40442 - acc: 0.8143 -- iter: 0128/3680
[A[ATraining Step: 2190  | total loss: [1m[32m0.40398[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40398 - acc: 0.8110 -- iter: 0160/3680
[A[ATraining Step: 2191  | total loss: [1m[32m0.38588[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38588 - acc: 0.8267 -- iter: 0192/3680
[A[ATraining Step: 2192  | total loss: [1m[32m0.40478[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40478 - acc: 0.8191 -- iter: 0224/3680
[A[ATraining Step: 2193  | total loss: [1m[32m0.40170[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40170 - acc: 0.8247 -- iter: 0256/3680
[A[ATraining Step: 2194  | total loss: [1m[32m0.41957[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41957 - acc: 0.8133 -- iter: 0288/3680
[A[ATraining Step: 2195  | total loss: [1m[32m0.41957[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41957 - acc: 0.8133 -- iter: 0320/3680
[A[ATraining Step: 2196  | total loss: [1m[32m0.42281[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42281 - acc: 0.8101 -- iter: 0352/3680
[A[ATraining Step: 2197  | total loss: [1m[32m0.44049[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44049 - acc: 0.8072 -- iter: 0384/3680
[A[ATraining Step: 2198  | total loss: [1m[32m0.45441[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45441 - acc: 0.7984 -- iter: 0416/3680
[A[ATraining Step: 2199  | total loss: [1m[32m0.45922[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45922 - acc: 0.7935 -- iter: 0448/3680
[A[ATraining Step: 2200  | total loss: [1m[32m0.44043[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44043 - acc: 0.8048 | val_loss: 0.42703 - val_acc: 0.8176 -- iter: 0480/3680
[A[ATraining Step: 2200  | total loss: [1m[32m0.44043[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44043 - acc: 0.8048 | val_loss: 0.42703 - val_acc: 0.8176 -- iter: 0480/3680
--
Training Step: 2201  | total loss: [1m[32m0.43877[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43877 - acc: 0.8118 -- iter: 0512/3680
[A[ATraining Step: 2202  | total loss: [1m[32m0.44228[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44228 - acc: 0.8150 -- iter: 0544/3680
[A[ATraining Step: 2203  | total loss: [1m[32m0.45329[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45329 - acc: 0.7960 -- iter: 0576/3680
[A[ATraining Step: 2204  | total loss: [1m[32m0.45425[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45425 - acc: 0.7977 -- iter: 0608/3680
[A[ATraining Step: 2205  | total loss: [1m[32m0.45666[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45666 - acc: 0.7898 -- iter: 0640/3680
[A[ATraining Step: 2206  | total loss: [1m[32m0.45179[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45179 - acc: 0.7952 -- iter: 0672/3680
[A[ATraining Step: 2207  | total loss: [1m[32m0.45128[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45128 - acc: 0.7866 -- iter: 0704/3680
[A[ATraining Step: 2208  | total loss: [1m[32m0.45128[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45128 - acc: 0.7866 -- iter: 0736/3680
[A[ATraining Step: 2209  | total loss: [1m[32m0.45713[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45713 - acc: 0.7798 -- iter: 0768/3680
[A[ATraining Step: 2210  | total loss: [1m[32m0.45301[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45301 - acc: 0.7862 -- iter: 0800/3680
[A[ATraining Step: 2211  | total loss: [1m[32m0.45660[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45660 - acc: 0.7888 -- iter: 0832/3680
[A[ATraining Step: 2212  | total loss: [1m[32m0.44510[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44510 - acc: 0.8006 -- iter: 0864/3680
[A[ATraining Step: 2213  | total loss: [1m[32m0.44443[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44443 - acc: 0.8049 -- iter: 0896/3680
[A[ATraining Step: 2214  | total loss: [1m[32m0.43786[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43786 - acc: 0.8056 -- iter: 0928/3680
[A[ATraining Step: 2215  | total loss: [1m[32m0.44395[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44395 - acc: 0.8063 -- iter: 0960/3680
[A[ATraining Step: 2216  | total loss: [1m[32m0.44577[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44577 - acc: 0.8007 -- iter: 0992/3680
[A[ATraining Step: 2217  | total loss: [1m[32m0.44556[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44556 - acc: 0.7988 -- iter: 1024/3680
[A[ATraining Step: 2218  | total loss: [1m[32m0.44585[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44585 - acc: 0.7939 -- iter: 1056/3680
[A[ATraining Step: 2219  | total loss: [1m[32m0.45041[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45041 - acc: 0.7926 -- iter: 1088/3680
[A[ATraining Step: 2220  | total loss: [1m[32m0.45865[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45865 - acc: 0.7852 -- iter: 1120/3680
[A[ATraining Step: 2221  | total loss: [1m[32m0.46009[0m[0m
[2K| Adam | epoch: 020 | loss: 0.46009 - acc: 0.7911 -- iter: 1152/3680
[A[ATraining Step: 2222  | total loss: [1m[32m0.46847[0m[0m
[2K| Adam | epoch: 020 | loss: 0.46847 - acc: 0.7870 -- iter: 1184/3680
[A[ATraining Step: 2223  | total loss: [1m[32m0.46118[0m[0m
[2K| Adam | epoch: 020 | loss: 0.46118 - acc: 0.7895 -- iter: 1216/3680
[A[ATraining Step: 2224  | total loss: [1m[32m0.44733[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44733 - acc: 0.7949 -- iter: 1248/3680
[A[ATraining Step: 2225  | total loss: [1m[32m0.43972[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43972 - acc: 0.7958 -- iter: 1280/3680
[A[ATraining Step: 2226  | total loss: [1m[32m0.43972[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43972 - acc: 0.7958 -- iter: 1312/3680
[A[ATraining Step: 2227  | total loss: [1m[32m0.44353[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44353 - acc: 0.7943 -- iter: 1344/3680
[A[ATraining Step: 2228  | total loss: [1m[32m0.45320[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45320 - acc: 0.7961 -- iter: 1376/3680
[A[ATraining Step: 2229  | total loss: [1m[32m0.44815[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44815 - acc: 0.7978 -- iter: 1408/3680
[A[ATraining Step: 2230  | total loss: [1m[32m0.43705[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43705 - acc: 0.8055 -- iter: 1440/3680
[A[ATraining Step: 2231  | total loss: [1m[32m0.42478[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42478 - acc: 0.8125 -- iter: 1472/3680
[A[ATraining Step: 2232  | total loss: [1m[32m0.42103[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42103 - acc: 0.8125 -- iter: 1504/3680
[A[ATraining Step: 2233  | total loss: [1m[32m0.43824[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43824 - acc: 0.7937 -- iter: 1536/3680
[A[ATraining Step: 2234  | total loss: [1m[32m0.43953[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43953 - acc: 0.7862 -- iter: 1568/3680
[A[ATraining Step: 2235  | total loss: [1m[32m0.43972[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43972 - acc: 0.7826 -- iter: 1600/3680
[A[ATraining Step: 2236  | total loss: [1m[32m0.43413[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43413 - acc: 0.7856 -- iter: 1632/3680
[A[ATraining Step: 2237  | total loss: [1m[32m0.42838[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42838 - acc: 0.7945 -- iter: 1664/3680
[A[ATraining Step: 2238  | total loss: [1m[32m0.43563[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43563 - acc: 0.7932 -- iter: 1696/3680
[A[ATraining Step: 2239  | total loss: [1m[32m0.43817[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43817 - acc: 0.7951 -- iter: 1728/3680
[A[ATraining Step: 2240  | total loss: [1m[32m0.43951[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43951 - acc: 0.8000 -- iter: 1760/3680
[A[ATraining Step: 2241  | total loss: [1m[32m0.43676[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43676 - acc: 0.8075 -- iter: 1792/3680
[A[ATraining Step: 2242  | total loss: [1m[32m0.43657[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43657 - acc: 0.8022 -- iter: 1824/3680
[A[ATraining Step: 2243  | total loss: [1m[32m0.43751[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43751 - acc: 0.8022 -- iter: 1856/3680
[A[ATraining Step: 2244  | total loss: [1m[32m0.43190[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43190 - acc: 0.8126 -- iter: 1888/3680
[A[ATraining Step: 2245  | total loss: [1m[32m0.43151[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43151 - acc: 0.8095 -- iter: 1920/3680
[A[ATraining Step: 2246  | total loss: [1m[32m0.42175[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42175 - acc: 0.8191 -- iter: 1952/3680
[A[ATraining Step: 2247  | total loss: [1m[32m0.42389[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42389 - acc: 0.8154 -- iter: 1984/3680
[A[ATraining Step: 2248  | total loss: [1m[32m0.42520[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42520 - acc: 0.8119 -- iter: 2016/3680
[A[ATraining Step: 2249  | total loss: [1m[32m0.42498[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42498 - acc: 0.8120 -- iter: 2048/3680
[A[ATraining Step: 2250  | total loss: [1m[32m0.42045[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42045 - acc: 0.8089 -- iter: 2080/3680
[A[ATraining Step: 2251  | total loss: [1m[32m0.41036[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41036 - acc: 0.8187 -- iter: 2112/3680
[A[ATraining Step: 2252  | total loss: [1m[32m0.41094[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41094 - acc: 0.8180 -- iter: 2144/3680
[A[ATraining Step: 2253  | total loss: [1m[32m0.41065[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41065 - acc: 0.8206 -- iter: 2176/3680
[A[ATraining Step: 2254  | total loss: [1m[32m0.41565[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41565 - acc: 0.8229 -- iter: 2208/3680
[A[ATraining Step: 2255  | total loss: [1m[32m0.42200[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42200 - acc: 0.8188 -- iter: 2240/3680
[A[ATraining Step: 2256  | total loss: [1m[32m0.42411[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42411 - acc: 0.8181 -- iter: 2272/3680
[A[ATraining Step: 2257  | total loss: [1m[32m0.42180[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42180 - acc: 0.8176 -- iter: 2304/3680
[A[ATraining Step: 2258  | total loss: [1m[32m0.42368[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42368 - acc: 0.8108 -- iter: 2336/3680
[A[ATraining Step: 2259  | total loss: [1m[32m0.41950[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41950 - acc: 0.8204 -- iter: 2368/3680
[A[ATraining Step: 2260  | total loss: [1m[32m0.41354[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41354 - acc: 0.8227 -- iter: 2400/3680
[A[ATraining Step: 2261  | total loss: [1m[32m0.41389[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41389 - acc: 0.8217 -- iter: 2432/3680
[A[ATraining Step: 2262  | total loss: [1m[32m0.41899[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41899 - acc: 0.8176 -- iter: 2464/3680
[A[ATraining Step: 2263  | total loss: [1m[32m0.41191[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41191 - acc: 0.8202 -- iter: 2496/3680
[A[ATraining Step: 2264  | total loss: [1m[32m0.41655[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41655 - acc: 0.8226 -- iter: 2528/3680
[A[ATraining Step: 2265  | total loss: [1m[32m0.42258[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42258 - acc: 0.8185 -- iter: 2560/3680
[A[ATraining Step: 2266  | total loss: [1m[32m0.41475[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41475 - acc: 0.8272 -- iter: 2592/3680
[A[ATraining Step: 2267  | total loss: [1m[32m0.41581[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41581 - acc: 0.8226 -- iter: 2624/3680
[A[ATraining Step: 2268  | total loss: [1m[32m0.42152[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42152 - acc: 0.8216 -- iter: 2656/3680
[A[ATraining Step: 2269  | total loss: [1m[32m0.41859[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41859 - acc: 0.8238 -- iter: 2688/3680
[A[ATraining Step: 2270  | total loss: [1m[32m0.41208[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41208 - acc: 0.8290 -- iter: 2720/3680
[A[ATraining Step: 2271  | total loss: [1m[32m0.40230[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40230 - acc: 0.8336 -- iter: 2752/3680
[A[ATraining Step: 2272  | total loss: [1m[32m0.40547[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40547 - acc: 0.8315 -- iter: 2784/3680
[A[ATraining Step: 2273  | total loss: [1m[32m0.42068[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42068 - acc: 0.8139 -- iter: 2816/3680
[A[ATraining Step: 2274  | total loss: [1m[32m0.43450[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43450 - acc: 0.7982 -- iter: 2848/3680
[A[ATraining Step: 2275  | total loss: [1m[32m0.45355[0m[0m
[2K| Adam | epoch: 020 | loss: 0.45355 - acc: 0.7933 -- iter: 2880/3680
[A[ATraining Step: 2276  | total loss: [1m[32m0.44579[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44579 - acc: 0.7953 -- iter: 2912/3680
[A[ATraining Step: 2277  | total loss: [1m[32m0.44520[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44520 - acc: 0.8001 -- iter: 2944/3680
[A[ATraining Step: 2278  | total loss: [1m[32m0.44223[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44223 - acc: 0.8045 -- iter: 2976/3680
[A[ATraining Step: 2279  | total loss: [1m[32m0.43348[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43348 - acc: 0.8115 -- iter: 3008/3680
[A[ATraining Step: 2280  | total loss: [1m[32m0.44609[0m[0m
[2K| Adam | epoch: 020 | loss: 0.44609 - acc: 0.8085 -- iter: 3040/3680
[A[ATraining Step: 2281  | total loss: [1m[32m0.43379[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43379 - acc: 0.8152 -- iter: 3072/3680
[A[ATraining Step: 2282  | total loss: [1m[32m0.43499[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43499 - acc: 0.8055 -- iter: 3104/3680
[A[ATraining Step: 2283  | total loss: [1m[32m0.43714[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43714 - acc: 0.8062 -- iter: 3136/3680
[A[ATraining Step: 2284  | total loss: [1m[32m0.43477[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43477 - acc: 0.8100 -- iter: 3168/3680
[A[ATraining Step: 2285  | total loss: [1m[32m0.43891[0m[0m
[2K| Adam | epoch: 020 | loss: 0.43891 - acc: 0.8071 -- iter: 3200/3680
[A[ATraining Step: 2286  | total loss: [1m[32m0.42564[0m[0m
[2K| Adam | epoch: 020 | loss: 0.42564 - acc: 0.8170 -- iter: 3232/3680
[A[ATraining Step: 2287  | total loss: [1m[32m0.41267[0m[0m
[2K| Adam | epoch: 020 | loss: 0.41267 - acc: 0.8228 -- iter: 3264/3680
[A[ATraining Step: 2288  | total loss: [1m[32m0.40781[0m[0m
[2K| Adam | epoch: 020 | loss: 0.40781 - acc: 0.8218 -- iter: 3296/3680
[A[ATraining Step: 2289  | total loss: [1m[32m0.39710[0m[0m
[2K| Adam | epoch: 020 | loss: 0.39710 - acc: 0.8271 -- iter: 3328/3680
[A[ATraining Step: 2290  | total loss: [1m[32m0.38667[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38667 - acc: 0.8319 -- iter: 3360/3680
[A[ATraining Step: 2291  | total loss: [1m[32m0.38890[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38890 - acc: 0.8268 -- iter: 3392/3680
[A[ATraining Step: 2292  | total loss: [1m[32m0.39705[0m[0m
[2K| Adam | epoch: 020 | loss: 0.39705 - acc: 0.8254 -- iter: 3424/3680
[A[ATraining Step: 2293  | total loss: [1m[32m0.39197[0m[0m
[2K| Adam | epoch: 020 | loss: 0.39197 - acc: 0.8304 -- iter: 3456/3680
[A[ATraining Step: 2294  | total loss: [1m[32m0.38680[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38680 - acc: 0.8348 -- iter: 3488/3680
[A[ATraining Step: 2295  | total loss: [1m[32m0.37792[0m[0m
[2K| Adam | epoch: 020 | loss: 0.37792 - acc: 0.8451 -- iter: 3520/3680
[A[ATraining Step: 2296  | total loss: [1m[32m0.37922[0m[0m
[2K| Adam | epoch: 020 | loss: 0.37922 - acc: 0.8450 -- iter: 3552/3680
[A[ATraining Step: 2297  | total loss: [1m[32m0.38301[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38301 - acc: 0.8448 -- iter: 3584/3680
[A[ATraining Step: 2298  | total loss: [1m[32m0.38200[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38200 - acc: 0.8416 -- iter: 3616/3680
[A[ATraining Step: 2299  | total loss: [1m[32m0.39593[0m[0m
[2K| Adam | epoch: 020 | loss: 0.39593 - acc: 0.8418 -- iter: 3648/3680
[A[ATraining Step: 2300  | total loss: [1m[32m0.38516[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38516 - acc: 0.8483 | val_loss: 0.41007 - val_acc: 0.8274 -- iter: 3680/3680
[A[ATraining Step: 2300  | total loss: [1m[32m0.38516[0m[0m
[2K| Adam | epoch: 020 | loss: 0.38516 - acc: 0.8483 | val_loss: 0.41007 - val_acc: 0.8274 -- iter: 3680/3680
--
Training Step: 2301  | total loss: [1m[32m0.40360[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40360 - acc: 0.8322 -- iter: 0032/3680
[A[ATraining Step: 2302  | total loss: [1m[32m0.39420[0m[0m
[2K| Adam | epoch: 021 | loss: 0.39420 - acc: 0.8333 -- iter: 0064/3680
[A[ATraining Step: 2303  | total loss: [1m[32m0.40324[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40324 - acc: 0.8219 -- iter: 0096/3680
[A[ATraining Step: 2304  | total loss: [1m[32m0.40176[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40176 - acc: 0.8303 -- iter: 0128/3680
[A[ATraining Step: 2305  | total loss: [1m[32m0.40010[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40010 - acc: 0.8285 -- iter: 0160/3680
[A[ATraining Step: 2306  | total loss: [1m[32m0.40394[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40394 - acc: 0.8269 -- iter: 0192/3680
[A[ATraining Step: 2307  | total loss: [1m[32m0.40180[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40180 - acc: 0.8255 -- iter: 0224/3680
[A[ATraining Step: 2308  | total loss: [1m[32m0.41035[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41035 - acc: 0.8211 -- iter: 0256/3680
[A[ATraining Step: 2309  | total loss: [1m[32m0.40965[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40965 - acc: 0.8202 -- iter: 0288/3680
[A[ATraining Step: 2310  | total loss: [1m[32m0.40407[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40407 - acc: 0.8288 -- iter: 0320/3680
[A[ATraining Step: 2311  | total loss: [1m[32m0.40533[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40533 - acc: 0.8272 -- iter: 0352/3680
[A[ATraining Step: 2312  | total loss: [1m[32m0.40232[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40232 - acc: 0.8226 -- iter: 0384/3680
[A[ATraining Step: 2313  | total loss: [1m[32m0.40170[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40170 - acc: 0.8185 -- iter: 0416/3680
[A[ATraining Step: 2314  | total loss: [1m[32m0.40453[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40453 - acc: 0.8116 -- iter: 0448/3680
[A[ATraining Step: 2315  | total loss: [1m[32m0.42982[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42982 - acc: 0.7992 -- iter: 0480/3680
[A[ATraining Step: 2316  | total loss: [1m[32m0.42296[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42296 - acc: 0.8037 -- iter: 0512/3680
[A[ATraining Step: 2317  | total loss: [1m[32m0.42909[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42909 - acc: 0.8108 -- iter: 0544/3680
[A[ATraining Step: 2318  | total loss: [1m[32m0.44436[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44436 - acc: 0.7985 -- iter: 0576/3680
[A[ATraining Step: 2319  | total loss: [1m[32m0.43821[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43821 - acc: 0.7999 -- iter: 0608/3680
[A[ATraining Step: 2320  | total loss: [1m[32m0.42647[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42647 - acc: 0.8074 -- iter: 0640/3680
[A[ATraining Step: 2321  | total loss: [1m[32m0.42367[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42367 - acc: 0.8048 -- iter: 0672/3680
[A[ATraining Step: 2322  | total loss: [1m[32m0.41984[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41984 - acc: 0.8055 -- iter: 0704/3680
[A[ATraining Step: 2323  | total loss: [1m[32m0.42686[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42686 - acc: 0.7922 -- iter: 0736/3680
[A[ATraining Step: 2324  | total loss: [1m[32m0.43763[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43763 - acc: 0.7973 -- iter: 0768/3680
[A[ATraining Step: 2325  | total loss: [1m[32m0.43127[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43127 - acc: 0.7973 -- iter: 0800/3680
[A[ATraining Step: 2326  | total loss: [1m[32m0.42686[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42686 - acc: 0.7988 -- iter: 0832/3680
[A[ATraining Step: 2327  | total loss: [1m[32m0.42452[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42452 - acc: 0.7971 -- iter: 0864/3680
[A[ATraining Step: 2328  | total loss: [1m[32m0.40885[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40885 - acc: 0.8080 -- iter: 0896/3680
[A[ATraining Step: 2329  | total loss: [1m[32m0.40711[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40711 - acc: 0.8116 -- iter: 0928/3680
[A[ATraining Step: 2330  | total loss: [1m[32m0.40911[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40911 - acc: 0.8179 -- iter: 0960/3680
[A[ATraining Step: 2331  | total loss: [1m[32m0.40896[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40896 - acc: 0.8236 -- iter: 0992/3680
[A[ATraining Step: 2332  | total loss: [1m[32m0.41395[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41395 - acc: 0.8163 -- iter: 1024/3680
[A[ATraining Step: 2333  | total loss: [1m[32m0.41739[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41739 - acc: 0.8128 -- iter: 1056/3680
[A[ATraining Step: 2334  | total loss: [1m[32m0.40763[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40763 - acc: 0.8159 -- iter: 1088/3680
[A[ATraining Step: 2335  | total loss: [1m[32m0.40119[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40119 - acc: 0.8118 -- iter: 1120/3680
[A[ATraining Step: 2336  | total loss: [1m[32m0.41730[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41730 - acc: 0.8118 -- iter: 1152/3680
[A[ATraining Step: 2337  | total loss: [1m[32m0.41255[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41255 - acc: 0.8119 -- iter: 1184/3680
[A[ATraining Step: 2338  | total loss: [1m[32m0.41635[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41635 - acc: 0.8088 -- iter: 1216/3680
[A[ATraining Step: 2339  | total loss: [1m[32m0.41839[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41839 - acc: 0.8123 -- iter: 1248/3680
[A[ATraining Step: 2340  | total loss: [1m[32m0.43513[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43513 - acc: 0.8092 -- iter: 1280/3680
[A[ATraining Step: 2341  | total loss: [1m[32m0.43791[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43791 - acc: 0.8064 -- iter: 1312/3680
[A[ATraining Step: 2342  | total loss: [1m[32m0.44271[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44271 - acc: 0.8101 -- iter: 1344/3680
[A[ATraining Step: 2343  | total loss: [1m[32m0.43689[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43689 - acc: 0.8135 -- iter: 1376/3680
[A[ATraining Step: 2344  | total loss: [1m[32m0.43885[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43885 - acc: 0.8071 -- iter: 1408/3680
[A[ATraining Step: 2345  | total loss: [1m[32m0.42553[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42553 - acc: 0.8139 -- iter: 1440/3680
[A[ATraining Step: 2346  | total loss: [1m[32m0.43368[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43368 - acc: 0.8044 -- iter: 1472/3680
[A[ATraining Step: 2347  | total loss: [1m[32m0.45183[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45183 - acc: 0.7958 -- iter: 1504/3680
[A[ATraining Step: 2348  | total loss: [1m[32m0.46384[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46384 - acc: 0.7878 -- iter: 1536/3680
[A[ATraining Step: 2349  | total loss: [1m[32m0.45819[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45819 - acc: 0.7878 -- iter: 1568/3680
[A[ATraining Step: 2350  | total loss: [1m[32m0.45214[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45214 - acc: 0.7871 -- iter: 1600/3680
[A[ATraining Step: 2351  | total loss: [1m[32m0.45074[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45074 - acc: 0.7896 -- iter: 1632/3680
[A[ATraining Step: 2352  | total loss: [1m[32m0.45854[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45854 - acc: 0.7857 -- iter: 1664/3680
[A[ATraining Step: 2353  | total loss: [1m[32m0.46402[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46402 - acc: 0.7852 -- iter: 1696/3680
[A[ATraining Step: 2354  | total loss: [1m[32m0.46184[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46184 - acc: 0.7880 -- iter: 1728/3680
[A[ATraining Step: 2355  | total loss: [1m[32m0.45694[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45694 - acc: 0.7873 -- iter: 1760/3680
[A[ATraining Step: 2356  | total loss: [1m[32m0.44765[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44765 - acc: 0.7961 -- iter: 1792/3680
[A[ATraining Step: 2357  | total loss: [1m[32m0.43445[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43445 - acc: 0.8040 -- iter: 1824/3680
[A[ATraining Step: 2358  | total loss: [1m[32m0.43413[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43413 - acc: 0.8048 -- iter: 1856/3680
[A[ATraining Step: 2359  | total loss: [1m[32m0.43011[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43011 - acc: 0.8087 -- iter: 1888/3680
[A[ATraining Step: 2360  | total loss: [1m[32m0.43240[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43240 - acc: 0.7997 -- iter: 1920/3680
[A[ATraining Step: 2361  | total loss: [1m[32m0.43604[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43604 - acc: 0.7916 -- iter: 1952/3680
[A[ATraining Step: 2362  | total loss: [1m[32m0.44634[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44634 - acc: 0.7843 -- iter: 1984/3680
[A[ATraining Step: 2363  | total loss: [1m[32m0.45388[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45388 - acc: 0.7746 -- iter: 2016/3680
[A[ATraining Step: 2364  | total loss: [1m[32m0.45368[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45368 - acc: 0.7816 -- iter: 2048/3680
[A[ATraining Step: 2365  | total loss: [1m[32m0.43860[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43860 - acc: 0.7940 -- iter: 2080/3680
[A[ATraining Step: 2366  | total loss: [1m[32m0.45040[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45040 - acc: 0.7834 -- iter: 2112/3680
[A[ATraining Step: 2367  | total loss: [1m[32m0.45135[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45135 - acc: 0.7863 -- iter: 2144/3680
[A[ATraining Step: 2368  | total loss: [1m[32m0.44672[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44672 - acc: 0.7889 -- iter: 2176/3680
[A[ATraining Step: 2369  | total loss: [1m[32m0.44743[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44743 - acc: 0.7913 -- iter: 2208/3680
[A[ATraining Step: 2370  | total loss: [1m[32m0.43968[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43968 - acc: 0.8012 -- iter: 2240/3680
[A[ATraining Step: 2371  | total loss: [1m[32m0.43968[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43968 - acc: 0.8012 -- iter: 2272/3680
[A[ATraining Step: 2372  | total loss: [1m[32m0.43196[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43196 - acc: 0.8024 -- iter: 2304/3680
[A[ATraining Step: 2373  | total loss: [1m[32m0.42586[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42586 - acc: 0.8065 -- iter: 2336/3680
[A[ATraining Step: 2374  | total loss: [1m[32m0.42815[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42815 - acc: 0.8040 -- iter: 2368/3680
[A[ATraining Step: 2375  | total loss: [1m[32m0.41873[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41873 - acc: 0.8142 -- iter: 2400/3680
[A[ATraining Step: 2376  | total loss: [1m[32m0.41527[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41527 - acc: 0.8109 -- iter: 2432/3680
[A[ATraining Step: 2377  | total loss: [1m[32m0.42677[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42677 - acc: 0.7986 -- iter: 2464/3680
[A[ATraining Step: 2378  | total loss: [1m[32m0.41825[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41825 - acc: 0.8000 -- iter: 2496/3680
[A[ATraining Step: 2379  | total loss: [1m[32m0.41726[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41726 - acc: 0.8043 -- iter: 2528/3680
[A[ATraining Step: 2380  | total loss: [1m[32m0.43319[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43319 - acc: 0.8083 -- iter: 2560/3680
[A[ATraining Step: 2381  | total loss: [1m[32m0.42753[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42753 - acc: 0.8118 -- iter: 2592/3680
[A[ATraining Step: 2382  | total loss: [1m[32m0.42892[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42892 - acc: 0.8150 -- iter: 2624/3680
[A[ATraining Step: 2383  | total loss: [1m[32m0.42250[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42250 - acc: 0.8210 -- iter: 2656/3680
[A[ATraining Step: 2384  | total loss: [1m[32m0.42835[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42835 - acc: 0.8170 -- iter: 2688/3680
[A[ATraining Step: 2385  | total loss: [1m[32m0.42575[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42575 - acc: 0.8228 -- iter: 2720/3680
[A[ATraining Step: 2386  | total loss: [1m[32m0.42481[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42481 - acc: 0.8156 -- iter: 2752/3680
[A[ATraining Step: 2387  | total loss: [1m[32m0.42561[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42561 - acc: 0.8152 -- iter: 2784/3680
[A[ATraining Step: 2388  | total loss: [1m[32m0.43040[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43040 - acc: 0.8056 -- iter: 2816/3680
[A[ATraining Step: 2389  | total loss: [1m[32m0.42770[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42770 - acc: 0.8125 -- iter: 2848/3680
[A[ATraining Step: 2390  | total loss: [1m[32m0.44228[0m[0m
[2K| Adam | epoch: 021 | loss: 0.44228 - acc: 0.8032 -- iter: 2880/3680
[A[ATraining Step: 2391  | total loss: [1m[32m0.43136[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43136 - acc: 0.8135 -- iter: 2912/3680
[A[ATraining Step: 2392  | total loss: [1m[32m0.43836[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43836 - acc: 0.8071 -- iter: 2944/3680
[A[ATraining Step: 2393  | total loss: [1m[32m0.43070[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43070 - acc: 0.8077 -- iter: 2976/3680
[A[ATraining Step: 2394  | total loss: [1m[32m0.42715[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42715 - acc: 0.8050 -- iter: 3008/3680
[A[ATraining Step: 2395  | total loss: [1m[32m0.41287[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41287 - acc: 0.8089 -- iter: 3040/3680
[A[ATraining Step: 2396  | total loss: [1m[32m0.39996[0m[0m
[2K| Adam | epoch: 021 | loss: 0.39996 - acc: 0.8186 -- iter: 3072/3680
[A[ATraining Step: 2397  | total loss: [1m[32m0.40695[0m[0m
[2K| Adam | epoch: 021 | loss: 0.40695 - acc: 0.8118 -- iter: 3104/3680
[A[ATraining Step: 2398  | total loss: [1m[32m0.41784[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41784 - acc: 0.8025 -- iter: 3136/3680
[A[ATraining Step: 2399  | total loss: [1m[32m0.41281[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41281 - acc: 0.8097 -- iter: 3168/3680
[A[ATraining Step: 2400  | total loss: [1m[32m0.41627[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41627 - acc: 0.8131 | val_loss: 0.41170 - val_acc: 0.8219 -- iter: 3200/3680
[A[ATraining Step: 2400  | total loss: [1m[32m0.41627[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41627 - acc: 0.8131 | val_loss: 0.41170 - val_acc: 0.8219 -- iter: 3200/3680
--
Training Step: 2401  | total loss: [1m[32m0.41843[0m[0m
[2K| Adam | epoch: 021 | loss: 0.41843 - acc: 0.8099 -- iter: 3232/3680
[A[ATraining Step: 2402  | total loss: [1m[32m0.42886[0m[0m
[2K| Adam | epoch: 021 | loss: 0.42886 - acc: 0.8071 -- iter: 3264/3680
[A[ATraining Step: 2403  | total loss: [1m[32m0.43007[0m[0m
[2K| Adam | epoch: 021 | loss: 0.43007 - acc: 0.8014 -- iter: 3296/3680
[A[ATraining Step: 2404  | total loss: [1m[32m0.48369[0m[0m
[2K| Adam | epoch: 021 | loss: 0.48369 - acc: 0.7837 -- iter: 3328/3680
[A[ATraining Step: 2405  | total loss: [1m[32m0.46248[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46248 - acc: 0.7929 -- iter: 3360/3680
[A[ATraining Step: 2406  | total loss: [1m[32m0.46651[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46651 - acc: 0.7938 -- iter: 3392/3680
[A[ATraining Step: 2407  | total loss: [1m[32m0.46636[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46636 - acc: 0.7938 -- iter: 3424/3680
[A[ATraining Step: 2408  | total loss: [1m[32m0.46553[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46553 - acc: 0.7988 -- iter: 3456/3680
[A[ATraining Step: 2409  | total loss: [1m[32m0.46559[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46559 - acc: 0.7970 -- iter: 3488/3680
[A[ATraining Step: 2410  | total loss: [1m[32m0.45640[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45640 - acc: 0.8000 -- iter: 3520/3680
[A[ATraining Step: 2411  | total loss: [1m[32m0.45640[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45640 - acc: 0.8000 -- iter: 3552/3680
[A[ATraining Step: 2412  | total loss: [1m[32m0.47590[0m[0m
[2K| Adam | epoch: 021 | loss: 0.47590 - acc: 0.7950 -- iter: 3584/3680
[A[ATraining Step: 2413  | total loss: [1m[32m0.46743[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46743 - acc: 0.8092 -- iter: 3616/3680
[A[ATraining Step: 2414  | total loss: [1m[32m0.46075[0m[0m
[2K| Adam | epoch: 021 | loss: 0.46075 - acc: 0.8158 -- iter: 3648/3680
[A[ATraining Step: 2415  | total loss: [1m[32m0.45369[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45369 - acc: 0.8217 | val_loss: 0.40851 - val_acc: 0.8219 -- iter: 3680/3680
[A[ATraining Step: 2415  | total loss: [1m[32m0.45369[0m[0m
[2K| Adam | epoch: 021 | loss: 0.45369 - acc: 0.8217 | val_loss: 0.40851 - val_acc: 0.8219 -- iter: 3680/3680
--
Training Step: 2416  | total loss: [1m[32m0.44893[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44893 - acc: 0.8239 -- iter: 0032/3680
[A[ATraining Step: 2417  | total loss: [1m[32m0.44153[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44153 - acc: 0.8259 -- iter: 0064/3680
[A[ATraining Step: 2418  | total loss: [1m[32m0.45439[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45439 - acc: 0.8121 -- iter: 0096/3680
[A[ATraining Step: 2419  | total loss: [1m[32m0.44818[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44818 - acc: 0.8090 -- iter: 0128/3680
[A[ATraining Step: 2420  | total loss: [1m[32m0.44779[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44779 - acc: 0.8093 -- iter: 0160/3680
[A[ATraining Step: 2421  | total loss: [1m[32m0.45968[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45968 - acc: 0.8065 -- iter: 0192/3680
[A[ATraining Step: 2422  | total loss: [1m[32m0.45895[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45895 - acc: 0.7977 -- iter: 0224/3680
[A[ATraining Step: 2423  | total loss: [1m[32m0.46045[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46045 - acc: 0.7898 -- iter: 0256/3680
[A[ATraining Step: 2424  | total loss: [1m[32m0.45538[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45538 - acc: 0.7984 -- iter: 0288/3680
[A[ATraining Step: 2425  | total loss: [1m[32m0.45031[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45031 - acc: 0.8029 -- iter: 0320/3680
[A[ATraining Step: 2426  | total loss: [1m[32m0.43832[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43832 - acc: 0.8101 -- iter: 0352/3680
[A[ATraining Step: 2427  | total loss: [1m[32m0.44783[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44783 - acc: 0.8104 -- iter: 0384/3680
[A[ATraining Step: 2428  | total loss: [1m[32m0.43865[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43865 - acc: 0.8168 -- iter: 0416/3680
[A[ATraining Step: 2429  | total loss: [1m[32m0.42078[0m[0m
[2K| Adam | epoch: 022 | loss: 0.42078 - acc: 0.8320 -- iter: 0448/3680
[A[ATraining Step: 2430  | total loss: [1m[32m0.41927[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41927 - acc: 0.8332 -- iter: 0480/3680
[A[ATraining Step: 2431  | total loss: [1m[32m0.41680[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41680 - acc: 0.8342 -- iter: 0512/3680
[A[ATraining Step: 2432  | total loss: [1m[32m0.41362[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41362 - acc: 0.8289 -- iter: 0544/3680
[A[ATraining Step: 2433  | total loss: [1m[32m0.41450[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41450 - acc: 0.8273 -- iter: 0576/3680
[A[ATraining Step: 2434  | total loss: [1m[32m0.41087[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41087 - acc: 0.8227 -- iter: 0608/3680
[A[ATraining Step: 2435  | total loss: [1m[32m0.41187[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41187 - acc: 0.8185 -- iter: 0640/3680
[A[ATraining Step: 2436  | total loss: [1m[32m0.40106[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40106 - acc: 0.8273 -- iter: 0672/3680
[A[ATraining Step: 2437  | total loss: [1m[32m0.39487[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39487 - acc: 0.8321 -- iter: 0704/3680
[A[ATraining Step: 2438  | total loss: [1m[32m0.39975[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39975 - acc: 0.8301 -- iter: 0736/3680
[A[ATraining Step: 2439  | total loss: [1m[32m0.40112[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40112 - acc: 0.8284 -- iter: 0768/3680
[A[ATraining Step: 2440  | total loss: [1m[32m0.40637[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40637 - acc: 0.8268 -- iter: 0800/3680
[A[ATraining Step: 2441  | total loss: [1m[32m0.40435[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40435 - acc: 0.8254 -- iter: 0832/3680
[A[ATraining Step: 2442  | total loss: [1m[32m0.39848[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39848 - acc: 0.8317 -- iter: 0864/3680
[A[ATraining Step: 2443  | total loss: [1m[32m0.39458[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39458 - acc: 0.8317 -- iter: 0896/3680
[A[ATraining Step: 2444  | total loss: [1m[32m0.38999[0m[0m
[2K| Adam | epoch: 022 | loss: 0.38999 - acc: 0.8329 -- iter: 0928/3680
[A[ATraining Step: 2445  | total loss: [1m[32m0.39932[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39932 - acc: 0.8340 -- iter: 0960/3680
[A[ATraining Step: 2446  | total loss: [1m[32m0.39679[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39679 - acc: 0.8349 -- iter: 0992/3680
[A[ATraining Step: 2447  | total loss: [1m[32m0.39664[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39664 - acc: 0.8358 -- iter: 1024/3680
[A[ATraining Step: 2448  | total loss: [1m[32m0.40237[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40237 - acc: 0.8304 -- iter: 1056/3680
[A[ATraining Step: 2449  | total loss: [1m[32m0.41660[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41660 - acc: 0.8098 -- iter: 1088/3680
[A[ATraining Step: 2450  | total loss: [1m[32m0.41166[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41166 - acc: 0.8163 -- iter: 1120/3680
[A[ATraining Step: 2451  | total loss: [1m[32m0.39646[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39646 - acc: 0.8316 -- iter: 1152/3680
[A[ATraining Step: 2452  | total loss: [1m[32m0.40273[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40273 - acc: 0.8234 -- iter: 1184/3680
[A[ATraining Step: 2453  | total loss: [1m[32m0.40054[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40054 - acc: 0.8161 -- iter: 1216/3680
[A[ATraining Step: 2454  | total loss: [1m[32m0.39014[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39014 - acc: 0.8367 -- iter: 1248/3680
[A[ATraining Step: 2455  | total loss: [1m[32m0.36976[0m[0m
[2K| Adam | epoch: 022 | loss: 0.36976 - acc: 0.8367 -- iter: 1280/3680
[A[ATraining Step: 2456  | total loss: [1m[32m0.37179[0m[0m
[2K| Adam | epoch: 022 | loss: 0.37179 - acc: 0.8374 -- iter: 1312/3680
[A[ATraining Step: 2457  | total loss: [1m[32m0.38370[0m[0m
[2K| Adam | epoch: 022 | loss: 0.38370 - acc: 0.8318 -- iter: 1344/3680
[A[ATraining Step: 2458  | total loss: [1m[32m0.39816[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39816 - acc: 0.8173 -- iter: 1376/3680
[A[ATraining Step: 2459  | total loss: [1m[32m0.39777[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39777 - acc: 0.8231 -- iter: 1408/3680
[A[ATraining Step: 2460  | total loss: [1m[32m0.41856[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41856 - acc: 0.8127 -- iter: 1440/3680
[A[ATraining Step: 2461  | total loss: [1m[32m0.41725[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41725 - acc: 0.8126 -- iter: 1472/3680
[A[ATraining Step: 2462  | total loss: [1m[32m0.45846[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45846 - acc: 0.7939 -- iter: 1504/3680
[A[ATraining Step: 2463  | total loss: [1m[32m0.44620[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44620 - acc: 0.7989 -- iter: 1536/3680
[A[ATraining Step: 2464  | total loss: [1m[32m0.44915[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44915 - acc: 0.7940 -- iter: 1568/3680
[A[ATraining Step: 2465  | total loss: [1m[32m0.46536[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46536 - acc: 0.7865 -- iter: 1600/3680
[A[ATraining Step: 2466  | total loss: [1m[32m0.46757[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46757 - acc: 0.7859 -- iter: 1632/3680
[A[ATraining Step: 2467  | total loss: [1m[32m0.46371[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46371 - acc: 0.7917 -- iter: 1664/3680
[A[ATraining Step: 2468  | total loss: [1m[32m0.46056[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46056 - acc: 0.7907 -- iter: 1696/3680
[A[ATraining Step: 2469  | total loss: [1m[32m0.46139[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46139 - acc: 0.7897 -- iter: 1728/3680
[A[ATraining Step: 2470  | total loss: [1m[32m0.46623[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46623 - acc: 0.7858 -- iter: 1760/3680
[A[ATraining Step: 2471  | total loss: [1m[32m0.46677[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46677 - acc: 0.7916 -- iter: 1792/3680
[A[ATraining Step: 2472  | total loss: [1m[32m0.47786[0m[0m
[2K| Adam | epoch: 022 | loss: 0.47786 - acc: 0.7811 -- iter: 1824/3680
[A[ATraining Step: 2473  | total loss: [1m[32m0.47327[0m[0m
[2K| Adam | epoch: 022 | loss: 0.47327 - acc: 0.7843 -- iter: 1856/3680
[A[ATraining Step: 2474  | total loss: [1m[32m0.46197[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46197 - acc: 0.7902 -- iter: 1888/3680
[A[ATraining Step: 2475  | total loss: [1m[32m0.45762[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45762 - acc: 0.7925 -- iter: 1920/3680
[A[ATraining Step: 2476  | total loss: [1m[32m0.46174[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46174 - acc: 0.7976 -- iter: 1952/3680
[A[ATraining Step: 2477  | total loss: [1m[32m0.46347[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46347 - acc: 0.8022 -- iter: 1984/3680
[A[ATraining Step: 2478  | total loss: [1m[32m0.45547[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45547 - acc: 0.8064 -- iter: 2016/3680
[A[ATraining Step: 2479  | total loss: [1m[32m0.44939[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44939 - acc: 0.8070 -- iter: 2048/3680
[A[ATraining Step: 2480  | total loss: [1m[32m0.44965[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44965 - acc: 0.8044 -- iter: 2080/3680
[A[ATraining Step: 2481  | total loss: [1m[32m0.43999[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43999 - acc: 0.8083 -- iter: 2112/3680
[A[ATraining Step: 2482  | total loss: [1m[32m0.45473[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45473 - acc: 0.7931 -- iter: 2144/3680
[A[ATraining Step: 2483  | total loss: [1m[32m0.45146[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45146 - acc: 0.7982 -- iter: 2176/3680
[A[ATraining Step: 2484  | total loss: [1m[32m0.43773[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43773 - acc: 0.8121 -- iter: 2208/3680
[A[ATraining Step: 2485  | total loss: [1m[32m0.43560[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43560 - acc: 0.8090 -- iter: 2240/3680
[A[ATraining Step: 2486  | total loss: [1m[32m0.43891[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43891 - acc: 0.8094 -- iter: 2272/3680
[A[ATraining Step: 2487  | total loss: [1m[32m0.45234[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45234 - acc: 0.7941 -- iter: 2304/3680
[A[ATraining Step: 2488  | total loss: [1m[32m0.45048[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45048 - acc: 0.7959 -- iter: 2336/3680
[A[ATraining Step: 2489  | total loss: [1m[32m0.44333[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44333 - acc: 0.8007 -- iter: 2368/3680
[A[ATraining Step: 2490  | total loss: [1m[32m0.44491[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44491 - acc: 0.7956 -- iter: 2400/3680
[A[ATraining Step: 2491  | total loss: [1m[32m0.44712[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44712 - acc: 0.7973 -- iter: 2432/3680
[A[ATraining Step: 2492  | total loss: [1m[32m0.45554[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45554 - acc: 0.7926 -- iter: 2464/3680
[A[ATraining Step: 2493  | total loss: [1m[32m0.45479[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45479 - acc: 0.7914 -- iter: 2496/3680
[A[ATraining Step: 2494  | total loss: [1m[32m0.45444[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45444 - acc: 0.7873 -- iter: 2528/3680
[A[ATraining Step: 2495  | total loss: [1m[32m0.46175[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46175 - acc: 0.7836 -- iter: 2560/3680
[A[ATraining Step: 2496  | total loss: [1m[32m0.46742[0m[0m
[2K| Adam | epoch: 022 | loss: 0.46742 - acc: 0.7865 -- iter: 2592/3680
[A[ATraining Step: 2497  | total loss: [1m[32m0.44906[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44906 - acc: 0.7984 -- iter: 2624/3680
[A[ATraining Step: 2498  | total loss: [1m[32m0.44059[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44059 - acc: 0.8030 -- iter: 2656/3680
[A[ATraining Step: 2499  | total loss: [1m[32m0.42583[0m[0m
[2K| Adam | epoch: 022 | loss: 0.42583 - acc: 0.8133 -- iter: 2688/3680
[A[ATraining Step: 2500  | total loss: [1m[32m0.42721[0m[0m
[2K| Adam | epoch: 022 | loss: 0.42721 - acc: 0.8132 | val_loss: 0.40796 - val_acc: 0.8306 -- iter: 2720/3680
[A[ATraining Step: 2500  | total loss: [1m[32m0.42721[0m[0m
[2K| Adam | epoch: 022 | loss: 0.42721 - acc: 0.8132 | val_loss: 0.40796 - val_acc: 0.8306 -- iter: 2720/3680
--
Training Step: 2501  | total loss: [1m[32m0.43978[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43978 - acc: 0.8100 -- iter: 2752/3680
[A[ATraining Step: 2502  | total loss: [1m[32m0.45019[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45019 - acc: 0.8103 -- iter: 2784/3680
[A[ATraining Step: 2503  | total loss: [1m[32m0.44397[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44397 - acc: 0.8105 -- iter: 2816/3680
[A[ATraining Step: 2504  | total loss: [1m[32m0.43522[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43522 - acc: 0.8107 -- iter: 2848/3680
[A[ATraining Step: 2505  | total loss: [1m[32m0.42480[0m[0m
[2K| Adam | epoch: 022 | loss: 0.42480 - acc: 0.8203 -- iter: 2880/3680
[A[ATraining Step: 2506  | total loss: [1m[32m0.41077[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41077 - acc: 0.8320 -- iter: 2912/3680
[A[ATraining Step: 2507  | total loss: [1m[32m0.41403[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41403 - acc: 0.8269 -- iter: 2944/3680
[A[ATraining Step: 2508  | total loss: [1m[32m0.40746[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40746 - acc: 0.8348 -- iter: 2976/3680
[A[ATraining Step: 2509  | total loss: [1m[32m0.39969[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39969 - acc: 0.8326 -- iter: 3008/3680
[A[ATraining Step: 2510  | total loss: [1m[32m0.41831[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41831 - acc: 0.8181 -- iter: 3040/3680
[A[ATraining Step: 2511  | total loss: [1m[32m0.41413[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41413 - acc: 0.8175 -- iter: 3072/3680
[A[ATraining Step: 2512  | total loss: [1m[32m0.43138[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43138 - acc: 0.8045 -- iter: 3104/3680
[A[ATraining Step: 2513  | total loss: [1m[32m0.43583[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43583 - acc: 0.8022 -- iter: 3136/3680
[A[ATraining Step: 2514  | total loss: [1m[32m0.42834[0m[0m
[2K| Adam | epoch: 022 | loss: 0.42834 - acc: 0.8095 -- iter: 3168/3680
[A[ATraining Step: 2515  | total loss: [1m[32m0.41300[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41300 - acc: 0.8191 -- iter: 3200/3680
[A[ATraining Step: 2516  | total loss: [1m[32m0.41300[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41300 - acc: 0.8191 -- iter: 3232/3680
[A[ATraining Step: 2517  | total loss: [1m[32m0.41052[0m[0m
[2K| Adam | epoch: 022 | loss: 0.41052 - acc: 0.8185 -- iter: 3264/3680
[A[ATraining Step: 2518  | total loss: [1m[32m0.40093[0m[0m
[2K| Adam | epoch: 022 | loss: 0.40093 - acc: 0.8241 -- iter: 3296/3680
[A[ATraining Step: 2519  | total loss: [1m[32m0.39180[0m[0m
[2K| Adam | epoch: 022 | loss: 0.39180 - acc: 0.8292 -- iter: 3328/3680
[A[ATraining Step: 2520  | total loss: [1m[32m0.48135[0m[0m
[2K| Adam | epoch: 022 | loss: 0.48135 - acc: 0.7932 -- iter: 3360/3680
[A[ATraining Step: 2521  | total loss: [1m[32m0.47245[0m[0m
[2K| Adam | epoch: 022 | loss: 0.47245 - acc: 0.7982 -- iter: 3392/3680
[A[ATraining Step: 2522  | total loss: [1m[32m0.45911[0m[0m
[2K| Adam | epoch: 022 | loss: 0.45911 - acc: 0.7965 -- iter: 3424/3680
[A[ATraining Step: 2523  | total loss: [1m[32m0.44752[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44752 - acc: 0.7981 -- iter: 3456/3680
[A[ATraining Step: 2524  | total loss: [1m[32m0.44910[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44910 - acc: 0.7964 -- iter: 3488/3680
[A[ATraining Step: 2525  | total loss: [1m[32m0.43824[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43824 - acc: 0.8043 -- iter: 3520/3680
[A[ATraining Step: 2526  | total loss: [1m[32m0.44195[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44195 - acc: 0.8093 -- iter: 3552/3680
[A[ATraining Step: 2527  | total loss: [1m[32m0.43741[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43741 - acc: 0.8093 -- iter: 3584/3680
[A[ATraining Step: 2528  | total loss: [1m[32m0.43927[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43927 - acc: 0.8159 -- iter: 3616/3680
[A[ATraining Step: 2529  | total loss: [1m[32m0.44235[0m[0m
[2K| Adam | epoch: 022 | loss: 0.44235 - acc: 0.8155 -- iter: 3648/3680
[A[ATraining Step: 2530  | total loss: [1m[32m0.43851[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43851 - acc: 0.8121 | val_loss: 0.40995 - val_acc: 0.8263 -- iter: 3680/3680
[A[ATraining Step: 2530  | total loss: [1m[32m0.43851[0m[0m
[2K| Adam | epoch: 022 | loss: 0.43851 - acc: 0.8121 | val_loss: 0.40995 - val_acc: 0.8263 -- iter: 3680/3680
--
Training Step: 2531  | total loss: [1m[32m0.45452[0m[0m
[2K| Adam | epoch: 023 | loss: 0.45452 - acc: 0.7996 -- iter: 0032/3680
[A[ATraining Step: 2532  | total loss: [1m[32m0.45957[0m[0m
[2K| Adam | epoch: 023 | loss: 0.45957 - acc: 0.7884 -- iter: 0064/3680
[A[ATraining Step: 2533  | total loss: [1m[32m0.44470[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44470 - acc: 0.8002 -- iter: 0096/3680
[A[ATraining Step: 2534  | total loss: [1m[32m0.44578[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44578 - acc: 0.8014 -- iter: 0128/3680
[A[ATraining Step: 2535  | total loss: [1m[32m0.43973[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43973 - acc: 0.7963 -- iter: 0160/3680
[A[ATraining Step: 2536  | total loss: [1m[32m0.42260[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42260 - acc: 0.8073 -- iter: 0192/3680
[A[ATraining Step: 2537  | total loss: [1m[32m0.43449[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43449 - acc: 0.8016 -- iter: 0224/3680
[A[ATraining Step: 2538  | total loss: [1m[32m0.43070[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43070 - acc: 0.8058 -- iter: 0256/3680
[A[ATraining Step: 2539  | total loss: [1m[32m0.43138[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43138 - acc: 0.8096 -- iter: 0288/3680
[A[ATraining Step: 2540  | total loss: [1m[32m0.44050[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44050 - acc: 0.8076 -- iter: 0320/3680
[A[ATraining Step: 2541  | total loss: [1m[32m0.44050[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44050 - acc: 0.8076 -- iter: 0352/3680
[A[ATraining Step: 2542  | total loss: [1m[32m0.43823[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43823 - acc: 0.8144 -- iter: 0384/3680
[A[ATraining Step: 2543  | total loss: [1m[32m0.45592[0m[0m
[2K| Adam | epoch: 023 | loss: 0.45592 - acc: 0.7986 -- iter: 0416/3680
[A[ATraining Step: 2544  | total loss: [1m[32m0.44944[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44944 - acc: 0.8031 -- iter: 0448/3680
[A[ATraining Step: 2545  | total loss: [1m[32m0.43767[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43767 - acc: 0.8071 -- iter: 0480/3680
[A[ATraining Step: 2546  | total loss: [1m[32m0.43607[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43607 - acc: 0.8108 -- iter: 0512/3680
[A[ATraining Step: 2547  | total loss: [1m[32m0.43340[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43340 - acc: 0.8203 -- iter: 0544/3680
[A[ATraining Step: 2548  | total loss: [1m[32m0.43586[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43586 - acc: 0.8133 -- iter: 0576/3680
[A[ATraining Step: 2549  | total loss: [1m[32m0.42814[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42814 - acc: 0.8226 -- iter: 0608/3680
[A[ATraining Step: 2550  | total loss: [1m[32m0.41794[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41794 - acc: 0.8278 -- iter: 0640/3680
[A[ATraining Step: 2551  | total loss: [1m[32m0.41128[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41128 - acc: 0.8357 -- iter: 0672/3680
[A[ATraining Step: 2552  | total loss: [1m[32m0.40361[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40361 - acc: 0.8396 -- iter: 0704/3680
[A[ATraining Step: 2553  | total loss: [1m[32m0.39350[0m[0m
[2K| Adam | epoch: 023 | loss: 0.39350 - acc: 0.8432 -- iter: 0736/3680
[A[ATraining Step: 2554  | total loss: [1m[32m0.40295[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40295 - acc: 0.8307 -- iter: 0768/3680
[A[ATraining Step: 2555  | total loss: [1m[32m0.40998[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40998 - acc: 0.8195 -- iter: 0800/3680
[A[ATraining Step: 2556  | total loss: [1m[32m0.40014[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40014 - acc: 0.8219 -- iter: 0832/3680
[A[ATraining Step: 2557  | total loss: [1m[32m0.40540[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40540 - acc: 0.8147 -- iter: 0864/3680
[A[ATraining Step: 2558  | total loss: [1m[32m0.40047[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40047 - acc: 0.8176 -- iter: 0896/3680
[A[ATraining Step: 2559  | total loss: [1m[32m0.41173[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41173 - acc: 0.8140 -- iter: 0928/3680
[A[ATraining Step: 2560  | total loss: [1m[32m0.43202[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43202 - acc: 0.8014 -- iter: 0960/3680
[A[ATraining Step: 2561  | total loss: [1m[32m0.41187[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41187 - acc: 0.8181 -- iter: 0992/3680
[A[ATraining Step: 2562  | total loss: [1m[32m0.40956[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40956 - acc: 0.8207 -- iter: 1024/3680
[A[ATraining Step: 2563  | total loss: [1m[32m0.41583[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41583 - acc: 0.8198 -- iter: 1056/3680
[A[ATraining Step: 2564  | total loss: [1m[32m0.42560[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42560 - acc: 0.8160 -- iter: 1088/3680
[A[ATraining Step: 2565  | total loss: [1m[32m0.42983[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42983 - acc: 0.8156 -- iter: 1120/3680
[A[ATraining Step: 2566  | total loss: [1m[32m0.45126[0m[0m
[2K| Adam | epoch: 023 | loss: 0.45126 - acc: 0.7966 -- iter: 1152/3680
[A[ATraining Step: 2567  | total loss: [1m[32m0.44734[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44734 - acc: 0.7982 -- iter: 1184/3680
[A[ATraining Step: 2568  | total loss: [1m[32m0.43917[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43917 - acc: 0.8058 -- iter: 1216/3680
[A[ATraining Step: 2569  | total loss: [1m[32m0.44157[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44157 - acc: 0.8003 -- iter: 1248/3680
[A[ATraining Step: 2570  | total loss: [1m[32m0.44944[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44944 - acc: 0.7921 -- iter: 1280/3680
[A[ATraining Step: 2571  | total loss: [1m[32m0.43796[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43796 - acc: 0.8067 -- iter: 1312/3680
[A[ATraining Step: 2572  | total loss: [1m[32m0.42451[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42451 - acc: 0.8197 -- iter: 1344/3680
[A[ATraining Step: 2573  | total loss: [1m[32m0.42197[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42197 - acc: 0.8159 -- iter: 1376/3680
[A[ATraining Step: 2574  | total loss: [1m[32m0.42609[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42609 - acc: 0.8187 -- iter: 1408/3680
[A[ATraining Step: 2575  | total loss: [1m[32m0.42542[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42542 - acc: 0.8149 -- iter: 1440/3680
[A[ATraining Step: 2576  | total loss: [1m[32m0.41758[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41758 - acc: 0.8209 -- iter: 1472/3680
[A[ATraining Step: 2577  | total loss: [1m[32m0.41933[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41933 - acc: 0.8170 -- iter: 1504/3680
[A[ATraining Step: 2578  | total loss: [1m[32m0.42717[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42717 - acc: 0.8134 -- iter: 1536/3680
[A[ATraining Step: 2579  | total loss: [1m[32m0.42542[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42542 - acc: 0.8133 -- iter: 1568/3680
[A[ATraining Step: 2580  | total loss: [1m[32m0.42947[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42947 - acc: 0.8101 -- iter: 1600/3680
[A[ATraining Step: 2581  | total loss: [1m[32m0.42687[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42687 - acc: 0.8135 -- iter: 1632/3680
[A[ATraining Step: 2582  | total loss: [1m[32m0.41617[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41617 - acc: 0.8227 -- iter: 1664/3680
[A[ATraining Step: 2583  | total loss: [1m[32m0.41965[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41965 - acc: 0.8186 -- iter: 1696/3680
[A[ATraining Step: 2584  | total loss: [1m[32m0.41683[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41683 - acc: 0.8211 -- iter: 1728/3680
[A[ATraining Step: 2585  | total loss: [1m[32m0.42015[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42015 - acc: 0.8171 -- iter: 1760/3680
[A[ATraining Step: 2586  | total loss: [1m[32m0.41361[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41361 - acc: 0.8229 -- iter: 1792/3680
[A[ATraining Step: 2587  | total loss: [1m[32m0.41076[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41076 - acc: 0.8187 -- iter: 1824/3680
[A[ATraining Step: 2588  | total loss: [1m[32m0.41873[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41873 - acc: 0.8150 -- iter: 1856/3680
[A[ATraining Step: 2589  | total loss: [1m[32m0.40758[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40758 - acc: 0.8241 -- iter: 1888/3680
[A[ATraining Step: 2590  | total loss: [1m[32m0.41186[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41186 - acc: 0.8230 -- iter: 1920/3680
[A[ATraining Step: 2591  | total loss: [1m[32m0.41106[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41106 - acc: 0.8250 -- iter: 1952/3680
[A[ATraining Step: 2592  | total loss: [1m[32m0.42457[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42457 - acc: 0.8175 -- iter: 1984/3680
[A[ATraining Step: 2593  | total loss: [1m[32m0.40283[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40283 - acc: 0.8295 -- iter: 2016/3680
[A[ATraining Step: 2594  | total loss: [1m[32m0.41711[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41711 - acc: 0.8216 -- iter: 2048/3680
[A[ATraining Step: 2595  | total loss: [1m[32m0.41647[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41647 - acc: 0.8175 -- iter: 2080/3680
[A[ATraining Step: 2596  | total loss: [1m[32m0.41603[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41603 - acc: 0.8170 -- iter: 2112/3680
[A[ATraining Step: 2597  | total loss: [1m[32m0.41376[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41376 - acc: 0.8228 -- iter: 2144/3680
[A[ATraining Step: 2598  | total loss: [1m[32m0.41381[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41381 - acc: 0.8249 -- iter: 2176/3680
[A[ATraining Step: 2599  | total loss: [1m[32m0.41759[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41759 - acc: 0.8206 -- iter: 2208/3680
[A[ATraining Step: 2600  | total loss: [1m[32m0.41598[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41598 - acc: 0.8166 | val_loss: 0.40108 - val_acc: 0.8328 -- iter: 2240/3680
[A[ATraining Step: 2600  | total loss: [1m[32m0.41598[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41598 - acc: 0.8166 | val_loss: 0.40108 - val_acc: 0.8328 -- iter: 2240/3680
--
Training Step: 2601  | total loss: [1m[32m0.41313[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41313 - acc: 0.8162 -- iter: 2272/3680
[A[ATraining Step: 2602  | total loss: [1m[32m0.40976[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40976 - acc: 0.8158 -- iter: 2304/3680
[A[ATraining Step: 2603  | total loss: [1m[32m0.42316[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42316 - acc: 0.7999 -- iter: 2336/3680
[A[ATraining Step: 2604  | total loss: [1m[32m0.42165[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42165 - acc: 0.7980 -- iter: 2368/3680
[A[ATraining Step: 2605  | total loss: [1m[32m0.43463[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43463 - acc: 0.7838 -- iter: 2400/3680
[A[ATraining Step: 2606  | total loss: [1m[32m0.42678[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42678 - acc: 0.7898 -- iter: 2432/3680
[A[ATraining Step: 2607  | total loss: [1m[32m0.43618[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43618 - acc: 0.7859 -- iter: 2464/3680
[A[ATraining Step: 2608  | total loss: [1m[32m0.42987[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42987 - acc: 0.7885 -- iter: 2496/3680
[A[ATraining Step: 2609  | total loss: [1m[32m0.43121[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43121 - acc: 0.7940 -- iter: 2528/3680
[A[ATraining Step: 2610  | total loss: [1m[32m0.44293[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44293 - acc: 0.7928 -- iter: 2560/3680
[A[ATraining Step: 2611  | total loss: [1m[32m0.42904[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42904 - acc: 0.8072 -- iter: 2592/3680
[A[ATraining Step: 2612  | total loss: [1m[32m0.41685[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41685 - acc: 0.8140 -- iter: 2624/3680
[A[ATraining Step: 2613  | total loss: [1m[32m0.40714[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40714 - acc: 0.8201 -- iter: 2656/3680
[A[ATraining Step: 2614  | total loss: [1m[32m0.41368[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41368 - acc: 0.8193 -- iter: 2688/3680
[A[ATraining Step: 2615  | total loss: [1m[32m0.42757[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42757 - acc: 0.8062 -- iter: 2720/3680
[A[ATraining Step: 2616  | total loss: [1m[32m0.42640[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42640 - acc: 0.8099 -- iter: 2752/3680
[A[ATraining Step: 2617  | total loss: [1m[32m0.42162[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42162 - acc: 0.8133 -- iter: 2784/3680
[A[ATraining Step: 2618  | total loss: [1m[32m0.41014[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41014 - acc: 0.8257 -- iter: 2816/3680
[A[ATraining Step: 2619  | total loss: [1m[32m0.41347[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41347 - acc: 0.8244 -- iter: 2848/3680
[A[ATraining Step: 2620  | total loss: [1m[32m0.40784[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40784 - acc: 0.8232 -- iter: 2880/3680
[A[ATraining Step: 2621  | total loss: [1m[32m0.39987[0m[0m
[2K| Adam | epoch: 023 | loss: 0.39987 - acc: 0.8315 -- iter: 2912/3680
[A[ATraining Step: 2622  | total loss: [1m[32m0.40311[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40311 - acc: 0.8296 -- iter: 2944/3680
[A[ATraining Step: 2623  | total loss: [1m[32m0.39940[0m[0m
[2K| Adam | epoch: 023 | loss: 0.39940 - acc: 0.8342 -- iter: 2976/3680
[A[ATraining Step: 2624  | total loss: [1m[32m0.39664[0m[0m
[2K| Adam | epoch: 023 | loss: 0.39664 - acc: 0.8320 -- iter: 3008/3680
[A[ATraining Step: 2625  | total loss: [1m[32m0.39809[0m[0m
[2K| Adam | epoch: 023 | loss: 0.39809 - acc: 0.8300 -- iter: 3040/3680
[A[ATraining Step: 2626  | total loss: [1m[32m0.39580[0m[0m
[2K| Adam | epoch: 023 | loss: 0.39580 - acc: 0.8283 -- iter: 3072/3680
[A[ATraining Step: 2627  | total loss: [1m[32m0.40202[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40202 - acc: 0.8236 -- iter: 3104/3680
[A[ATraining Step: 2628  | total loss: [1m[32m0.40453[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40453 - acc: 0.8225 -- iter: 3136/3680
[A[ATraining Step: 2629  | total loss: [1m[32m0.40394[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40394 - acc: 0.8277 -- iter: 3168/3680
[A[ATraining Step: 2630  | total loss: [1m[32m0.40904[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40904 - acc: 0.8231 -- iter: 3200/3680
[A[ATraining Step: 2631  | total loss: [1m[32m0.41755[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41755 - acc: 0.8158 -- iter: 3232/3680
[A[ATraining Step: 2632  | total loss: [1m[32m0.42152[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42152 - acc: 0.8061 -- iter: 3264/3680
[A[ATraining Step: 2633  | total loss: [1m[32m0.41534[0m[0m
[2K| Adam | epoch: 023 | loss: 0.41534 - acc: 0.8130 -- iter: 3296/3680
[A[ATraining Step: 2634  | total loss: [1m[32m0.40758[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40758 - acc: 0.8192 -- iter: 3328/3680
[A[ATraining Step: 2635  | total loss: [1m[32m0.40466[0m[0m
[2K| Adam | epoch: 023 | loss: 0.40466 - acc: 0.8216 -- iter: 3360/3680
[A[ATraining Step: 2636  | total loss: [1m[32m0.48864[0m[0m
[2K| Adam | epoch: 023 | loss: 0.48864 - acc: 0.7863 -- iter: 3392/3680
[A[ATraining Step: 2637  | total loss: [1m[32m0.47438[0m[0m
[2K| Adam | epoch: 023 | loss: 0.47438 - acc: 0.7890 -- iter: 3424/3680
[A[ATraining Step: 2638  | total loss: [1m[32m0.46030[0m[0m
[2K| Adam | epoch: 023 | loss: 0.46030 - acc: 0.7976 -- iter: 3456/3680
[A[ATraining Step: 2639  | total loss: [1m[32m0.45976[0m[0m
[2K| Adam | epoch: 023 | loss: 0.45976 - acc: 0.7928 -- iter: 3488/3680
[A[ATraining Step: 2640  | total loss: [1m[32m0.46341[0m[0m
[2K| Adam | epoch: 023 | loss: 0.46341 - acc: 0.7885 -- iter: 3520/3680
[A[ATraining Step: 2641  | total loss: [1m[32m0.44898[0m[0m
[2K| Adam | epoch: 023 | loss: 0.44898 - acc: 0.8003 -- iter: 3552/3680
[A[ATraining Step: 2642  | total loss: [1m[32m0.43782[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43782 - acc: 0.8078 -- iter: 3584/3680
[A[ATraining Step: 2643  | total loss: [1m[32m0.43072[0m[0m
[2K| Adam | epoch: 023 | loss: 0.43072 - acc: 0.8114 -- iter: 3616/3680
[A[ATraining Step: 2644  | total loss: [1m[32m0.42693[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42693 - acc: 0.8177 -- iter: 3648/3680
[A[ATraining Step: 2645  | total loss: [1m[32m0.42543[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42543 - acc: 0.8235 | val_loss: 0.40205 - val_acc: 0.8393 -- iter: 3680/3680
[A[ATraining Step: 2645  | total loss: [1m[32m0.42543[0m[0m
[2K| Adam | epoch: 023 | loss: 0.42543 - acc: 0.8235 | val_loss: 0.40205 - val_acc: 0.8393 -- iter: 3680/3680
--
Training Step: 2646  | total loss: [1m[32m0.41357[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41357 - acc: 0.8317 -- iter: 0032/3680
[A[ATraining Step: 2647  | total loss: [1m[32m0.40795[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40795 - acc: 0.8392 -- iter: 0064/3680
[A[ATraining Step: 2648  | total loss: [1m[32m0.40724[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40724 - acc: 0.8428 -- iter: 0096/3680
[A[ATraining Step: 2649  | total loss: [1m[32m0.40608[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40608 - acc: 0.8491 -- iter: 0128/3680
[A[ATraining Step: 2650  | total loss: [1m[32m0.41296[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41296 - acc: 0.8392 -- iter: 0160/3680
[A[ATraining Step: 2651  | total loss: [1m[32m0.39977[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39977 - acc: 0.8459 -- iter: 0192/3680
[A[ATraining Step: 2652  | total loss: [1m[32m0.40189[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40189 - acc: 0.8488 -- iter: 0224/3680
[A[ATraining Step: 2653  | total loss: [1m[32m0.39724[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39724 - acc: 0.8452 -- iter: 0256/3680
[A[ATraining Step: 2654  | total loss: [1m[32m0.39117[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39117 - acc: 0.8513 -- iter: 0288/3680
[A[ATraining Step: 2655  | total loss: [1m[32m0.39390[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39390 - acc: 0.8537 -- iter: 0320/3680
[A[ATraining Step: 2656  | total loss: [1m[32m0.40351[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40351 - acc: 0.8464 -- iter: 0352/3680
[A[ATraining Step: 2657  | total loss: [1m[32m0.42066[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42066 - acc: 0.8337 -- iter: 0384/3680
[A[ATraining Step: 2658  | total loss: [1m[32m0.41093[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41093 - acc: 0.8347 -- iter: 0416/3680
[A[ATraining Step: 2659  | total loss: [1m[32m0.41260[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41260 - acc: 0.8324 -- iter: 0448/3680
[A[ATraining Step: 2660  | total loss: [1m[32m0.42920[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42920 - acc: 0.8305 -- iter: 0480/3680
[A[ATraining Step: 2661  | total loss: [1m[32m0.42265[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42265 - acc: 0.8287 -- iter: 0512/3680
[A[ATraining Step: 2662  | total loss: [1m[32m0.41809[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41809 - acc: 0.8333 -- iter: 0544/3680
[A[ATraining Step: 2663  | total loss: [1m[32m0.41337[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41337 - acc: 0.8375 -- iter: 0576/3680
[A[ATraining Step: 2664  | total loss: [1m[32m0.40963[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40963 - acc: 0.8350 -- iter: 0608/3680
[A[ATraining Step: 2665  | total loss: [1m[32m0.40176[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40176 - acc: 0.8390 -- iter: 0640/3680
[A[ATraining Step: 2666  | total loss: [1m[32m0.39441[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39441 - acc: 0.8394 -- iter: 0672/3680
[A[ATraining Step: 2667  | total loss: [1m[32m0.40073[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40073 - acc: 0.8336 -- iter: 0704/3680
[A[ATraining Step: 2668  | total loss: [1m[32m0.40569[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40569 - acc: 0.8284 -- iter: 0736/3680
[A[ATraining Step: 2669  | total loss: [1m[32m0.41441[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41441 - acc: 0.8237 -- iter: 0768/3680
[A[ATraining Step: 2670  | total loss: [1m[32m0.41860[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41860 - acc: 0.8163 -- iter: 0800/3680
[A[ATraining Step: 2671  | total loss: [1m[32m0.42627[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42627 - acc: 0.8128 -- iter: 0832/3680
[A[ATraining Step: 2672  | total loss: [1m[32m0.43847[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43847 - acc: 0.8096 -- iter: 0864/3680
[A[ATraining Step: 2673  | total loss: [1m[32m0.44754[0m[0m
[2K| Adam | epoch: 024 | loss: 0.44754 - acc: 0.8037 -- iter: 0896/3680
[A[ATraining Step: 2674  | total loss: [1m[32m0.45582[0m[0m
[2K| Adam | epoch: 024 | loss: 0.45582 - acc: 0.7952 -- iter: 0928/3680
[A[ATraining Step: 2675  | total loss: [1m[32m0.44346[0m[0m
[2K| Adam | epoch: 024 | loss: 0.44346 - acc: 0.8063 -- iter: 0960/3680
[A[ATraining Step: 2676  | total loss: [1m[32m0.44089[0m[0m
[2K| Adam | epoch: 024 | loss: 0.44089 - acc: 0.8038 -- iter: 0992/3680
[A[ATraining Step: 2677  | total loss: [1m[32m0.43733[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43733 - acc: 0.8047 -- iter: 1024/3680
[A[ATraining Step: 2678  | total loss: [1m[32m0.42440[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42440 - acc: 0.8148 -- iter: 1056/3680
[A[ATraining Step: 2679  | total loss: [1m[32m0.43058[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43058 - acc: 0.8021 -- iter: 1088/3680
[A[ATraining Step: 2680  | total loss: [1m[32m0.43344[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43344 - acc: 0.7969 -- iter: 1120/3680
[A[ATraining Step: 2681  | total loss: [1m[32m0.42769[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42769 - acc: 0.7984 -- iter: 1152/3680
[A[ATraining Step: 2682  | total loss: [1m[32m0.43775[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43775 - acc: 0.7967 -- iter: 1184/3680
[A[ATraining Step: 2683  | total loss: [1m[32m0.42476[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42476 - acc: 0.8077 -- iter: 1216/3680
[A[ATraining Step: 2684  | total loss: [1m[32m0.42489[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42489 - acc: 0.8019 -- iter: 1248/3680
[A[ATraining Step: 2685  | total loss: [1m[32m0.42890[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42890 - acc: 0.8061 -- iter: 1280/3680
[A[ATraining Step: 2686  | total loss: [1m[32m0.43685[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43685 - acc: 0.8005 -- iter: 1312/3680
[A[ATraining Step: 2687  | total loss: [1m[32m0.44356[0m[0m
[2K| Adam | epoch: 024 | loss: 0.44356 - acc: 0.7923 -- iter: 1344/3680
[A[ATraining Step: 2688  | total loss: [1m[32m0.43132[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43132 - acc: 0.7975 -- iter: 1376/3680
[A[ATraining Step: 2689  | total loss: [1m[32m0.42701[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42701 - acc: 0.7990 -- iter: 1408/3680
[A[ATraining Step: 2690  | total loss: [1m[32m0.41238[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41238 - acc: 0.8066 -- iter: 1440/3680
[A[ATraining Step: 2691  | total loss: [1m[32m0.41422[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41422 - acc: 0.8040 -- iter: 1472/3680
[A[ATraining Step: 2692  | total loss: [1m[32m0.41823[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41823 - acc: 0.8080 -- iter: 1504/3680
[A[ATraining Step: 2693  | total loss: [1m[32m0.40049[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40049 - acc: 0.8210 -- iter: 1536/3680
[A[ATraining Step: 2694  | total loss: [1m[32m0.39737[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39737 - acc: 0.8232 -- iter: 1568/3680
[A[ATraining Step: 2695  | total loss: [1m[32m0.39751[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39751 - acc: 0.8284 -- iter: 1600/3680
[A[ATraining Step: 2696  | total loss: [1m[32m0.40377[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40377 - acc: 0.8237 -- iter: 1632/3680
[A[ATraining Step: 2697  | total loss: [1m[32m0.38782[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38782 - acc: 0.8319 -- iter: 1664/3680
[A[ATraining Step: 2698  | total loss: [1m[32m0.37909[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37909 - acc: 0.8425 -- iter: 1696/3680
[A[ATraining Step: 2699  | total loss: [1m[32m0.39524[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39524 - acc: 0.8333 -- iter: 1728/3680
[A[ATraining Step: 2700  | total loss: [1m[32m0.41164[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41164 - acc: 0.8249 | val_loss: 0.38501 - val_acc: 0.8436 -- iter: 1760/3680
[A[ATraining Step: 2700  | total loss: [1m[32m0.41164[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41164 - acc: 0.8249 | val_loss: 0.38501 - val_acc: 0.8436 -- iter: 1760/3680
--
Training Step: 2701  | total loss: [1m[32m0.41694[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41694 - acc: 0.8143 -- iter: 1792/3680
[A[ATraining Step: 2702  | total loss: [1m[32m0.41909[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41909 - acc: 0.8141 -- iter: 1824/3680
[A[ATraining Step: 2703  | total loss: [1m[32m0.40757[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40757 - acc: 0.8233 -- iter: 1856/3680
[A[ATraining Step: 2704  | total loss: [1m[32m0.40867[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40867 - acc: 0.8316 -- iter: 1888/3680
[A[ATraining Step: 2705  | total loss: [1m[32m0.40305[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40305 - acc: 0.8360 -- iter: 1920/3680
[A[ATraining Step: 2706  | total loss: [1m[32m0.38596[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38596 - acc: 0.8430 -- iter: 1952/3680
[A[ATraining Step: 2707  | total loss: [1m[32m0.38627[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38627 - acc: 0.8399 -- iter: 1984/3680
[A[ATraining Step: 2708  | total loss: [1m[32m0.37509[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37509 - acc: 0.8435 -- iter: 2016/3680
[A[ATraining Step: 2709  | total loss: [1m[32m0.37927[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37927 - acc: 0.8435 -- iter: 2048/3680
[A[ATraining Step: 2710  | total loss: [1m[32m0.37545[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37545 - acc: 0.8404 -- iter: 2080/3680
[A[ATraining Step: 2711  | total loss: [1m[32m0.38861[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38861 - acc: 0.8376 -- iter: 2112/3680
[A[ATraining Step: 2712  | total loss: [1m[32m0.38656[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38656 - acc: 0.8413 -- iter: 2144/3680
[A[ATraining Step: 2713  | total loss: [1m[32m0.38017[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38017 - acc: 0.8416 -- iter: 2176/3680
[A[ATraining Step: 2714  | total loss: [1m[32m0.37351[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37351 - acc: 0.8449 -- iter: 2208/3680
[A[ATraining Step: 2715  | total loss: [1m[32m0.36951[0m[0m
[2K| Adam | epoch: 024 | loss: 0.36951 - acc: 0.8511 -- iter: 2240/3680
[A[ATraining Step: 2716  | total loss: [1m[32m0.36639[0m[0m
[2K| Adam | epoch: 024 | loss: 0.36639 - acc: 0.8503 -- iter: 2272/3680
[A[ATraining Step: 2717  | total loss: [1m[32m0.37702[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37702 - acc: 0.8403 -- iter: 2304/3680
[A[ATraining Step: 2718  | total loss: [1m[32m0.39038[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39038 - acc: 0.8406 -- iter: 2336/3680
[A[ATraining Step: 2719  | total loss: [1m[32m0.37906[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37906 - acc: 0.8503 -- iter: 2368/3680
[A[ATraining Step: 2720  | total loss: [1m[32m0.37673[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37673 - acc: 0.8528 -- iter: 2400/3680
[A[ATraining Step: 2721  | total loss: [1m[32m0.36217[0m[0m
[2K| Adam | epoch: 024 | loss: 0.36217 - acc: 0.8581 -- iter: 2432/3680
[A[ATraining Step: 2722  | total loss: [1m[32m0.36782[0m[0m
[2K| Adam | epoch: 024 | loss: 0.36782 - acc: 0.8536 -- iter: 2464/3680
[A[ATraining Step: 2723  | total loss: [1m[32m0.37829[0m[0m
[2K| Adam | epoch: 024 | loss: 0.37829 - acc: 0.8463 -- iter: 2496/3680
[A[ATraining Step: 2724  | total loss: [1m[32m0.38588[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38588 - acc: 0.8398 -- iter: 2528/3680
[A[ATraining Step: 2725  | total loss: [1m[32m0.38461[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38461 - acc: 0.8402 -- iter: 2560/3680
[A[ATraining Step: 2726  | total loss: [1m[32m0.39096[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39096 - acc: 0.8312 -- iter: 2592/3680
[A[ATraining Step: 2727  | total loss: [1m[32m0.38900[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38900 - acc: 0.8293 -- iter: 2624/3680
[A[ATraining Step: 2728  | total loss: [1m[32m0.39195[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39195 - acc: 0.8308 -- iter: 2656/3680
[A[ATraining Step: 2729  | total loss: [1m[32m0.39271[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39271 - acc: 0.8289 -- iter: 2688/3680
[A[ATraining Step: 2730  | total loss: [1m[32m0.38682[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38682 - acc: 0.8304 -- iter: 2720/3680
[A[ATraining Step: 2731  | total loss: [1m[32m0.38554[0m[0m
[2K| Adam | epoch: 024 | loss: 0.38554 - acc: 0.8318 -- iter: 2752/3680
[A[ATraining Step: 2732  | total loss: [1m[32m0.39956[0m[0m
[2K| Adam | epoch: 024 | loss: 0.39956 - acc: 0.8205 -- iter: 2784/3680
[A[ATraining Step: 2733  | total loss: [1m[32m0.41281[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41281 - acc: 0.8072 -- iter: 2816/3680
[A[ATraining Step: 2734  | total loss: [1m[32m0.41655[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41655 - acc: 0.8014 -- iter: 2848/3680
[A[ATraining Step: 2735  | total loss: [1m[32m0.42015[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42015 - acc: 0.7932 -- iter: 2880/3680
[A[ATraining Step: 2736  | total loss: [1m[32m0.41318[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41318 - acc: 0.8045 -- iter: 2912/3680
[A[ATraining Step: 2737  | total loss: [1m[32m0.41038[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41038 - acc: 0.8084 -- iter: 2944/3680
[A[ATraining Step: 2738  | total loss: [1m[32m0.41612[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41612 - acc: 0.8026 -- iter: 2976/3680
[A[ATraining Step: 2739  | total loss: [1m[32m0.41036[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41036 - acc: 0.8098 -- iter: 3008/3680
[A[ATraining Step: 2740  | total loss: [1m[32m0.41402[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41402 - acc: 0.8163 -- iter: 3040/3680
[A[ATraining Step: 2741  | total loss: [1m[32m0.42017[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42017 - acc: 0.8159 -- iter: 3072/3680
[A[ATraining Step: 2742  | total loss: [1m[32m0.43570[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43570 - acc: 0.8125 -- iter: 3104/3680
[A[ATraining Step: 2743  | total loss: [1m[32m0.44117[0m[0m
[2K| Adam | epoch: 024 | loss: 0.44117 - acc: 0.8125 -- iter: 3136/3680
[A[ATraining Step: 2744  | total loss: [1m[32m0.43312[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43312 - acc: 0.8125 -- iter: 3168/3680
[A[ATraining Step: 2745  | total loss: [1m[32m0.42781[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42781 - acc: 0.8219 -- iter: 3200/3680
[A[ATraining Step: 2746  | total loss: [1m[32m0.43784[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43784 - acc: 0.8115 -- iter: 3232/3680
[A[ATraining Step: 2747  | total loss: [1m[32m0.44014[0m[0m
[2K| Adam | epoch: 024 | loss: 0.44014 - acc: 0.8148 -- iter: 3264/3680
[A[ATraining Step: 2748  | total loss: [1m[32m0.42571[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42571 - acc: 0.8208 -- iter: 3296/3680
[A[ATraining Step: 2749  | total loss: [1m[32m0.42053[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42053 - acc: 0.8262 -- iter: 3328/3680
[A[ATraining Step: 2750  | total loss: [1m[32m0.41482[0m[0m
[2K| Adam | epoch: 024 | loss: 0.41482 - acc: 0.8311 -- iter: 3360/3680
[A[ATraining Step: 2751  | total loss: [1m[32m0.40406[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40406 - acc: 0.8292 -- iter: 3392/3680
[A[ATraining Step: 2752  | total loss: [1m[32m0.50424[0m[0m
[2K| Adam | epoch: 024 | loss: 0.50424 - acc: 0.7932 -- iter: 3424/3680
[A[ATraining Step: 2753  | total loss: [1m[32m0.48472[0m[0m
[2K| Adam | epoch: 024 | loss: 0.48472 - acc: 0.7982 -- iter: 3456/3680
[A[ATraining Step: 2754  | total loss: [1m[32m0.46783[0m[0m
[2K| Adam | epoch: 024 | loss: 0.46783 - acc: 0.8090 -- iter: 3488/3680
[A[ATraining Step: 2755  | total loss: [1m[32m0.45760[0m[0m
[2K| Adam | epoch: 024 | loss: 0.45760 - acc: 0.8125 -- iter: 3520/3680
[A[ATraining Step: 2756  | total loss: [1m[32m0.43625[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43625 - acc: 0.8281 -- iter: 3552/3680
[A[ATraining Step: 2757  | total loss: [1m[32m0.43501[0m[0m
[2K| Adam | epoch: 024 | loss: 0.43501 - acc: 0.8234 -- iter: 3584/3680
[A[ATraining Step: 2758  | total loss: [1m[32m0.42237[0m[0m
[2K| Adam | epoch: 024 | loss: 0.42237 - acc: 0.8317 -- iter: 3616/3680
[A[ATraining Step: 2759  | total loss: [1m[32m0.40809[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40809 - acc: 0.8361 -- iter: 3648/3680
[A[ATraining Step: 2760  | total loss: [1m[32m0.40400[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40400 - acc: 0.8399 | val_loss: 0.38505 - val_acc: 0.8491 -- iter: 3680/3680
[A[ATraining Step: 2760  | total loss: [1m[32m0.40400[0m[0m
[2K| Adam | epoch: 024 | loss: 0.40400 - acc: 0.8399 | val_loss: 0.38505 - val_acc: 0.8491 -- iter: 3680/3680
--
Training Step: 2761  | total loss: [1m[32m0.40865[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40865 - acc: 0.8341 -- iter: 0032/3680
[A[ATraining Step: 2762  | total loss: [1m[32m0.40579[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40579 - acc: 0.8319 -- iter: 0064/3680
[A[ATraining Step: 2763  | total loss: [1m[32m0.41274[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41274 - acc: 0.8331 -- iter: 0096/3680
[A[ATraining Step: 2764  | total loss: [1m[32m0.40693[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40693 - acc: 0.8342 -- iter: 0128/3680
[A[ATraining Step: 2765  | total loss: [1m[32m0.41259[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41259 - acc: 0.8320 -- iter: 0160/3680
[A[ATraining Step: 2766  | total loss: [1m[32m0.43797[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43797 - acc: 0.8238 -- iter: 0192/3680
[A[ATraining Step: 2767  | total loss: [1m[32m0.44527[0m[0m
[2K| Adam | epoch: 025 | loss: 0.44527 - acc: 0.8227 -- iter: 0224/3680
[A[ATraining Step: 2768  | total loss: [1m[32m0.44420[0m[0m
[2K| Adam | epoch: 025 | loss: 0.44420 - acc: 0.8185 -- iter: 0256/3680
[A[ATraining Step: 2769  | total loss: [1m[32m0.44472[0m[0m
[2K| Adam | epoch: 025 | loss: 0.44472 - acc: 0.8148 -- iter: 0288/3680
[A[ATraining Step: 2770  | total loss: [1m[32m0.43620[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43620 - acc: 0.8146 -- iter: 0320/3680
[A[ATraining Step: 2771  | total loss: [1m[32m0.43707[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43707 - acc: 0.8144 -- iter: 0352/3680
[A[ATraining Step: 2772  | total loss: [1m[32m0.43336[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43336 - acc: 0.8142 -- iter: 0384/3680
[A[ATraining Step: 2773  | total loss: [1m[32m0.43448[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43448 - acc: 0.8140 -- iter: 0416/3680
[A[ATraining Step: 2774  | total loss: [1m[32m0.43896[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43896 - acc: 0.8107 -- iter: 0448/3680
[A[ATraining Step: 2775  | total loss: [1m[32m0.42645[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42645 - acc: 0.8172 -- iter: 0480/3680
[A[ATraining Step: 2776  | total loss: [1m[32m0.41751[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41751 - acc: 0.8292 -- iter: 0512/3680
[A[ATraining Step: 2777  | total loss: [1m[32m0.41684[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41684 - acc: 0.8307 -- iter: 0544/3680
[A[ATraining Step: 2778  | total loss: [1m[32m0.41082[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41082 - acc: 0.8382 -- iter: 0576/3680
[A[ATraining Step: 2779  | total loss: [1m[32m0.41046[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41046 - acc: 0.8294 -- iter: 0608/3680
[A[ATraining Step: 2780  | total loss: [1m[32m0.42042[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42042 - acc: 0.8215 -- iter: 0640/3680
[A[ATraining Step: 2781  | total loss: [1m[32m0.41261[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41261 - acc: 0.8268 -- iter: 0672/3680
[A[ATraining Step: 2782  | total loss: [1m[32m0.41772[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41772 - acc: 0.8244 -- iter: 0704/3680
[A[ATraining Step: 2783  | total loss: [1m[32m0.41404[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41404 - acc: 0.8244 -- iter: 0736/3680
[A[ATraining Step: 2784  | total loss: [1m[32m0.41196[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41196 - acc: 0.8295 -- iter: 0768/3680
[A[ATraining Step: 2785  | total loss: [1m[32m0.41058[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41058 - acc: 0.8412 -- iter: 0800/3680
[A[ATraining Step: 2786  | total loss: [1m[32m0.40682[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40682 - acc: 0.8412 -- iter: 0832/3680
[A[ATraining Step: 2787  | total loss: [1m[32m0.40659[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40659 - acc: 0.8321 -- iter: 0864/3680
[A[ATraining Step: 2788  | total loss: [1m[32m0.38938[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38938 - acc: 0.8427 -- iter: 0896/3680
[A[ATraining Step: 2789  | total loss: [1m[32m0.39040[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39040 - acc: 0.8428 -- iter: 0928/3680
[A[ATraining Step: 2790  | total loss: [1m[32m0.39969[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39969 - acc: 0.8397 -- iter: 0960/3680
[A[ATraining Step: 2791  | total loss: [1m[32m0.40457[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40457 - acc: 0.8401 -- iter: 0992/3680
[A[ATraining Step: 2792  | total loss: [1m[32m0.41177[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41177 - acc: 0.8342 -- iter: 1024/3680
[A[ATraining Step: 2793  | total loss: [1m[32m0.39586[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39586 - acc: 0.8446 -- iter: 1056/3680
[A[ATraining Step: 2794  | total loss: [1m[32m0.39752[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39752 - acc: 0.8445 -- iter: 1088/3680
[A[ATraining Step: 2795  | total loss: [1m[32m0.38490[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38490 - acc: 0.8507 -- iter: 1120/3680
[A[ATraining Step: 2796  | total loss: [1m[32m0.38953[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38953 - acc: 0.8437 -- iter: 1152/3680
[A[ATraining Step: 2797  | total loss: [1m[32m0.39873[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39873 - acc: 0.8344 -- iter: 1184/3680
[A[ATraining Step: 2798  | total loss: [1m[32m0.41574[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41574 - acc: 0.8277 -- iter: 1216/3680
[A[ATraining Step: 2799  | total loss: [1m[32m0.42138[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42138 - acc: 0.8277 -- iter: 1248/3680
[A[ATraining Step: 2800  | total loss: [1m[32m0.42907[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42907 - acc: 0.8231 | val_loss: 0.38814 - val_acc: 0.8415 -- iter: 1280/3680
[A[ATraining Step: 2800  | total loss: [1m[32m0.42907[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42907 - acc: 0.8231 | val_loss: 0.38814 - val_acc: 0.8415 -- iter: 1280/3680
--
Training Step: 2801  | total loss: [1m[32m0.42311[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42311 - acc: 0.8251 -- iter: 1312/3680
[A[ATraining Step: 2802  | total loss: [1m[32m0.43539[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43539 - acc: 0.8207 -- iter: 1344/3680
[A[ATraining Step: 2803  | total loss: [1m[32m0.43643[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43643 - acc: 0.8230 -- iter: 1376/3680
[A[ATraining Step: 2804  | total loss: [1m[32m0.43827[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43827 - acc: 0.8189 -- iter: 1408/3680
[A[ATraining Step: 2805  | total loss: [1m[32m0.43771[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43771 - acc: 0.8120 -- iter: 1440/3680
[A[ATraining Step: 2806  | total loss: [1m[32m0.42036[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42036 - acc: 0.8245 -- iter: 1472/3680
[A[ATraining Step: 2807  | total loss: [1m[32m0.41587[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41587 - acc: 0.8296 -- iter: 1504/3680
[A[ATraining Step: 2808  | total loss: [1m[32m0.43051[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43051 - acc: 0.8216 -- iter: 1536/3680
[A[ATraining Step: 2809  | total loss: [1m[32m0.42626[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42626 - acc: 0.8207 -- iter: 1568/3680
[A[ATraining Step: 2810  | total loss: [1m[32m0.42737[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42737 - acc: 0.8136 -- iter: 1600/3680
[A[ATraining Step: 2811  | total loss: [1m[32m0.41714[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41714 - acc: 0.8229 -- iter: 1632/3680
[A[ATraining Step: 2812  | total loss: [1m[32m0.42109[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42109 - acc: 0.8156 -- iter: 1664/3680
[A[ATraining Step: 2813  | total loss: [1m[32m0.41245[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41245 - acc: 0.8153 -- iter: 1696/3680
[A[ATraining Step: 2814  | total loss: [1m[32m0.41240[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41240 - acc: 0.8150 -- iter: 1728/3680
[A[ATraining Step: 2815  | total loss: [1m[32m0.40407[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40407 - acc: 0.8179 -- iter: 1760/3680
[A[ATraining Step: 2816  | total loss: [1m[32m0.41159[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41159 - acc: 0.8174 -- iter: 1792/3680
[A[ATraining Step: 2817  | total loss: [1m[32m0.41593[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41593 - acc: 0.8137 -- iter: 1824/3680
[A[ATraining Step: 2818  | total loss: [1m[32m0.41652[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41652 - acc: 0.8105 -- iter: 1856/3680
[A[ATraining Step: 2819  | total loss: [1m[32m0.40994[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40994 - acc: 0.8201 -- iter: 1888/3680
[A[ATraining Step: 2820  | total loss: [1m[32m0.43769[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43769 - acc: 0.8037 -- iter: 1920/3680
[A[ATraining Step: 2821  | total loss: [1m[32m0.42344[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42344 - acc: 0.8139 -- iter: 1952/3680
[A[ATraining Step: 2822  | total loss: [1m[32m0.41616[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41616 - acc: 0.8200 -- iter: 1984/3680
[A[ATraining Step: 2823  | total loss: [1m[32m0.41878[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41878 - acc: 0.8162 -- iter: 2016/3680
[A[ATraining Step: 2824  | total loss: [1m[32m0.41359[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41359 - acc: 0.8158 -- iter: 2048/3680
[A[ATraining Step: 2825  | total loss: [1m[32m0.41194[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41194 - acc: 0.8217 -- iter: 2080/3680
[A[ATraining Step: 2826  | total loss: [1m[32m0.40509[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40509 - acc: 0.8239 -- iter: 2112/3680
[A[ATraining Step: 2827  | total loss: [1m[32m0.41473[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41473 - acc: 0.8165 -- iter: 2144/3680
[A[ATraining Step: 2828  | total loss: [1m[32m0.42673[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42673 - acc: 0.8068 -- iter: 2176/3680
[A[ATraining Step: 2829  | total loss: [1m[32m0.41457[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41457 - acc: 0.8136 -- iter: 2208/3680
[A[ATraining Step: 2830  | total loss: [1m[32m0.41131[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41131 - acc: 0.8103 -- iter: 2240/3680
[A[ATraining Step: 2831  | total loss: [1m[32m0.40088[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40088 - acc: 0.8231 -- iter: 2272/3680
[A[ATraining Step: 2832  | total loss: [1m[32m0.39449[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39449 - acc: 0.8314 -- iter: 2304/3680
[A[ATraining Step: 2833  | total loss: [1m[32m0.39429[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39429 - acc: 0.8295 -- iter: 2336/3680
[A[ATraining Step: 2834  | total loss: [1m[32m0.38661[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38661 - acc: 0.8340 -- iter: 2368/3680
[A[ATraining Step: 2835  | total loss: [1m[32m0.39179[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39179 - acc: 0.8225 -- iter: 2400/3680
[A[ATraining Step: 2836  | total loss: [1m[32m0.39504[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39504 - acc: 0.8278 -- iter: 2432/3680
[A[ATraining Step: 2837  | total loss: [1m[32m0.40962[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40962 - acc: 0.8231 -- iter: 2464/3680
[A[ATraining Step: 2838  | total loss: [1m[32m0.41165[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41165 - acc: 0.8127 -- iter: 2496/3680
[A[ATraining Step: 2839  | total loss: [1m[32m0.41419[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41419 - acc: 0.8033 -- iter: 2528/3680
[A[ATraining Step: 2840  | total loss: [1m[32m0.38914[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38914 - acc: 0.8230 -- iter: 2560/3680
[A[ATraining Step: 2841  | total loss: [1m[32m0.38942[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38942 - acc: 0.8219 -- iter: 2592/3680
[A[ATraining Step: 2842  | total loss: [1m[32m0.39986[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39986 - acc: 0.8210 -- iter: 2624/3680
[A[ATraining Step: 2843  | total loss: [1m[32m0.38893[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38893 - acc: 0.8264 -- iter: 2656/3680
[A[ATraining Step: 2844  | total loss: [1m[32m0.37844[0m[0m
[2K| Adam | epoch: 025 | loss: 0.37844 - acc: 0.8312 -- iter: 2688/3680
[A[ATraining Step: 2845  | total loss: [1m[32m0.38519[0m[0m
[2K| Adam | epoch: 025 | loss: 0.38519 - acc: 0.8294 -- iter: 2720/3680
[A[ATraining Step: 2846  | total loss: [1m[32m0.37444[0m[0m
[2K| Adam | epoch: 025 | loss: 0.37444 - acc: 0.8402 -- iter: 2752/3680
[A[ATraining Step: 2847  | total loss: [1m[32m0.39011[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39011 - acc: 0.8312 -- iter: 2784/3680
[A[ATraining Step: 2848  | total loss: [1m[32m0.39842[0m[0m
[2K| Adam | epoch: 025 | loss: 0.39842 - acc: 0.8199 -- iter: 2816/3680
[A[ATraining Step: 2849  | total loss: [1m[32m0.41486[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41486 - acc: 0.8129 -- iter: 2848/3680
[A[ATraining Step: 2850  | total loss: [1m[32m0.42605[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42605 - acc: 0.8098 -- iter: 2880/3680
[A[ATraining Step: 2851  | total loss: [1m[32m0.41372[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41372 - acc: 0.8093 -- iter: 2912/3680
[A[ATraining Step: 2852  | total loss: [1m[32m0.42060[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42060 - acc: 0.8065 -- iter: 2944/3680
[A[ATraining Step: 2853  | total loss: [1m[32m0.42484[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42484 - acc: 0.8065 -- iter: 2976/3680
[A[ATraining Step: 2854  | total loss: [1m[32m0.41136[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41136 - acc: 0.8040 -- iter: 3008/3680
[A[ATraining Step: 2855  | total loss: [1m[32m0.40752[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40752 - acc: 0.8049 -- iter: 3040/3680
[A[ATraining Step: 2856  | total loss: [1m[32m0.40399[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40399 - acc: 0.8056 -- iter: 3072/3680
[A[ATraining Step: 2857  | total loss: [1m[32m0.40190[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40190 - acc: 0.8063 -- iter: 3104/3680
[A[ATraining Step: 2858  | total loss: [1m[32m0.40345[0m[0m
[2K| Adam | epoch: 025 | loss: 0.40345 - acc: 0.8132 -- iter: 3136/3680
[A[ATraining Step: 2859  | total loss: [1m[32m0.41393[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41393 - acc: 0.8131 -- iter: 3168/3680
[A[ATraining Step: 2860  | total loss: [1m[32m0.41282[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41282 - acc: 0.8162 -- iter: 3200/3680
[A[ATraining Step: 2861  | total loss: [1m[32m0.41242[0m[0m
[2K| Adam | epoch: 025 | loss: 0.41242 - acc: 0.8158 -- iter: 3232/3680
[A[ATraining Step: 2862  | total loss: [1m[32m0.44208[0m[0m
[2K| Adam | epoch: 025 | loss: 0.44208 - acc: 0.8030 -- iter: 3264/3680
[A[ATraining Step: 2863  | total loss: [1m[32m0.43137[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43137 - acc: 0.8071 -- iter: 3296/3680
[A[ATraining Step: 2864  | total loss: [1m[32m0.42547[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42547 - acc: 0.8076 -- iter: 3328/3680
[A[ATraining Step: 2865  | total loss: [1m[32m0.44562[0m[0m
[2K| Adam | epoch: 025 | loss: 0.44562 - acc: 0.7862 -- iter: 3360/3680
[A[ATraining Step: 2866  | total loss: [1m[32m0.42767[0m[0m
[2K| Adam | epoch: 025 | loss: 0.42767 - acc: 0.7951 -- iter: 3392/3680
[A[ATraining Step: 2867  | total loss: [1m[32m0.43817[0m[0m
[2K| Adam | epoch: 025 | loss: 0.43817 - acc: 0.7906 -- iter: 3424/3680
[A[ATraining Step: 2868  | total loss: [1m[32m0.52763[0m[0m
[2K| Adam | epoch: 025 | loss: 0.52763 - acc: 0.7521 -- iter: 3456/3680
[A[ATraining Step: 2869  | total loss: [1m[32m0.52388[0m[0m
[2K| Adam | epoch: 025 | loss: 0.52388 - acc: 0.7519 -- iter: 3488/3680
[A[ATraining Step: 2870  | total loss: [1m[32m0.49674[0m[0m
[2K| Adam | epoch: 025 | loss: 0.49674 - acc: 0.7736 -- iter: 3520/3680
[A[ATraining Step: 2871  | total loss: [1m[32m0.48959[0m[0m
[2K| Adam | epoch: 025 | loss: 0.48959 - acc: 0.7806 -- iter: 3552/3680
[A[ATraining Step: 2872  | total loss: [1m[32m0.49164[0m[0m
[2K| Adam | epoch: 025 | loss: 0.49164 - acc: 0.7807 -- iter: 3584/3680
[A[ATraining Step: 2873  | total loss: [1m[32m0.48460[0m[0m
[2K| Adam | epoch: 025 | loss: 0.48460 - acc: 0.7870 -- iter: 3616/3680
[A[ATraining Step: 2874  | total loss: [1m[32m0.48099[0m[0m
[2K| Adam | epoch: 025 | loss: 0.48099 - acc: 0.7833 -- iter: 3648/3680
[A[ATraining Step: 2875  | total loss: [1m[32m0.45375[0m[0m
[2K| Adam | epoch: 025 | loss: 0.45375 - acc: 0.8050 | val_loss: 0.39527 - val_acc: 0.8480 -- iter: 3680/3680
[A[ATraining Step: 2875  | total loss: [1m[32m0.45375[0m[0m
[2K| Adam | epoch: 025 | loss: 0.45375 - acc: 0.8050 | val_loss: 0.39527 - val_acc: 0.8480 -- iter: 3680/3680
--
Training Step: 2876  | total loss: [1m[32m0.44895[0m[0m
[2K| Adam | epoch: 026 | loss: 0.44895 - acc: 0.8026 -- iter: 0032/3680
[A[ATraining Step: 2877  | total loss: [1m[32m0.44735[0m[0m
[2K| Adam | epoch: 026 | loss: 0.44735 - acc: 0.8036 -- iter: 0064/3680
[A[ATraining Step: 2878  | total loss: [1m[32m0.45567[0m[0m
[2K| Adam | epoch: 026 | loss: 0.45567 - acc: 0.7982 -- iter: 0096/3680
[A[ATraining Step: 2879  | total loss: [1m[32m0.43934[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43934 - acc: 0.8090 -- iter: 0128/3680
[A[ATraining Step: 2880  | total loss: [1m[32m0.44115[0m[0m
[2K| Adam | epoch: 026 | loss: 0.44115 - acc: 0.8125 -- iter: 0160/3680
[A[ATraining Step: 2881  | total loss: [1m[32m0.42352[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42352 - acc: 0.8219 -- iter: 0192/3680
[A[ATraining Step: 2882  | total loss: [1m[32m0.41014[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41014 - acc: 0.8334 -- iter: 0224/3680
[A[ATraining Step: 2883  | total loss: [1m[32m0.41209[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41209 - acc: 0.8345 -- iter: 0256/3680
[A[ATraining Step: 2884  | total loss: [1m[32m0.40391[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40391 - acc: 0.8323 -- iter: 0288/3680
[A[ATraining Step: 2885  | total loss: [1m[32m0.39617[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39617 - acc: 0.8365 -- iter: 0320/3680
[A[ATraining Step: 2886  | total loss: [1m[32m0.41641[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41641 - acc: 0.8154 -- iter: 0352/3680
[A[ATraining Step: 2887  | total loss: [1m[32m0.41442[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41442 - acc: 0.8182 -- iter: 0384/3680
[A[ATraining Step: 2888  | total loss: [1m[32m0.41949[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41949 - acc: 0.8114 -- iter: 0416/3680
[A[ATraining Step: 2889  | total loss: [1m[32m0.42475[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42475 - acc: 0.8178 -- iter: 0448/3680
[A[ATraining Step: 2890  | total loss: [1m[32m0.41524[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41524 - acc: 0.8235 -- iter: 0480/3680
[A[ATraining Step: 2891  | total loss: [1m[32m0.41600[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41600 - acc: 0.8255 -- iter: 0512/3680
[A[ATraining Step: 2892  | total loss: [1m[32m0.40964[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40964 - acc: 0.8273 -- iter: 0544/3680
[A[ATraining Step: 2893  | total loss: [1m[32m0.40688[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40688 - acc: 0.8259 -- iter: 0576/3680
[A[ATraining Step: 2894  | total loss: [1m[32m0.38884[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38884 - acc: 0.8308 -- iter: 0608/3680
[A[ATraining Step: 2895  | total loss: [1m[32m0.41586[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41586 - acc: 0.8102 -- iter: 0640/3680
[A[ATraining Step: 2896  | total loss: [1m[32m0.41824[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41824 - acc: 0.8104 -- iter: 0672/3680
[A[ATraining Step: 2897  | total loss: [1m[32m0.42889[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42889 - acc: 0.7989 -- iter: 0704/3680
[A[ATraining Step: 2898  | total loss: [1m[32m0.44261[0m[0m
[2K| Adam | epoch: 026 | loss: 0.44261 - acc: 0.7909 -- iter: 0736/3680
[A[ATraining Step: 2899  | total loss: [1m[32m0.44261[0m[0m
[2K| Adam | epoch: 026 | loss: 0.44261 - acc: 0.7909 -- iter: 0768/3680
[A[ATraining Step: 2900  | total loss: [1m[32m0.43009[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43009 - acc: 0.7931 | val_loss: 0.37141 - val_acc: 0.8556 -- iter: 0800/3680
[A[ATraining Step: 2900  | total loss: [1m[32m0.43009[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43009 - acc: 0.7931 | val_loss: 0.37141 - val_acc: 0.8556 -- iter: 0800/3680
--
Training Step: 2901  | total loss: [1m[32m0.42299[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42299 - acc: 0.7981 -- iter: 0832/3680
[A[ATraining Step: 2902  | total loss: [1m[32m0.42068[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42068 - acc: 0.7996 -- iter: 0864/3680
[A[ATraining Step: 2903  | total loss: [1m[32m0.41706[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41706 - acc: 0.8071 -- iter: 0896/3680
[A[ATraining Step: 2904  | total loss: [1m[32m0.39707[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39707 - acc: 0.8202 -- iter: 0928/3680
[A[ATraining Step: 2905  | total loss: [1m[32m0.41180[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41180 - acc: 0.8100 -- iter: 0960/3680
[A[ATraining Step: 2906  | total loss: [1m[32m0.41810[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41810 - acc: 0.8071 -- iter: 0992/3680
[A[ATraining Step: 2907  | total loss: [1m[32m0.41788[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41788 - acc: 0.8138 -- iter: 1024/3680
[A[ATraining Step: 2908  | total loss: [1m[32m0.41223[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41223 - acc: 0.8138 -- iter: 1056/3680
[A[ATraining Step: 2909  | total loss: [1m[32m0.41713[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41713 - acc: 0.8106 -- iter: 1088/3680
[A[ATraining Step: 2910  | total loss: [1m[32m0.41113[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41113 - acc: 0.8139 -- iter: 1120/3680
[A[ATraining Step: 2911  | total loss: [1m[32m0.41196[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41196 - acc: 0.8130 -- iter: 1152/3680
[A[ATraining Step: 2912  | total loss: [1m[32m0.41196[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41196 - acc: 0.8130 -- iter: 1184/3680
[A[ATraining Step: 2913  | total loss: [1m[32m0.41483[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41483 - acc: 0.8098 -- iter: 1216/3680
[A[ATraining Step: 2914  | total loss: [1m[32m0.40733[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40733 - acc: 0.8132 -- iter: 1248/3680
[A[ATraining Step: 2915  | total loss: [1m[32m0.41185[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41185 - acc: 0.8194 -- iter: 1280/3680
[A[ATraining Step: 2916  | total loss: [1m[32m0.41515[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41515 - acc: 0.8187 -- iter: 1312/3680
[A[ATraining Step: 2917  | total loss: [1m[32m0.41913[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41913 - acc: 0.8087 -- iter: 1344/3680
[A[ATraining Step: 2918  | total loss: [1m[32m0.42252[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42252 - acc: 0.8060 -- iter: 1376/3680
[A[ATraining Step: 2919  | total loss: [1m[32m0.42614[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42614 - acc: 0.8097 -- iter: 1408/3680
[A[ATraining Step: 2920  | total loss: [1m[32m0.41982[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41982 - acc: 0.8194 -- iter: 1440/3680
[A[ATraining Step: 2921  | total loss: [1m[32m0.41970[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41970 - acc: 0.8187 -- iter: 1472/3680
[A[ATraining Step: 2922  | total loss: [1m[32m0.40535[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40535 - acc: 0.8306 -- iter: 1504/3680
[A[ATraining Step: 2923  | total loss: [1m[32m0.42037[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42037 - acc: 0.8194 -- iter: 1536/3680
[A[ATraining Step: 2924  | total loss: [1m[32m0.43926[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43926 - acc: 0.8125 -- iter: 1568/3680
[A[ATraining Step: 2925  | total loss: [1m[32m0.43077[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43077 - acc: 0.8187 -- iter: 1600/3680
[A[ATraining Step: 2926  | total loss: [1m[32m0.42154[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42154 - acc: 0.8243 -- iter: 1632/3680
[A[ATraining Step: 2927  | total loss: [1m[32m0.41335[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41335 - acc: 0.8294 -- iter: 1664/3680
[A[ATraining Step: 2928  | total loss: [1m[32m0.41974[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41974 - acc: 0.8183 -- iter: 1696/3680
[A[ATraining Step: 2929  | total loss: [1m[32m0.43904[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43904 - acc: 0.8084 -- iter: 1728/3680
[A[ATraining Step: 2930  | total loss: [1m[32m0.42721[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42721 - acc: 0.8182 -- iter: 1760/3680
[A[ATraining Step: 2931  | total loss: [1m[32m0.42943[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42943 - acc: 0.8145 -- iter: 1792/3680
[A[ATraining Step: 2932  | total loss: [1m[32m0.42309[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42309 - acc: 0.8174 -- iter: 1824/3680
[A[ATraining Step: 2933  | total loss: [1m[32m0.41849[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41849 - acc: 0.8169 -- iter: 1856/3680
[A[ATraining Step: 2934  | total loss: [1m[32m0.41289[0m[0m
[2K| Adam | epoch: 026 | loss: 0.41289 - acc: 0.8196 -- iter: 1888/3680
[A[ATraining Step: 2935  | total loss: [1m[32m0.42356[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42356 - acc: 0.8158 -- iter: 1920/3680
[A[ATraining Step: 2936  | total loss: [1m[32m0.44670[0m[0m
[2K| Adam | epoch: 026 | loss: 0.44670 - acc: 0.7998 -- iter: 1952/3680
[A[ATraining Step: 2937  | total loss: [1m[32m0.45618[0m[0m
[2K| Adam | epoch: 026 | loss: 0.45618 - acc: 0.7998 -- iter: 1984/3680
[A[ATraining Step: 2938  | total loss: [1m[32m0.45767[0m[0m
[2K| Adam | epoch: 026 | loss: 0.45767 - acc: 0.7917 -- iter: 2016/3680
[A[ATraining Step: 2939  | total loss: [1m[32m0.46545[0m[0m
[2K| Adam | epoch: 026 | loss: 0.46545 - acc: 0.7876 -- iter: 2048/3680
[A[ATraining Step: 2940  | total loss: [1m[32m0.46830[0m[0m
[2K| Adam | epoch: 026 | loss: 0.46830 - acc: 0.7932 -- iter: 2080/3680
[A[ATraining Step: 2941  | total loss: [1m[32m0.46396[0m[0m
[2K| Adam | epoch: 026 | loss: 0.46396 - acc: 0.7951 -- iter: 2112/3680
[A[ATraining Step: 2942  | total loss: [1m[32m0.45006[0m[0m
[2K| Adam | epoch: 026 | loss: 0.45006 - acc: 0.7968 -- iter: 2144/3680
[A[ATraining Step: 2943  | total loss: [1m[32m0.42991[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42991 - acc: 0.8109 -- iter: 2176/3680
[A[ATraining Step: 2944  | total loss: [1m[32m0.43601[0m[0m
[2K| Adam | epoch: 026 | loss: 0.43601 - acc: 0.8048 -- iter: 2208/3680
[A[ATraining Step: 2945  | total loss: [1m[32m0.42984[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42984 - acc: 0.8087 -- iter: 2240/3680
[A[ATraining Step: 2946  | total loss: [1m[32m0.42070[0m[0m
[2K| Adam | epoch: 026 | loss: 0.42070 - acc: 0.8091 -- iter: 2272/3680
[A[ATraining Step: 2947  | total loss: [1m[32m0.40049[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40049 - acc: 0.8251 -- iter: 2304/3680
[A[ATraining Step: 2948  | total loss: [1m[32m0.39481[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39481 - acc: 0.8269 -- iter: 2336/3680
[A[ATraining Step: 2949  | total loss: [1m[32m0.38623[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38623 - acc: 0.8317 -- iter: 2368/3680
[A[ATraining Step: 2950  | total loss: [1m[32m0.38939[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38939 - acc: 0.8298 -- iter: 2400/3680
[A[ATraining Step: 2951  | total loss: [1m[32m0.38403[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38403 - acc: 0.8312 -- iter: 2432/3680
[A[ATraining Step: 2952  | total loss: [1m[32m0.39348[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39348 - acc: 0.8325 -- iter: 2464/3680
[A[ATraining Step: 2953  | total loss: [1m[32m0.39203[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39203 - acc: 0.8336 -- iter: 2496/3680
[A[ATraining Step: 2954  | total loss: [1m[32m0.38214[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38214 - acc: 0.8409 -- iter: 2528/3680
[A[ATraining Step: 2955  | total loss: [1m[32m0.38401[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38401 - acc: 0.8318 -- iter: 2560/3680
[A[ATraining Step: 2956  | total loss: [1m[32m0.37206[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37206 - acc: 0.8361 -- iter: 2592/3680
[A[ATraining Step: 2957  | total loss: [1m[32m0.37391[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37391 - acc: 0.8306 -- iter: 2624/3680
[A[ATraining Step: 2958  | total loss: [1m[32m0.39028[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39028 - acc: 0.8225 -- iter: 2656/3680
[A[ATraining Step: 2959  | total loss: [1m[32m0.38321[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38321 - acc: 0.8247 -- iter: 2688/3680
[A[ATraining Step: 2960  | total loss: [1m[32m0.37755[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37755 - acc: 0.8297 -- iter: 2720/3680
[A[ATraining Step: 2961  | total loss: [1m[32m0.37810[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37810 - acc: 0.8311 -- iter: 2752/3680
[A[ATraining Step: 2962  | total loss: [1m[32m0.36977[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36977 - acc: 0.8386 -- iter: 2784/3680
[A[ATraining Step: 2963  | total loss: [1m[32m0.36315[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36315 - acc: 0.8423 -- iter: 2816/3680
[A[ATraining Step: 2964  | total loss: [1m[32m0.35959[0m[0m
[2K| Adam | epoch: 026 | loss: 0.35959 - acc: 0.8455 -- iter: 2848/3680
[A[ATraining Step: 2965  | total loss: [1m[32m0.36935[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36935 - acc: 0.8422 -- iter: 2880/3680
[A[ATraining Step: 2966  | total loss: [1m[32m0.36552[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36552 - acc: 0.8486 -- iter: 2912/3680
[A[ATraining Step: 2967  | total loss: [1m[32m0.36232[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36232 - acc: 0.8481 -- iter: 2944/3680
[A[ATraining Step: 2968  | total loss: [1m[32m0.35747[0m[0m
[2K| Adam | epoch: 026 | loss: 0.35747 - acc: 0.8540 -- iter: 2976/3680
[A[ATraining Step: 2969  | total loss: [1m[32m0.36624[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36624 - acc: 0.8467 -- iter: 3008/3680
[A[ATraining Step: 2970  | total loss: [1m[32m0.36944[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36944 - acc: 0.8401 -- iter: 3040/3680
[A[ATraining Step: 2971  | total loss: [1m[32m0.38388[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38388 - acc: 0.8286 -- iter: 3072/3680
[A[ATraining Step: 2972  | total loss: [1m[32m0.38388[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38388 - acc: 0.8286 -- iter: 3104/3680
[A[ATraining Step: 2973  | total loss: [1m[32m0.39478[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39478 - acc: 0.8239 -- iter: 3136/3680
[A[ATraining Step: 2974  | total loss: [1m[32m0.40456[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40456 - acc: 0.8165 -- iter: 3168/3680
[A[ATraining Step: 2975  | total loss: [1m[32m0.40353[0m[0m
[2K| Adam | epoch: 026 | loss: 0.40353 - acc: 0.8161 -- iter: 3200/3680
[A[ATraining Step: 2976  | total loss: [1m[32m0.39961[0m[0m
[2K| Adam | epoch: 026 | loss: 0.39961 - acc: 0.8220 -- iter: 3232/3680
[A[ATraining Step: 2977  | total loss: [1m[32m0.38759[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38759 - acc: 0.8335 -- iter: 3264/3680
[A[ATraining Step: 2978  | total loss: [1m[32m0.38475[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38475 - acc: 0.8346 -- iter: 3296/3680
[A[ATraining Step: 2979  | total loss: [1m[32m0.37777[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37777 - acc: 0.8386 -- iter: 3328/3680
[A[ATraining Step: 2980  | total loss: [1m[32m0.37211[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37211 - acc: 0.8423 -- iter: 3360/3680
[A[ATraining Step: 2981  | total loss: [1m[32m0.38190[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38190 - acc: 0.8393 -- iter: 3392/3680
[A[ATraining Step: 2982  | total loss: [1m[32m0.36952[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36952 - acc: 0.8460 -- iter: 3424/3680
[A[ATraining Step: 2983  | total loss: [1m[32m0.37657[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37657 - acc: 0.8458 -- iter: 3456/3680
[A[ATraining Step: 2984  | total loss: [1m[32m0.37993[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37993 - acc: 0.8393 -- iter: 3488/3680
[A[ATraining Step: 2985  | total loss: [1m[32m0.38104[0m[0m
[2K| Adam | epoch: 026 | loss: 0.38104 - acc: 0.8397 -- iter: 3520/3680
[A[ATraining Step: 2986  | total loss: [1m[32m0.36857[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36857 - acc: 0.8495 -- iter: 3552/3680
[A[ATraining Step: 2987  | total loss: [1m[32m0.36769[0m[0m
[2K| Adam | epoch: 026 | loss: 0.36769 - acc: 0.8489 -- iter: 3584/3680
[A[ATraining Step: 2988  | total loss: [1m[32m0.37114[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37114 - acc: 0.8422 -- iter: 3616/3680
[A[ATraining Step: 2989  | total loss: [1m[32m0.37827[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37827 - acc: 0.8392 -- iter: 3648/3680
[A[ATraining Step: 2990  | total loss: [1m[32m0.37598[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37598 - acc: 0.8365 | val_loss: 0.37624 - val_acc: 0.8491 -- iter: 3680/3680
[A[ATraining Step: 2990  | total loss: [1m[32m0.37598[0m[0m
[2K| Adam | epoch: 026 | loss: 0.37598 - acc: 0.8365 | val_loss: 0.37624 - val_acc: 0.8491 -- iter: 3680/3680
--
Training Step: 2991  | total loss: [1m[32m0.37791[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37791 - acc: 0.8373 -- iter: 0032/3680
[A[ATraining Step: 2992  | total loss: [1m[32m0.37034[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37034 - acc: 0.8410 -- iter: 0064/3680
[A[ATraining Step: 2993  | total loss: [1m[32m0.36246[0m[0m
[2K| Adam | epoch: 027 | loss: 0.36246 - acc: 0.8476 -- iter: 0096/3680
[A[ATraining Step: 2994  | total loss: [1m[32m0.38917[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38917 - acc: 0.8534 -- iter: 0128/3680
[A[ATraining Step: 2995  | total loss: [1m[32m0.37810[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37810 - acc: 0.8534 -- iter: 0160/3680
[A[ATraining Step: 2996  | total loss: [1m[32m0.37357[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37357 - acc: 0.8556 -- iter: 0192/3680
[A[ATraining Step: 2997  | total loss: [1m[32m0.37143[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37143 - acc: 0.8481 -- iter: 0224/3680
[A[ATraining Step: 2998  | total loss: [1m[32m0.36124[0m[0m
[2K| Adam | epoch: 027 | loss: 0.36124 - acc: 0.8508 -- iter: 0256/3680
[A[ATraining Step: 2999  | total loss: [1m[32m0.35751[0m[0m
[2K| Adam | epoch: 027 | loss: 0.35751 - acc: 0.8501 -- iter: 0288/3680
[A[ATraining Step: 3000  | total loss: [1m[32m0.35556[0m[0m
[2K| Adam | epoch: 027 | loss: 0.35556 - acc: 0.8495 | val_loss: 0.39013 - val_acc: 0.8371 -- iter: 0320/3680
[A[ATraining Step: 3000  | total loss: [1m[32m0.35556[0m[0m
[2K| Adam | epoch: 027 | loss: 0.35556 - acc: 0.8495 | val_loss: 0.39013 - val_acc: 0.8371 -- iter: 0320/3680
--
Training Step: 3001  | total loss: [1m[32m0.34893[0m[0m
[2K| Adam | epoch: 027 | loss: 0.34893 - acc: 0.8583 -- iter: 0352/3680
[A[ATraining Step: 3002  | total loss: [1m[32m0.33680[0m[0m
[2K| Adam | epoch: 027 | loss: 0.33680 - acc: 0.8662 -- iter: 0384/3680
[A[ATraining Step: 3003  | total loss: [1m[32m0.33284[0m[0m
[2K| Adam | epoch: 027 | loss: 0.33284 - acc: 0.8640 -- iter: 0416/3680
[A[ATraining Step: 3004  | total loss: [1m[32m0.34297[0m[0m
[2K| Adam | epoch: 027 | loss: 0.34297 - acc: 0.8557 -- iter: 0448/3680
[A[ATraining Step: 3005  | total loss: [1m[32m0.33798[0m[0m
[2K| Adam | epoch: 027 | loss: 0.33798 - acc: 0.8576 -- iter: 0480/3680
[A[ATraining Step: 3006  | total loss: [1m[32m0.32865[0m[0m
[2K| Adam | epoch: 027 | loss: 0.32865 - acc: 0.8625 -- iter: 0512/3680
[A[ATraining Step: 3007  | total loss: [1m[32m0.33951[0m[0m
[2K| Adam | epoch: 027 | loss: 0.33951 - acc: 0.8544 -- iter: 0544/3680
[A[ATraining Step: 3008  | total loss: [1m[32m0.33499[0m[0m
[2K| Adam | epoch: 027 | loss: 0.33499 - acc: 0.8595 -- iter: 0576/3680
[A[ATraining Step: 3009  | total loss: [1m[32m0.34245[0m[0m
[2K| Adam | epoch: 027 | loss: 0.34245 - acc: 0.8294 -- iter: 0608/3680
[A[ATraining Step: 3010  | total loss: [1m[32m0.36348[0m[0m
[2K| Adam | epoch: 027 | loss: 0.36348 - acc: 0.8294 -- iter: 0640/3680
[A[ATraining Step: 3011  | total loss: [1m[32m0.39135[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39135 - acc: 0.8183 -- iter: 0672/3680
[A[ATraining Step: 3012  | total loss: [1m[32m0.38350[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38350 - acc: 0.8271 -- iter: 0704/3680
[A[ATraining Step: 3013  | total loss: [1m[32m0.39804[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39804 - acc: 0.8194 -- iter: 0736/3680
[A[ATraining Step: 3014  | total loss: [1m[32m0.40763[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40763 - acc: 0.8218 -- iter: 0768/3680
[A[ATraining Step: 3015  | total loss: [1m[32m0.40027[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40027 - acc: 0.8271 -- iter: 0800/3680
[A[ATraining Step: 3016  | total loss: [1m[32m0.42059[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42059 - acc: 0.8100 -- iter: 0832/3680
[A[ATraining Step: 3017  | total loss: [1m[32m0.43782[0m[0m
[2K| Adam | epoch: 027 | loss: 0.43782 - acc: 0.7978 -- iter: 0864/3680
[A[ATraining Step: 3018  | total loss: [1m[32m0.42962[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42962 - acc: 0.8024 -- iter: 0896/3680
[A[ATraining Step: 3019  | total loss: [1m[32m0.42503[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42503 - acc: 0.8065 -- iter: 0928/3680
[A[ATraining Step: 3020  | total loss: [1m[32m0.40799[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40799 - acc: 0.8196 -- iter: 0960/3680
[A[ATraining Step: 3021  | total loss: [1m[32m0.40769[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40769 - acc: 0.8158 -- iter: 0992/3680
[A[ATraining Step: 3022  | total loss: [1m[32m0.40088[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40088 - acc: 0.8277 -- iter: 1024/3680
[A[ATraining Step: 3023  | total loss: [1m[32m0.40078[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40078 - acc: 0.8261 -- iter: 1056/3680
[A[ATraining Step: 3024  | total loss: [1m[32m0.40547[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40547 - acc: 0.8261 -- iter: 1088/3680
[A[ATraining Step: 3025  | total loss: [1m[32m0.39225[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39225 - acc: 0.8373 -- iter: 1120/3680
[A[ATraining Step: 3026  | total loss: [1m[32m0.38299[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38299 - acc: 0.8411 -- iter: 1152/3680
[A[ATraining Step: 3027  | total loss: [1m[32m0.38624[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38624 - acc: 0.8382 -- iter: 1184/3680
[A[ATraining Step: 3028  | total loss: [1m[32m0.37635[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37635 - acc: 0.8450 -- iter: 1216/3680
[A[ATraining Step: 3029  | total loss: [1m[32m0.37406[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37406 - acc: 0.8449 -- iter: 1248/3680
[A[ATraining Step: 3030  | total loss: [1m[32m0.38348[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38348 - acc: 0.8385 -- iter: 1280/3680
[A[ATraining Step: 3031  | total loss: [1m[32m0.38344[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38344 - acc: 0.8390 -- iter: 1312/3680
[A[ATraining Step: 3032  | total loss: [1m[32m0.37035[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37035 - acc: 0.8331 -- iter: 1344/3680
[A[ATraining Step: 3033  | total loss: [1m[32m0.38238[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38238 - acc: 0.8331 -- iter: 1376/3680
[A[ATraining Step: 3034  | total loss: [1m[32m0.38309[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38309 - acc: 0.8373 -- iter: 1408/3680
[A[ATraining Step: 3035  | total loss: [1m[32m0.37862[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37862 - acc: 0.8410 -- iter: 1440/3680
[A[ATraining Step: 3036  | total loss: [1m[32m0.37353[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37353 - acc: 0.8382 -- iter: 1472/3680
[A[ATraining Step: 3037  | total loss: [1m[32m0.37946[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37946 - acc: 0.8325 -- iter: 1504/3680
[A[ATraining Step: 3038  | total loss: [1m[32m0.37869[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37869 - acc: 0.8399 -- iter: 1536/3680
[A[ATraining Step: 3039  | total loss: [1m[32m0.39721[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39721 - acc: 0.8246 -- iter: 1568/3680
[A[ATraining Step: 3040  | total loss: [1m[32m0.39913[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39913 - acc: 0.8234 -- iter: 1600/3680
[A[ATraining Step: 3041  | total loss: [1m[32m0.41120[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41120 - acc: 0.8192 -- iter: 1632/3680
[A[ATraining Step: 3042  | total loss: [1m[32m0.40938[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40938 - acc: 0.8217 -- iter: 1664/3680
[A[ATraining Step: 3043  | total loss: [1m[32m0.39675[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39675 - acc: 0.8270 -- iter: 1696/3680
[A[ATraining Step: 3044  | total loss: [1m[32m0.38792[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38792 - acc: 0.8380 -- iter: 1728/3680
[A[ATraining Step: 3045  | total loss: [1m[32m0.38722[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38722 - acc: 0.8386 -- iter: 1760/3680
[A[ATraining Step: 3046  | total loss: [1m[32m0.38400[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38400 - acc: 0.8391 -- iter: 1792/3680
[A[ATraining Step: 3047  | total loss: [1m[32m0.37372[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37372 - acc: 0.8396 -- iter: 1824/3680
[A[ATraining Step: 3048  | total loss: [1m[32m0.37869[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37869 - acc: 0.8338 -- iter: 1856/3680
[A[ATraining Step: 3049  | total loss: [1m[32m0.38404[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38404 - acc: 0.8263 -- iter: 1888/3680
[A[ATraining Step: 3050  | total loss: [1m[32m0.39917[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39917 - acc: 0.8263 -- iter: 1920/3680
[A[ATraining Step: 3051  | total loss: [1m[32m0.39241[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39241 - acc: 0.8280 -- iter: 1952/3680
[A[ATraining Step: 3052  | total loss: [1m[32m0.40201[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40201 - acc: 0.8265 -- iter: 1984/3680
[A[ATraining Step: 3053  | total loss: [1m[32m0.39356[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39356 - acc: 0.8282 -- iter: 2016/3680
[A[ATraining Step: 3054  | total loss: [1m[32m0.39640[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39640 - acc: 0.8329 -- iter: 2048/3680
[A[ATraining Step: 3055  | total loss: [1m[32m0.41099[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41099 - acc: 0.8246 -- iter: 2080/3680
[A[ATraining Step: 3056  | total loss: [1m[32m0.40836[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40836 - acc: 0.8234 -- iter: 2112/3680
[A[ATraining Step: 3057  | total loss: [1m[32m0.40982[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40982 - acc: 0.8192 -- iter: 2144/3680
[A[ATraining Step: 3058  | total loss: [1m[32m0.40027[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40027 - acc: 0.8310 -- iter: 2176/3680
[A[ATraining Step: 3059  | total loss: [1m[32m0.39811[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39811 - acc: 0.8354 -- iter: 2208/3680
[A[ATraining Step: 3060  | total loss: [1m[32m0.41926[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41926 - acc: 0.8257 -- iter: 2240/3680
[A[ATraining Step: 3061  | total loss: [1m[32m0.41926[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41926 - acc: 0.8257 -- iter: 2272/3680
[A[ATraining Step: 3062  | total loss: [1m[32m0.41863[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41863 - acc: 0.8213 -- iter: 2304/3680
[A[ATraining Step: 3063  | total loss: [1m[32m0.42933[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42933 - acc: 0.8110 -- iter: 2336/3680
[A[ATraining Step: 3064  | total loss: [1m[32m0.41960[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41960 - acc: 0.8174 -- iter: 2368/3680
[A[ATraining Step: 3065  | total loss: [1m[32m0.41195[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41195 - acc: 0.8169 -- iter: 2400/3680
[A[ATraining Step: 3066  | total loss: [1m[32m0.40874[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40874 - acc: 0.8196 -- iter: 2432/3680
[A[ATraining Step: 3067  | total loss: [1m[32m0.41055[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41055 - acc: 0.8189 -- iter: 2464/3680
[A[ATraining Step: 3068  | total loss: [1m[32m0.39551[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39551 - acc: 0.8308 -- iter: 2496/3680
[A[ATraining Step: 3069  | total loss: [1m[32m0.39233[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39233 - acc: 0.8352 -- iter: 2528/3680
[A[ATraining Step: 3070  | total loss: [1m[32m0.39012[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39012 - acc: 0.8329 -- iter: 2560/3680
[A[ATraining Step: 3071  | total loss: [1m[32m0.38862[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38862 - acc: 0.8309 -- iter: 2592/3680
[A[ATraining Step: 3072  | total loss: [1m[32m0.38444[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38444 - acc: 0.8290 -- iter: 2624/3680
[A[ATraining Step: 3073  | total loss: [1m[32m0.39467[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39467 - acc: 0.8305 -- iter: 2656/3680
[A[ATraining Step: 3074  | total loss: [1m[32m0.39636[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39636 - acc: 0.8287 -- iter: 2688/3680
[A[ATraining Step: 3075  | total loss: [1m[32m0.40591[0m[0m
[2K| Adam | epoch: 027 | loss: 0.40591 - acc: 0.8302 -- iter: 2720/3680
[A[ATraining Step: 3076  | total loss: [1m[32m0.41779[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41779 - acc: 0.8222 -- iter: 2752/3680
[A[ATraining Step: 3077  | total loss: [1m[32m0.42655[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42655 - acc: 0.8212 -- iter: 2784/3680
[A[ATraining Step: 3078  | total loss: [1m[32m0.42029[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42029 - acc: 0.8266 -- iter: 2816/3680
[A[ATraining Step: 3079  | total loss: [1m[32m0.43271[0m[0m
[2K| Adam | epoch: 027 | loss: 0.43271 - acc: 0.8127 -- iter: 2848/3680
[A[ATraining Step: 3080  | total loss: [1m[32m0.43368[0m[0m
[2K| Adam | epoch: 027 | loss: 0.43368 - acc: 0.8158 -- iter: 2880/3680
[A[ATraining Step: 3081  | total loss: [1m[32m0.43248[0m[0m
[2K| Adam | epoch: 027 | loss: 0.43248 - acc: 0.8123 -- iter: 2912/3680
[A[ATraining Step: 3082  | total loss: [1m[32m0.42396[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42396 - acc: 0.8217 -- iter: 2944/3680
[A[ATraining Step: 3083  | total loss: [1m[32m0.43209[0m[0m
[2K| Adam | epoch: 027 | loss: 0.43209 - acc: 0.8114 -- iter: 2976/3680
[A[ATraining Step: 3084  | total loss: [1m[32m0.43394[0m[0m
[2K| Adam | epoch: 027 | loss: 0.43394 - acc: 0.7990 -- iter: 3008/3680
[A[ATraining Step: 3085  | total loss: [1m[32m0.42059[0m[0m
[2K| Adam | epoch: 027 | loss: 0.42059 - acc: 0.8035 -- iter: 3040/3680
[A[ATraining Step: 3086  | total loss: [1m[32m0.41648[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41648 - acc: 0.8107 -- iter: 3072/3680
[A[ATraining Step: 3087  | total loss: [1m[32m0.41973[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41973 - acc: 0.8046 -- iter: 3104/3680
[A[ATraining Step: 3088  | total loss: [1m[32m0.41675[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41675 - acc: 0.8054 -- iter: 3136/3680
[A[ATraining Step: 3089  | total loss: [1m[32m0.39898[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39898 - acc: 0.8217 -- iter: 3168/3680
[A[ATraining Step: 3090  | total loss: [1m[32m0.38503[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38503 - acc: 0.8302 -- iter: 3200/3680
[A[ATraining Step: 3091  | total loss: [1m[32m0.38439[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38439 - acc: 0.8284 -- iter: 3232/3680
[A[ATraining Step: 3092  | total loss: [1m[32m0.37613[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37613 - acc: 0.8331 -- iter: 3264/3680
[A[ATraining Step: 3093  | total loss: [1m[32m0.38065[0m[0m
[2K| Adam | epoch: 027 | loss: 0.38065 - acc: 0.8373 -- iter: 3296/3680
[A[ATraining Step: 3094  | total loss: [1m[32m0.37594[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37594 - acc: 0.8379 -- iter: 3328/3680
[A[ATraining Step: 3095  | total loss: [1m[32m0.36121[0m[0m
[2K| Adam | epoch: 027 | loss: 0.36121 - acc: 0.8541 -- iter: 3360/3680
[A[ATraining Step: 3096  | total loss: [1m[32m0.37186[0m[0m
[2K| Adam | epoch: 027 | loss: 0.37186 - acc: 0.8375 -- iter: 3392/3680
[A[ATraining Step: 3097  | total loss: [1m[32m0.39240[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39240 - acc: 0.8256 -- iter: 3424/3680
[A[ATraining Step: 3098  | total loss: [1m[32m0.39116[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39116 - acc: 0.8243 -- iter: 3456/3680
[A[ATraining Step: 3099  | total loss: [1m[32m0.39121[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39121 - acc: 0.8262 -- iter: 3488/3680
[A[ATraining Step: 3100  | total loss: [1m[32m0.39847[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39847 - acc: 0.8155 | val_loss: 0.36549 - val_acc: 0.8534 -- iter: 3520/3680
[A[ATraining Step: 3100  | total loss: [1m[32m0.39847[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39847 - acc: 0.8155 | val_loss: 0.36549 - val_acc: 0.8534 -- iter: 3520/3680
--
Training Step: 3101  | total loss: [1m[32m0.39861[0m[0m
[2K| Adam | epoch: 027 | loss: 0.39861 - acc: 0.8089 -- iter: 3552/3680
[A[ATraining Step: 3102  | total loss: [1m[32m0.41530[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41530 - acc: 0.8062 -- iter: 3584/3680
[A[ATraining Step: 3103  | total loss: [1m[32m0.41366[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41366 - acc: 0.8099 -- iter: 3616/3680
[A[ATraining Step: 3104  | total loss: [1m[32m0.41930[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41930 - acc: 0.8071 -- iter: 3648/3680
[A[ATraining Step: 3105  | total loss: [1m[32m0.41466[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41466 - acc: 0.8076 | val_loss: 0.37464 - val_acc: 0.8491 -- iter: 3680/3680
[A[ATraining Step: 3105  | total loss: [1m[32m0.41466[0m[0m
[2K| Adam | epoch: 027 | loss: 0.41466 - acc: 0.8076 | val_loss: 0.37464 - val_acc: 0.8491 -- iter: 3680/3680
--
Training Step: 3106  | total loss: [1m[32m0.41519[0m[0m
[2K| Adam | epoch: 028 | loss: 0.41519 - acc: 0.8050 -- iter: 0032/3680
[A[ATraining Step: 3107  | total loss: [1m[32m0.41934[0m[0m
[2K| Adam | epoch: 028 | loss: 0.41934 - acc: 0.8057 -- iter: 0064/3680
[A[ATraining Step: 3108  | total loss: [1m[32m0.42198[0m[0m
[2K| Adam | epoch: 028 | loss: 0.42198 - acc: 0.8126 -- iter: 0096/3680
[A[ATraining Step: 3109  | total loss: [1m[32m0.40481[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40481 - acc: 0.8220 -- iter: 0128/3680
[A[ATraining Step: 3110  | total loss: [1m[32m0.39878[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39878 - acc: 0.8304 -- iter: 0160/3680
[A[ATraining Step: 3111  | total loss: [1m[32m0.40356[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40356 - acc: 0.8224 -- iter: 0192/3680
[A[ATraining Step: 3112  | total loss: [1m[32m0.39261[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39261 - acc: 0.8339 -- iter: 0224/3680
[A[ATraining Step: 3113  | total loss: [1m[32m0.39503[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39503 - acc: 0.8286 -- iter: 0256/3680
[A[ATraining Step: 3114  | total loss: [1m[32m0.39562[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39562 - acc: 0.8364 -- iter: 0288/3680
[A[ATraining Step: 3115  | total loss: [1m[32m0.39552[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39552 - acc: 0.8350 -- iter: 0320/3680
[A[ATraining Step: 3116  | total loss: [1m[32m0.39111[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39111 - acc: 0.8350 -- iter: 0352/3680
[A[ATraining Step: 3117  | total loss: [1m[32m0.37513[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37513 - acc: 0.8390 -- iter: 0384/3680
[A[ATraining Step: 3118  | total loss: [1m[32m0.36308[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36308 - acc: 0.8457 -- iter: 0416/3680
[A[ATraining Step: 3119  | total loss: [1m[32m0.36677[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36677 - acc: 0.8486 -- iter: 0448/3680
[A[ATraining Step: 3120  | total loss: [1m[32m0.37313[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37313 - acc: 0.8419 -- iter: 0480/3680
[A[ATraining Step: 3121  | total loss: [1m[32m0.37293[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37293 - acc: 0.8358 -- iter: 0512/3680
[A[ATraining Step: 3122  | total loss: [1m[32m0.35531[0m[0m
[2K| Adam | epoch: 028 | loss: 0.35531 - acc: 0.8523 -- iter: 0544/3680
[A[ATraining Step: 3123  | total loss: [1m[32m0.34921[0m[0m
[2K| Adam | epoch: 028 | loss: 0.34921 - acc: 0.8577 -- iter: 0576/3680
[A[ATraining Step: 3124  | total loss: [1m[32m0.33886[0m[0m
[2K| Adam | epoch: 028 | loss: 0.33886 - acc: 0.8625 -- iter: 0608/3680
[A[ATraining Step: 3125  | total loss: [1m[32m0.35442[0m[0m
[2K| Adam | epoch: 028 | loss: 0.35442 - acc: 0.8544 -- iter: 0640/3680
[A[ATraining Step: 3126  | total loss: [1m[32m0.35917[0m[0m
[2K| Adam | epoch: 028 | loss: 0.35917 - acc: 0.8533 -- iter: 0672/3680
[A[ATraining Step: 3127  | total loss: [1m[32m0.36643[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36643 - acc: 0.8524 -- iter: 0704/3680
[A[ATraining Step: 3128  | total loss: [1m[32m0.38446[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38446 - acc: 0.8453 -- iter: 0736/3680
[A[ATraining Step: 3129  | total loss: [1m[32m0.38706[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38706 - acc: 0.8389 -- iter: 0768/3680
[A[ATraining Step: 3130  | total loss: [1m[32m0.37930[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37930 - acc: 0.8456 -- iter: 0800/3680
[A[ATraining Step: 3131  | total loss: [1m[32m0.39698[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39698 - acc: 0.8329 -- iter: 0832/3680
[A[ATraining Step: 3132  | total loss: [1m[32m0.39291[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39291 - acc: 0.8371 -- iter: 0864/3680
[A[ATraining Step: 3133  | total loss: [1m[32m0.38708[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38708 - acc: 0.8378 -- iter: 0896/3680
[A[ATraining Step: 3134  | total loss: [1m[32m0.38318[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38318 - acc: 0.8415 -- iter: 0928/3680
[A[ATraining Step: 3135  | total loss: [1m[32m0.37731[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37731 - acc: 0.8417 -- iter: 0960/3680
[A[ATraining Step: 3136  | total loss: [1m[32m0.38472[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38472 - acc: 0.8419 -- iter: 0992/3680
[A[ATraining Step: 3137  | total loss: [1m[32m0.39055[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39055 - acc: 0.8327 -- iter: 1024/3680
[A[ATraining Step: 3138  | total loss: [1m[32m0.39235[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39235 - acc: 0.8307 -- iter: 1056/3680
[A[ATraining Step: 3139  | total loss: [1m[32m0.39701[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39701 - acc: 0.8320 -- iter: 1088/3680
[A[ATraining Step: 3140  | total loss: [1m[32m0.39068[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39068 - acc: 0.8363 -- iter: 1120/3680
[A[ATraining Step: 3141  | total loss: [1m[32m0.38918[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38918 - acc: 0.8402 -- iter: 1152/3680
[A[ATraining Step: 3142  | total loss: [1m[32m0.38265[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38265 - acc: 0.8468 -- iter: 1184/3680
[A[ATraining Step: 3143  | total loss: [1m[32m0.39497[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39497 - acc: 0.8434 -- iter: 1216/3680
[A[ATraining Step: 3144  | total loss: [1m[32m0.38479[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38479 - acc: 0.8528 -- iter: 1248/3680
[A[ATraining Step: 3145  | total loss: [1m[32m0.38602[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38602 - acc: 0.8487 -- iter: 1280/3680
[A[ATraining Step: 3146  | total loss: [1m[32m0.37694[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37694 - acc: 0.8514 -- iter: 1312/3680
[A[ATraining Step: 3147  | total loss: [1m[32m0.36521[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36521 - acc: 0.8569 -- iter: 1344/3680
[A[ATraining Step: 3148  | total loss: [1m[32m0.36433[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36433 - acc: 0.8555 -- iter: 1376/3680
[A[ATraining Step: 3149  | total loss: [1m[32m0.36758[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36758 - acc: 0.8512 -- iter: 1408/3680
[A[ATraining Step: 3150  | total loss: [1m[32m0.37125[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37125 - acc: 0.8411 -- iter: 1440/3680
[A[ATraining Step: 3151  | total loss: [1m[32m0.36926[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36926 - acc: 0.8383 -- iter: 1472/3680
[A[ATraining Step: 3152  | total loss: [1m[32m0.39976[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39976 - acc: 0.8201 -- iter: 1504/3680
[A[ATraining Step: 3153  | total loss: [1m[32m0.38966[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38966 - acc: 0.8287 -- iter: 1536/3680
[A[ATraining Step: 3154  | total loss: [1m[32m0.40394[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40394 - acc: 0.8271 -- iter: 1568/3680
[A[ATraining Step: 3155  | total loss: [1m[32m0.40715[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40715 - acc: 0.8194 -- iter: 1600/3680
[A[ATraining Step: 3156  | total loss: [1m[32m0.41131[0m[0m
[2K| Adam | epoch: 028 | loss: 0.41131 - acc: 0.8124 -- iter: 1632/3680
[A[ATraining Step: 3157  | total loss: [1m[32m0.41133[0m[0m
[2K| Adam | epoch: 028 | loss: 0.41133 - acc: 0.8187 -- iter: 1664/3680
[A[ATraining Step: 3158  | total loss: [1m[32m0.40952[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40952 - acc: 0.8149 -- iter: 1696/3680
[A[ATraining Step: 3159  | total loss: [1m[32m0.40075[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40075 - acc: 0.8241 -- iter: 1728/3680
[A[ATraining Step: 3160  | total loss: [1m[32m0.39744[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39744 - acc: 0.8292 -- iter: 1760/3680
[A[ATraining Step: 3161  | total loss: [1m[32m0.38196[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38196 - acc: 0.8376 -- iter: 1792/3680
[A[ATraining Step: 3162  | total loss: [1m[32m0.38165[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38165 - acc: 0.8376 -- iter: 1824/3680
[A[ATraining Step: 3163  | total loss: [1m[32m0.38599[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38599 - acc: 0.8288 -- iter: 1856/3680
[A[ATraining Step: 3164  | total loss: [1m[32m0.38565[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38565 - acc: 0.8272 -- iter: 1888/3680
[A[ATraining Step: 3165  | total loss: [1m[32m0.38567[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38567 - acc: 0.8351 -- iter: 1920/3680
[A[ATraining Step: 3166  | total loss: [1m[32m0.38360[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38360 - acc: 0.8328 -- iter: 1952/3680
[A[ATraining Step: 3167  | total loss: [1m[32m0.37552[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37552 - acc: 0.8370 -- iter: 1984/3680
[A[ATraining Step: 3168  | total loss: [1m[32m0.37353[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37353 - acc: 0.8408 -- iter: 2016/3680
[A[ATraining Step: 3169  | total loss: [1m[32m0.37780[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37780 - acc: 0.8411 -- iter: 2048/3680
[A[ATraining Step: 3170  | total loss: [1m[32m0.38281[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38281 - acc: 0.8351 -- iter: 2080/3680
[A[ATraining Step: 3171  | total loss: [1m[32m0.38107[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38107 - acc: 0.8391 -- iter: 2112/3680
[A[ATraining Step: 3172  | total loss: [1m[32m0.38589[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38589 - acc: 0.8365 -- iter: 2144/3680
[A[ATraining Step: 3173  | total loss: [1m[32m0.37435[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37435 - acc: 0.8434 -- iter: 2176/3680
[A[ATraining Step: 3174  | total loss: [1m[32m0.37380[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37380 - acc: 0.8372 -- iter: 2208/3680
[A[ATraining Step: 3175  | total loss: [1m[32m0.38402[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38402 - acc: 0.8316 -- iter: 2240/3680
[A[ATraining Step: 3176  | total loss: [1m[32m0.38554[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38554 - acc: 0.8328 -- iter: 2272/3680
[A[ATraining Step: 3177  | total loss: [1m[32m0.38533[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38533 - acc: 0.8339 -- iter: 2304/3680
[A[ATraining Step: 3178  | total loss: [1m[32m0.37326[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37326 - acc: 0.8380 -- iter: 2336/3680
[A[ATraining Step: 3179  | total loss: [1m[32m0.38178[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38178 - acc: 0.8355 -- iter: 2368/3680
[A[ATraining Step: 3180  | total loss: [1m[32m0.38505[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38505 - acc: 0.8332 -- iter: 2400/3680
[A[ATraining Step: 3181  | total loss: [1m[32m0.36660[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36660 - acc: 0.8436 -- iter: 2432/3680
[A[ATraining Step: 3182  | total loss: [1m[32m0.38397[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38397 - acc: 0.8343 -- iter: 2464/3680
[A[ATraining Step: 3183  | total loss: [1m[32m0.37113[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37113 - acc: 0.8477 -- iter: 2496/3680
[A[ATraining Step: 3184  | total loss: [1m[32m0.37964[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37964 - acc: 0.8411 -- iter: 2528/3680
[A[ATraining Step: 3185  | total loss: [1m[32m0.38894[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38894 - acc: 0.8320 -- iter: 2560/3680
[A[ATraining Step: 3186  | total loss: [1m[32m0.39749[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39749 - acc: 0.8331 -- iter: 2592/3680
[A[ATraining Step: 3187  | total loss: [1m[32m0.39424[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39424 - acc: 0.8311 -- iter: 2624/3680
[A[ATraining Step: 3188  | total loss: [1m[32m0.39908[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39908 - acc: 0.8261 -- iter: 2656/3680
[A[ATraining Step: 3189  | total loss: [1m[32m0.39875[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39875 - acc: 0.8279 -- iter: 2688/3680
[A[ATraining Step: 3190  | total loss: [1m[32m0.39580[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39580 - acc: 0.8263 -- iter: 2720/3680
[A[ATraining Step: 3191  | total loss: [1m[32m0.40177[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40177 - acc: 0.8281 -- iter: 2752/3680
[A[ATraining Step: 3192  | total loss: [1m[32m0.39583[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39583 - acc: 0.8265 -- iter: 2784/3680
[A[ATraining Step: 3193  | total loss: [1m[32m0.39398[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39398 - acc: 0.8251 -- iter: 2816/3680
[A[ATraining Step: 3194  | total loss: [1m[32m0.39786[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39786 - acc: 0.8332 -- iter: 2848/3680
[A[ATraining Step: 3195  | total loss: [1m[32m0.38494[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38494 - acc: 0.8374 -- iter: 2880/3680
[A[ATraining Step: 3196  | total loss: [1m[32m0.37445[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37445 - acc: 0.8499 -- iter: 2912/3680
[A[ATraining Step: 3197  | total loss: [1m[32m0.37569[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37569 - acc: 0.8499 -- iter: 2944/3680
[A[ATraining Step: 3198  | total loss: [1m[32m0.36980[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36980 - acc: 0.8524 -- iter: 2976/3680
[A[ATraining Step: 3199  | total loss: [1m[32m0.36460[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36460 - acc: 0.8578 -- iter: 3008/3680
[A[ATraining Step: 3200  | total loss: [1m[32m0.37198[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37198 - acc: 0.8532 | val_loss: 0.39387 - val_acc: 0.8241 -- iter: 3040/3680
[A[ATraining Step: 3200  | total loss: [1m[32m0.37198[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37198 - acc: 0.8532 | val_loss: 0.39387 - val_acc: 0.8241 -- iter: 3040/3680
--
Training Step: 3201  | total loss: [1m[32m0.36764[0m[0m
[2K| Adam | epoch: 028 | loss: 0.36764 - acc: 0.8523 -- iter: 3072/3680
[A[ATraining Step: 3202  | total loss: [1m[32m0.38381[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38381 - acc: 0.8421 -- iter: 3104/3680
[A[ATraining Step: 3203  | total loss: [1m[32m0.38041[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38041 - acc: 0.8422 -- iter: 3136/3680
[A[ATraining Step: 3204  | total loss: [1m[32m0.37238[0m[0m
[2K| Adam | epoch: 028 | loss: 0.37238 - acc: 0.8518 -- iter: 3168/3680
[A[ATraining Step: 3205  | total loss: [1m[32m0.38932[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38932 - acc: 0.8353 -- iter: 3200/3680
[A[ATraining Step: 3206  | total loss: [1m[32m0.39422[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39422 - acc: 0.8299 -- iter: 3232/3680
[A[ATraining Step: 3207  | total loss: [1m[32m0.39944[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39944 - acc: 0.8251 -- iter: 3264/3680
[A[ATraining Step: 3208  | total loss: [1m[32m0.40914[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40914 - acc: 0.8238 -- iter: 3296/3680
[A[ATraining Step: 3209  | total loss: [1m[32m0.40441[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40441 - acc: 0.8289 -- iter: 3328/3680
[A[ATraining Step: 3210  | total loss: [1m[32m0.39926[0m[0m
[2K| Adam | epoch: 028 | loss: 0.39926 - acc: 0.8273 -- iter: 3360/3680
[A[ATraining Step: 3211  | total loss: [1m[32m0.38790[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38790 - acc: 0.8289 -- iter: 3392/3680
[A[ATraining Step: 3212  | total loss: [1m[32m0.38735[0m[0m
[2K| Adam | epoch: 028 | loss: 0.38735 - acc: 0.8335 -- iter: 3424/3680
[A[ATraining Step: 3213  | total loss: [1m[32m0.40991[0m[0m
[2K| Adam | epoch: 028 | loss: 0.40991 - acc: 0.8252 -- iter: 3456/3680
[A[ATraining Step: 3214  | total loss: [1m[32m0.42047[0m[0m
[2K| Adam | epoch: 028 | loss: 0.42047 - acc: 0.8114 -- iter: 3488/3680
[A[ATraining Step: 3215  | total loss: [1m[32m0.42271[0m[0m
[2K| Adam | epoch: 028 | loss: 0.42271 - acc: 0.8115 -- iter: 3520/3680
[A[ATraining Step: 3216  | total loss: [1m[32m0.48747[0m[0m
[2K| Adam | epoch: 028 | loss: 0.48747 - acc: 0.7835 -- iter: 3552/3680
[A[ATraining Step: 3217  | total loss: [1m[32m0.47675[0m[0m
[2K| Adam | epoch: 028 | loss: 0.47675 - acc: 0.7833 -- iter: 3584/3680
[A[ATraining Step: 3218  | total loss: [1m[32m0.49484[0m[0m
[2K| Adam | epoch: 028 | loss: 0.49484 - acc: 0.7706 -- iter: 3616/3680
[A[ATraining Step: 3219  | total loss: [1m[32m0.49761[0m[0m
[2K| Adam | epoch: 028 | loss: 0.49761 - acc: 0.7685 -- iter: 3648/3680
[A[ATraining Step: 3220  | total loss: [1m[32m0.50459[0m[0m
[2K| Adam | epoch: 028 | loss: 0.50459 - acc: 0.7760 | val_loss: 0.37731 - val_acc: 0.8545 -- iter: 3680/3680
[A[ATraining Step: 3220  | total loss: [1m[32m0.50459[0m[0m
[2K| Adam | epoch: 028 | loss: 0.50459 - acc: 0.7760 | val_loss: 0.37731 - val_acc: 0.8545 -- iter: 3680/3680
--
Training Step: 3221  | total loss: [1m[32m0.49364[0m[0m
[2K| Adam | epoch: 029 | loss: 0.49364 - acc: 0.7859 -- iter: 0032/3680
[A[ATraining Step: 3222  | total loss: [1m[32m0.48076[0m[0m
[2K| Adam | epoch: 029 | loss: 0.48076 - acc: 0.7886 -- iter: 0064/3680
[A[ATraining Step: 3223  | total loss: [1m[32m0.47197[0m[0m
[2K| Adam | epoch: 029 | loss: 0.47197 - acc: 0.7972 -- iter: 0096/3680
[A[ATraining Step: 3224  | total loss: [1m[32m0.45985[0m[0m
[2K| Adam | epoch: 029 | loss: 0.45985 - acc: 0.8019 -- iter: 0128/3680
[A[ATraining Step: 3225  | total loss: [1m[32m0.44364[0m[0m
[2K| Adam | epoch: 029 | loss: 0.44364 - acc: 0.8123 -- iter: 0160/3680
[A[ATraining Step: 3226  | total loss: [1m[32m0.44150[0m[0m
[2K| Adam | epoch: 029 | loss: 0.44150 - acc: 0.8092 -- iter: 0192/3680
[A[ATraining Step: 3227  | total loss: [1m[32m0.44371[0m[0m
[2K| Adam | epoch: 029 | loss: 0.44371 - acc: 0.8092 -- iter: 0224/3680
[A[ATraining Step: 3228  | total loss: [1m[32m0.43120[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43120 - acc: 0.8189 -- iter: 0256/3680
[A[ATraining Step: 3229  | total loss: [1m[32m0.42942[0m[0m
[2K| Adam | epoch: 029 | loss: 0.42942 - acc: 0.8214 -- iter: 0288/3680
[A[ATraining Step: 3230  | total loss: [1m[32m0.43355[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43355 - acc: 0.8143 -- iter: 0320/3680
[A[ATraining Step: 3231  | total loss: [1m[32m0.42150[0m[0m
[2K| Adam | epoch: 029 | loss: 0.42150 - acc: 0.8203 -- iter: 0352/3680
[A[ATraining Step: 3232  | total loss: [1m[32m0.41701[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41701 - acc: 0.8258 -- iter: 0384/3680
[A[ATraining Step: 3233  | total loss: [1m[32m0.41480[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41480 - acc: 0.8245 -- iter: 0416/3680
[A[ATraining Step: 3234  | total loss: [1m[32m0.40087[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40087 - acc: 0.8358 -- iter: 0448/3680
[A[ATraining Step: 3235  | total loss: [1m[32m0.39499[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39499 - acc: 0.8397 -- iter: 0480/3680
[A[ATraining Step: 3236  | total loss: [1m[32m0.38585[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38585 - acc: 0.8401 -- iter: 0512/3680
[A[ATraining Step: 3237  | total loss: [1m[32m0.39698[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39698 - acc: 0.8311 -- iter: 0544/3680
[A[ATraining Step: 3238  | total loss: [1m[32m0.40131[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40131 - acc: 0.8324 -- iter: 0576/3680
[A[ATraining Step: 3239  | total loss: [1m[32m0.40172[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40172 - acc: 0.8304 -- iter: 0608/3680
[A[ATraining Step: 3240  | total loss: [1m[32m0.39409[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39409 - acc: 0.8317 -- iter: 0640/3680
[A[ATraining Step: 3241  | total loss: [1m[32m0.39168[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39168 - acc: 0.8298 -- iter: 0672/3680
[A[ATraining Step: 3242  | total loss: [1m[32m0.39365[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39365 - acc: 0.8312 -- iter: 0704/3680
[A[ATraining Step: 3243  | total loss: [1m[32m0.39700[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39700 - acc: 0.8231 -- iter: 0736/3680
[A[ATraining Step: 3244  | total loss: [1m[32m0.40215[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40215 - acc: 0.8158 -- iter: 0768/3680
[A[ATraining Step: 3245  | total loss: [1m[32m0.41598[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41598 - acc: 0.8061 -- iter: 0800/3680
[A[ATraining Step: 3246  | total loss: [1m[32m0.41231[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41231 - acc: 0.8130 -- iter: 0832/3680
[A[ATraining Step: 3247  | total loss: [1m[32m0.40847[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40847 - acc: 0.8129 -- iter: 0864/3680
[A[ATraining Step: 3248  | total loss: [1m[32m0.40769[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40769 - acc: 0.8160 -- iter: 0896/3680
[A[ATraining Step: 3249  | total loss: [1m[32m0.40628[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40628 - acc: 0.8188 -- iter: 0928/3680
[A[ATraining Step: 3250  | total loss: [1m[32m0.40266[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40266 - acc: 0.8150 -- iter: 0960/3680
[A[ATraining Step: 3251  | total loss: [1m[32m0.41893[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41893 - acc: 0.8085 -- iter: 0992/3680
[A[ATraining Step: 3252  | total loss: [1m[32m0.43618[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43618 - acc: 0.7964 -- iter: 1024/3680
[A[ATraining Step: 3253  | total loss: [1m[32m0.43671[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43671 - acc: 0.8043 -- iter: 1056/3680
[A[ATraining Step: 3254  | total loss: [1m[32m0.44773[0m[0m
[2K| Adam | epoch: 029 | loss: 0.44773 - acc: 0.7988 -- iter: 1088/3680
[A[ATraining Step: 3255  | total loss: [1m[32m0.43575[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43575 - acc: 0.8065 -- iter: 1120/3680
[A[ATraining Step: 3256  | total loss: [1m[32m0.42330[0m[0m
[2K| Adam | epoch: 029 | loss: 0.42330 - acc: 0.8133 -- iter: 1152/3680
[A[ATraining Step: 3257  | total loss: [1m[32m0.42742[0m[0m
[2K| Adam | epoch: 029 | loss: 0.42742 - acc: 0.8007 -- iter: 1184/3680
[A[ATraining Step: 3258  | total loss: [1m[32m0.40469[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40469 - acc: 0.8183 -- iter: 1216/3680
[A[ATraining Step: 3259  | total loss: [1m[32m0.40469[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40469 - acc: 0.8183 -- iter: 1248/3680
[A[ATraining Step: 3260  | total loss: [1m[32m0.39856[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39856 - acc: 0.8208 -- iter: 1280/3680
[A[ATraining Step: 3261  | total loss: [1m[32m0.38667[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38667 - acc: 0.8294 -- iter: 1312/3680
[A[ATraining Step: 3262  | total loss: [1m[32m0.39066[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39066 - acc: 0.8371 -- iter: 1344/3680
[A[ATraining Step: 3263  | total loss: [1m[32m0.38727[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38727 - acc: 0.8409 -- iter: 1376/3680
[A[ATraining Step: 3264  | total loss: [1m[32m0.38011[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38011 - acc: 0.8443 -- iter: 1408/3680
[A[ATraining Step: 3265  | total loss: [1m[32m0.37564[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37564 - acc: 0.8536 -- iter: 1440/3680
[A[ATraining Step: 3266  | total loss: [1m[32m0.37607[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37607 - acc: 0.8557 -- iter: 1472/3680
[A[ATraining Step: 3267  | total loss: [1m[32m0.37864[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37864 - acc: 0.8545 -- iter: 1504/3680
[A[ATraining Step: 3268  | total loss: [1m[32m0.37178[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37178 - acc: 0.8566 -- iter: 1536/3680
[A[ATraining Step: 3269  | total loss: [1m[32m0.36647[0m[0m
[2K| Adam | epoch: 029 | loss: 0.36647 - acc: 0.8584 -- iter: 1568/3680
[A[ATraining Step: 3270  | total loss: [1m[32m0.37861[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37861 - acc: 0.8570 -- iter: 1600/3680
[A[ATraining Step: 3271  | total loss: [1m[32m0.38696[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38696 - acc: 0.8556 -- iter: 1632/3680
[A[ATraining Step: 3272  | total loss: [1m[32m0.37926[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37926 - acc: 0.8576 -- iter: 1664/3680
[A[ATraining Step: 3273  | total loss: [1m[32m0.39760[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39760 - acc: 0.8437 -- iter: 1696/3680
[A[ATraining Step: 3274  | total loss: [1m[32m0.39940[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39940 - acc: 0.8406 -- iter: 1728/3680
[A[ATraining Step: 3275  | total loss: [1m[32m0.39351[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39351 - acc: 0.8409 -- iter: 1760/3680
[A[ATraining Step: 3276  | total loss: [1m[32m0.39266[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39266 - acc: 0.8349 -- iter: 1792/3680
[A[ATraining Step: 3277  | total loss: [1m[32m0.39226[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39226 - acc: 0.8389 -- iter: 1824/3680
[A[ATraining Step: 3278  | total loss: [1m[32m0.38789[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38789 - acc: 0.8363 -- iter: 1856/3680
[A[ATraining Step: 3279  | total loss: [1m[32m0.39915[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39915 - acc: 0.8308 -- iter: 1888/3680
[A[ATraining Step: 3280  | total loss: [1m[32m0.39214[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39214 - acc: 0.8321 -- iter: 1920/3680
[A[ATraining Step: 3281  | total loss: [1m[32m0.37615[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37615 - acc: 0.8426 -- iter: 1952/3680
[A[ATraining Step: 3282  | total loss: [1m[32m0.38081[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38081 - acc: 0.8396 -- iter: 1984/3680
[A[ATraining Step: 3283  | total loss: [1m[32m0.38488[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38488 - acc: 0.8369 -- iter: 2016/3680
[A[ATraining Step: 3284  | total loss: [1m[32m0.38277[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38277 - acc: 0.8438 -- iter: 2048/3680
[A[ATraining Step: 3285  | total loss: [1m[32m0.38079[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38079 - acc: 0.8438 -- iter: 2080/3680
[A[ATraining Step: 3286  | total loss: [1m[32m0.37222[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37222 - acc: 0.8469 -- iter: 2112/3680
[A[ATraining Step: 3287  | total loss: [1m[32m0.37854[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37854 - acc: 0.8341 -- iter: 2144/3680
[A[ATraining Step: 3288  | total loss: [1m[32m0.39152[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39152 - acc: 0.8257 -- iter: 2176/3680
[A[ATraining Step: 3289  | total loss: [1m[32m0.38583[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38583 - acc: 0.8275 -- iter: 2208/3680
[A[ATraining Step: 3290  | total loss: [1m[32m0.37541[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37541 - acc: 0.8323 -- iter: 2240/3680
[A[ATraining Step: 3291  | total loss: [1m[32m0.37430[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37430 - acc: 0.8334 -- iter: 2272/3680
[A[ATraining Step: 3292  | total loss: [1m[32m0.38613[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38613 - acc: 0.8282 -- iter: 2304/3680
[A[ATraining Step: 3293  | total loss: [1m[32m0.38450[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38450 - acc: 0.8298 -- iter: 2336/3680
[A[ATraining Step: 3294  | total loss: [1m[32m0.38941[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38941 - acc: 0.8280 -- iter: 2368/3680
[A[ATraining Step: 3295  | total loss: [1m[32m0.40341[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40341 - acc: 0.8202 -- iter: 2400/3680
[A[ATraining Step: 3296  | total loss: [1m[32m0.42055[0m[0m
[2K| Adam | epoch: 029 | loss: 0.42055 - acc: 0.8101 -- iter: 2432/3680
[A[ATraining Step: 3297  | total loss: [1m[32m0.40626[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40626 - acc: 0.8166 -- iter: 2464/3680
[A[ATraining Step: 3298  | total loss: [1m[32m0.40671[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40671 - acc: 0.8162 -- iter: 2496/3680
[A[ATraining Step: 3299  | total loss: [1m[32m0.39307[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39307 - acc: 0.8252 -- iter: 2528/3680
[A[ATraining Step: 3300  | total loss: [1m[32m0.39013[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39013 - acc: 0.8239 | val_loss: 0.36414 - val_acc: 0.8523 -- iter: 2560/3680
[A[ATraining Step: 3300  | total loss: [1m[32m0.39013[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39013 - acc: 0.8239 | val_loss: 0.36414 - val_acc: 0.8523 -- iter: 2560/3680
--
Training Step: 3301  | total loss: [1m[32m0.38229[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38229 - acc: 0.8259 -- iter: 2592/3680
[A[ATraining Step: 3302  | total loss: [1m[32m0.38217[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38217 - acc: 0.8152 -- iter: 2624/3680
[A[ATraining Step: 3303  | total loss: [1m[32m0.37527[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37527 - acc: 0.8212 -- iter: 2656/3680
[A[ATraining Step: 3304  | total loss: [1m[32m0.38756[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38756 - acc: 0.8203 -- iter: 2688/3680
[A[ATraining Step: 3305  | total loss: [1m[32m0.38771[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38771 - acc: 0.8195 -- iter: 2720/3680
[A[ATraining Step: 3306  | total loss: [1m[32m0.38919[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38919 - acc: 0.8219 -- iter: 2752/3680
[A[ATraining Step: 3307  | total loss: [1m[32m0.39812[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39812 - acc: 0.8054 -- iter: 2784/3680
[A[ATraining Step: 3308  | total loss: [1m[32m0.41436[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41436 - acc: 0.7998 -- iter: 2816/3680
[A[ATraining Step: 3309  | total loss: [1m[32m0.41805[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41805 - acc: 0.7980 -- iter: 2848/3680
[A[ATraining Step: 3310  | total loss: [1m[32m0.41328[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41328 - acc: 0.7994 -- iter: 2880/3680
[A[ATraining Step: 3311  | total loss: [1m[32m0.41065[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41065 - acc: 0.8070 -- iter: 2912/3680
[A[ATraining Step: 3312  | total loss: [1m[32m0.41726[0m[0m
[2K| Adam | epoch: 029 | loss: 0.41726 - acc: 0.7982 -- iter: 2944/3680
[A[ATraining Step: 3313  | total loss: [1m[32m0.40662[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40662 - acc: 0.8058 -- iter: 2976/3680
[A[ATraining Step: 3314  | total loss: [1m[32m0.40096[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40096 - acc: 0.8096 -- iter: 3008/3680
[A[ATraining Step: 3315  | total loss: [1m[32m0.38407[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38407 - acc: 0.8193 -- iter: 3040/3680
[A[ATraining Step: 3316  | total loss: [1m[32m0.38954[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38954 - acc: 0.8155 -- iter: 3072/3680
[A[ATraining Step: 3317  | total loss: [1m[32m0.38567[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38567 - acc: 0.8246 -- iter: 3104/3680
[A[ATraining Step: 3318  | total loss: [1m[32m0.38958[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38958 - acc: 0.8265 -- iter: 3136/3680
[A[ATraining Step: 3319  | total loss: [1m[32m0.39129[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39129 - acc: 0.8298 -- iter: 3168/3680
[A[ATraining Step: 3320  | total loss: [1m[32m0.38951[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38951 - acc: 0.8298 -- iter: 3200/3680
[A[ATraining Step: 3321  | total loss: [1m[32m0.39255[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39255 - acc: 0.8280 -- iter: 3232/3680
[A[ATraining Step: 3322  | total loss: [1m[32m0.39171[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39171 - acc: 0.8265 -- iter: 3264/3680
[A[ATraining Step: 3323  | total loss: [1m[32m0.39096[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39096 - acc: 0.8251 -- iter: 3296/3680
[A[ATraining Step: 3324  | total loss: [1m[32m0.38425[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38425 - acc: 0.8408 -- iter: 3328/3680
[A[ATraining Step: 3325  | total loss: [1m[32m0.37173[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37173 - acc: 0.8408 -- iter: 3360/3680
[A[ATraining Step: 3326  | total loss: [1m[32m0.37904[0m[0m
[2K| Adam | epoch: 029 | loss: 0.37904 - acc: 0.8317 -- iter: 3392/3680
[A[ATraining Step: 3327  | total loss: [1m[32m0.38327[0m[0m
[2K| Adam | epoch: 029 | loss: 0.38327 - acc: 0.8236 -- iter: 3424/3680
[A[ATraining Step: 3328  | total loss: [1m[32m0.39950[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39950 - acc: 0.8131 -- iter: 3456/3680
[A[ATraining Step: 3329  | total loss: [1m[32m0.40578[0m[0m
[2K| Adam | epoch: 029 | loss: 0.40578 - acc: 0.8130 -- iter: 3488/3680
[A[ATraining Step: 3330  | total loss: [1m[32m0.39609[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39609 - acc: 0.8255 -- iter: 3520/3680
[A[ATraining Step: 3331  | total loss: [1m[32m0.39435[0m[0m
[2K| Adam | epoch: 029 | loss: 0.39435 - acc: 0.8273 -- iter: 3552/3680
[A[ATraining Step: 3332  | total loss: [1m[32m0.47875[0m[0m
[2K| Adam | epoch: 029 | loss: 0.47875 - acc: 0.7914 -- iter: 3584/3680
[A[ATraining Step: 3333  | total loss: [1m[32m0.45524[0m[0m
[2K| Adam | epoch: 029 | loss: 0.45524 - acc: 0.8061 -- iter: 3616/3680
[A[ATraining Step: 3334  | total loss: [1m[32m0.43708[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43708 - acc: 0.8192 -- iter: 3648/3680
[A[ATraining Step: 3335  | total loss: [1m[32m0.43233[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43233 - acc: 0.8154 | val_loss: 0.36693 - val_acc: 0.8578 -- iter: 3680/3680
[A[ATraining Step: 3335  | total loss: [1m[32m0.43233[0m[0m
[2K| Adam | epoch: 029 | loss: 0.43233 - acc: 0.8154 | val_loss: 0.36693 - val_acc: 0.8578 -- iter: 3680/3680
--
Training Step: 3336  | total loss: [1m[32m0.42068[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42068 - acc: 0.8245 -- iter: 0032/3680
[A[ATraining Step: 3337  | total loss: [1m[32m0.41656[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41656 - acc: 0.8264 -- iter: 0064/3680
[A[ATraining Step: 3338  | total loss: [1m[32m0.41822[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41822 - acc: 0.8281 -- iter: 0096/3680
[A[ATraining Step: 3339  | total loss: [1m[32m0.41314[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41314 - acc: 0.8328 -- iter: 0128/3680
[A[ATraining Step: 3340  | total loss: [1m[32m0.42002[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42002 - acc: 0.8339 -- iter: 0160/3680
[A[ATraining Step: 3341  | total loss: [1m[32m0.41289[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41289 - acc: 0.8318 -- iter: 0192/3680
[A[ATraining Step: 3342  | total loss: [1m[32m0.41650[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41650 - acc: 0.8236 -- iter: 0224/3680
[A[ATraining Step: 3343  | total loss: [1m[32m0.42413[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42413 - acc: 0.8162 -- iter: 0256/3680
[A[ATraining Step: 3344  | total loss: [1m[32m0.41543[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41543 - acc: 0.8221 -- iter: 0288/3680
[A[ATraining Step: 3345  | total loss: [1m[32m0.40832[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40832 - acc: 0.8274 -- iter: 0320/3680
[A[ATraining Step: 3346  | total loss: [1m[32m0.39696[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39696 - acc: 0.8353 -- iter: 0352/3680
[A[ATraining Step: 3347  | total loss: [1m[32m0.41206[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41206 - acc: 0.8330 -- iter: 0384/3680
[A[ATraining Step: 3348  | total loss: [1m[32m0.41076[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41076 - acc: 0.8310 -- iter: 0416/3680
[A[ATraining Step: 3349  | total loss: [1m[32m0.41687[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41687 - acc: 0.8260 -- iter: 0448/3680
[A[ATraining Step: 3350  | total loss: [1m[32m0.41507[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41507 - acc: 0.8246 -- iter: 0480/3680
[A[ATraining Step: 3351  | total loss: [1m[32m0.41119[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41119 - acc: 0.8234 -- iter: 0512/3680
[A[ATraining Step: 3352  | total loss: [1m[32m0.41839[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41839 - acc: 0.8161 -- iter: 0544/3680
[A[ATraining Step: 3353  | total loss: [1m[32m0.42572[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42572 - acc: 0.8095 -- iter: 0576/3680
[A[ATraining Step: 3354  | total loss: [1m[32m0.42576[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42576 - acc: 0.8063 -- iter: 0608/3680
[A[ATraining Step: 3355  | total loss: [1m[32m0.42576[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42576 - acc: 0.8063 -- iter: 0640/3680
[A[ATraining Step: 3356  | total loss: [1m[32m0.41778[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41778 - acc: 0.8163 -- iter: 0672/3680
[A[ATraining Step: 3357  | total loss: [1m[32m0.41736[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41736 - acc: 0.8159 -- iter: 0704/3680
[A[ATraining Step: 3358  | total loss: [1m[32m0.41415[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41415 - acc: 0.8156 -- iter: 0736/3680
[A[ATraining Step: 3359  | total loss: [1m[32m0.40442[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40442 - acc: 0.8246 -- iter: 0768/3680
[A[ATraining Step: 3360  | total loss: [1m[32m0.40899[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40899 - acc: 0.8203 -- iter: 0800/3680
[A[ATraining Step: 3361  | total loss: [1m[32m0.39656[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39656 - acc: 0.8289 -- iter: 0832/3680
[A[ATraining Step: 3362  | total loss: [1m[32m0.39034[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39034 - acc: 0.8335 -- iter: 0864/3680
[A[ATraining Step: 3363  | total loss: [1m[32m0.38163[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38163 - acc: 0.8408 -- iter: 0896/3680
[A[ATraining Step: 3364  | total loss: [1m[32m0.38933[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38933 - acc: 0.8411 -- iter: 0928/3680
[A[ATraining Step: 3365  | total loss: [1m[32m0.39260[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39260 - acc: 0.8351 -- iter: 0960/3680
[A[ATraining Step: 3366  | total loss: [1m[32m0.39522[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39522 - acc: 0.8360 -- iter: 0992/3680
[A[ATraining Step: 3367  | total loss: [1m[32m0.39645[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39645 - acc: 0.8367 -- iter: 1024/3680
[A[ATraining Step: 3368  | total loss: [1m[32m0.38103[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38103 - acc: 0.8468 -- iter: 1056/3680
[A[ATraining Step: 3369  | total loss: [1m[32m0.38353[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38353 - acc: 0.8434 -- iter: 1088/3680
[A[ATraining Step: 3370  | total loss: [1m[32m0.38197[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38197 - acc: 0.8434 -- iter: 1120/3680
[A[ATraining Step: 3371  | total loss: [1m[32m0.38920[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38920 - acc: 0.8466 -- iter: 1152/3680
[A[ATraining Step: 3372  | total loss: [1m[32m0.38130[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38130 - acc: 0.8494 -- iter: 1184/3680
[A[ATraining Step: 3373  | total loss: [1m[32m0.37389[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37389 - acc: 0.8489 -- iter: 1216/3680
[A[ATraining Step: 3374  | total loss: [1m[32m0.37000[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37000 - acc: 0.8483 -- iter: 1248/3680
[A[ATraining Step: 3375  | total loss: [1m[32m0.36990[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36990 - acc: 0.8387 -- iter: 1280/3680
[A[ATraining Step: 3376  | total loss: [1m[32m0.37686[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37686 - acc: 0.8387 -- iter: 1312/3680
[A[ATraining Step: 3377  | total loss: [1m[32m0.37608[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37608 - acc: 0.8423 -- iter: 1344/3680
[A[ATraining Step: 3378  | total loss: [1m[32m0.37225[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37225 - acc: 0.8339 -- iter: 1376/3680
[A[ATraining Step: 3379  | total loss: [1m[32m0.37163[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37163 - acc: 0.8339 -- iter: 1408/3680
[A[ATraining Step: 3380  | total loss: [1m[32m0.37375[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37375 - acc: 0.8255 -- iter: 1440/3680
[A[ATraining Step: 3381  | total loss: [1m[32m0.37846[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37846 - acc: 0.8242 -- iter: 1472/3680
[A[ATraining Step: 3382  | total loss: [1m[32m0.36709[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36709 - acc: 0.8293 -- iter: 1504/3680
[A[ATraining Step: 3383  | total loss: [1m[32m0.37343[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37343 - acc: 0.8276 -- iter: 1536/3680
[A[ATraining Step: 3384  | total loss: [1m[32m0.35978[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35978 - acc: 0.8417 -- iter: 1568/3680
[A[ATraining Step: 3385  | total loss: [1m[32m0.34189[0m[0m
[2K| Adam | epoch: 030 | loss: 0.34189 - acc: 0.8544 -- iter: 1600/3680
[A[ATraining Step: 3386  | total loss: [1m[32m0.35562[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35562 - acc: 0.8533 -- iter: 1632/3680
[A[ATraining Step: 3387  | total loss: [1m[32m0.34461[0m[0m
[2K| Adam | epoch: 030 | loss: 0.34461 - acc: 0.8537 -- iter: 1664/3680
[A[ATraining Step: 3388  | total loss: [1m[32m0.35486[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35486 - acc: 0.8537 -- iter: 1696/3680
[A[ATraining Step: 3389  | total loss: [1m[32m0.34288[0m[0m
[2K| Adam | epoch: 030 | loss: 0.34288 - acc: 0.8590 -- iter: 1728/3680
[A[ATraining Step: 3390  | total loss: [1m[32m0.35117[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35117 - acc: 0.8512 -- iter: 1760/3680
[A[ATraining Step: 3391  | total loss: [1m[32m0.36656[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36656 - acc: 0.8411 -- iter: 1792/3680
[A[ATraining Step: 3392  | total loss: [1m[32m0.36049[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36049 - acc: 0.8413 -- iter: 1824/3680
[A[ATraining Step: 3393  | total loss: [1m[32m0.36008[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36008 - acc: 0.8478 -- iter: 1856/3680
[A[ATraining Step: 3394  | total loss: [1m[32m0.35665[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35665 - acc: 0.8505 -- iter: 1888/3680
[A[ATraining Step: 3395  | total loss: [1m[32m0.34854[0m[0m
[2K| Adam | epoch: 030 | loss: 0.34854 - acc: 0.8561 -- iter: 1920/3680
[A[ATraining Step: 3396  | total loss: [1m[32m0.35563[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35563 - acc: 0.8486 -- iter: 1952/3680
[A[ATraining Step: 3397  | total loss: [1m[32m0.35848[0m[0m
[2K| Adam | epoch: 030 | loss: 0.35848 - acc: 0.8481 -- iter: 1984/3680
[A[ATraining Step: 3398  | total loss: [1m[32m0.36317[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36317 - acc: 0.8446 -- iter: 2016/3680
[A[ATraining Step: 3399  | total loss: [1m[32m0.36730[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36730 - acc: 0.8414 -- iter: 2048/3680
[A[ATraining Step: 3400  | total loss: [1m[32m0.36610[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36610 - acc: 0.8447 | val_loss: 0.37243 - val_acc: 0.8469 -- iter: 2080/3680
[A[ATraining Step: 3400  | total loss: [1m[32m0.36610[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36610 - acc: 0.8447 | val_loss: 0.37243 - val_acc: 0.8469 -- iter: 2080/3680
--
Training Step: 3401  | total loss: [1m[32m0.36817[0m[0m
[2K| Adam | epoch: 030 | loss: 0.36817 - acc: 0.8415 -- iter: 2112/3680
[A[ATraining Step: 3402  | total loss: [1m[32m0.39284[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39284 - acc: 0.8292 -- iter: 2144/3680
[A[ATraining Step: 3403  | total loss: [1m[32m0.40608[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40608 - acc: 0.8119 -- iter: 2176/3680
[A[ATraining Step: 3404  | total loss: [1m[32m0.42408[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42408 - acc: 0.7995 -- iter: 2208/3680
[A[ATraining Step: 3405  | total loss: [1m[32m0.42271[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42271 - acc: 0.7945 -- iter: 2240/3680
[A[ATraining Step: 3406  | total loss: [1m[32m0.43138[0m[0m
[2K| Adam | epoch: 030 | loss: 0.43138 - acc: 0.7963 -- iter: 2272/3680
[A[ATraining Step: 3407  | total loss: [1m[32m0.43972[0m[0m
[2K| Adam | epoch: 030 | loss: 0.43972 - acc: 0.7917 -- iter: 2304/3680
[A[ATraining Step: 3408  | total loss: [1m[32m0.43238[0m[0m
[2K| Adam | epoch: 030 | loss: 0.43238 - acc: 0.8000 -- iter: 2336/3680
[A[ATraining Step: 3409  | total loss: [1m[32m0.44425[0m[0m
[2K| Adam | epoch: 030 | loss: 0.44425 - acc: 0.7857 -- iter: 2368/3680
[A[ATraining Step: 3410  | total loss: [1m[32m0.43113[0m[0m
[2K| Adam | epoch: 030 | loss: 0.43113 - acc: 0.7946 -- iter: 2400/3680
[A[ATraining Step: 3411  | total loss: [1m[32m0.42320[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42320 - acc: 0.8026 -- iter: 2432/3680
[A[ATraining Step: 3412  | total loss: [1m[32m0.43353[0m[0m
[2K| Adam | epoch: 030 | loss: 0.43353 - acc: 0.8005 -- iter: 2464/3680
[A[ATraining Step: 3413  | total loss: [1m[32m0.45340[0m[0m
[2K| Adam | epoch: 030 | loss: 0.45340 - acc: 0.7954 -- iter: 2496/3680
[A[ATraining Step: 3414  | total loss: [1m[32m0.43483[0m[0m
[2K| Adam | epoch: 030 | loss: 0.43483 - acc: 0.8096 -- iter: 2528/3680
[A[ATraining Step: 3415  | total loss: [1m[32m0.42240[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42240 - acc: 0.8162 -- iter: 2560/3680
[A[ATraining Step: 3416  | total loss: [1m[32m0.41419[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41419 - acc: 0.8189 -- iter: 2592/3680
[A[ATraining Step: 3417  | total loss: [1m[32m0.40539[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40539 - acc: 0.8277 -- iter: 2624/3680
[A[ATraining Step: 3418  | total loss: [1m[32m0.40908[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40908 - acc: 0.8230 -- iter: 2656/3680
[A[ATraining Step: 3419  | total loss: [1m[32m0.40854[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40854 - acc: 0.8189 -- iter: 2688/3680
[A[ATraining Step: 3420  | total loss: [1m[32m0.41255[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41255 - acc: 0.8151 -- iter: 2720/3680
[A[ATraining Step: 3421  | total loss: [1m[32m0.41123[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41123 - acc: 0.8180 -- iter: 2752/3680
[A[ATraining Step: 3422  | total loss: [1m[32m0.41008[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41008 - acc: 0.8205 -- iter: 2784/3680
[A[ATraining Step: 3423  | total loss: [1m[32m0.39349[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39349 - acc: 0.8303 -- iter: 2816/3680
[A[ATraining Step: 3424  | total loss: [1m[32m0.39327[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39327 - acc: 0.8303 -- iter: 2848/3680
[A[ATraining Step: 3425  | total loss: [1m[32m0.38514[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38514 - acc: 0.8347 -- iter: 2880/3680
[A[ATraining Step: 3426  | total loss: [1m[32m0.39629[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39629 - acc: 0.8325 -- iter: 2912/3680
[A[ATraining Step: 3427  | total loss: [1m[32m0.38868[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38868 - acc: 0.8368 -- iter: 2944/3680
[A[ATraining Step: 3428  | total loss: [1m[32m0.38197[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38197 - acc: 0.8375 -- iter: 2976/3680
[A[ATraining Step: 3429  | total loss: [1m[32m0.38015[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38015 - acc: 0.8381 -- iter: 3008/3680
[A[ATraining Step: 3430  | total loss: [1m[32m0.40560[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40560 - acc: 0.8199 -- iter: 3040/3680
[A[ATraining Step: 3431  | total loss: [1m[32m0.41310[0m[0m
[2K| Adam | epoch: 030 | loss: 0.41310 - acc: 0.8129 -- iter: 3072/3680
[A[ATraining Step: 3432  | total loss: [1m[32m0.42330[0m[0m
[2K| Adam | epoch: 030 | loss: 0.42330 - acc: 0.8097 -- iter: 3104/3680
[A[ATraining Step: 3433  | total loss: [1m[32m0.40548[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40548 - acc: 0.8194 -- iter: 3136/3680
[A[ATraining Step: 3434  | total loss: [1m[32m0.40412[0m[0m
[2K| Adam | epoch: 030 | loss: 0.40412 - acc: 0.8187 -- iter: 3168/3680
[A[ATraining Step: 3435  | total loss: [1m[32m0.39431[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39431 - acc: 0.8181 -- iter: 3200/3680
[A[ATraining Step: 3436  | total loss: [1m[32m0.39504[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39504 - acc: 0.8175 -- iter: 3232/3680
[A[ATraining Step: 3437  | total loss: [1m[32m0.38133[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38133 - acc: 0.8222 -- iter: 3264/3680
[A[ATraining Step: 3438  | total loss: [1m[32m0.39360[0m[0m
[2K| Adam | epoch: 030 | loss: 0.39360 - acc: 0.8222 -- iter: 3296/3680
[A[ATraining Step: 3439  | total loss: [1m[32m0.38702[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38702 - acc: 0.8244 -- iter: 3328/3680
[A[ATraining Step: 3440  | total loss: [1m[32m0.38471[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38471 - acc: 0.8325 -- iter: 3360/3680
[A[ATraining Step: 3441  | total loss: [1m[32m0.37862[0m[0m
[2K| Adam | epoch: 030 | loss: 0.37862 - acc: 0.8337 -- iter: 3392/3680
[A[ATraining Step: 3442  | total loss: [1m[32m0.38302[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38302 - acc: 0.8253 -- iter: 3424/3680
[A[ATraining Step: 3443  | total loss: [1m[32m0.38139[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38139 - acc: 0.8271 -- iter: 3456/3680
[A[ATraining Step: 3444  | total loss: [1m[32m0.38621[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38621 - acc: 0.8319 -- iter: 3488/3680
[A[ATraining Step: 3445  | total loss: [1m[32m0.38839[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38839 - acc: 0.8300 -- iter: 3520/3680
[A[ATraining Step: 3446  | total loss: [1m[32m0.38032[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38032 - acc: 0.8376 -- iter: 3552/3680
[A[ATraining Step: 3447  | total loss: [1m[32m0.38334[0m[0m
[2K| Adam | epoch: 030 | loss: 0.38334 - acc: 0.8382 -- iter: 3584/3680
[A[ATraining Step: 3448  | total loss: [1m[32m0.48177[0m[0m
[2K| Adam | epoch: 030 | loss: 0.48177 - acc: 0.7950 -- iter: 3616/3680
[A[ATraining Step: 3449  | total loss: [1m[32m0.47002[0m[0m
[2K| Adam | epoch: 030 | loss: 0.47002 - acc: 0.7937 -- iter: 3648/3680
[A[ATraining Step: 3450  | total loss: [1m[32m0.45360[0m[0m
[2K| Adam | epoch: 030 | loss: 0.45360 - acc: 0.8018 | val_loss: 0.36350 - val_acc: 0.8610 -- iter: 3680/3680
[A[ATraining Step: 3450  | total loss: [1m[32m0.45360[0m[0m
[2K| Adam | epoch: 030 | loss: 0.45360 - acc: 0.8018 | val_loss: 0.36350 - val_acc: 0.8610 -- iter: 3680/3680
--
Training Step: 3451  | total loss: [1m[32m0.44118[0m[0m
[2K| Adam | epoch: 031 | loss: 0.44118 - acc: 0.8091 -- iter: 0032/3680
[A[ATraining Step: 3452  | total loss: [1m[32m0.43835[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43835 - acc: 0.8126 -- iter: 0064/3680
[A[ATraining Step: 3453  | total loss: [1m[32m0.45043[0m[0m
[2K| Adam | epoch: 031 | loss: 0.45043 - acc: 0.8063 -- iter: 0096/3680
[A[ATraining Step: 3454  | total loss: [1m[32m0.44079[0m[0m
[2K| Adam | epoch: 031 | loss: 0.44079 - acc: 0.8069 -- iter: 0128/3680
[A[ATraining Step: 3455  | total loss: [1m[32m0.42498[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42498 - acc: 0.8137 -- iter: 0160/3680
[A[ATraining Step: 3456  | total loss: [1m[32m0.41981[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41981 - acc: 0.8167 -- iter: 0192/3680
[A[ATraining Step: 3457  | total loss: [1m[32m0.42684[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42684 - acc: 0.8101 -- iter: 0224/3680
[A[ATraining Step: 3458  | total loss: [1m[32m0.41682[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41682 - acc: 0.8166 -- iter: 0256/3680
[A[ATraining Step: 3459  | total loss: [1m[32m0.40586[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40586 - acc: 0.8224 -- iter: 0288/3680
[A[ATraining Step: 3460  | total loss: [1m[32m0.39575[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39575 - acc: 0.8268 -- iter: 0320/3680
[A[ATraining Step: 3461  | total loss: [1m[32m0.39575[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39575 - acc: 0.8268 -- iter: 0352/3680
[A[ATraining Step: 3462  | total loss: [1m[32m0.40178[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40178 - acc: 0.8222 -- iter: 0384/3680
[A[ATraining Step: 3463  | total loss: [1m[32m0.40534[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40534 - acc: 0.8244 -- iter: 0416/3680
[A[ATraining Step: 3464  | total loss: [1m[32m0.39178[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39178 - acc: 0.8326 -- iter: 0448/3680
[A[ATraining Step: 3465  | total loss: [1m[32m0.38238[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38238 - acc: 0.8368 -- iter: 0480/3680
[A[ATraining Step: 3466  | total loss: [1m[32m0.38787[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38787 - acc: 0.8312 -- iter: 0512/3680
[A[ATraining Step: 3467  | total loss: [1m[32m0.38123[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38123 - acc: 0.8356 -- iter: 0544/3680
[A[ATraining Step: 3468  | total loss: [1m[32m0.37760[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37760 - acc: 0.8427 -- iter: 0576/3680
[A[ATraining Step: 3469  | total loss: [1m[32m0.38102[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38102 - acc: 0.8428 -- iter: 0608/3680
[A[ATraining Step: 3470  | total loss: [1m[32m0.38247[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38247 - acc: 0.8366 -- iter: 0640/3680
[A[ATraining Step: 3471  | total loss: [1m[32m0.37686[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37686 - acc: 0.8373 -- iter: 0672/3680
[A[ATraining Step: 3472  | total loss: [1m[32m0.37124[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37124 - acc: 0.8411 -- iter: 0704/3680
[A[ATraining Step: 3473  | total loss: [1m[32m0.37242[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37242 - acc: 0.8445 -- iter: 0736/3680
[A[ATraining Step: 3474  | total loss: [1m[32m0.37288[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37288 - acc: 0.8476 -- iter: 0768/3680
[A[ATraining Step: 3475  | total loss: [1m[32m0.39138[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39138 - acc: 0.8378 -- iter: 0800/3680
[A[ATraining Step: 3476  | total loss: [1m[32m0.39509[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39509 - acc: 0.8290 -- iter: 0832/3680
[A[ATraining Step: 3477  | total loss: [1m[32m0.38777[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38777 - acc: 0.8274 -- iter: 0864/3680
[A[ATraining Step: 3478  | total loss: [1m[32m0.39828[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39828 - acc: 0.8196 -- iter: 0896/3680
[A[ATraining Step: 3479  | total loss: [1m[32m0.40621[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40621 - acc: 0.8189 -- iter: 0928/3680
[A[ATraining Step: 3480  | total loss: [1m[32m0.43705[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43705 - acc: 0.7995 -- iter: 0960/3680
[A[ATraining Step: 3481  | total loss: [1m[32m0.45662[0m[0m
[2K| Adam | epoch: 031 | loss: 0.45662 - acc: 0.7946 -- iter: 0992/3680
[A[ATraining Step: 3482  | total loss: [1m[32m0.45947[0m[0m
[2K| Adam | epoch: 031 | loss: 0.45947 - acc: 0.7870 -- iter: 1024/3680
[A[ATraining Step: 3483  | total loss: [1m[32m0.44809[0m[0m
[2K| Adam | epoch: 031 | loss: 0.44809 - acc: 0.7958 -- iter: 1056/3680
[A[ATraining Step: 3484  | total loss: [1m[32m0.43237[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43237 - acc: 0.8100 -- iter: 1088/3680
[A[ATraining Step: 3485  | total loss: [1m[32m0.43036[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43036 - acc: 0.8133 -- iter: 1120/3680
[A[ATraining Step: 3486  | total loss: [1m[32m0.43556[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43556 - acc: 0.8070 -- iter: 1152/3680
[A[ATraining Step: 3487  | total loss: [1m[32m0.42903[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42903 - acc: 0.8076 -- iter: 1184/3680
[A[ATraining Step: 3488  | total loss: [1m[32m0.43729[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43729 - acc: 0.7956 -- iter: 1216/3680
[A[ATraining Step: 3489  | total loss: [1m[32m0.42454[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42454 - acc: 0.8129 -- iter: 1248/3680
[A[ATraining Step: 3490  | total loss: [1m[32m0.42022[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42022 - acc: 0.8097 -- iter: 1280/3680
[A[ATraining Step: 3491  | total loss: [1m[32m0.42099[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42099 - acc: 0.8100 -- iter: 1312/3680
[A[ATraining Step: 3492  | total loss: [1m[32m0.42269[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42269 - acc: 0.8134 -- iter: 1344/3680
[A[ATraining Step: 3493  | total loss: [1m[32m0.41469[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41469 - acc: 0.8164 -- iter: 1376/3680
[A[ATraining Step: 3494  | total loss: [1m[32m0.41038[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41038 - acc: 0.8223 -- iter: 1408/3680
[A[ATraining Step: 3495  | total loss: [1m[32m0.39934[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39934 - acc: 0.8338 -- iter: 1440/3680
[A[ATraining Step: 3496  | total loss: [1m[32m0.40827[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40827 - acc: 0.8348 -- iter: 1472/3680
[A[ATraining Step: 3497  | total loss: [1m[32m0.40257[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40257 - acc: 0.8388 -- iter: 1504/3680
[A[ATraining Step: 3498  | total loss: [1m[32m0.39633[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39633 - acc: 0.8487 -- iter: 1536/3680
[A[ATraining Step: 3499  | total loss: [1m[32m0.38995[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38995 - acc: 0.8544 -- iter: 1568/3680
[A[ATraining Step: 3500  | total loss: [1m[32m0.37169[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37169 - acc: 0.8627 | val_loss: 0.35682 - val_acc: 0.8632 -- iter: 1600/3680
[A[ATraining Step: 3500  | total loss: [1m[32m0.37169[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37169 - acc: 0.8627 | val_loss: 0.35682 - val_acc: 0.8632 -- iter: 1600/3680
--
Training Step: 3501  | total loss: [1m[32m0.37238[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37238 - acc: 0.8608 -- iter: 1632/3680
[A[ATraining Step: 3502  | total loss: [1m[32m0.35905[0m[0m
[2K| Adam | epoch: 031 | loss: 0.35905 - acc: 0.8685 -- iter: 1664/3680
[A[ATraining Step: 3503  | total loss: [1m[32m0.35514[0m[0m
[2K| Adam | epoch: 031 | loss: 0.35514 - acc: 0.8660 -- iter: 1696/3680
[A[ATraining Step: 3504  | total loss: [1m[32m0.37637[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37637 - acc: 0.8513 -- iter: 1728/3680
[A[ATraining Step: 3505  | total loss: [1m[32m0.38141[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38141 - acc: 0.8537 -- iter: 1760/3680
[A[ATraining Step: 3506  | total loss: [1m[32m0.38448[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38448 - acc: 0.8527 -- iter: 1792/3680
[A[ATraining Step: 3507  | total loss: [1m[32m0.38784[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38784 - acc: 0.8487 -- iter: 1824/3680
[A[ATraining Step: 3508  | total loss: [1m[32m0.40356[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40356 - acc: 0.8388 -- iter: 1856/3680
[A[ATraining Step: 3509  | total loss: [1m[32m0.39558[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39558 - acc: 0.8455 -- iter: 1888/3680
[A[ATraining Step: 3510  | total loss: [1m[32m0.42152[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42152 - acc: 0.8297 -- iter: 1920/3680
[A[ATraining Step: 3511  | total loss: [1m[32m0.40931[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40931 - acc: 0.8405 -- iter: 1952/3680
[A[ATraining Step: 3512  | total loss: [1m[32m0.41846[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41846 - acc: 0.8315 -- iter: 1984/3680
[A[ATraining Step: 3513  | total loss: [1m[32m0.42233[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42233 - acc: 0.8233 -- iter: 2016/3680
[A[ATraining Step: 3514  | total loss: [1m[32m0.42407[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42407 - acc: 0.8191 -- iter: 2048/3680
[A[ATraining Step: 3515  | total loss: [1m[32m0.43095[0m[0m
[2K| Adam | epoch: 031 | loss: 0.43095 - acc: 0.8122 -- iter: 2080/3680
[A[ATraining Step: 3516  | total loss: [1m[32m0.41602[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41602 - acc: 0.8185 -- iter: 2112/3680
[A[ATraining Step: 3517  | total loss: [1m[32m0.41262[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41262 - acc: 0.8148 -- iter: 2144/3680
[A[ATraining Step: 3518  | total loss: [1m[32m0.40603[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40603 - acc: 0.8265 -- iter: 2176/3680
[A[ATraining Step: 3519  | total loss: [1m[32m0.40603[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40603 - acc: 0.8265 -- iter: 2208/3680
[A[ATraining Step: 3520  | total loss: [1m[32m0.39990[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39990 - acc: 0.8345 -- iter: 2240/3680
[A[ATraining Step: 3521  | total loss: [1m[32m0.39585[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39585 - acc: 0.8544 -- iter: 2272/3680
[A[ATraining Step: 3522  | total loss: [1m[32m0.37892[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37892 - acc: 0.8544 -- iter: 2304/3680
[A[ATraining Step: 3523  | total loss: [1m[32m0.38796[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38796 - acc: 0.8439 -- iter: 2336/3680
[A[ATraining Step: 3524  | total loss: [1m[32m0.37760[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37760 - acc: 0.8439 -- iter: 2368/3680
[A[ATraining Step: 3525  | total loss: [1m[32m0.38733[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38733 - acc: 0.8377 -- iter: 2400/3680
[A[ATraining Step: 3526  | total loss: [1m[32m0.38285[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38285 - acc: 0.8383 -- iter: 2432/3680
[A[ATraining Step: 3527  | total loss: [1m[32m0.37775[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37775 - acc: 0.8546 -- iter: 2464/3680
[A[ATraining Step: 3528  | total loss: [1m[32m0.36124[0m[0m
[2K| Adam | epoch: 031 | loss: 0.36124 - acc: 0.8546 -- iter: 2496/3680
[A[ATraining Step: 3529  | total loss: [1m[32m0.36636[0m[0m
[2K| Adam | epoch: 031 | loss: 0.36636 - acc: 0.8535 -- iter: 2528/3680
[A[ATraining Step: 3530  | total loss: [1m[32m0.37085[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37085 - acc: 0.8494 -- iter: 2560/3680
[A[ATraining Step: 3531  | total loss: [1m[32m0.39285[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39285 - acc: 0.8426 -- iter: 2592/3680
[A[ATraining Step: 3532  | total loss: [1m[32m0.39725[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39725 - acc: 0.8490 -- iter: 2624/3680
[A[ATraining Step: 3533  | total loss: [1m[32m0.39345[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39345 - acc: 0.8516 -- iter: 2656/3680
[A[ATraining Step: 3534  | total loss: [1m[32m0.39917[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39917 - acc: 0.8445 -- iter: 2688/3680
[A[ATraining Step: 3535  | total loss: [1m[32m0.39326[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39326 - acc: 0.8507 -- iter: 2720/3680
[A[ATraining Step: 3536  | total loss: [1m[32m0.38369[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38369 - acc: 0.8456 -- iter: 2752/3680
[A[ATraining Step: 3537  | total loss: [1m[32m0.38923[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38923 - acc: 0.8456 -- iter: 2784/3680
[A[ATraining Step: 3538  | total loss: [1m[32m0.37316[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37316 - acc: 0.8517 -- iter: 2816/3680
[A[ATraining Step: 3539  | total loss: [1m[32m0.36432[0m[0m
[2K| Adam | epoch: 031 | loss: 0.36432 - acc: 0.8572 -- iter: 2848/3680
[A[ATraining Step: 3540  | total loss: [1m[32m0.37294[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37294 - acc: 0.8527 -- iter: 2880/3680
[A[ATraining Step: 3541  | total loss: [1m[32m0.38069[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38069 - acc: 0.8455 -- iter: 2912/3680
[A[ATraining Step: 3542  | total loss: [1m[32m0.37299[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37299 - acc: 0.8516 -- iter: 2944/3680
[A[ATraining Step: 3543  | total loss: [1m[32m0.37181[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37181 - acc: 0.8540 -- iter: 2976/3680
[A[ATraining Step: 3544  | total loss: [1m[32m0.37573[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37573 - acc: 0.8561 -- iter: 3008/3680
[A[ATraining Step: 3545  | total loss: [1m[32m0.36686[0m[0m
[2K| Adam | epoch: 031 | loss: 0.36686 - acc: 0.8642 -- iter: 3040/3680
[A[ATraining Step: 3546  | total loss: [1m[32m0.35399[0m[0m
[2K| Adam | epoch: 031 | loss: 0.35399 - acc: 0.8747 -- iter: 3072/3680
[A[ATraining Step: 3547  | total loss: [1m[32m0.35592[0m[0m
[2K| Adam | epoch: 031 | loss: 0.35592 - acc: 0.8684 -- iter: 3104/3680
[A[ATraining Step: 3548  | total loss: [1m[32m0.35861[0m[0m
[2K| Adam | epoch: 031 | loss: 0.35861 - acc: 0.8566 -- iter: 3136/3680
[A[ATraining Step: 3549  | total loss: [1m[32m0.37537[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37537 - acc: 0.8491 -- iter: 3168/3680
[A[ATraining Step: 3550  | total loss: [1m[32m0.37760[0m[0m
[2K| Adam | epoch: 031 | loss: 0.37760 - acc: 0.8485 -- iter: 3200/3680
[A[ATraining Step: 3551  | total loss: [1m[32m0.38277[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38277 - acc: 0.8418 -- iter: 3232/3680
[A[ATraining Step: 3552  | total loss: [1m[32m0.38785[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38785 - acc: 0.8357 -- iter: 3264/3680
[A[ATraining Step: 3553  | total loss: [1m[32m0.38465[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38465 - acc: 0.8397 -- iter: 3296/3680
[A[ATraining Step: 3554  | total loss: [1m[32m0.41264[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41264 - acc: 0.8245 -- iter: 3328/3680
[A[ATraining Step: 3555  | total loss: [1m[32m0.42282[0m[0m
[2K| Adam | epoch: 031 | loss: 0.42282 - acc: 0.8233 -- iter: 3360/3680
[A[ATraining Step: 3556  | total loss: [1m[32m0.41478[0m[0m
[2K| Adam | epoch: 031 | loss: 0.41478 - acc: 0.8284 -- iter: 3392/3680
[A[ATraining Step: 3557  | total loss: [1m[32m0.40557[0m[0m
[2K| Adam | epoch: 031 | loss: 0.40557 - acc: 0.8331 -- iter: 3424/3680
[A[ATraining Step: 3558  | total loss: [1m[32m0.39252[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39252 - acc: 0.8404 -- iter: 3456/3680
[A[ATraining Step: 3559  | total loss: [1m[32m0.38489[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38489 - acc: 0.8407 -- iter: 3488/3680
[A[ATraining Step: 3560  | total loss: [1m[32m0.38670[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38670 - acc: 0.8348 -- iter: 3520/3680
[A[ATraining Step: 3561  | total loss: [1m[32m0.39540[0m[0m
[2K| Adam | epoch: 031 | loss: 0.39540 - acc: 0.8232 -- iter: 3552/3680
[A[ATraining Step: 3562  | total loss: [1m[32m0.38384[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38384 - acc: 0.8284 -- iter: 3584/3680
[A[ATraining Step: 3563  | total loss: [1m[32m0.38376[0m[0m
[2K| Adam | epoch: 031 | loss: 0.38376 - acc: 0.8299 -- iter: 3616/3680
[A[ATraining Step: 3564  | total loss: [1m[32m0.47864[0m[0m
[2K| Adam | epoch: 031 | loss: 0.47864 - acc: 0.8000 -- iter: 3648/3680
[A[ATraining Step: 3565  | total loss: [1m[32m0.47888[0m[0m
[2K| Adam | epoch: 031 | loss: 0.47888 - acc: 0.7950 | val_loss: 0.36556 - val_acc: 0.8588 -- iter: 3680/3680
[A[ATraining Step: 3565  | total loss: [1m[32m0.47888[0m[0m
[2K| Adam | epoch: 031 | loss: 0.47888 - acc: 0.7950 | val_loss: 0.36556 - val_acc: 0.8588 -- iter: 3680/3680
--
Training Step: 3566  | total loss: [1m[32m0.46044[0m[0m
[2K| Adam | epoch: 032 | loss: 0.46044 - acc: 0.8062 -- iter: 0032/3680
[A[ATraining Step: 3567  | total loss: [1m[32m0.46046[0m[0m
[2K| Adam | epoch: 032 | loss: 0.46046 - acc: 0.8099 -- iter: 0064/3680
[A[ATraining Step: 3568  | total loss: [1m[32m0.45944[0m[0m
[2K| Adam | epoch: 032 | loss: 0.45944 - acc: 0.8198 -- iter: 0096/3680
[A[ATraining Step: 3569  | total loss: [1m[32m0.43959[0m[0m
[2K| Adam | epoch: 032 | loss: 0.43959 - acc: 0.8198 -- iter: 0128/3680
[A[ATraining Step: 3570  | total loss: [1m[32m0.43747[0m[0m
[2K| Adam | epoch: 032 | loss: 0.43747 - acc: 0.8191 -- iter: 0160/3680
[A[ATraining Step: 3571  | total loss: [1m[32m0.42868[0m[0m
[2K| Adam | epoch: 032 | loss: 0.42868 - acc: 0.8246 -- iter: 0192/3680
[A[ATraining Step: 3572  | total loss: [1m[32m0.41260[0m[0m
[2K| Adam | epoch: 032 | loss: 0.41260 - acc: 0.8342 -- iter: 0224/3680
[A[ATraining Step: 3573  | total loss: [1m[32m0.40311[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40311 - acc: 0.8342 -- iter: 0256/3680
[A[ATraining Step: 3574  | total loss: [1m[32m0.39832[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39832 - acc: 0.8320 -- iter: 0288/3680
[A[ATraining Step: 3575  | total loss: [1m[32m0.38311[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38311 - acc: 0.8426 -- iter: 0320/3680
[A[ATraining Step: 3576  | total loss: [1m[32m0.38101[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38101 - acc: 0.8396 -- iter: 0352/3680
[A[ATraining Step: 3577  | total loss: [1m[32m0.37174[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37174 - acc: 0.8462 -- iter: 0384/3680
[A[ATraining Step: 3578  | total loss: [1m[32m0.38433[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38433 - acc: 0.8460 -- iter: 0416/3680
[A[ATraining Step: 3579  | total loss: [1m[32m0.37470[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37470 - acc: 0.8520 -- iter: 0448/3680
[A[ATraining Step: 3580  | total loss: [1m[32m0.39078[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39078 - acc: 0.8418 -- iter: 0480/3680
[A[ATraining Step: 3581  | total loss: [1m[32m0.39328[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39328 - acc: 0.8358 -- iter: 0512/3680
[A[ATraining Step: 3582  | total loss: [1m[32m0.38823[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38823 - acc: 0.8366 -- iter: 0544/3680
[A[ATraining Step: 3583  | total loss: [1m[32m0.37863[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37863 - acc: 0.8373 -- iter: 0576/3680
[A[ATraining Step: 3584  | total loss: [1m[32m0.36410[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36410 - acc: 0.8536 -- iter: 0608/3680
[A[ATraining Step: 3585  | total loss: [1m[32m0.36297[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36297 - acc: 0.8526 -- iter: 0640/3680
[A[ATraining Step: 3586  | total loss: [1m[32m0.36915[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36915 - acc: 0.8486 -- iter: 0672/3680
[A[ATraining Step: 3587  | total loss: [1m[32m0.37361[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37361 - acc: 0.8450 -- iter: 0704/3680
[A[ATraining Step: 3588  | total loss: [1m[32m0.37327[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37327 - acc: 0.8417 -- iter: 0736/3680
[A[ATraining Step: 3589  | total loss: [1m[32m0.39026[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39026 - acc: 0.8357 -- iter: 0768/3680
[A[ATraining Step: 3590  | total loss: [1m[32m0.38316[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38316 - acc: 0.8396 -- iter: 0800/3680
[A[ATraining Step: 3591  | total loss: [1m[32m0.38551[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38551 - acc: 0.8369 -- iter: 0832/3680
[A[ATraining Step: 3592  | total loss: [1m[32m0.39697[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39697 - acc: 0.8282 -- iter: 0864/3680
[A[ATraining Step: 3593  | total loss: [1m[32m0.41115[0m[0m
[2K| Adam | epoch: 032 | loss: 0.41115 - acc: 0.8141 -- iter: 0896/3680
[A[ATraining Step: 3594  | total loss: [1m[32m0.40875[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40875 - acc: 0.8233 -- iter: 0928/3680
[A[ATraining Step: 3595  | total loss: [1m[32m0.40231[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40231 - acc: 0.8285 -- iter: 0960/3680
[A[ATraining Step: 3596  | total loss: [1m[32m0.40424[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40424 - acc: 0.8332 -- iter: 0992/3680
[A[ATraining Step: 3597  | total loss: [1m[32m0.40624[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40624 - acc: 0.8342 -- iter: 1024/3680
[A[ATraining Step: 3598  | total loss: [1m[32m0.39794[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39794 - acc: 0.8383 -- iter: 1056/3680
[A[ATraining Step: 3599  | total loss: [1m[32m0.38619[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38619 - acc: 0.8451 -- iter: 1088/3680
[A[ATraining Step: 3600  | total loss: [1m[32m0.37992[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37992 - acc: 0.8512 | val_loss: 0.36196 - val_acc: 0.8621 -- iter: 1120/3680
[A[ATraining Step: 3600  | total loss: [1m[32m0.37992[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37992 - acc: 0.8512 | val_loss: 0.36196 - val_acc: 0.8621 -- iter: 1120/3680
--
Training Step: 3601  | total loss: [1m[32m0.38119[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38119 - acc: 0.8536 -- iter: 1152/3680
[A[ATraining Step: 3602  | total loss: [1m[32m0.36734[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36734 - acc: 0.8620 -- iter: 1184/3680
[A[ATraining Step: 3603  | total loss: [1m[32m0.38579[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38579 - acc: 0.8539 -- iter: 1216/3680
[A[ATraining Step: 3604  | total loss: [1m[32m0.39130[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39130 - acc: 0.8529 -- iter: 1248/3680
[A[ATraining Step: 3605  | total loss: [1m[32m0.40010[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40010 - acc: 0.8457 -- iter: 1280/3680
[A[ATraining Step: 3606  | total loss: [1m[32m0.38897[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38897 - acc: 0.8518 -- iter: 1312/3680
[A[ATraining Step: 3607  | total loss: [1m[32m0.38618[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38618 - acc: 0.8479 -- iter: 1344/3680
[A[ATraining Step: 3608  | total loss: [1m[32m0.38729[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38729 - acc: 0.8443 -- iter: 1376/3680
[A[ATraining Step: 3609  | total loss: [1m[32m0.38253[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38253 - acc: 0.8443 -- iter: 1408/3680
[A[ATraining Step: 3610  | total loss: [1m[32m0.38510[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38510 - acc: 0.8411 -- iter: 1440/3680
[A[ATraining Step: 3611  | total loss: [1m[32m0.37056[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37056 - acc: 0.8538 -- iter: 1472/3680
[A[ATraining Step: 3612  | total loss: [1m[32m0.37690[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37690 - acc: 0.8466 -- iter: 1504/3680
[A[ATraining Step: 3613  | total loss: [1m[32m0.36323[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36323 - acc: 0.8526 -- iter: 1536/3680
[A[ATraining Step: 3614  | total loss: [1m[32m0.36058[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36058 - acc: 0.8579 -- iter: 1568/3680
[A[ATraining Step: 3615  | total loss: [1m[32m0.36387[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36387 - acc: 0.8503 -- iter: 1600/3680
[A[ATraining Step: 3616  | total loss: [1m[32m0.37472[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37472 - acc: 0.8465 -- iter: 1632/3680
[A[ATraining Step: 3617  | total loss: [1m[32m0.37193[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37193 - acc: 0.8493 -- iter: 1664/3680
[A[ATraining Step: 3618  | total loss: [1m[32m0.38490[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38490 - acc: 0.8394 -- iter: 1696/3680
[A[ATraining Step: 3619  | total loss: [1m[32m0.36989[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36989 - acc: 0.8492 -- iter: 1728/3680
[A[ATraining Step: 3620  | total loss: [1m[32m0.36247[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36247 - acc: 0.8549 -- iter: 1760/3680
[A[ATraining Step: 3621  | total loss: [1m[32m0.36369[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36369 - acc: 0.8569 -- iter: 1792/3680
[A[ATraining Step: 3622  | total loss: [1m[32m0.36016[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36016 - acc: 0.8619 -- iter: 1824/3680
[A[ATraining Step: 3623  | total loss: [1m[32m0.36496[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36496 - acc: 0.8600 -- iter: 1856/3680
[A[ATraining Step: 3624  | total loss: [1m[32m0.37924[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37924 - acc: 0.8459 -- iter: 1888/3680
[A[ATraining Step: 3625  | total loss: [1m[32m0.36450[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36450 - acc: 0.8488 -- iter: 1920/3680
[A[ATraining Step: 3626  | total loss: [1m[32m0.37585[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37585 - acc: 0.8358 -- iter: 1952/3680
[A[ATraining Step: 3627  | total loss: [1m[32m0.38278[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38278 - acc: 0.8272 -- iter: 1984/3680
[A[ATraining Step: 3628  | total loss: [1m[32m0.36567[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36567 - acc: 0.8414 -- iter: 2016/3680
[A[ATraining Step: 3629  | total loss: [1m[32m0.35278[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35278 - acc: 0.8479 -- iter: 2048/3680
[A[ATraining Step: 3630  | total loss: [1m[32m0.36592[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36592 - acc: 0.8475 -- iter: 2080/3680
[A[ATraining Step: 3631  | total loss: [1m[32m0.36915[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36915 - acc: 0.8440 -- iter: 2112/3680
[A[ATraining Step: 3632  | total loss: [1m[32m0.35541[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35541 - acc: 0.8502 -- iter: 2144/3680
[A[ATraining Step: 3633  | total loss: [1m[32m0.34600[0m[0m
[2K| Adam | epoch: 032 | loss: 0.34600 - acc: 0.8558 -- iter: 2176/3680
[A[ATraining Step: 3634  | total loss: [1m[32m0.33848[0m[0m
[2K| Adam | epoch: 032 | loss: 0.33848 - acc: 0.8608 -- iter: 2208/3680
[A[ATraining Step: 3635  | total loss: [1m[32m0.35070[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35070 - acc: 0.8560 -- iter: 2240/3680
[A[ATraining Step: 3636  | total loss: [1m[32m0.36517[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36517 - acc: 0.8485 -- iter: 2272/3680
[A[ATraining Step: 3637  | total loss: [1m[32m0.35991[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35991 - acc: 0.8574 -- iter: 2304/3680
[A[ATraining Step: 3638  | total loss: [1m[32m0.35478[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35478 - acc: 0.8561 -- iter: 2336/3680
[A[ATraining Step: 3639  | total loss: [1m[32m0.34504[0m[0m
[2K| Adam | epoch: 032 | loss: 0.34504 - acc: 0.8611 -- iter: 2368/3680
[A[ATraining Step: 3640  | total loss: [1m[32m0.34337[0m[0m
[2K| Adam | epoch: 032 | loss: 0.34337 - acc: 0.8625 -- iter: 2400/3680
[A[ATraining Step: 3641  | total loss: [1m[32m0.35511[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35511 - acc: 0.8575 -- iter: 2432/3680
[A[ATraining Step: 3642  | total loss: [1m[32m0.35045[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35045 - acc: 0.8592 -- iter: 2464/3680
[A[ATraining Step: 3643  | total loss: [1m[32m0.34621[0m[0m
[2K| Adam | epoch: 032 | loss: 0.34621 - acc: 0.8577 -- iter: 2496/3680
[A[ATraining Step: 3644  | total loss: [1m[32m0.36037[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36037 - acc: 0.8625 -- iter: 2528/3680
[A[ATraining Step: 3645  | total loss: [1m[32m0.35494[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35494 - acc: 0.8575 -- iter: 2560/3680
[A[ATraining Step: 3646  | total loss: [1m[32m0.37343[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37343 - acc: 0.8405 -- iter: 2592/3680
[A[ATraining Step: 3647  | total loss: [1m[32m0.39245[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39245 - acc: 0.8315 -- iter: 2624/3680
[A[ATraining Step: 3648  | total loss: [1m[32m0.38720[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38720 - acc: 0.8327 -- iter: 2656/3680
[A[ATraining Step: 3649  | total loss: [1m[32m0.38333[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38333 - acc: 0.8369 -- iter: 2688/3680
[A[ATraining Step: 3650  | total loss: [1m[32m0.37614[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37614 - acc: 0.8470 -- iter: 2720/3680
[A[ATraining Step: 3651  | total loss: [1m[32m0.38178[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38178 - acc: 0.8435 -- iter: 2752/3680
[A[ATraining Step: 3652  | total loss: [1m[32m0.37114[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37114 - acc: 0.8529 -- iter: 2784/3680
[A[ATraining Step: 3653  | total loss: [1m[32m0.36954[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36954 - acc: 0.8551 -- iter: 2816/3680
[A[ATraining Step: 3654  | total loss: [1m[32m0.36749[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36749 - acc: 0.8571 -- iter: 2848/3680
[A[ATraining Step: 3655  | total loss: [1m[32m0.36448[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36448 - acc: 0.8589 -- iter: 2880/3680
[A[ATraining Step: 3656  | total loss: [1m[32m0.36298[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36298 - acc: 0.8574 -- iter: 2912/3680
[A[ATraining Step: 3657  | total loss: [1m[32m0.35616[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35616 - acc: 0.8623 -- iter: 2944/3680
[A[ATraining Step: 3658  | total loss: [1m[32m0.36856[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36856 - acc: 0.8604 -- iter: 2976/3680
[A[ATraining Step: 3659  | total loss: [1m[32m0.35833[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35833 - acc: 0.8713 -- iter: 3008/3680
[A[ATraining Step: 3660  | total loss: [1m[32m0.35942[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35942 - acc: 0.8685 -- iter: 3040/3680
[A[ATraining Step: 3661  | total loss: [1m[32m0.38251[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38251 - acc: 0.8567 -- iter: 3072/3680
[A[ATraining Step: 3662  | total loss: [1m[32m0.37488[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37488 - acc: 0.8647 -- iter: 3104/3680
[A[ATraining Step: 3663  | total loss: [1m[32m0.36428[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36428 - acc: 0.8658 -- iter: 3136/3680
[A[ATraining Step: 3664  | total loss: [1m[32m0.36706[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36706 - acc: 0.8542 -- iter: 3168/3680
[A[ATraining Step: 3665  | total loss: [1m[32m0.38258[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38258 - acc: 0.8406 -- iter: 3200/3680
[A[ATraining Step: 3666  | total loss: [1m[32m0.37285[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37285 - acc: 0.8441 -- iter: 3232/3680
[A[ATraining Step: 3667  | total loss: [1m[32m0.37399[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37399 - acc: 0.8409 -- iter: 3264/3680
[A[ATraining Step: 3668  | total loss: [1m[32m0.37492[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37492 - acc: 0.8443 -- iter: 3296/3680
[A[ATraining Step: 3669  | total loss: [1m[32m0.37340[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37340 - acc: 0.8474 -- iter: 3328/3680
[A[ATraining Step: 3670  | total loss: [1m[32m0.37889[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37889 - acc: 0.8439 -- iter: 3360/3680
[A[ATraining Step: 3671  | total loss: [1m[32m0.40500[0m[0m
[2K| Adam | epoch: 032 | loss: 0.40500 - acc: 0.8376 -- iter: 3392/3680
[A[ATraining Step: 3672  | total loss: [1m[32m0.39509[0m[0m
[2K| Adam | epoch: 032 | loss: 0.39509 - acc: 0.8414 -- iter: 3424/3680
[A[ATraining Step: 3673  | total loss: [1m[32m0.38299[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38299 - acc: 0.8479 -- iter: 3456/3680
[A[ATraining Step: 3674  | total loss: [1m[32m0.38690[0m[0m
[2K| Adam | epoch: 032 | loss: 0.38690 - acc: 0.8506 -- iter: 3488/3680
[A[ATraining Step: 3675  | total loss: [1m[32m0.36652[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36652 - acc: 0.8593 -- iter: 3520/3680
[A[ATraining Step: 3676  | total loss: [1m[32m0.37561[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37561 - acc: 0.8515 -- iter: 3552/3680
[A[ATraining Step: 3677  | total loss: [1m[32m0.36857[0m[0m
[2K| Adam | epoch: 032 | loss: 0.36857 - acc: 0.8569 -- iter: 3584/3680
[A[ATraining Step: 3678  | total loss: [1m[32m0.35894[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35894 - acc: 0.8650 -- iter: 3616/3680
[A[ATraining Step: 3679  | total loss: [1m[32m0.35343[0m[0m
[2K| Adam | epoch: 032 | loss: 0.35343 - acc: 0.8691 -- iter: 3648/3680
[A[ATraining Step: 3680  | total loss: [1m[32m0.37399[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37399 - acc: 0.8666 | val_loss: 0.35349 - val_acc: 0.8567 -- iter: 3680/3680
[A[ATraining Step: 3680  | total loss: [1m[32m0.37399[0m[0m
[2K| Adam | epoch: 032 | loss: 0.37399 - acc: 0.8666 | val_loss: 0.35349 - val_acc: 0.8567 -- iter: 3680/3680
--
Training Step: 3681  | total loss: [1m[32m0.37432[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37432 - acc: 0.8612 -- iter: 0032/3680
[A[ATraining Step: 3682  | total loss: [1m[32m0.37931[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37931 - acc: 0.8626 -- iter: 0064/3680
[A[ATraining Step: 3683  | total loss: [1m[32m0.36406[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36406 - acc: 0.8701 -- iter: 0096/3680
[A[ATraining Step: 3684  | total loss: [1m[32m0.35329[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35329 - acc: 0.8737 -- iter: 0128/3680
[A[ATraining Step: 3685  | total loss: [1m[32m0.34289[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34289 - acc: 0.8769 -- iter: 0160/3680
[A[ATraining Step: 3686  | total loss: [1m[32m0.35070[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35070 - acc: 0.8642 -- iter: 0192/3680
[A[ATraining Step: 3687  | total loss: [1m[32m0.35020[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35020 - acc: 0.8653 -- iter: 0224/3680
[A[ATraining Step: 3688  | total loss: [1m[32m0.37572[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37572 - acc: 0.8600 -- iter: 0256/3680
[A[ATraining Step: 3689  | total loss: [1m[32m0.36404[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36404 - acc: 0.8678 -- iter: 0288/3680
[A[ATraining Step: 3690  | total loss: [1m[32m0.36349[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36349 - acc: 0.8685 -- iter: 0320/3680
[A[ATraining Step: 3691  | total loss: [1m[32m0.36755[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36755 - acc: 0.8610 -- iter: 0352/3680
[A[ATraining Step: 3692  | total loss: [1m[32m0.37017[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37017 - acc: 0.8610 -- iter: 0384/3680
[A[ATraining Step: 3693  | total loss: [1m[32m0.36689[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36689 - acc: 0.8624 -- iter: 0416/3680
[A[ATraining Step: 3694  | total loss: [1m[32m0.36555[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36555 - acc: 0.8617 -- iter: 0448/3680
[A[ATraining Step: 3695  | total loss: [1m[32m0.36441[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36441 - acc: 0.8617 -- iter: 0480/3680
[A[ATraining Step: 3696  | total loss: [1m[32m0.37285[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37285 - acc: 0.8536 -- iter: 0512/3680
[A[ATraining Step: 3697  | total loss: [1m[32m0.36764[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36764 - acc: 0.8589 -- iter: 0544/3680
[A[ATraining Step: 3698  | total loss: [1m[32m0.36598[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36598 - acc: 0.8542 -- iter: 0576/3680
[A[ATraining Step: 3699  | total loss: [1m[32m0.37438[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37438 - acc: 0.8532 -- iter: 0608/3680
[A[ATraining Step: 3700  | total loss: [1m[32m0.37589[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37589 - acc: 0.8460 | val_loss: 0.35151 - val_acc: 0.8675 -- iter: 0640/3680
[A[ATraining Step: 3700  | total loss: [1m[32m0.37589[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37589 - acc: 0.8460 | val_loss: 0.35151 - val_acc: 0.8675 -- iter: 0640/3680
--
Training Step: 3701  | total loss: [1m[32m0.37420[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37420 - acc: 0.8458 -- iter: 0672/3680
[A[ATraining Step: 3702  | total loss: [1m[32m0.37328[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37328 - acc: 0.8487 -- iter: 0704/3680
[A[ATraining Step: 3703  | total loss: [1m[32m0.37341[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37341 - acc: 0.8451 -- iter: 0736/3680
[A[ATraining Step: 3704  | total loss: [1m[32m0.38098[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38098 - acc: 0.8387 -- iter: 0768/3680
[A[ATraining Step: 3705  | total loss: [1m[32m0.40442[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40442 - acc: 0.8267 -- iter: 0800/3680
[A[ATraining Step: 3706  | total loss: [1m[32m0.41055[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41055 - acc: 0.8190 -- iter: 0832/3680
[A[ATraining Step: 3707  | total loss: [1m[32m0.39627[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39627 - acc: 0.8215 -- iter: 0864/3680
[A[ATraining Step: 3708  | total loss: [1m[32m0.39627[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39627 - acc: 0.8215 -- iter: 0896/3680
[A[ATraining Step: 3709  | total loss: [1m[32m0.38788[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38788 - acc: 0.8300 -- iter: 0928/3680
[A[ATraining Step: 3710  | total loss: [1m[32m0.39078[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39078 - acc: 0.8251 -- iter: 0960/3680
[A[ATraining Step: 3711  | total loss: [1m[32m0.40482[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40482 - acc: 0.8145 -- iter: 0992/3680
[A[ATraining Step: 3712  | total loss: [1m[32m0.41318[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41318 - acc: 0.8080 -- iter: 1024/3680
[A[ATraining Step: 3713  | total loss: [1m[32m0.41989[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41989 - acc: 0.8054 -- iter: 1056/3680
[A[ATraining Step: 3714  | total loss: [1m[32m0.41795[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41795 - acc: 0.8030 -- iter: 1088/3680
[A[ATraining Step: 3715  | total loss: [1m[32m0.40352[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40352 - acc: 0.8102 -- iter: 1120/3680
[A[ATraining Step: 3716  | total loss: [1m[32m0.38860[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38860 - acc: 0.8229 -- iter: 1152/3680
[A[ATraining Step: 3717  | total loss: [1m[32m0.39155[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39155 - acc: 0.8187 -- iter: 1184/3680
[A[ATraining Step: 3718  | total loss: [1m[32m0.39212[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39212 - acc: 0.8181 -- iter: 1216/3680
[A[ATraining Step: 3719  | total loss: [1m[32m0.38578[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38578 - acc: 0.8238 -- iter: 1248/3680
[A[ATraining Step: 3720  | total loss: [1m[32m0.38409[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38409 - acc: 0.8258 -- iter: 1280/3680
[A[ATraining Step: 3721  | total loss: [1m[32m0.38499[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38499 - acc: 0.8307 -- iter: 1312/3680
[A[ATraining Step: 3722  | total loss: [1m[32m0.37255[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37255 - acc: 0.8414 -- iter: 1344/3680
[A[ATraining Step: 3723  | total loss: [1m[32m0.36103[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36103 - acc: 0.8479 -- iter: 1376/3680
[A[ATraining Step: 3724  | total loss: [1m[32m0.36024[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36024 - acc: 0.8506 -- iter: 1408/3680
[A[ATraining Step: 3725  | total loss: [1m[32m0.35155[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35155 - acc: 0.8530 -- iter: 1440/3680
[A[ATraining Step: 3726  | total loss: [1m[32m0.35839[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35839 - acc: 0.8521 -- iter: 1472/3680
[A[ATraining Step: 3727  | total loss: [1m[32m0.34084[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34084 - acc: 0.8606 -- iter: 1504/3680
[A[ATraining Step: 3728  | total loss: [1m[32m0.33053[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33053 - acc: 0.8652 -- iter: 1536/3680
[A[ATraining Step: 3729  | total loss: [1m[32m0.32286[0m[0m
[2K| Adam | epoch: 033 | loss: 0.32286 - acc: 0.8724 -- iter: 1568/3680
[A[ATraining Step: 3730  | total loss: [1m[32m0.33774[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33774 - acc: 0.8633 -- iter: 1600/3680
[A[ATraining Step: 3731  | total loss: [1m[32m0.36638[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36638 - acc: 0.8489 -- iter: 1632/3680
[A[ATraining Step: 3732  | total loss: [1m[32m0.35947[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35947 - acc: 0.8515 -- iter: 1664/3680
[A[ATraining Step: 3733  | total loss: [1m[32m0.34260[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34260 - acc: 0.8632 -- iter: 1696/3680
[A[ATraining Step: 3734  | total loss: [1m[32m0.34587[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34587 - acc: 0.8613 -- iter: 1728/3680
[A[ATraining Step: 3735  | total loss: [1m[32m0.33953[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33953 - acc: 0.8564 -- iter: 1760/3680
[A[ATraining Step: 3736  | total loss: [1m[32m0.33255[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33255 - acc: 0.8645 -- iter: 1792/3680
[A[ATraining Step: 3737  | total loss: [1m[32m0.34321[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34321 - acc: 0.8593 -- iter: 1824/3680
[A[ATraining Step: 3738  | total loss: [1m[32m0.35570[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35570 - acc: 0.8515 -- iter: 1856/3680
[A[ATraining Step: 3739  | total loss: [1m[32m0.34395[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34395 - acc: 0.8601 -- iter: 1888/3680
[A[ATraining Step: 3740  | total loss: [1m[32m0.33536[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33536 - acc: 0.8647 -- iter: 1920/3680
[A[ATraining Step: 3741  | total loss: [1m[32m0.33937[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33937 - acc: 0.8626 -- iter: 1952/3680
[A[ATraining Step: 3742  | total loss: [1m[32m0.34685[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34685 - acc: 0.8545 -- iter: 1984/3680
[A[ATraining Step: 3743  | total loss: [1m[32m0.34773[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34773 - acc: 0.8597 -- iter: 2016/3680
[A[ATraining Step: 3744  | total loss: [1m[32m0.34662[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34662 - acc: 0.8549 -- iter: 2048/3680
[A[ATraining Step: 3745  | total loss: [1m[32m0.34592[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34592 - acc: 0.8632 -- iter: 2080/3680
[A[ATraining Step: 3746  | total loss: [1m[32m0.34274[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34274 - acc: 0.8675 -- iter: 2112/3680
[A[ATraining Step: 3747  | total loss: [1m[32m0.34669[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34669 - acc: 0.8620 -- iter: 2144/3680
[A[ATraining Step: 3748  | total loss: [1m[32m0.34860[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34860 - acc: 0.8539 -- iter: 2176/3680
[A[ATraining Step: 3749  | total loss: [1m[32m0.37524[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37524 - acc: 0.8404 -- iter: 2208/3680
[A[ATraining Step: 3750  | total loss: [1m[32m0.38474[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38474 - acc: 0.8345 -- iter: 2240/3680
[A[ATraining Step: 3751  | total loss: [1m[32m0.38112[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38112 - acc: 0.8323 -- iter: 2272/3680
[A[ATraining Step: 3752  | total loss: [1m[32m0.38408[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38408 - acc: 0.8303 -- iter: 2304/3680
[A[ATraining Step: 3753  | total loss: [1m[32m0.37289[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37289 - acc: 0.8348 -- iter: 2336/3680
[A[ATraining Step: 3754  | total loss: [1m[32m0.38588[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38588 - acc: 0.8263 -- iter: 2368/3680
[A[ATraining Step: 3755  | total loss: [1m[32m0.39048[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39048 - acc: 0.8218 -- iter: 2400/3680
[A[ATraining Step: 3756  | total loss: [1m[32m0.38452[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38452 - acc: 0.8302 -- iter: 2432/3680
[A[ATraining Step: 3757  | total loss: [1m[32m0.39024[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39024 - acc: 0.8253 -- iter: 2464/3680
[A[ATraining Step: 3758  | total loss: [1m[32m0.39416[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39416 - acc: 0.8209 -- iter: 2496/3680
[A[ATraining Step: 3759  | total loss: [1m[32m0.40684[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40684 - acc: 0.8232 -- iter: 2528/3680
[A[ATraining Step: 3760  | total loss: [1m[32m0.40630[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40630 - acc: 0.8221 -- iter: 2560/3680
[A[ATraining Step: 3761  | total loss: [1m[32m0.42718[0m[0m
[2K| Adam | epoch: 033 | loss: 0.42718 - acc: 0.8118 -- iter: 2592/3680
[A[ATraining Step: 3762  | total loss: [1m[32m0.41779[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41779 - acc: 0.8150 -- iter: 2624/3680
[A[ATraining Step: 3763  | total loss: [1m[32m0.41005[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41005 - acc: 0.8210 -- iter: 2656/3680
[A[ATraining Step: 3764  | total loss: [1m[32m0.40925[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40925 - acc: 0.8233 -- iter: 2688/3680
[A[ATraining Step: 3765  | total loss: [1m[32m0.39896[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39896 - acc: 0.8253 -- iter: 2720/3680
[A[ATraining Step: 3766  | total loss: [1m[32m0.38891[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38891 - acc: 0.8303 -- iter: 2752/3680
[A[ATraining Step: 3767  | total loss: [1m[32m0.40628[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40628 - acc: 0.8098 -- iter: 2784/3680
[A[ATraining Step: 3768  | total loss: [1m[32m0.40980[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40980 - acc: 0.8069 -- iter: 2816/3680
[A[ATraining Step: 3769  | total loss: [1m[32m0.41918[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41918 - acc: 0.8012 -- iter: 2848/3680
[A[ATraining Step: 3770  | total loss: [1m[32m0.40096[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40096 - acc: 0.8148 -- iter: 2880/3680
[A[ATraining Step: 3771  | total loss: [1m[32m0.41399[0m[0m
[2K| Adam | epoch: 033 | loss: 0.41399 - acc: 0.8021 -- iter: 2912/3680
[A[ATraining Step: 3772  | total loss: [1m[32m0.40753[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40753 - acc: 0.8125 -- iter: 2944/3680
[A[ATraining Step: 3773  | total loss: [1m[32m0.43977[0m[0m
[2K| Adam | epoch: 033 | loss: 0.43977 - acc: 0.7969 -- iter: 2976/3680
[A[ATraining Step: 3774  | total loss: [1m[32m0.43076[0m[0m
[2K| Adam | epoch: 033 | loss: 0.43076 - acc: 0.7985 -- iter: 3008/3680
[A[ATraining Step: 3775  | total loss: [1m[32m0.42706[0m[0m
[2K| Adam | epoch: 033 | loss: 0.42706 - acc: 0.8061 -- iter: 3040/3680
[A[ATraining Step: 3776  | total loss: [1m[32m0.40712[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40712 - acc: 0.8161 -- iter: 3072/3680
[A[ATraining Step: 3777  | total loss: [1m[32m0.40483[0m[0m
[2K| Adam | epoch: 033 | loss: 0.40483 - acc: 0.8189 -- iter: 3104/3680
[A[ATraining Step: 3778  | total loss: [1m[32m0.38964[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38964 - acc: 0.8276 -- iter: 3136/3680
[A[ATraining Step: 3779  | total loss: [1m[32m0.38627[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38627 - acc: 0.8324 -- iter: 3168/3680
[A[ATraining Step: 3780  | total loss: [1m[32m0.39032[0m[0m
[2K| Adam | epoch: 033 | loss: 0.39032 - acc: 0.8241 -- iter: 3200/3680
[A[ATraining Step: 3781  | total loss: [1m[32m0.37889[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37889 - acc: 0.8323 -- iter: 3232/3680
[A[ATraining Step: 3782  | total loss: [1m[32m0.37571[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37571 - acc: 0.8366 -- iter: 3264/3680
[A[ATraining Step: 3783  | total loss: [1m[32m0.38551[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38551 - acc: 0.8311 -- iter: 3296/3680
[A[ATraining Step: 3784  | total loss: [1m[32m0.38428[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38428 - acc: 0.8261 -- iter: 3328/3680
[A[ATraining Step: 3785  | total loss: [1m[32m0.38265[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38265 - acc: 0.8310 -- iter: 3360/3680
[A[ATraining Step: 3786  | total loss: [1m[32m0.38718[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38718 - acc: 0.8323 -- iter: 3392/3680
[A[ATraining Step: 3787  | total loss: [1m[32m0.38765[0m[0m
[2K| Adam | epoch: 033 | loss: 0.38765 - acc: 0.8334 -- iter: 3424/3680
[A[ATraining Step: 3788  | total loss: [1m[32m0.37149[0m[0m
[2K| Adam | epoch: 033 | loss: 0.37149 - acc: 0.8469 -- iter: 3456/3680
[A[ATraining Step: 3789  | total loss: [1m[32m0.36685[0m[0m
[2K| Adam | epoch: 033 | loss: 0.36685 - acc: 0.8554 -- iter: 3488/3680
[A[ATraining Step: 3790  | total loss: [1m[32m0.35809[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35809 - acc: 0.8554 -- iter: 3520/3680
[A[ATraining Step: 3791  | total loss: [1m[32m0.35473[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35473 - acc: 0.8542 -- iter: 3552/3680
[A[ATraining Step: 3792  | total loss: [1m[32m0.34311[0m[0m
[2K| Adam | epoch: 033 | loss: 0.34311 - acc: 0.8657 -- iter: 3584/3680
[A[ATraining Step: 3793  | total loss: [1m[32m0.33074[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33074 - acc: 0.8729 -- iter: 3616/3680
[A[ATraining Step: 3794  | total loss: [1m[32m0.35091[0m[0m
[2K| Adam | epoch: 033 | loss: 0.35091 - acc: 0.8543 -- iter: 3648/3680
[A[ATraining Step: 3795  | total loss: [1m[32m0.33995[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33995 - acc: 0.8626 | val_loss: 0.35385 - val_acc: 0.8675 -- iter: 3680/3680
[A[ATraining Step: 3795  | total loss: [1m[32m0.33995[0m[0m
[2K| Adam | epoch: 033 | loss: 0.33995 - acc: 0.8626 | val_loss: 0.35385 - val_acc: 0.8675 -- iter: 3680/3680
--
Training Step: 3796  | total loss: [1m[32m0.34071[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34071 - acc: 0.8639 -- iter: 0032/3680
[A[ATraining Step: 3797  | total loss: [1m[32m0.35057[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35057 - acc: 0.8587 -- iter: 0064/3680
[A[ATraining Step: 3798  | total loss: [1m[32m0.34252[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34252 - acc: 0.8572 -- iter: 0096/3680
[A[ATraining Step: 3799  | total loss: [1m[32m0.34321[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34321 - acc: 0.8590 -- iter: 0128/3680
[A[ATraining Step: 3800  | total loss: [1m[32m0.34528[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34528 - acc: 0.8544 | val_loss: 0.34715 - val_acc: 0.8675 -- iter: 0160/3680
[A[ATraining Step: 3800  | total loss: [1m[32m0.34528[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34528 - acc: 0.8544 | val_loss: 0.34715 - val_acc: 0.8675 -- iter: 0160/3680
--
Training Step: 3801  | total loss: [1m[32m0.35667[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35667 - acc: 0.8564 -- iter: 0192/3680
[A[ATraining Step: 3802  | total loss: [1m[32m0.35359[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35359 - acc: 0.8583 -- iter: 0224/3680
[A[ATraining Step: 3803  | total loss: [1m[32m0.37375[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37375 - acc: 0.8381 -- iter: 0256/3680
[A[ATraining Step: 3804  | total loss: [1m[32m0.37072[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37072 - acc: 0.8418 -- iter: 0288/3680
[A[ATraining Step: 3805  | total loss: [1m[32m0.36714[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36714 - acc: 0.8482 -- iter: 0320/3680
[A[ATraining Step: 3806  | total loss: [1m[32m0.39139[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39139 - acc: 0.8322 -- iter: 0352/3680
[A[ATraining Step: 3807  | total loss: [1m[32m0.39961[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39961 - acc: 0.8271 -- iter: 0384/3680
[A[ATraining Step: 3808  | total loss: [1m[32m0.40283[0m[0m
[2K| Adam | epoch: 034 | loss: 0.40283 - acc: 0.8124 -- iter: 0416/3680
[A[ATraining Step: 3809  | total loss: [1m[32m0.40725[0m[0m
[2K| Adam | epoch: 034 | loss: 0.40725 - acc: 0.8124 -- iter: 0448/3680
[A[ATraining Step: 3810  | total loss: [1m[32m0.39936[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39936 - acc: 0.8218 -- iter: 0480/3680
[A[ATraining Step: 3811  | total loss: [1m[32m0.39075[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39075 - acc: 0.8271 -- iter: 0512/3680
[A[ATraining Step: 3812  | total loss: [1m[32m0.39515[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39515 - acc: 0.8288 -- iter: 0544/3680
[A[ATraining Step: 3813  | total loss: [1m[32m0.40375[0m[0m
[2K| Adam | epoch: 034 | loss: 0.40375 - acc: 0.8240 -- iter: 0576/3680
[A[ATraining Step: 3814  | total loss: [1m[32m0.39513[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39513 - acc: 0.8260 -- iter: 0608/3680
[A[ATraining Step: 3815  | total loss: [1m[32m0.40299[0m[0m
[2K| Adam | epoch: 034 | loss: 0.40299 - acc: 0.8215 -- iter: 0640/3680
[A[ATraining Step: 3816  | total loss: [1m[32m0.39424[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39424 - acc: 0.8269 -- iter: 0672/3680
[A[ATraining Step: 3817  | total loss: [1m[32m0.38875[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38875 - acc: 0.8317 -- iter: 0704/3680
[A[ATraining Step: 3818  | total loss: [1m[32m0.39538[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39538 - acc: 0.8266 -- iter: 0736/3680
[A[ATraining Step: 3819  | total loss: [1m[32m0.38642[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38642 - acc: 0.8346 -- iter: 0768/3680
[A[ATraining Step: 3820  | total loss: [1m[32m0.37084[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37084 - acc: 0.8479 -- iter: 0800/3680
[A[ATraining Step: 3821  | total loss: [1m[32m0.36134[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36134 - acc: 0.8479 -- iter: 0832/3680
[A[ATraining Step: 3822  | total loss: [1m[32m0.37092[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37092 - acc: 0.8506 -- iter: 0864/3680
[A[ATraining Step: 3823  | total loss: [1m[32m0.39040[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39040 - acc: 0.8468 -- iter: 0896/3680
[A[ATraining Step: 3824  | total loss: [1m[32m0.38294[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38294 - acc: 0.8527 -- iter: 0928/3680
[A[ATraining Step: 3825  | total loss: [1m[32m0.38543[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38543 - acc: 0.8518 -- iter: 0960/3680
[A[ATraining Step: 3826  | total loss: [1m[32m0.38149[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38149 - acc: 0.8542 -- iter: 0992/3680
[A[ATraining Step: 3827  | total loss: [1m[32m0.38037[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38037 - acc: 0.8562 -- iter: 1024/3680
[A[ATraining Step: 3828  | total loss: [1m[32m0.39058[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39058 - acc: 0.8456 -- iter: 1056/3680
[A[ATraining Step: 3829  | total loss: [1m[32m0.40824[0m[0m
[2K| Adam | epoch: 034 | loss: 0.40824 - acc: 0.8361 -- iter: 1088/3680
[A[ATraining Step: 3830  | total loss: [1m[32m0.40109[0m[0m
[2K| Adam | epoch: 034 | loss: 0.40109 - acc: 0.8431 -- iter: 1120/3680
[A[ATraining Step: 3831  | total loss: [1m[32m0.38731[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38731 - acc: 0.8494 -- iter: 1152/3680
[A[ATraining Step: 3832  | total loss: [1m[32m0.37007[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37007 - acc: 0.8613 -- iter: 1184/3680
[A[ATraining Step: 3833  | total loss: [1m[32m0.36264[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36264 - acc: 0.8627 -- iter: 1216/3680
[A[ATraining Step: 3834  | total loss: [1m[32m0.36698[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36698 - acc: 0.8625 -- iter: 1248/3680
[A[ATraining Step: 3835  | total loss: [1m[32m0.35552[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35552 - acc: 0.8625 -- iter: 1280/3680
[A[ATraining Step: 3836  | total loss: [1m[32m0.35670[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35670 - acc: 0.8575 -- iter: 1312/3680
[A[ATraining Step: 3837  | total loss: [1m[32m0.34709[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34709 - acc: 0.8655 -- iter: 1344/3680
[A[ATraining Step: 3838  | total loss: [1m[32m0.34252[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34252 - acc: 0.8665 -- iter: 1376/3680
[A[ATraining Step: 3839  | total loss: [1m[32m0.34129[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34129 - acc: 0.8673 -- iter: 1408/3680
[A[ATraining Step: 3840  | total loss: [1m[32m0.34215[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34215 - acc: 0.8650 -- iter: 1440/3680
[A[ATraining Step: 3841  | total loss: [1m[32m0.35197[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35197 - acc: 0.8628 -- iter: 1472/3680
[A[ATraining Step: 3842  | total loss: [1m[32m0.35392[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35392 - acc: 0.8578 -- iter: 1504/3680
[A[ATraining Step: 3843  | total loss: [1m[32m0.37052[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37052 - acc: 0.8470 -- iter: 1536/3680
[A[ATraining Step: 3844  | total loss: [1m[32m0.36144[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36144 - acc: 0.8467 -- iter: 1568/3680
[A[ATraining Step: 3845  | total loss: [1m[32m0.35850[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35850 - acc: 0.8527 -- iter: 1600/3680
[A[ATraining Step: 3846  | total loss: [1m[32m0.37060[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37060 - acc: 0.8549 -- iter: 1632/3680
[A[ATraining Step: 3847  | total loss: [1m[32m0.36746[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36746 - acc: 0.8569 -- iter: 1664/3680
[A[ATraining Step: 3848  | total loss: [1m[32m0.36859[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36859 - acc: 0.8556 -- iter: 1696/3680
[A[ATraining Step: 3849  | total loss: [1m[32m0.35832[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35832 - acc: 0.8575 -- iter: 1728/3680
[A[ATraining Step: 3850  | total loss: [1m[32m0.34460[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34460 - acc: 0.8718 -- iter: 1760/3680
[A[ATraining Step: 3851  | total loss: [1m[32m0.34862[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34862 - acc: 0.8658 -- iter: 1792/3680
[A[ATraining Step: 3852  | total loss: [1m[32m0.35519[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35519 - acc: 0.8605 -- iter: 1824/3680
[A[ATraining Step: 3853  | total loss: [1m[32m0.34001[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34001 - acc: 0.8651 -- iter: 1856/3680
[A[ATraining Step: 3854  | total loss: [1m[32m0.33583[0m[0m
[2K| Adam | epoch: 034 | loss: 0.33583 - acc: 0.8630 -- iter: 1888/3680
[A[ATraining Step: 3855  | total loss: [1m[32m0.33661[0m[0m
[2K| Adam | epoch: 034 | loss: 0.33661 - acc: 0.8642 -- iter: 1920/3680
[A[ATraining Step: 3856  | total loss: [1m[32m0.34338[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34338 - acc: 0.8590 -- iter: 1952/3680
[A[ATraining Step: 3857  | total loss: [1m[32m0.35400[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35400 - acc: 0.8543 -- iter: 1984/3680
[A[ATraining Step: 3858  | total loss: [1m[32m0.36027[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36027 - acc: 0.8502 -- iter: 2016/3680
[A[ATraining Step: 3859  | total loss: [1m[32m0.34990[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34990 - acc: 0.8589 -- iter: 2048/3680
[A[ATraining Step: 3860  | total loss: [1m[32m0.34623[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34623 - acc: 0.8574 -- iter: 2080/3680
[A[ATraining Step: 3861  | total loss: [1m[32m0.36581[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36581 - acc: 0.8466 -- iter: 2112/3680
[A[ATraining Step: 3862  | total loss: [1m[32m0.36274[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36274 - acc: 0.8526 -- iter: 2144/3680
[A[ATraining Step: 3863  | total loss: [1m[32m0.36065[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36065 - acc: 0.8548 -- iter: 2176/3680
[A[ATraining Step: 3864  | total loss: [1m[32m0.36497[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36497 - acc: 0.8506 -- iter: 2208/3680
[A[ATraining Step: 3865  | total loss: [1m[32m0.37215[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37215 - acc: 0.8437 -- iter: 2240/3680
[A[ATraining Step: 3866  | total loss: [1m[32m0.37630[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37630 - acc: 0.8406 -- iter: 2272/3680
[A[ATraining Step: 3867  | total loss: [1m[32m0.36529[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36529 - acc: 0.8502 -- iter: 2304/3680
[A[ATraining Step: 3868  | total loss: [1m[32m0.36173[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36173 - acc: 0.8527 -- iter: 2336/3680
[A[ATraining Step: 3869  | total loss: [1m[32m0.35570[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35570 - acc: 0.8487 -- iter: 2368/3680
[A[ATraining Step: 3870  | total loss: [1m[32m0.35570[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35570 - acc: 0.8576 -- iter: 2400/3680
[A[ATraining Step: 3871  | total loss: [1m[32m0.35545[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35545 - acc: 0.8531 -- iter: 2432/3680
[A[ATraining Step: 3872  | total loss: [1m[32m0.34814[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34814 - acc: 0.8553 -- iter: 2464/3680
[A[ATraining Step: 3873  | total loss: [1m[32m0.35486[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35486 - acc: 0.8479 -- iter: 2496/3680
[A[ATraining Step: 3874  | total loss: [1m[32m0.35636[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35636 - acc: 0.8506 -- iter: 2528/3680
[A[ATraining Step: 3875  | total loss: [1m[32m0.34960[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34960 - acc: 0.8530 -- iter: 2560/3680
[A[ATraining Step: 3876  | total loss: [1m[32m0.33746[0m[0m
[2K| Adam | epoch: 034 | loss: 0.33746 - acc: 0.8552 -- iter: 2592/3680
[A[ATraining Step: 3877  | total loss: [1m[32m0.34311[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34311 - acc: 0.8572 -- iter: 2624/3680
[A[ATraining Step: 3878  | total loss: [1m[32m0.36382[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36382 - acc: 0.8371 -- iter: 2656/3680
[A[ATraining Step: 3879  | total loss: [1m[32m0.36090[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36090 - acc: 0.8409 -- iter: 2688/3680
[A[ATraining Step: 3880  | total loss: [1m[32m0.36710[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36710 - acc: 0.8443 -- iter: 2720/3680
[A[ATraining Step: 3881  | total loss: [1m[32m0.35559[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35559 - acc: 0.8505 -- iter: 2752/3680
[A[ATraining Step: 3882  | total loss: [1m[32m0.36134[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36134 - acc: 0.8467 -- iter: 2784/3680
[A[ATraining Step: 3883  | total loss: [1m[32m0.35619[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35619 - acc: 0.8527 -- iter: 2816/3680
[A[ATraining Step: 3884  | total loss: [1m[32m0.36723[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36723 - acc: 0.8424 -- iter: 2848/3680
[A[ATraining Step: 3885  | total loss: [1m[32m0.37049[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37049 - acc: 0.8456 -- iter: 2880/3680
[A[ATraining Step: 3886  | total loss: [1m[32m0.36896[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36896 - acc: 0.8517 -- iter: 2912/3680
[A[ATraining Step: 3887  | total loss: [1m[32m0.36133[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36133 - acc: 0.8540 -- iter: 2944/3680
[A[ATraining Step: 3888  | total loss: [1m[32m0.34987[0m[0m
[2K| Adam | epoch: 034 | loss: 0.34987 - acc: 0.8655 -- iter: 2976/3680
[A[ATraining Step: 3889  | total loss: [1m[32m0.35793[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35793 - acc: 0.8571 -- iter: 3008/3680
[A[ATraining Step: 3890  | total loss: [1m[32m0.35546[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35546 - acc: 0.8620 -- iter: 3040/3680
[A[ATraining Step: 3891  | total loss: [1m[32m0.36198[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36198 - acc: 0.8539 -- iter: 3072/3680
[A[ATraining Step: 3892  | total loss: [1m[32m0.36035[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36035 - acc: 0.8560 -- iter: 3104/3680
[A[ATraining Step: 3893  | total loss: [1m[32m0.35868[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35868 - acc: 0.8579 -- iter: 3136/3680
[A[ATraining Step: 3894  | total loss: [1m[32m0.35578[0m[0m
[2K| Adam | epoch: 034 | loss: 0.35578 - acc: 0.8659 -- iter: 3168/3680
[A[ATraining Step: 3895  | total loss: [1m[32m0.36637[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36637 - acc: 0.8574 -- iter: 3200/3680
[A[ATraining Step: 3896  | total loss: [1m[32m0.37421[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37421 - acc: 0.8561 -- iter: 3232/3680
[A[ATraining Step: 3897  | total loss: [1m[32m0.37142[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37142 - acc: 0.8579 -- iter: 3264/3680
[A[ATraining Step: 3898  | total loss: [1m[32m0.36908[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36908 - acc: 0.8565 -- iter: 3296/3680
[A[ATraining Step: 3899  | total loss: [1m[32m0.38913[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38913 - acc: 0.8428 -- iter: 3328/3680
[A[ATraining Step: 3900  | total loss: [1m[32m0.39858[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39858 - acc: 0.8366 | val_loss: 0.35450 - val_acc: 0.8621 -- iter: 3360/3680
[A[ATraining Step: 3900  | total loss: [1m[32m0.39858[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39858 - acc: 0.8366 | val_loss: 0.35450 - val_acc: 0.8621 -- iter: 3360/3680
--
Training Step: 3901  | total loss: [1m[32m0.38727[0m[0m
[2K| Adam | epoch: 034 | loss: 0.38727 - acc: 0.8404 -- iter: 3392/3680
[A[ATraining Step: 3902  | total loss: [1m[32m0.36902[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36902 - acc: 0.8533 -- iter: 3424/3680
[A[ATraining Step: 3903  | total loss: [1m[32m0.37891[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37891 - acc: 0.8492 -- iter: 3456/3680
[A[ATraining Step: 3904  | total loss: [1m[32m0.37157[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37157 - acc: 0.8549 -- iter: 3488/3680
[A[ATraining Step: 3905  | total loss: [1m[32m0.36991[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36991 - acc: 0.8444 -- iter: 3520/3680
[A[ATraining Step: 3906  | total loss: [1m[32m0.37442[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37442 - acc: 0.8412 -- iter: 3552/3680
[A[ATraining Step: 3907  | total loss: [1m[32m0.37881[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37881 - acc: 0.8383 -- iter: 3584/3680
[A[ATraining Step: 3908  | total loss: [1m[32m0.37743[0m[0m
[2K| Adam | epoch: 034 | loss: 0.37743 - acc: 0.8451 -- iter: 3616/3680
[A[ATraining Step: 3909  | total loss: [1m[32m0.39117[0m[0m
[2K| Adam | epoch: 034 | loss: 0.39117 - acc: 0.8356 -- iter: 3648/3680
[A[ATraining Step: 3910  | total loss: [1m[32m0.36718[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36718 - acc: 0.8489 | val_loss: 0.36057 - val_acc: 0.8534 -- iter: 3680/3680
[A[ATraining Step: 3910  | total loss: [1m[32m0.36718[0m[0m
[2K| Adam | epoch: 034 | loss: 0.36718 - acc: 0.8489 | val_loss: 0.36057 - val_acc: 0.8534 -- iter: 3680/3680
--
Training Step: 3911  | total loss: [1m[32m0.38758[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38758 - acc: 0.8484 -- iter: 0032/3680
[A[ATraining Step: 3912  | total loss: [1m[32m0.49920[0m[0m
[2K| Adam | epoch: 035 | loss: 0.49920 - acc: 0.8136 -- iter: 0064/3680
[A[ATraining Step: 3913  | total loss: [1m[32m0.49439[0m[0m
[2K| Adam | epoch: 035 | loss: 0.49439 - acc: 0.8102 -- iter: 0096/3680
[A[ATraining Step: 3914  | total loss: [1m[32m0.48973[0m[0m
[2K| Adam | epoch: 035 | loss: 0.48973 - acc: 0.8102 -- iter: 0128/3680
[A[ATraining Step: 3915  | total loss: [1m[32m0.49315[0m[0m
[2K| Adam | epoch: 035 | loss: 0.49315 - acc: 0.8042 -- iter: 0160/3680
[A[ATraining Step: 3916  | total loss: [1m[32m0.47697[0m[0m
[2K| Adam | epoch: 035 | loss: 0.47697 - acc: 0.8113 -- iter: 0192/3680
[A[ATraining Step: 3917  | total loss: [1m[32m0.46398[0m[0m
[2K| Adam | epoch: 035 | loss: 0.46398 - acc: 0.8145 -- iter: 0224/3680
[A[ATraining Step: 3918  | total loss: [1m[32m0.46351[0m[0m
[2K| Adam | epoch: 035 | loss: 0.46351 - acc: 0.8237 -- iter: 0256/3680
[A[ATraining Step: 3919  | total loss: [1m[32m0.44364[0m[0m
[2K| Adam | epoch: 035 | loss: 0.44364 - acc: 0.8351 -- iter: 0288/3680
[A[ATraining Step: 3920  | total loss: [1m[32m0.43730[0m[0m
[2K| Adam | epoch: 035 | loss: 0.43730 - acc: 0.8360 -- iter: 0320/3680
[A[ATraining Step: 3921  | total loss: [1m[32m0.44282[0m[0m
[2K| Adam | epoch: 035 | loss: 0.44282 - acc: 0.8305 -- iter: 0352/3680
[A[ATraining Step: 3922  | total loss: [1m[32m0.43002[0m[0m
[2K| Adam | epoch: 035 | loss: 0.43002 - acc: 0.8412 -- iter: 0384/3680
[A[ATraining Step: 3923  | total loss: [1m[32m0.42274[0m[0m
[2K| Adam | epoch: 035 | loss: 0.42274 - acc: 0.8383 -- iter: 0416/3680
[A[ATraining Step: 3924  | total loss: [1m[32m0.41731[0m[0m
[2K| Adam | epoch: 035 | loss: 0.41731 - acc: 0.8420 -- iter: 0448/3680
[A[ATraining Step: 3925  | total loss: [1m[32m0.41119[0m[0m
[2K| Adam | epoch: 035 | loss: 0.41119 - acc: 0.8453 -- iter: 0480/3680
[A[ATraining Step: 3926  | total loss: [1m[32m0.40758[0m[0m
[2K| Adam | epoch: 035 | loss: 0.40758 - acc: 0.8451 -- iter: 0512/3680
[A[ATraining Step: 3927  | total loss: [1m[32m0.42011[0m[0m
[2K| Adam | epoch: 035 | loss: 0.42011 - acc: 0.8419 -- iter: 0544/3680
[A[ATraining Step: 3928  | total loss: [1m[32m0.42048[0m[0m
[2K| Adam | epoch: 035 | loss: 0.42048 - acc: 0.8389 -- iter: 0576/3680
[A[ATraining Step: 3929  | total loss: [1m[32m0.40282[0m[0m
[2K| Adam | epoch: 035 | loss: 0.40282 - acc: 0.8457 -- iter: 0608/3680
[A[ATraining Step: 3930  | total loss: [1m[32m0.42002[0m[0m
[2K| Adam | epoch: 035 | loss: 0.42002 - acc: 0.8173 -- iter: 0640/3680
[A[ATraining Step: 3931  | total loss: [1m[32m0.42469[0m[0m
[2K| Adam | epoch: 035 | loss: 0.42469 - acc: 0.8169 -- iter: 0672/3680
[A[ATraining Step: 3932  | total loss: [1m[32m0.40806[0m[0m
[2K| Adam | epoch: 035 | loss: 0.40806 - acc: 0.8258 -- iter: 0704/3680
[A[ATraining Step: 3933  | total loss: [1m[32m0.41013[0m[0m
[2K| Adam | epoch: 035 | loss: 0.41013 - acc: 0.8151 -- iter: 0736/3680
[A[ATraining Step: 3934  | total loss: [1m[32m0.40844[0m[0m
[2K| Adam | epoch: 035 | loss: 0.40844 - acc: 0.8180 -- iter: 0768/3680
[A[ATraining Step: 3935  | total loss: [1m[32m0.39678[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39678 - acc: 0.8205 -- iter: 0800/3680
[A[ATraining Step: 3936  | total loss: [1m[32m0.39591[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39591 - acc: 0.8229 -- iter: 0832/3680
[A[ATraining Step: 3937  | total loss: [1m[32m0.38311[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38311 - acc: 0.8343 -- iter: 0864/3680
[A[ATraining Step: 3938  | total loss: [1m[32m0.36956[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36956 - acc: 0.8446 -- iter: 0896/3680
[A[ATraining Step: 3939  | total loss: [1m[32m0.36196[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36196 - acc: 0.8477 -- iter: 0928/3680
[A[ATraining Step: 3940  | total loss: [1m[32m0.35416[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35416 - acc: 0.8535 -- iter: 0960/3680
[A[ATraining Step: 3941  | total loss: [1m[32m0.38163[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38163 - acc: 0.8463 -- iter: 0992/3680
[A[ATraining Step: 3942  | total loss: [1m[32m0.38109[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38109 - acc: 0.8429 -- iter: 1024/3680
[A[ATraining Step: 3943  | total loss: [1m[32m0.37785[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37785 - acc: 0.8524 -- iter: 1056/3680
[A[ATraining Step: 3944  | total loss: [1m[32m0.37443[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37443 - acc: 0.8484 -- iter: 1088/3680
[A[ATraining Step: 3945  | total loss: [1m[32m0.37611[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37611 - acc: 0.8447 -- iter: 1120/3680
[A[ATraining Step: 3946  | total loss: [1m[32m0.37611[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37611 - acc: 0.8447 -- iter: 1152/3680
[A[ATraining Step: 3947  | total loss: [1m[32m0.38739[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38739 - acc: 0.8415 -- iter: 1184/3680
[A[ATraining Step: 3948  | total loss: [1m[32m0.38937[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38937 - acc: 0.8482 -- iter: 1216/3680
[A[ATraining Step: 3949  | total loss: [1m[32m0.38401[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38401 - acc: 0.8482 -- iter: 1248/3680
[A[ATraining Step: 3950  | total loss: [1m[32m0.38222[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38222 - acc: 0.8415 -- iter: 1280/3680
[A[ATraining Step: 3951  | total loss: [1m[32m0.39227[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39227 - acc: 0.8323 -- iter: 1312/3680
[A[ATraining Step: 3952  | total loss: [1m[32m0.38955[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38955 - acc: 0.8303 -- iter: 1344/3680
[A[ATraining Step: 3953  | total loss: [1m[32m0.39439[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39439 - acc: 0.8317 -- iter: 1376/3680
[A[ATraining Step: 3954  | total loss: [1m[32m0.40369[0m[0m
[2K| Adam | epoch: 035 | loss: 0.40369 - acc: 0.8329 -- iter: 1408/3680
[A[ATraining Step: 3955  | total loss: [1m[32m0.40363[0m[0m
[2K| Adam | epoch: 035 | loss: 0.40363 - acc: 0.8309 -- iter: 1440/3680
[A[ATraining Step: 3956  | total loss: [1m[32m0.39515[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39515 - acc: 0.8353 -- iter: 1472/3680
[A[ATraining Step: 3957  | total loss: [1m[32m0.38391[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38391 - acc: 0.8392 -- iter: 1504/3680
[A[ATraining Step: 3958  | total loss: [1m[32m0.37601[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37601 - acc: 0.8428 -- iter: 1536/3680
[A[ATraining Step: 3959  | total loss: [1m[32m0.37624[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37624 - acc: 0.8398 -- iter: 1568/3680
[A[ATraining Step: 3960  | total loss: [1m[32m0.37406[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37406 - acc: 0.8433 -- iter: 1600/3680
[A[ATraining Step: 3961  | total loss: [1m[32m0.37472[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37472 - acc: 0.8402 -- iter: 1632/3680
[A[ATraining Step: 3962  | total loss: [1m[32m0.37990[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37990 - acc: 0.8381 -- iter: 1664/3680
[A[ATraining Step: 3963  | total loss: [1m[32m0.37990[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37990 - acc: 0.8381 -- iter: 1696/3680
[A[ATraining Step: 3964  | total loss: [1m[32m0.38014[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38014 - acc: 0.8355 -- iter: 1728/3680
[A[ATraining Step: 3965  | total loss: [1m[32m0.37531[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37531 - acc: 0.8395 -- iter: 1760/3680
[A[ATraining Step: 3966  | total loss: [1m[32m0.39175[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39175 - acc: 0.8336 -- iter: 1792/3680
[A[ATraining Step: 3967  | total loss: [1m[32m0.39304[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39304 - acc: 0.8347 -- iter: 1824/3680
[A[ATraining Step: 3968  | total loss: [1m[32m0.38664[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38664 - acc: 0.8356 -- iter: 1856/3680
[A[ATraining Step: 3969  | total loss: [1m[32m0.38320[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38320 - acc: 0.8364 -- iter: 1888/3680
[A[ATraining Step: 3970  | total loss: [1m[32m0.37708[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37708 - acc: 0.8402 -- iter: 1920/3680
[A[ATraining Step: 3971  | total loss: [1m[32m0.36721[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36721 - acc: 0.8500 -- iter: 1952/3680
[A[ATraining Step: 3972  | total loss: [1m[32m0.37214[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37214 - acc: 0.8431 -- iter: 1984/3680
[A[ATraining Step: 3973  | total loss: [1m[32m0.36950[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36950 - acc: 0.8432 -- iter: 2016/3680
[A[ATraining Step: 3974  | total loss: [1m[32m0.37913[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37913 - acc: 0.8401 -- iter: 2048/3680
[A[ATraining Step: 3975  | total loss: [1m[32m0.37462[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37462 - acc: 0.8405 -- iter: 2080/3680
[A[ATraining Step: 3976  | total loss: [1m[32m0.37793[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37793 - acc: 0.8314 -- iter: 2112/3680
[A[ATraining Step: 3977  | total loss: [1m[32m0.37593[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37593 - acc: 0.8295 -- iter: 2144/3680
[A[ATraining Step: 3978  | total loss: [1m[32m0.37510[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37510 - acc: 0.8309 -- iter: 2176/3680
[A[ATraining Step: 3979  | total loss: [1m[32m0.38058[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38058 - acc: 0.8197 -- iter: 2208/3680
[A[ATraining Step: 3980  | total loss: [1m[32m0.39063[0m[0m
[2K| Adam | epoch: 035 | loss: 0.39063 - acc: 0.8128 -- iter: 2240/3680
[A[ATraining Step: 3981  | total loss: [1m[32m0.38254[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38254 - acc: 0.8190 -- iter: 2272/3680
[A[ATraining Step: 3982  | total loss: [1m[32m0.36909[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36909 - acc: 0.8277 -- iter: 2304/3680
[A[ATraining Step: 3983  | total loss: [1m[32m0.37740[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37740 - acc: 0.8199 -- iter: 2336/3680
[A[ATraining Step: 3984  | total loss: [1m[32m0.36942[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36942 - acc: 0.8335 -- iter: 2368/3680
[A[ATraining Step: 3985  | total loss: [1m[32m0.35948[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35948 - acc: 0.8335 -- iter: 2400/3680
[A[ATraining Step: 3986  | total loss: [1m[32m0.35544[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35544 - acc: 0.8377 -- iter: 2432/3680
[A[ATraining Step: 3987  | total loss: [1m[32m0.34638[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34638 - acc: 0.8383 -- iter: 2464/3680
[A[ATraining Step: 3988  | total loss: [1m[32m0.35235[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35235 - acc: 0.8357 -- iter: 2496/3680
[A[ATraining Step: 3989  | total loss: [1m[32m0.34733[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34733 - acc: 0.8428 -- iter: 2528/3680
[A[ATraining Step: 3990  | total loss: [1m[32m0.35371[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35371 - acc: 0.8460 -- iter: 2560/3680
[A[ATraining Step: 3991  | total loss: [1m[32m0.34952[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34952 - acc: 0.8489 -- iter: 2592/3680
[A[ATraining Step: 3992  | total loss: [1m[32m0.34026[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34026 - acc: 0.8546 -- iter: 2624/3680
[A[ATraining Step: 3993  | total loss: [1m[32m0.34143[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34143 - acc: 0.8535 -- iter: 2656/3680
[A[ATraining Step: 3994  | total loss: [1m[32m0.33738[0m[0m
[2K| Adam | epoch: 035 | loss: 0.33738 - acc: 0.8557 -- iter: 2688/3680
[A[ATraining Step: 3995  | total loss: [1m[32m0.33608[0m[0m
[2K| Adam | epoch: 035 | loss: 0.33608 - acc: 0.8576 -- iter: 2720/3680
[A[ATraining Step: 3996  | total loss: [1m[32m0.34985[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34985 - acc: 0.8468 -- iter: 2752/3680
[A[ATraining Step: 3997  | total loss: [1m[32m0.34647[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34647 - acc: 0.8497 -- iter: 2784/3680
[A[ATraining Step: 3998  | total loss: [1m[32m0.34293[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34293 - acc: 0.8491 -- iter: 2816/3680
[A[ATraining Step: 3999  | total loss: [1m[32m0.34603[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34603 - acc: 0.8485 -- iter: 2848/3680
[A[ATraining Step: 4000  | total loss: [1m[32m0.35972[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35972 - acc: 0.8324 | val_loss: 0.35176 - val_acc: 0.8567 -- iter: 2880/3680
[A[ATraining Step: 4000  | total loss: [1m[32m0.35972[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35972 - acc: 0.8324 | val_loss: 0.35176 - val_acc: 0.8567 -- iter: 2880/3680
--
Training Step: 4001  | total loss: [1m[32m0.37149[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37149 - acc: 0.8242 -- iter: 2912/3680
[A[ATraining Step: 4002  | total loss: [1m[32m0.35241[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35241 - acc: 0.8355 -- iter: 2944/3680
[A[ATraining Step: 4003  | total loss: [1m[32m0.34177[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34177 - acc: 0.8426 -- iter: 2976/3680
[A[ATraining Step: 4004  | total loss: [1m[32m0.36787[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36787 - acc: 0.8333 -- iter: 3008/3680
[A[ATraining Step: 4005  | total loss: [1m[32m0.35899[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35899 - acc: 0.8375 -- iter: 3040/3680
[A[ATraining Step: 4006  | total loss: [1m[32m0.36215[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36215 - acc: 0.8350 -- iter: 3072/3680
[A[ATraining Step: 4007  | total loss: [1m[32m0.34746[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34746 - acc: 0.8390 -- iter: 3104/3680
[A[ATraining Step: 4008  | total loss: [1m[32m0.33830[0m[0m
[2K| Adam | epoch: 035 | loss: 0.33830 - acc: 0.8457 -- iter: 3136/3680
[A[ATraining Step: 4009  | total loss: [1m[32m0.37191[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37191 - acc: 0.8268 -- iter: 3168/3680
[A[ATraining Step: 4010  | total loss: [1m[32m0.37559[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37559 - acc: 0.8160 -- iter: 3200/3680
[A[ATraining Step: 4011  | total loss: [1m[32m0.38543[0m[0m
[2K| Adam | epoch: 035 | loss: 0.38543 - acc: 0.8094 -- iter: 3232/3680
[A[ATraining Step: 4012  | total loss: [1m[32m0.37558[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37558 - acc: 0.8222 -- iter: 3264/3680
[A[ATraining Step: 4013  | total loss: [1m[32m0.36132[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36132 - acc: 0.8337 -- iter: 3296/3680
[A[ATraining Step: 4014  | total loss: [1m[32m0.36101[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36101 - acc: 0.8378 -- iter: 3328/3680
[A[ATraining Step: 4015  | total loss: [1m[32m0.35186[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35186 - acc: 0.8447 -- iter: 3360/3680
[A[ATraining Step: 4016  | total loss: [1m[32m0.34495[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34495 - acc: 0.8415 -- iter: 3392/3680
[A[ATraining Step: 4017  | total loss: [1m[32m0.35214[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35214 - acc: 0.8448 -- iter: 3424/3680
[A[ATraining Step: 4018  | total loss: [1m[32m0.35175[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35175 - acc: 0.8447 -- iter: 3456/3680
[A[ATraining Step: 4019  | total loss: [1m[32m0.37339[0m[0m
[2K| Adam | epoch: 035 | loss: 0.37339 - acc: 0.8290 -- iter: 3488/3680
[A[ATraining Step: 4020  | total loss: [1m[32m0.36273[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36273 - acc: 0.8336 -- iter: 3520/3680
[A[ATraining Step: 4021  | total loss: [1m[32m0.35979[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35979 - acc: 0.8377 -- iter: 3552/3680
[A[ATraining Step: 4022  | total loss: [1m[32m0.36776[0m[0m
[2K| Adam | epoch: 035 | loss: 0.36776 - acc: 0.8454 -- iter: 3584/3680
[A[ATraining Step: 4023  | total loss: [1m[32m0.35345[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35345 - acc: 0.8454 -- iter: 3616/3680
[A[ATraining Step: 4024  | total loss: [1m[32m0.34525[0m[0m
[2K| Adam | epoch: 035 | loss: 0.34525 - acc: 0.8515 -- iter: 3648/3680
[A[ATraining Step: 4025  | total loss: [1m[32m0.35714[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35714 - acc: 0.8414 | val_loss: 0.35359 - val_acc: 0.8675 -- iter: 3680/3680
[A[ATraining Step: 4025  | total loss: [1m[32m0.35714[0m[0m
[2K| Adam | epoch: 035 | loss: 0.35714 - acc: 0.8414 | val_loss: 0.35359 - val_acc: 0.8675 -- iter: 3680/3680
--
Training Step: 4026  | total loss: [1m[32m0.34852[0m[0m
[2K| Adam | epoch: 036 | loss: 0.34852 - acc: 0.8416 -- iter: 0032/3680
[A[ATraining Step: 4027  | total loss: [1m[32m0.36417[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36417 - acc: 0.8324 -- iter: 0064/3680
[A[ATraining Step: 4028  | total loss: [1m[32m0.47686[0m[0m
[2K| Adam | epoch: 036 | loss: 0.47686 - acc: 0.7961 -- iter: 0096/3680
[A[ATraining Step: 4029  | total loss: [1m[32m0.47518[0m[0m
[2K| Adam | epoch: 036 | loss: 0.47518 - acc: 0.8008 -- iter: 0128/3680
[A[ATraining Step: 4030  | total loss: [1m[32m0.45964[0m[0m
[2K| Adam | epoch: 036 | loss: 0.45964 - acc: 0.8124 -- iter: 0160/3680
[A[ATraining Step: 4031  | total loss: [1m[32m0.45964[0m[0m
[2K| Adam | epoch: 036 | loss: 0.45964 - acc: 0.8124 -- iter: 0192/3680
[A[ATraining Step: 4032  | total loss: [1m[32m0.44865[0m[0m
[2K| Adam | epoch: 036 | loss: 0.44865 - acc: 0.8156 -- iter: 0224/3680
[A[ATraining Step: 4033  | total loss: [1m[32m0.43680[0m[0m
[2K| Adam | epoch: 036 | loss: 0.43680 - acc: 0.8215 -- iter: 0256/3680
[A[ATraining Step: 4034  | total loss: [1m[32m0.41908[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41908 - acc: 0.8300 -- iter: 0288/3680
[A[ATraining Step: 4035  | total loss: [1m[32m0.40240[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40240 - acc: 0.8376 -- iter: 0320/3680
[A[ATraining Step: 4036  | total loss: [1m[32m0.40483[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40483 - acc: 0.8382 -- iter: 0352/3680
[A[ATraining Step: 4037  | total loss: [1m[32m0.38939[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38939 - acc: 0.8450 -- iter: 0384/3680
[A[ATraining Step: 4038  | total loss: [1m[32m0.37881[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37881 - acc: 0.8574 -- iter: 0416/3680
[A[ATraining Step: 4039  | total loss: [1m[32m0.37398[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37398 - acc: 0.8623 -- iter: 0448/3680
[A[ATraining Step: 4040  | total loss: [1m[32m0.36433[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36433 - acc: 0.8604 -- iter: 0480/3680
[A[ATraining Step: 4041  | total loss: [1m[32m0.37076[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37076 - acc: 0.8556 -- iter: 0512/3680
[A[ATraining Step: 4042  | total loss: [1m[32m0.37558[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37558 - acc: 0.8482 -- iter: 0544/3680
[A[ATraining Step: 4043  | total loss: [1m[32m0.37165[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37165 - acc: 0.8415 -- iter: 0576/3680
[A[ATraining Step: 4044  | total loss: [1m[32m0.37185[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37185 - acc: 0.8386 -- iter: 0608/3680
[A[ATraining Step: 4045  | total loss: [1m[32m0.36485[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36485 - acc: 0.8422 -- iter: 0640/3680
[A[ATraining Step: 4046  | total loss: [1m[32m0.35807[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35807 - acc: 0.8455 -- iter: 0672/3680
[A[ATraining Step: 4047  | total loss: [1m[32m0.34261[0m[0m
[2K| Adam | epoch: 036 | loss: 0.34261 - acc: 0.8578 -- iter: 0704/3680
[A[ATraining Step: 4048  | total loss: [1m[32m0.33092[0m[0m
[2K| Adam | epoch: 036 | loss: 0.33092 - acc: 0.8658 -- iter: 0736/3680
[A[ATraining Step: 4049  | total loss: [1m[32m0.32780[0m[0m
[2K| Adam | epoch: 036 | loss: 0.32780 - acc: 0.8730 -- iter: 0768/3680
[A[ATraining Step: 4050  | total loss: [1m[32m0.32413[0m[0m
[2K| Adam | epoch: 036 | loss: 0.32413 - acc: 0.8732 -- iter: 0800/3680
[A[ATraining Step: 4051  | total loss: [1m[32m0.33114[0m[0m
[2K| Adam | epoch: 036 | loss: 0.33114 - acc: 0.8702 -- iter: 0832/3680
[A[ATraining Step: 4052  | total loss: [1m[32m0.32259[0m[0m
[2K| Adam | epoch: 036 | loss: 0.32259 - acc: 0.8738 -- iter: 0864/3680
[A[ATraining Step: 4053  | total loss: [1m[32m0.32340[0m[0m
[2K| Adam | epoch: 036 | loss: 0.32340 - acc: 0.8677 -- iter: 0896/3680
[A[ATraining Step: 4054  | total loss: [1m[32m0.33376[0m[0m
[2K| Adam | epoch: 036 | loss: 0.33376 - acc: 0.8622 -- iter: 0928/3680
[A[ATraining Step: 4055  | total loss: [1m[32m0.33242[0m[0m
[2K| Adam | epoch: 036 | loss: 0.33242 - acc: 0.8603 -- iter: 0960/3680
[A[ATraining Step: 4056  | total loss: [1m[32m0.34316[0m[0m
[2K| Adam | epoch: 036 | loss: 0.34316 - acc: 0.8524 -- iter: 0992/3680
[A[ATraining Step: 4057  | total loss: [1m[32m0.35505[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35505 - acc: 0.8422 -- iter: 1024/3680
[A[ATraining Step: 4058  | total loss: [1m[32m0.35779[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35779 - acc: 0.8423 -- iter: 1056/3680
[A[ATraining Step: 4059  | total loss: [1m[32m0.35912[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35912 - acc: 0.8394 -- iter: 1088/3680
[A[ATraining Step: 4060  | total loss: [1m[32m0.36633[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36633 - acc: 0.8335 -- iter: 1120/3680
[A[ATraining Step: 4061  | total loss: [1m[32m0.36751[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36751 - acc: 0.8346 -- iter: 1152/3680
[A[ATraining Step: 4062  | total loss: [1m[32m0.36163[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36163 - acc: 0.8417 -- iter: 1184/3680
[A[ATraining Step: 4063  | total loss: [1m[32m0.37707[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37707 - acc: 0.8388 -- iter: 1216/3680
[A[ATraining Step: 4064  | total loss: [1m[32m0.36170[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36170 - acc: 0.8456 -- iter: 1248/3680
[A[ATraining Step: 4065  | total loss: [1m[32m0.36420[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36420 - acc: 0.8516 -- iter: 1280/3680
[A[ATraining Step: 4066  | total loss: [1m[32m0.35390[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35390 - acc: 0.8602 -- iter: 1312/3680
[A[ATraining Step: 4067  | total loss: [1m[32m0.35084[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35084 - acc: 0.8617 -- iter: 1344/3680
[A[ATraining Step: 4068  | total loss: [1m[32m0.34628[0m[0m
[2K| Adam | epoch: 036 | loss: 0.34628 - acc: 0.8599 -- iter: 1376/3680
[A[ATraining Step: 4069  | total loss: [1m[32m0.36560[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36560 - acc: 0.8458 -- iter: 1408/3680
[A[ATraining Step: 4070  | total loss: [1m[32m0.36479[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36479 - acc: 0.8487 -- iter: 1440/3680
[A[ATraining Step: 4071  | total loss: [1m[32m0.37167[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37167 - acc: 0.8420 -- iter: 1472/3680
[A[ATraining Step: 4072  | total loss: [1m[32m0.37600[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37600 - acc: 0.8359 -- iter: 1504/3680
[A[ATraining Step: 4073  | total loss: [1m[32m0.36542[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36542 - acc: 0.8429 -- iter: 1536/3680
[A[ATraining Step: 4074  | total loss: [1m[32m0.37412[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37412 - acc: 0.8430 -- iter: 1568/3680
[A[ATraining Step: 4075  | total loss: [1m[32m0.36704[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36704 - acc: 0.8493 -- iter: 1600/3680
[A[ATraining Step: 4076  | total loss: [1m[32m0.36372[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36372 - acc: 0.8488 -- iter: 1632/3680
[A[ATraining Step: 4077  | total loss: [1m[32m0.37535[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37535 - acc: 0.8358 -- iter: 1664/3680
[A[ATraining Step: 4078  | total loss: [1m[32m0.37737[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37737 - acc: 0.8334 -- iter: 1696/3680
[A[ATraining Step: 4079  | total loss: [1m[32m0.38643[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38643 - acc: 0.8313 -- iter: 1728/3680
[A[ATraining Step: 4080  | total loss: [1m[32m0.38357[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38357 - acc: 0.8263 -- iter: 1760/3680
[A[ATraining Step: 4081  | total loss: [1m[32m0.39389[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39389 - acc: 0.8187 -- iter: 1792/3680
[A[ATraining Step: 4082  | total loss: [1m[32m0.40320[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40320 - acc: 0.8150 -- iter: 1824/3680
[A[ATraining Step: 4083  | total loss: [1m[32m0.41886[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41886 - acc: 0.8022 -- iter: 1856/3680
[A[ATraining Step: 4084  | total loss: [1m[32m0.40423[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40423 - acc: 0.8157 -- iter: 1888/3680
[A[ATraining Step: 4085  | total loss: [1m[32m0.39673[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39673 - acc: 0.8185 -- iter: 1920/3680
[A[ATraining Step: 4086  | total loss: [1m[32m0.38076[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38076 - acc: 0.8273 -- iter: 1952/3680
[A[ATraining Step: 4087  | total loss: [1m[32m0.36872[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36872 - acc: 0.8352 -- iter: 1984/3680
[A[ATraining Step: 4088  | total loss: [1m[32m0.36410[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36410 - acc: 0.8423 -- iter: 2016/3680
[A[ATraining Step: 4089  | total loss: [1m[32m0.37185[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37185 - acc: 0.8425 -- iter: 2048/3680
[A[ATraining Step: 4090  | total loss: [1m[32m0.38109[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38109 - acc: 0.8426 -- iter: 2080/3680
[A[ATraining Step: 4091  | total loss: [1m[32m0.36309[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36309 - acc: 0.8552 -- iter: 2112/3680
[A[ATraining Step: 4092  | total loss: [1m[32m0.35951[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35951 - acc: 0.8603 -- iter: 2144/3680
[A[ATraining Step: 4093  | total loss: [1m[32m0.38260[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38260 - acc: 0.8493 -- iter: 2176/3680
[A[ATraining Step: 4094  | total loss: [1m[32m0.38906[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38906 - acc: 0.8426 -- iter: 2208/3680
[A[ATraining Step: 4095  | total loss: [1m[32m0.39252[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39252 - acc: 0.8426 -- iter: 2240/3680
[A[ATraining Step: 4096  | total loss: [1m[32m0.39912[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39912 - acc: 0.8365 -- iter: 2272/3680
[A[ATraining Step: 4097  | total loss: [1m[32m0.39643[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39643 - acc: 0.8341 -- iter: 2304/3680
[A[ATraining Step: 4098  | total loss: [1m[32m0.39728[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39728 - acc: 0.8257 -- iter: 2336/3680
[A[ATraining Step: 4099  | total loss: [1m[32m0.38893[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38893 - acc: 0.8306 -- iter: 2368/3680
[A[ATraining Step: 4100  | total loss: [1m[32m0.39292[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39292 - acc: 0.8288 | val_loss: 0.34500 - val_acc: 0.8740 -- iter: 2400/3680
[A[ATraining Step: 4100  | total loss: [1m[32m0.39292[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39292 - acc: 0.8288 | val_loss: 0.34500 - val_acc: 0.8740 -- iter: 2400/3680
--
Training Step: 4101  | total loss: [1m[32m0.38603[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38603 - acc: 0.8334 -- iter: 2432/3680
[A[ATraining Step: 4102  | total loss: [1m[32m0.39594[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39594 - acc: 0.8282 -- iter: 2464/3680
[A[ATraining Step: 4103  | total loss: [1m[32m0.40971[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40971 - acc: 0.8266 -- iter: 2496/3680
[A[ATraining Step: 4104  | total loss: [1m[32m0.40061[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40061 - acc: 0.8377 -- iter: 2528/3680
[A[ATraining Step: 4105  | total loss: [1m[32m0.39123[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39123 - acc: 0.8446 -- iter: 2560/3680
[A[ATraining Step: 4106  | total loss: [1m[32m0.38873[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38873 - acc: 0.8482 -- iter: 2592/3680
[A[ATraining Step: 4107  | total loss: [1m[32m0.38873[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38873 - acc: 0.8482 -- iter: 2624/3680
[A[ATraining Step: 4108  | total loss: [1m[32m0.36731[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36731 - acc: 0.8602 -- iter: 2656/3680
[A[ATraining Step: 4109  | total loss: [1m[32m0.36259[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36259 - acc: 0.8586 -- iter: 2688/3680
[A[ATraining Step: 4110  | total loss: [1m[32m0.36960[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36960 - acc: 0.8571 -- iter: 2720/3680
[A[ATraining Step: 4111  | total loss: [1m[32m0.34949[0m[0m
[2K| Adam | epoch: 036 | loss: 0.34949 - acc: 0.8683 -- iter: 2752/3680
[A[ATraining Step: 4112  | total loss: [1m[32m0.35103[0m[0m
[2K| Adam | epoch: 036 | loss: 0.35103 - acc: 0.8689 -- iter: 2784/3680
[A[ATraining Step: 4113  | total loss: [1m[32m0.34796[0m[0m
[2K| Adam | epoch: 036 | loss: 0.34796 - acc: 0.8695 -- iter: 2816/3680
[A[ATraining Step: 4114  | total loss: [1m[32m0.36376[0m[0m
[2K| Adam | epoch: 036 | loss: 0.36376 - acc: 0.8607 -- iter: 2848/3680
[A[ATraining Step: 4115  | total loss: [1m[32m0.37418[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37418 - acc: 0.8496 -- iter: 2880/3680
[A[ATraining Step: 4116  | total loss: [1m[32m0.37545[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37545 - acc: 0.8490 -- iter: 2912/3680
[A[ATraining Step: 4117  | total loss: [1m[32m0.38299[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38299 - acc: 0.8454 -- iter: 2944/3680
[A[ATraining Step: 4118  | total loss: [1m[32m0.40380[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40380 - acc: 0.8370 -- iter: 2976/3680
[A[ATraining Step: 4119  | total loss: [1m[32m0.39272[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39272 - acc: 0.8370 -- iter: 3008/3680
[A[ATraining Step: 4120  | total loss: [1m[32m0.38726[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38726 - acc: 0.8376 -- iter: 3040/3680
[A[ATraining Step: 4121  | total loss: [1m[32m0.38255[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38255 - acc: 0.8382 -- iter: 3072/3680
[A[ATraining Step: 4122  | total loss: [1m[32m0.38861[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38861 - acc: 0.8388 -- iter: 3104/3680
[A[ATraining Step: 4123  | total loss: [1m[32m0.39733[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39733 - acc: 0.8330 -- iter: 3136/3680
[A[ATraining Step: 4124  | total loss: [1m[32m0.39785[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39785 - acc: 0.8163 -- iter: 3168/3680
[A[ATraining Step: 4125  | total loss: [1m[32m0.41722[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41722 - acc: 0.8222 -- iter: 3200/3680
[A[ATraining Step: 4126  | total loss: [1m[32m0.40903[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40903 - acc: 0.8222 -- iter: 3232/3680
[A[ATraining Step: 4127  | total loss: [1m[32m0.42462[0m[0m
[2K| Adam | epoch: 036 | loss: 0.42462 - acc: 0.8332 -- iter: 3264/3680
[A[ATraining Step: 4128  | total loss: [1m[32m0.40639[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40639 - acc: 0.8332 -- iter: 3296/3680
[A[ATraining Step: 4129  | total loss: [1m[32m0.41745[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41745 - acc: 0.8280 -- iter: 3328/3680
[A[ATraining Step: 4130  | total loss: [1m[32m0.40764[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40764 - acc: 0.8358 -- iter: 3360/3680
[A[ATraining Step: 4131  | total loss: [1m[32m0.40355[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40355 - acc: 0.8366 -- iter: 3392/3680
[A[ATraining Step: 4132  | total loss: [1m[32m0.40068[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40068 - acc: 0.8342 -- iter: 3424/3680
[A[ATraining Step: 4133  | total loss: [1m[32m0.39619[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39619 - acc: 0.8354 -- iter: 3456/3680
[A[ATraining Step: 4134  | total loss: [1m[32m0.40760[0m[0m
[2K| Adam | epoch: 036 | loss: 0.40760 - acc: 0.8354 -- iter: 3488/3680
[A[ATraining Step: 4135  | total loss: [1m[32m0.39864[0m[0m
[2K| Adam | epoch: 036 | loss: 0.39864 - acc: 0.8435 -- iter: 3520/3680
[A[ATraining Step: 4136  | total loss: [1m[32m0.38562[0m[0m
[2K| Adam | epoch: 036 | loss: 0.38562 - acc: 0.8435 -- iter: 3552/3680
[A[ATraining Step: 4137  | total loss: [1m[32m0.37790[0m[0m
[2K| Adam | epoch: 036 | loss: 0.37790 - acc: 0.8498 -- iter: 3584/3680
[A[ATraining Step: 4138  | total loss: [1m[32m0.41071[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41071 - acc: 0.8336 -- iter: 3616/3680
[A[ATraining Step: 4139  | total loss: [1m[32m0.42123[0m[0m
[2K| Adam | epoch: 036 | loss: 0.42123 - acc: 0.8283 -- iter: 3648/3680
[A[ATraining Step: 4140  | total loss: [1m[32m0.41234[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41234 - acc: 0.8330 | val_loss: 0.34465 - val_acc: 0.8719 -- iter: 3680/3680
[A[ATraining Step: 4140  | total loss: [1m[32m0.41234[0m[0m
[2K| Adam | epoch: 036 | loss: 0.41234 - acc: 0.8330 | val_loss: 0.34465 - val_acc: 0.8719 -- iter: 3680/3680
--
Training Step: 4141  | total loss: [1m[32m0.40390[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40390 - acc: 0.8379 -- iter: 0032/3680
[A[ATraining Step: 4142  | total loss: [1m[32m0.39381[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39381 - acc: 0.8379 -- iter: 0064/3680
[A[ATraining Step: 4143  | total loss: [1m[32m0.37246[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37246 - acc: 0.8478 -- iter: 0096/3680
[A[ATraining Step: 4144  | total loss: [1m[32m0.44054[0m[0m
[2K| Adam | epoch: 037 | loss: 0.44054 - acc: 0.8162 -- iter: 0128/3680
[A[ATraining Step: 4145  | total loss: [1m[32m0.42648[0m[0m
[2K| Adam | epoch: 037 | loss: 0.42648 - acc: 0.8221 -- iter: 0160/3680
[A[ATraining Step: 4146  | total loss: [1m[32m0.44727[0m[0m
[2K| Adam | epoch: 037 | loss: 0.44727 - acc: 0.8117 -- iter: 0192/3680
[A[ATraining Step: 4147  | total loss: [1m[32m0.43234[0m[0m
[2K| Adam | epoch: 037 | loss: 0.43234 - acc: 0.8180 -- iter: 0224/3680
[A[ATraining Step: 4148  | total loss: [1m[32m0.42789[0m[0m
[2K| Adam | epoch: 037 | loss: 0.42789 - acc: 0.8206 -- iter: 0256/3680
[A[ATraining Step: 4149  | total loss: [1m[32m0.43294[0m[0m
[2K| Adam | epoch: 037 | loss: 0.43294 - acc: 0.8104 -- iter: 0288/3680
[A[ATraining Step: 4150  | total loss: [1m[32m0.44015[0m[0m
[2K| Adam | epoch: 037 | loss: 0.44015 - acc: 0.8044 -- iter: 0320/3680
[A[ATraining Step: 4151  | total loss: [1m[32m0.43182[0m[0m
[2K| Adam | epoch: 037 | loss: 0.43182 - acc: 0.8083 -- iter: 0352/3680
[A[ATraining Step: 4152  | total loss: [1m[32m0.41605[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41605 - acc: 0.8212 -- iter: 0384/3680
[A[ATraining Step: 4153  | total loss: [1m[32m0.41777[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41777 - acc: 0.8235 -- iter: 0416/3680
[A[ATraining Step: 4154  | total loss: [1m[32m0.41252[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41252 - acc: 0.8255 -- iter: 0448/3680
[A[ATraining Step: 4155  | total loss: [1m[32m0.40934[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40934 - acc: 0.8273 -- iter: 0480/3680
[A[ATraining Step: 4156  | total loss: [1m[32m0.39216[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39216 - acc: 0.8352 -- iter: 0512/3680
[A[ATraining Step: 4157  | total loss: [1m[32m0.39240[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39240 - acc: 0.8330 -- iter: 0544/3680
[A[ATraining Step: 4158  | total loss: [1m[32m0.40243[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40243 - acc: 0.8215 -- iter: 0576/3680
[A[ATraining Step: 4159  | total loss: [1m[32m0.39615[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39615 - acc: 0.8269 -- iter: 0608/3680
[A[ATraining Step: 4160  | total loss: [1m[32m0.39045[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39045 - acc: 0.8332 -- iter: 0640/3680
[A[ATraining Step: 4161  | total loss: [1m[32m0.39045[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39045 - acc: 0.8332 -- iter: 0672/3680
[A[ATraining Step: 4162  | total loss: [1m[32m0.40147[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40147 - acc: 0.8280 -- iter: 0704/3680
[A[ATraining Step: 4163  | total loss: [1m[32m0.39604[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39604 - acc: 0.8327 -- iter: 0736/3680
[A[ATraining Step: 4164  | total loss: [1m[32m0.38530[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38530 - acc: 0.8401 -- iter: 0768/3680
[A[ATraining Step: 4165  | total loss: [1m[32m0.38222[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38222 - acc: 0.8436 -- iter: 0800/3680
[A[ATraining Step: 4166  | total loss: [1m[32m0.36975[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36975 - acc: 0.8498 -- iter: 0832/3680
[A[ATraining Step: 4167  | total loss: [1m[32m0.36339[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36339 - acc: 0.8523 -- iter: 0864/3680
[A[ATraining Step: 4168  | total loss: [1m[32m0.36720[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36720 - acc: 0.8484 -- iter: 0896/3680
[A[ATraining Step: 4169  | total loss: [1m[32m0.37207[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37207 - acc: 0.8448 -- iter: 0928/3680
[A[ATraining Step: 4170  | total loss: [1m[32m0.36830[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36830 - acc: 0.8478 -- iter: 0960/3680
[A[ATraining Step: 4171  | total loss: [1m[32m0.36580[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36580 - acc: 0.8474 -- iter: 0992/3680
[A[ATraining Step: 4172  | total loss: [1m[32m0.39768[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39768 - acc: 0.8345 -- iter: 1024/3680
[A[ATraining Step: 4173  | total loss: [1m[32m0.39060[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39060 - acc: 0.8323 -- iter: 1056/3680
[A[ATraining Step: 4174  | total loss: [1m[32m0.38612[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38612 - acc: 0.8335 -- iter: 1088/3680
[A[ATraining Step: 4175  | total loss: [1m[32m0.37336[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37336 - acc: 0.8376 -- iter: 1120/3680
[A[ATraining Step: 4176  | total loss: [1m[32m0.38757[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38757 - acc: 0.8325 -- iter: 1152/3680
[A[ATraining Step: 4177  | total loss: [1m[32m0.39854[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39854 - acc: 0.8325 -- iter: 1184/3680
[A[ATraining Step: 4178  | total loss: [1m[32m0.39754[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39754 - acc: 0.8305 -- iter: 1216/3680
[A[ATraining Step: 4179  | total loss: [1m[32m0.41486[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41486 - acc: 0.8319 -- iter: 1248/3680
[A[ATraining Step: 4180  | total loss: [1m[32m0.41744[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41744 - acc: 0.8362 -- iter: 1280/3680
[A[ATraining Step: 4181  | total loss: [1m[32m0.41925[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41925 - acc: 0.8338 -- iter: 1312/3680
[A[ATraining Step: 4182  | total loss: [1m[32m0.41362[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41362 - acc: 0.8269 -- iter: 1344/3680
[A[ATraining Step: 4183  | total loss: [1m[32m0.41362[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41362 - acc: 0.8269 -- iter: 1376/3680
[A[ATraining Step: 4184  | total loss: [1m[32m0.40758[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40758 - acc: 0.8349 -- iter: 1408/3680
[A[ATraining Step: 4185  | total loss: [1m[32m0.41718[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41718 - acc: 0.8295 -- iter: 1440/3680
[A[ATraining Step: 4186  | total loss: [1m[32m0.40773[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40773 - acc: 0.8341 -- iter: 1472/3680
[A[ATraining Step: 4187  | total loss: [1m[32m0.40210[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40210 - acc: 0.8413 -- iter: 1504/3680
[A[ATraining Step: 4188  | total loss: [1m[32m0.39563[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39563 - acc: 0.8415 -- iter: 1536/3680
[A[ATraining Step: 4189  | total loss: [1m[32m0.39703[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39703 - acc: 0.8324 -- iter: 1568/3680
[A[ATraining Step: 4190  | total loss: [1m[32m0.39703[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39703 - acc: 0.8304 -- iter: 1600/3680
[A[ATraining Step: 4191  | total loss: [1m[32m0.40163[0m[0m
[2K| Adam | epoch: 037 | loss: 0.40163 - acc: 0.8317 -- iter: 1632/3680
[A[ATraining Step: 4192  | total loss: [1m[32m0.38812[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38812 - acc: 0.8361 -- iter: 1664/3680
[A[ATraining Step: 4193  | total loss: [1m[32m0.38112[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38112 - acc: 0.8431 -- iter: 1696/3680
[A[ATraining Step: 4194  | total loss: [1m[32m0.37800[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37800 - acc: 0.8463 -- iter: 1728/3680
[A[ATraining Step: 4195  | total loss: [1m[32m0.37137[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37137 - acc: 0.8429 -- iter: 1760/3680
[A[ATraining Step: 4196  | total loss: [1m[32m0.36641[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36641 - acc: 0.8461 -- iter: 1792/3680
[A[ATraining Step: 4197  | total loss: [1m[32m0.35737[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35737 - acc: 0.8521 -- iter: 1824/3680
[A[ATraining Step: 4198  | total loss: [1m[32m0.37576[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37576 - acc: 0.8419 -- iter: 1856/3680
[A[ATraining Step: 4199  | total loss: [1m[32m0.36865[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36865 - acc: 0.8483 -- iter: 1888/3680
[A[ATraining Step: 4200  | total loss: [1m[32m0.36382[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36382 - acc: 0.8479 | val_loss: 0.34705 - val_acc: 0.8643 -- iter: 1920/3680
[A[ATraining Step: 4200  | total loss: [1m[32m0.36382[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36382 - acc: 0.8479 | val_loss: 0.34705 - val_acc: 0.8643 -- iter: 1920/3680
--
Training Step: 4201  | total loss: [1m[32m0.34383[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34383 - acc: 0.8600 -- iter: 1952/3680
[A[ATraining Step: 4202  | total loss: [1m[32m0.34768[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34768 - acc: 0.8552 -- iter: 1984/3680
[A[ATraining Step: 4203  | total loss: [1m[32m0.35284[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35284 - acc: 0.8541 -- iter: 2016/3680
[A[ATraining Step: 4204  | total loss: [1m[32m0.34653[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34653 - acc: 0.8562 -- iter: 2048/3680
[A[ATraining Step: 4205  | total loss: [1m[32m0.34607[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34607 - acc: 0.8549 -- iter: 2080/3680
[A[ATraining Step: 4206  | total loss: [1m[32m0.35547[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35547 - acc: 0.8476 -- iter: 2112/3680
[A[ATraining Step: 4207  | total loss: [1m[32m0.34450[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34450 - acc: 0.8566 -- iter: 2144/3680
[A[ATraining Step: 4208  | total loss: [1m[32m0.35893[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35893 - acc: 0.8490 -- iter: 2176/3680
[A[ATraining Step: 4209  | total loss: [1m[32m0.36724[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36724 - acc: 0.8485 -- iter: 2208/3680
[A[ATraining Step: 4210  | total loss: [1m[32m0.35836[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35836 - acc: 0.8543 -- iter: 2240/3680
[A[ATraining Step: 4211  | total loss: [1m[32m0.37491[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37491 - acc: 0.8532 -- iter: 2272/3680
[A[ATraining Step: 4212  | total loss: [1m[32m0.37519[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37519 - acc: 0.8523 -- iter: 2304/3680
[A[ATraining Step: 4213  | total loss: [1m[32m0.37830[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37830 - acc: 0.8577 -- iter: 2336/3680
[A[ATraining Step: 4214  | total loss: [1m[32m0.37875[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37875 - acc: 0.8625 -- iter: 2368/3680
[A[ATraining Step: 4215  | total loss: [1m[32m0.37698[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37698 - acc: 0.8606 -- iter: 2400/3680
[A[ATraining Step: 4216  | total loss: [1m[32m0.36604[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36604 - acc: 0.8652 -- iter: 2432/3680
[A[ATraining Step: 4217  | total loss: [1m[32m0.36552[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36552 - acc: 0.8631 -- iter: 2464/3680
[A[ATraining Step: 4218  | total loss: [1m[32m0.36496[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36496 - acc: 0.8580 -- iter: 2496/3680
[A[ATraining Step: 4219  | total loss: [1m[32m0.36360[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36360 - acc: 0.8566 -- iter: 2528/3680
[A[ATraining Step: 4220  | total loss: [1m[32m0.36133[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36133 - acc: 0.8553 -- iter: 2560/3680
[A[ATraining Step: 4221  | total loss: [1m[32m0.36133[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36133 - acc: 0.8604 -- iter: 2592/3680
[A[ATraining Step: 4222  | total loss: [1m[32m0.34999[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34999 - acc: 0.8619 -- iter: 2624/3680
[A[ATraining Step: 4223  | total loss: [1m[32m0.35248[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35248 - acc: 0.8569 -- iter: 2656/3680
[A[ATraining Step: 4224  | total loss: [1m[32m0.36358[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36358 - acc: 0.8462 -- iter: 2688/3680
[A[ATraining Step: 4225  | total loss: [1m[32m0.37244[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37244 - acc: 0.8397 -- iter: 2720/3680
[A[ATraining Step: 4226  | total loss: [1m[32m0.37916[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37916 - acc: 0.8308 -- iter: 2752/3680
[A[ATraining Step: 4227  | total loss: [1m[32m0.37544[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37544 - acc: 0.8321 -- iter: 2784/3680
[A[ATraining Step: 4228  | total loss: [1m[32m0.39229[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39229 - acc: 0.8176 -- iter: 2816/3680
[A[ATraining Step: 4229  | total loss: [1m[32m0.38765[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38765 - acc: 0.8202 -- iter: 2848/3680
[A[ATraining Step: 4230  | total loss: [1m[32m0.37341[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37341 - acc: 0.8288 -- iter: 2880/3680
[A[ATraining Step: 4231  | total loss: [1m[32m0.38578[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38578 - acc: 0.8272 -- iter: 2912/3680
[A[ATraining Step: 4232  | total loss: [1m[32m0.39034[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39034 - acc: 0.8288 -- iter: 2944/3680
[A[ATraining Step: 4233  | total loss: [1m[32m0.37788[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37788 - acc: 0.8397 -- iter: 2976/3680
[A[ATraining Step: 4234  | total loss: [1m[32m0.37608[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37608 - acc: 0.8401 -- iter: 3008/3680
[A[ATraining Step: 4235  | total loss: [1m[32m0.36347[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36347 - acc: 0.8499 -- iter: 3040/3680
[A[ATraining Step: 4236  | total loss: [1m[32m0.36425[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36425 - acc: 0.8492 -- iter: 3072/3680
[A[ATraining Step: 4237  | total loss: [1m[32m0.39572[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39572 - acc: 0.8331 -- iter: 3104/3680
[A[ATraining Step: 4238  | total loss: [1m[32m0.39144[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39144 - acc: 0.8435 -- iter: 3136/3680
[A[ATraining Step: 4239  | total loss: [1m[32m0.41536[0m[0m
[2K| Adam | epoch: 037 | loss: 0.41536 - acc: 0.8404 -- iter: 3168/3680
[A[ATraining Step: 4240  | total loss: [1m[32m0.39958[0m[0m
[2K| Adam | epoch: 037 | loss: 0.39958 - acc: 0.8470 -- iter: 3200/3680
[A[ATraining Step: 4241  | total loss: [1m[32m0.38397[0m[0m
[2K| Adam | epoch: 037 | loss: 0.38397 - acc: 0.8467 -- iter: 3232/3680
[A[ATraining Step: 4242  | total loss: [1m[32m0.37457[0m[0m
[2K| Adam | epoch: 037 | loss: 0.37457 - acc: 0.8495 -- iter: 3264/3680
[A[ATraining Step: 4243  | total loss: [1m[32m0.36664[0m[0m
[2K| Adam | epoch: 037 | loss: 0.36664 - acc: 0.8489 -- iter: 3296/3680
[A[ATraining Step: 4244  | total loss: [1m[32m0.35606[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35606 - acc: 0.8578 -- iter: 3328/3680
[A[ATraining Step: 4245  | total loss: [1m[32m0.35122[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35122 - acc: 0.8595 -- iter: 3360/3680
[A[ATraining Step: 4246  | total loss: [1m[32m0.35937[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35937 - acc: 0.8599 -- iter: 3392/3680
[A[ATraining Step: 4247  | total loss: [1m[32m0.34620[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34620 - acc: 0.8599 -- iter: 3424/3680
[A[ATraining Step: 4248  | total loss: [1m[32m0.34717[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34717 - acc: 0.8583 -- iter: 3456/3680
[A[ATraining Step: 4249  | total loss: [1m[32m0.34097[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34097 - acc: 0.8600 -- iter: 3488/3680
[A[ATraining Step: 4250  | total loss: [1m[32m0.34426[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34426 - acc: 0.8615 -- iter: 3520/3680
[A[ATraining Step: 4251  | total loss: [1m[32m0.34661[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34661 - acc: 0.8597 -- iter: 3552/3680
[A[ATraining Step: 4252  | total loss: [1m[32m0.35094[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35094 - acc: 0.8550 -- iter: 3584/3680
[A[ATraining Step: 4253  | total loss: [1m[32m0.34834[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34834 - acc: 0.8570 -- iter: 3616/3680
[A[ATraining Step: 4254  | total loss: [1m[32m0.34329[0m[0m
[2K| Adam | epoch: 037 | loss: 0.34329 - acc: 0.8619 -- iter: 3648/3680
[A[ATraining Step: 4255  | total loss: [1m[32m0.35419[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35419 - acc: 0.8539 | val_loss: 0.35214 - val_acc: 0.8708 -- iter: 3680/3680
[A[ATraining Step: 4255  | total loss: [1m[32m0.35419[0m[0m
[2K| Adam | epoch: 037 | loss: 0.35419 - acc: 0.8539 | val_loss: 0.35214 - val_acc: 0.8708 -- iter: 3680/3680
--
Training Step: 4256  | total loss: [1m[32m0.34926[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34926 - acc: 0.8560 -- iter: 0032/3680
[A[ATraining Step: 4257  | total loss: [1m[32m0.35084[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35084 - acc: 0.8579 -- iter: 0064/3680
[A[ATraining Step: 4258  | total loss: [1m[32m0.36192[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36192 - acc: 0.8471 -- iter: 0096/3680
[A[ATraining Step: 4259  | total loss: [1m[32m0.34678[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34678 - acc: 0.8593 -- iter: 0128/3680
[A[ATraining Step: 4260  | total loss: [1m[32m0.40026[0m[0m
[2K| Adam | epoch: 038 | loss: 0.40026 - acc: 0.8358 -- iter: 0160/3680
[A[ATraining Step: 4261  | total loss: [1m[32m0.38455[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38455 - acc: 0.8460 -- iter: 0192/3680
[A[ATraining Step: 4262  | total loss: [1m[32m0.38165[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38165 - acc: 0.8458 -- iter: 0224/3680
[A[ATraining Step: 4263  | total loss: [1m[32m0.37211[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37211 - acc: 0.8518 -- iter: 0256/3680
[A[ATraining Step: 4264  | total loss: [1m[32m0.37220[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37220 - acc: 0.8541 -- iter: 0288/3680
[A[ATraining Step: 4265  | total loss: [1m[32m0.38335[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38335 - acc: 0.8531 -- iter: 0320/3680
[A[ATraining Step: 4266  | total loss: [1m[32m0.37880[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37880 - acc: 0.8522 -- iter: 0352/3680
[A[ATraining Step: 4267  | total loss: [1m[32m0.38984[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38984 - acc: 0.8451 -- iter: 0384/3680
[A[ATraining Step: 4268  | total loss: [1m[32m0.39122[0m[0m
[2K| Adam | epoch: 038 | loss: 0.39122 - acc: 0.8449 -- iter: 0416/3680
[A[ATraining Step: 4269  | total loss: [1m[32m0.39402[0m[0m
[2K| Adam | epoch: 038 | loss: 0.39402 - acc: 0.8386 -- iter: 0448/3680
[A[ATraining Step: 4270  | total loss: [1m[32m0.39146[0m[0m
[2K| Adam | epoch: 038 | loss: 0.39146 - acc: 0.8422 -- iter: 0480/3680
[A[ATraining Step: 4271  | total loss: [1m[32m0.41093[0m[0m
[2K| Adam | epoch: 038 | loss: 0.41093 - acc: 0.8174 -- iter: 0512/3680
[A[ATraining Step: 4272  | total loss: [1m[32m0.41572[0m[0m
[2K| Adam | epoch: 038 | loss: 0.41572 - acc: 0.8169 -- iter: 0544/3680
[A[ATraining Step: 4273  | total loss: [1m[32m0.40129[0m[0m
[2K| Adam | epoch: 038 | loss: 0.40129 - acc: 0.8289 -- iter: 0576/3680
[A[ATraining Step: 4274  | total loss: [1m[32m0.39961[0m[0m
[2K| Adam | epoch: 038 | loss: 0.39961 - acc: 0.8304 -- iter: 0608/3680
[A[ATraining Step: 4275  | total loss: [1m[32m0.40831[0m[0m
[2K| Adam | epoch: 038 | loss: 0.40831 - acc: 0.8224 -- iter: 0640/3680
[A[ATraining Step: 4276  | total loss: [1m[32m0.40046[0m[0m
[2K| Adam | epoch: 038 | loss: 0.40046 - acc: 0.8276 -- iter: 0672/3680
[A[ATraining Step: 4277  | total loss: [1m[32m0.39252[0m[0m
[2K| Adam | epoch: 038 | loss: 0.39252 - acc: 0.8324 -- iter: 0704/3680
[A[ATraining Step: 4278  | total loss: [1m[32m0.39245[0m[0m
[2K| Adam | epoch: 038 | loss: 0.39245 - acc: 0.8335 -- iter: 0736/3680
[A[ATraining Step: 4279  | total loss: [1m[32m0.38240[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38240 - acc: 0.8439 -- iter: 0768/3680
[A[ATraining Step: 4280  | total loss: [1m[32m0.37102[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37102 - acc: 0.8439 -- iter: 0800/3680
[A[ATraining Step: 4281  | total loss: [1m[32m0.38769[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38769 - acc: 0.8376 -- iter: 0832/3680
[A[ATraining Step: 4282  | total loss: [1m[32m0.38128[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38128 - acc: 0.8414 -- iter: 0864/3680
[A[ATraining Step: 4283  | total loss: [1m[32m0.37358[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37358 - acc: 0.8447 -- iter: 0896/3680
[A[ATraining Step: 4284  | total loss: [1m[32m0.37397[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37397 - acc: 0.8415 -- iter: 0928/3680
[A[ATraining Step: 4285  | total loss: [1m[32m0.36933[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36933 - acc: 0.8449 -- iter: 0960/3680
[A[ATraining Step: 4286  | total loss: [1m[32m0.36462[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36462 - acc: 0.8447 -- iter: 0992/3680
[A[ATraining Step: 4287  | total loss: [1m[32m0.35871[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35871 - acc: 0.8478 -- iter: 1024/3680
[A[ATraining Step: 4288  | total loss: [1m[32m0.35490[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35490 - acc: 0.8474 -- iter: 1056/3680
[A[ATraining Step: 4289  | total loss: [1m[32m0.36012[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36012 - acc: 0.8408 -- iter: 1088/3680
[A[ATraining Step: 4290  | total loss: [1m[32m0.34940[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34940 - acc: 0.8504 -- iter: 1120/3680
[A[ATraining Step: 4291  | total loss: [1m[32m0.33553[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33553 - acc: 0.8623 -- iter: 1152/3680
[A[ATraining Step: 4292  | total loss: [1m[32m0.33090[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33090 - acc: 0.8635 -- iter: 1184/3680
[A[ATraining Step: 4293  | total loss: [1m[32m0.31947[0m[0m
[2K| Adam | epoch: 038 | loss: 0.31947 - acc: 0.8709 -- iter: 1216/3680
[A[ATraining Step: 4294  | total loss: [1m[32m0.33510[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33510 - acc: 0.8713 -- iter: 1248/3680
[A[ATraining Step: 4295  | total loss: [1m[32m0.34964[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34964 - acc: 0.8498 -- iter: 1280/3680
[A[ATraining Step: 4296  | total loss: [1m[32m0.35644[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35644 - acc: 0.8461 -- iter: 1312/3680
[A[ATraining Step: 4297  | total loss: [1m[32m0.34774[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34774 - acc: 0.8459 -- iter: 1344/3680
[A[ATraining Step: 4298  | total loss: [1m[32m0.33990[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33990 - acc: 0.8550 -- iter: 1376/3680
[A[ATraining Step: 4299  | total loss: [1m[32m0.32422[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32422 - acc: 0.8664 -- iter: 1408/3680
[A[ATraining Step: 4300  | total loss: [1m[32m0.33694[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33694 - acc: 0.8579 | val_loss: 0.34984 - val_acc: 0.8588 -- iter: 1440/3680
[A[ATraining Step: 4300  | total loss: [1m[32m0.33694[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33694 - acc: 0.8579 | val_loss: 0.34984 - val_acc: 0.8588 -- iter: 1440/3680
--
Training Step: 4301  | total loss: [1m[32m0.34213[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34213 - acc: 0.8502 -- iter: 1472/3680
[A[ATraining Step: 4302  | total loss: [1m[32m0.33098[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33098 - acc: 0.8558 -- iter: 1504/3680
[A[ATraining Step: 4303  | total loss: [1m[32m0.34308[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34308 - acc: 0.8515 -- iter: 1536/3680
[A[ATraining Step: 4304  | total loss: [1m[32m0.33505[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33505 - acc: 0.8570 -- iter: 1568/3680
[A[ATraining Step: 4305  | total loss: [1m[32m0.32312[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32312 - acc: 0.8650 -- iter: 1600/3680
[A[ATraining Step: 4306  | total loss: [1m[32m0.32113[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32113 - acc: 0.8660 -- iter: 1632/3680
[A[ATraining Step: 4307  | total loss: [1m[32m0.32679[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32679 - acc: 0.8607 -- iter: 1664/3680
[A[ATraining Step: 4308  | total loss: [1m[32m0.31296[0m[0m
[2K| Adam | epoch: 038 | loss: 0.31296 - acc: 0.8715 -- iter: 1696/3680
[A[ATraining Step: 4309  | total loss: [1m[32m0.32464[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32464 - acc: 0.8687 -- iter: 1728/3680
[A[ATraining Step: 4310  | total loss: [1m[32m0.33850[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33850 - acc: 0.8537 -- iter: 1760/3680
[A[ATraining Step: 4311  | total loss: [1m[32m0.33565[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33565 - acc: 0.8558 -- iter: 1792/3680
[A[ATraining Step: 4312  | total loss: [1m[32m0.34025[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34025 - acc: 0.8578 -- iter: 1824/3680
[A[ATraining Step: 4313  | total loss: [1m[32m0.35270[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35270 - acc: 0.8532 -- iter: 1856/3680
[A[ATraining Step: 4314  | total loss: [1m[32m0.36050[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36050 - acc: 0.8492 -- iter: 1888/3680
[A[ATraining Step: 4315  | total loss: [1m[32m0.36197[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36197 - acc: 0.8486 -- iter: 1920/3680
[A[ATraining Step: 4316  | total loss: [1m[32m0.35275[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35275 - acc: 0.8544 -- iter: 1952/3680
[A[ATraining Step: 4317  | total loss: [1m[32m0.36404[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36404 - acc: 0.8471 -- iter: 1984/3680
[A[ATraining Step: 4318  | total loss: [1m[32m0.35561[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35561 - acc: 0.8530 -- iter: 2016/3680
[A[ATraining Step: 4319  | total loss: [1m[32m0.36401[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36401 - acc: 0.8489 -- iter: 2048/3680
[A[ATraining Step: 4320  | total loss: [1m[32m0.36367[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36367 - acc: 0.8484 -- iter: 2080/3680
[A[ATraining Step: 4321  | total loss: [1m[32m0.36295[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36295 - acc: 0.8542 -- iter: 2112/3680
[A[ATraining Step: 4322  | total loss: [1m[32m0.36250[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36250 - acc: 0.8469 -- iter: 2144/3680
[A[ATraining Step: 4323  | total loss: [1m[32m0.35615[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35615 - acc: 0.8497 -- iter: 2176/3680
[A[ATraining Step: 4324  | total loss: [1m[32m0.34463[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34463 - acc: 0.8522 -- iter: 2208/3680
[A[ATraining Step: 4325  | total loss: [1m[32m0.34880[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34880 - acc: 0.8514 -- iter: 2240/3680
[A[ATraining Step: 4326  | total loss: [1m[32m0.33654[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33654 - acc: 0.8569 -- iter: 2272/3680
[A[ATraining Step: 4327  | total loss: [1m[32m0.33047[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33047 - acc: 0.8556 -- iter: 2304/3680
[A[ATraining Step: 4328  | total loss: [1m[32m0.33165[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33165 - acc: 0.8606 -- iter: 2336/3680
[A[ATraining Step: 4329  | total loss: [1m[32m0.35485[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35485 - acc: 0.8464 -- iter: 2368/3680
[A[ATraining Step: 4330  | total loss: [1m[32m0.35299[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35299 - acc: 0.8524 -- iter: 2400/3680
[A[ATraining Step: 4331  | total loss: [1m[32m0.34561[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34561 - acc: 0.8578 -- iter: 2432/3680
[A[ATraining Step: 4332  | total loss: [1m[32m0.34335[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34335 - acc: 0.8595 -- iter: 2464/3680
[A[ATraining Step: 4333  | total loss: [1m[32m0.34240[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34240 - acc: 0.8611 -- iter: 2496/3680
[A[ATraining Step: 4334  | total loss: [1m[32m0.32973[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32973 - acc: 0.8687 -- iter: 2528/3680
[A[ATraining Step: 4335  | total loss: [1m[32m0.34119[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34119 - acc: 0.8631 -- iter: 2560/3680
[A[ATraining Step: 4336  | total loss: [1m[32m0.33358[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33358 - acc: 0.8643 -- iter: 2592/3680
[A[ATraining Step: 4337  | total loss: [1m[32m0.35234[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35234 - acc: 0.8560 -- iter: 2624/3680
[A[ATraining Step: 4338  | total loss: [1m[32m0.36509[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36509 - acc: 0.8516 -- iter: 2656/3680
[A[ATraining Step: 4339  | total loss: [1m[32m0.36335[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36335 - acc: 0.8508 -- iter: 2688/3680
[A[ATraining Step: 4340  | total loss: [1m[32m0.35984[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35984 - acc: 0.8501 -- iter: 2720/3680
[A[ATraining Step: 4341  | total loss: [1m[32m0.35346[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35346 - acc: 0.8526 -- iter: 2752/3680
[A[ATraining Step: 4342  | total loss: [1m[32m0.35560[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35560 - acc: 0.8486 -- iter: 2784/3680
[A[ATraining Step: 4343  | total loss: [1m[32m0.35066[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35066 - acc: 0.8512 -- iter: 2816/3680
[A[ATraining Step: 4344  | total loss: [1m[32m0.35182[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35182 - acc: 0.8474 -- iter: 2848/3680
[A[ATraining Step: 4345  | total loss: [1m[32m0.34242[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34242 - acc: 0.8533 -- iter: 2880/3680
[A[ATraining Step: 4346  | total loss: [1m[32m0.34644[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34644 - acc: 0.8492 -- iter: 2912/3680
[A[ATraining Step: 4347  | total loss: [1m[32m0.34659[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34659 - acc: 0.8486 -- iter: 2944/3680
[A[ATraining Step: 4348  | total loss: [1m[32m0.34795[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34795 - acc: 0.8482 -- iter: 2976/3680
[A[ATraining Step: 4349  | total loss: [1m[32m0.34413[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34413 - acc: 0.8540 -- iter: 3008/3680
[A[ATraining Step: 4350  | total loss: [1m[32m0.34639[0m[0m
[2K| Adam | epoch: 038 | loss: 0.34639 - acc: 0.8498 -- iter: 3040/3680
[A[ATraining Step: 4351  | total loss: [1m[32m0.33165[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33165 - acc: 0.8555 -- iter: 3072/3680
[A[ATraining Step: 4352  | total loss: [1m[32m0.33189[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33189 - acc: 0.8574 -- iter: 3104/3680
[A[ATraining Step: 4353  | total loss: [1m[32m0.32140[0m[0m
[2K| Adam | epoch: 038 | loss: 0.32140 - acc: 0.8654 -- iter: 3136/3680
[A[ATraining Step: 4354  | total loss: [1m[32m0.33926[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33926 - acc: 0.8539 -- iter: 3168/3680
[A[ATraining Step: 4355  | total loss: [1m[32m0.33669[0m[0m
[2K| Adam | epoch: 038 | loss: 0.33669 - acc: 0.8423 -- iter: 3200/3680
[A[ATraining Step: 4356  | total loss: [1m[32m0.35621[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35621 - acc: 0.8423 -- iter: 3232/3680
[A[ATraining Step: 4357  | total loss: [1m[32m0.36464[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36464 - acc: 0.8362 -- iter: 3264/3680
[A[ATraining Step: 4358  | total loss: [1m[32m0.35694[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35694 - acc: 0.8432 -- iter: 3296/3680
[A[ATraining Step: 4359  | total loss: [1m[32m0.36416[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36416 - acc: 0.8339 -- iter: 3328/3680
[A[ATraining Step: 4360  | total loss: [1m[32m0.36603[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36603 - acc: 0.8348 -- iter: 3360/3680
[A[ATraining Step: 4361  | total loss: [1m[32m0.36130[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36130 - acc: 0.8420 -- iter: 3392/3680
[A[ATraining Step: 4362  | total loss: [1m[32m0.35445[0m[0m
[2K| Adam | epoch: 038 | loss: 0.35445 - acc: 0.8484 -- iter: 3424/3680
[A[ATraining Step: 4363  | total loss: [1m[32m0.36349[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36349 - acc: 0.8417 -- iter: 3456/3680
[A[ATraining Step: 4364  | total loss: [1m[32m0.38135[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38135 - acc: 0.8294 -- iter: 3488/3680
[A[ATraining Step: 4365  | total loss: [1m[32m0.37418[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37418 - acc: 0.8371 -- iter: 3520/3680
[A[ATraining Step: 4366  | total loss: [1m[32m0.36708[0m[0m
[2K| Adam | epoch: 038 | loss: 0.36708 - acc: 0.8471 -- iter: 3552/3680
[A[ATraining Step: 4367  | total loss: [1m[32m0.38158[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38158 - acc: 0.8374 -- iter: 3584/3680
[A[ATraining Step: 4368  | total loss: [1m[32m0.38313[0m[0m
[2K| Adam | epoch: 038 | loss: 0.38313 - acc: 0.8349 -- iter: 3616/3680
[A[ATraining Step: 4369  | total loss: [1m[32m0.37932[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37932 - acc: 0.8327 -- iter: 3648/3680
[A[ATraining Step: 4370  | total loss: [1m[32m0.37563[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37563 - acc: 0.8400 | val_loss: 0.33364 - val_acc: 0.8740 -- iter: 3680/3680
[A[ATraining Step: 4370  | total loss: [1m[32m0.37563[0m[0m
[2K| Adam | epoch: 038 | loss: 0.37563 - acc: 0.8400 | val_loss: 0.33364 - val_acc: 0.8740 -- iter: 3680/3680
--
Training Step: 4371  | total loss: [1m[32m0.37722[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37722 - acc: 0.8404 -- iter: 0032/3680
[A[ATraining Step: 4372  | total loss: [1m[32m0.38031[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38031 - acc: 0.8439 -- iter: 0064/3680
[A[ATraining Step: 4373  | total loss: [1m[32m0.37603[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37603 - acc: 0.8439 -- iter: 0096/3680
[A[ATraining Step: 4374  | total loss: [1m[32m0.38733[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38733 - acc: 0.8376 -- iter: 0128/3680
[A[ATraining Step: 4375  | total loss: [1m[32m0.38802[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38802 - acc: 0.8320 -- iter: 0160/3680
[A[ATraining Step: 4376  | total loss: [1m[32m0.46862[0m[0m
[2K| Adam | epoch: 039 | loss: 0.46862 - acc: 0.8019 -- iter: 0192/3680
[A[ATraining Step: 4377  | total loss: [1m[32m0.46052[0m[0m
[2K| Adam | epoch: 039 | loss: 0.46052 - acc: 0.8061 -- iter: 0224/3680
[A[ATraining Step: 4378  | total loss: [1m[32m0.44263[0m[0m
[2K| Adam | epoch: 039 | loss: 0.44263 - acc: 0.8161 -- iter: 0256/3680
[A[ATraining Step: 4379  | total loss: [1m[32m0.43422[0m[0m
[2K| Adam | epoch: 039 | loss: 0.43422 - acc: 0.8157 -- iter: 0288/3680
[A[ATraining Step: 4380  | total loss: [1m[32m0.42575[0m[0m
[2K| Adam | epoch: 039 | loss: 0.42575 - acc: 0.8217 -- iter: 0320/3680
[A[ATraining Step: 4381  | total loss: [1m[32m0.42295[0m[0m
[2K| Adam | epoch: 039 | loss: 0.42295 - acc: 0.8287 -- iter: 0352/3680
[A[ATraining Step: 4382  | total loss: [1m[32m0.41727[0m[0m
[2K| Adam | epoch: 039 | loss: 0.41727 - acc: 0.8287 -- iter: 0384/3680
[A[ATraining Step: 4383  | total loss: [1m[32m0.40555[0m[0m
[2K| Adam | epoch: 039 | loss: 0.40555 - acc: 0.8364 -- iter: 0416/3680
[A[ATraining Step: 4384  | total loss: [1m[32m0.40116[0m[0m
[2K| Adam | epoch: 039 | loss: 0.40116 - acc: 0.8372 -- iter: 0448/3680
[A[ATraining Step: 4385  | total loss: [1m[32m0.40431[0m[0m
[2K| Adam | epoch: 039 | loss: 0.40431 - acc: 0.8347 -- iter: 0480/3680
[A[ATraining Step: 4386  | total loss: [1m[32m0.41528[0m[0m
[2K| Adam | epoch: 039 | loss: 0.41528 - acc: 0.8274 -- iter: 0512/3680
[A[ATraining Step: 4387  | total loss: [1m[32m0.43782[0m[0m
[2K| Adam | epoch: 039 | loss: 0.43782 - acc: 0.8274 -- iter: 0544/3680
[A[ATraining Step: 4388  | total loss: [1m[32m0.44938[0m[0m
[2K| Adam | epoch: 039 | loss: 0.44938 - acc: 0.8227 -- iter: 0576/3680
[A[ATraining Step: 4389  | total loss: [1m[32m0.43466[0m[0m
[2K| Adam | epoch: 039 | loss: 0.43466 - acc: 0.8311 -- iter: 0608/3680
[A[ATraining Step: 4390  | total loss: [1m[32m0.42293[0m[0m
[2K| Adam | epoch: 039 | loss: 0.42293 - acc: 0.8355 -- iter: 0640/3680
[A[ATraining Step: 4391  | total loss: [1m[32m0.40447[0m[0m
[2K| Adam | epoch: 039 | loss: 0.40447 - acc: 0.8457 -- iter: 0672/3680
[A[ATraining Step: 4392  | total loss: [1m[32m0.39296[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39296 - acc: 0.8517 -- iter: 0704/3680
[A[ATraining Step: 4393  | total loss: [1m[32m0.38623[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38623 - acc: 0.8572 -- iter: 0736/3680
[A[ATraining Step: 4394  | total loss: [1m[32m0.40063[0m[0m
[2K| Adam | epoch: 039 | loss: 0.40063 - acc: 0.8433 -- iter: 0768/3680
[A[ATraining Step: 4395  | total loss: [1m[32m0.39339[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39339 - acc: 0.8465 -- iter: 0800/3680
[A[ATraining Step: 4396  | total loss: [1m[32m0.39771[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39771 - acc: 0.8400 -- iter: 0832/3680
[A[ATraining Step: 4397  | total loss: [1m[32m0.39367[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39367 - acc: 0.8435 -- iter: 0864/3680
[A[ATraining Step: 4398  | total loss: [1m[32m0.39386[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39386 - acc: 0.8466 -- iter: 0896/3680
[A[ATraining Step: 4399  | total loss: [1m[32m0.38327[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38327 - acc: 0.8526 -- iter: 0928/3680
[A[ATraining Step: 4400  | total loss: [1m[32m0.36702[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36702 - acc: 0.8611 | val_loss: 0.35748 - val_acc: 0.8599 -- iter: 0960/3680
[A[ATraining Step: 4400  | total loss: [1m[32m0.36702[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36702 - acc: 0.8611 | val_loss: 0.35748 - val_acc: 0.8599 -- iter: 0960/3680
--
Training Step: 4401  | total loss: [1m[32m0.35841[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35841 - acc: 0.8656 -- iter: 0992/3680
[A[ATraining Step: 4402  | total loss: [1m[32m0.35895[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35895 - acc: 0.8634 -- iter: 1024/3680
[A[ATraining Step: 4403  | total loss: [1m[32m0.36795[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36795 - acc: 0.8521 -- iter: 1056/3680
[A[ATraining Step: 4404  | total loss: [1m[32m0.38464[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38464 - acc: 0.8387 -- iter: 1088/3680
[A[ATraining Step: 4405  | total loss: [1m[32m0.37678[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37678 - acc: 0.8455 -- iter: 1120/3680
[A[ATraining Step: 4406  | total loss: [1m[32m0.37329[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37329 - acc: 0.8453 -- iter: 1152/3680
[A[ATraining Step: 4407  | total loss: [1m[32m0.38130[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38130 - acc: 0.8389 -- iter: 1184/3680
[A[ATraining Step: 4408  | total loss: [1m[32m0.36675[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36675 - acc: 0.8488 -- iter: 1216/3680
[A[ATraining Step: 4409  | total loss: [1m[32m0.35400[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35400 - acc: 0.8576 -- iter: 1248/3680
[A[ATraining Step: 4410  | total loss: [1m[32m0.35386[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35386 - acc: 0.8531 -- iter: 1280/3680
[A[ATraining Step: 4411  | total loss: [1m[32m0.35447[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35447 - acc: 0.8584 -- iter: 1312/3680
[A[ATraining Step: 4412  | total loss: [1m[32m0.36500[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36500 - acc: 0.8538 -- iter: 1344/3680
[A[ATraining Step: 4413  | total loss: [1m[32m0.35430[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35430 - acc: 0.8622 -- iter: 1376/3680
[A[ATraining Step: 4414  | total loss: [1m[32m0.34214[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34214 - acc: 0.8640 -- iter: 1408/3680
[A[ATraining Step: 4415  | total loss: [1m[32m0.35312[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35312 - acc: 0.8640 -- iter: 1440/3680
[A[ATraining Step: 4416  | total loss: [1m[32m0.36394[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36394 - acc: 0.8557 -- iter: 1472/3680
[A[ATraining Step: 4417  | total loss: [1m[32m0.36928[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36928 - acc: 0.8483 -- iter: 1504/3680
[A[ATraining Step: 4418  | total loss: [1m[32m0.37648[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37648 - acc: 0.8385 -- iter: 1536/3680
[A[ATraining Step: 4419  | total loss: [1m[32m0.38495[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38495 - acc: 0.8390 -- iter: 1568/3680
[A[ATraining Step: 4420  | total loss: [1m[32m0.36894[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36894 - acc: 0.8457 -- iter: 1600/3680
[A[ATraining Step: 4421  | total loss: [1m[32m0.36970[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36970 - acc: 0.8486 -- iter: 1632/3680
[A[ATraining Step: 4422  | total loss: [1m[32m0.36165[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36165 - acc: 0.8515 -- iter: 1664/3680
[A[ATraining Step: 4423  | total loss: [1m[32m0.36165[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36165 - acc: 0.8515 -- iter: 1696/3680
[A[ATraining Step: 4424  | total loss: [1m[32m0.35875[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35875 - acc: 0.8507 -- iter: 1728/3680
[A[ATraining Step: 4425  | total loss: [1m[32m0.34673[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34673 - acc: 0.8594 -- iter: 1760/3680
[A[ATraining Step: 4426  | total loss: [1m[32m0.37647[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37647 - acc: 0.8547 -- iter: 1792/3680
[A[ATraining Step: 4427  | total loss: [1m[32m0.37093[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37093 - acc: 0.8630 -- iter: 1824/3680
[A[ATraining Step: 4428  | total loss: [1m[32m0.37116[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37116 - acc: 0.8610 -- iter: 1856/3680
[A[ATraining Step: 4429  | total loss: [1m[32m0.37485[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37485 - acc: 0.8487 -- iter: 1888/3680
[A[ATraining Step: 4430  | total loss: [1m[32m0.38067[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38067 - acc: 0.8545 -- iter: 1920/3680
[A[ATraining Step: 4431  | total loss: [1m[32m0.36836[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36836 - acc: 0.8545 -- iter: 1952/3680
[A[ATraining Step: 4432  | total loss: [1m[32m0.36056[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36056 - acc: 0.8565 -- iter: 1984/3680
[A[ATraining Step: 4433  | total loss: [1m[32m0.35308[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35308 - acc: 0.8584 -- iter: 2016/3680
[A[ATraining Step: 4434  | total loss: [1m[32m0.35075[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35075 - acc: 0.8569 -- iter: 2048/3680
[A[ATraining Step: 4435  | total loss: [1m[32m0.34476[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34476 - acc: 0.8650 -- iter: 2080/3680
[A[ATraining Step: 4436  | total loss: [1m[32m0.38014[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38014 - acc: 0.8597 -- iter: 2112/3680
[A[ATraining Step: 4437  | total loss: [1m[32m0.36612[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36612 - acc: 0.8644 -- iter: 2144/3680
[A[ATraining Step: 4438  | total loss: [1m[32m0.35417[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35417 - acc: 0.8686 -- iter: 2176/3680
[A[ATraining Step: 4439  | total loss: [1m[32m0.35790[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35790 - acc: 0.8723 -- iter: 2208/3680
[A[ATraining Step: 4440  | total loss: [1m[32m0.35246[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35246 - acc: 0.8726 -- iter: 2240/3680
[A[ATraining Step: 4441  | total loss: [1m[32m0.35800[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35800 - acc: 0.8635 -- iter: 2272/3680
[A[ATraining Step: 4442  | total loss: [1m[32m0.34320[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34320 - acc: 0.8677 -- iter: 2304/3680
[A[ATraining Step: 4443  | total loss: [1m[32m0.34018[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34018 - acc: 0.8716 -- iter: 2336/3680
[A[ATraining Step: 4444  | total loss: [1m[32m0.35017[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35017 - acc: 0.8594 -- iter: 2368/3680
[A[ATraining Step: 4445  | total loss: [1m[32m0.37683[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37683 - acc: 0.8454 -- iter: 2400/3680
[A[ATraining Step: 4446  | total loss: [1m[32m0.37406[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37406 - acc: 0.8483 -- iter: 2432/3680
[A[ATraining Step: 4447  | total loss: [1m[32m0.39185[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39185 - acc: 0.8385 -- iter: 2464/3680
[A[ATraining Step: 4448  | total loss: [1m[32m0.38654[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38654 - acc: 0.8390 -- iter: 2496/3680
[A[ATraining Step: 4449  | total loss: [1m[32m0.39672[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39672 - acc: 0.8364 -- iter: 2528/3680
[A[ATraining Step: 4450  | total loss: [1m[32m0.39462[0m[0m
[2K| Adam | epoch: 039 | loss: 0.39462 - acc: 0.8340 -- iter: 2560/3680
[A[ATraining Step: 4451  | total loss: [1m[32m0.38348[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38348 - acc: 0.8412 -- iter: 2592/3680
[A[ATraining Step: 4452  | total loss: [1m[32m0.38359[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38359 - acc: 0.8383 -- iter: 2624/3680
[A[ATraining Step: 4453  | total loss: [1m[32m0.38277[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38277 - acc: 0.8389 -- iter: 2656/3680
[A[ATraining Step: 4454  | total loss: [1m[32m0.36669[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36669 - acc: 0.8456 -- iter: 2688/3680
[A[ATraining Step: 4455  | total loss: [1m[32m0.36928[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36928 - acc: 0.8423 -- iter: 2720/3680
[A[ATraining Step: 4456  | total loss: [1m[32m0.37831[0m[0m
[2K| Adam | epoch: 039 | loss: 0.37831 - acc: 0.8362 -- iter: 2752/3680
[A[ATraining Step: 4457  | total loss: [1m[32m0.36712[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36712 - acc: 0.8401 -- iter: 2784/3680
[A[ATraining Step: 4458  | total loss: [1m[32m0.36516[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36516 - acc: 0.8311 -- iter: 2816/3680
[A[ATraining Step: 4459  | total loss: [1m[32m0.38656[0m[0m
[2K| Adam | epoch: 039 | loss: 0.38656 - acc: 0.8230 -- iter: 2848/3680
[A[ATraining Step: 4460  | total loss: [1m[32m0.36690[0m[0m
[2K| Adam | epoch: 039 | loss: 0.36690 - acc: 0.8344 -- iter: 2880/3680
[A[ATraining Step: 4461  | total loss: [1m[32m0.35782[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35782 - acc: 0.8416 -- iter: 2912/3680
[A[ATraining Step: 4462  | total loss: [1m[32m0.35116[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35116 - acc: 0.8445 -- iter: 2944/3680
[A[ATraining Step: 4463  | total loss: [1m[32m0.34738[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34738 - acc: 0.8445 -- iter: 2976/3680
[A[ATraining Step: 4464  | total loss: [1m[32m0.34793[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34793 - acc: 0.8444 -- iter: 3008/3680
[A[ATraining Step: 4465  | total loss: [1m[32m0.33983[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33983 - acc: 0.8506 -- iter: 3040/3680
[A[ATraining Step: 4466  | total loss: [1m[32m0.33987[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33987 - acc: 0.8499 -- iter: 3072/3680
[A[ATraining Step: 4467  | total loss: [1m[32m0.35089[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35089 - acc: 0.8431 -- iter: 3104/3680
[A[ATraining Step: 4468  | total loss: [1m[32m0.35657[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35657 - acc: 0.8400 -- iter: 3136/3680
[A[ATraining Step: 4469  | total loss: [1m[32m0.35439[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35439 - acc: 0.8529 -- iter: 3168/3680
[A[ATraining Step: 4470  | total loss: [1m[32m0.35164[0m[0m
[2K| Adam | epoch: 039 | loss: 0.35164 - acc: 0.8529 -- iter: 3200/3680
[A[ATraining Step: 4471  | total loss: [1m[32m0.34840[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34840 - acc: 0.8551 -- iter: 3232/3680
[A[ATraining Step: 4472  | total loss: [1m[32m0.33693[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33693 - acc: 0.8602 -- iter: 3264/3680
[A[ATraining Step: 4473  | total loss: [1m[32m0.34392[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34392 - acc: 0.8617 -- iter: 3296/3680
[A[ATraining Step: 4474  | total loss: [1m[32m0.34559[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34559 - acc: 0.8568 -- iter: 3328/3680
[A[ATraining Step: 4475  | total loss: [1m[32m0.34308[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34308 - acc: 0.8555 -- iter: 3360/3680
[A[ATraining Step: 4476  | total loss: [1m[32m0.34082[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34082 - acc: 0.8606 -- iter: 3392/3680
[A[ATraining Step: 4477  | total loss: [1m[32m0.33734[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33734 - acc: 0.8620 -- iter: 3424/3680
[A[ATraining Step: 4478  | total loss: [1m[32m0.33446[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33446 - acc: 0.8571 -- iter: 3456/3680
[A[ATraining Step: 4479  | total loss: [1m[32m0.34515[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34515 - acc: 0.8526 -- iter: 3488/3680
[A[ATraining Step: 4480  | total loss: [1m[32m0.33333[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33333 - acc: 0.8611 -- iter: 3520/3680
[A[ATraining Step: 4481  | total loss: [1m[32m0.32304[0m[0m
[2K| Adam | epoch: 039 | loss: 0.32304 - acc: 0.8656 -- iter: 3552/3680
[A[ATraining Step: 4482  | total loss: [1m[32m0.34539[0m[0m
[2K| Adam | epoch: 039 | loss: 0.34539 - acc: 0.8603 -- iter: 3584/3680
[A[ATraining Step: 4483  | total loss: [1m[32m0.32669[0m[0m
[2K| Adam | epoch: 039 | loss: 0.32669 - acc: 0.8680 -- iter: 3616/3680
[A[ATraining Step: 4484  | total loss: [1m[32m0.33001[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33001 - acc: 0.8656 -- iter: 3648/3680
[A[ATraining Step: 4485  | total loss: [1m[32m0.33098[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33098 - acc: 0.8665 | val_loss: 0.33322 - val_acc: 0.8697 -- iter: 3680/3680
[A[ATraining Step: 4485  | total loss: [1m[32m0.33098[0m[0m
[2K| Adam | epoch: 039 | loss: 0.33098 - acc: 0.8665 | val_loss: 0.33322 - val_acc: 0.8697 -- iter: 3680/3680
--
Training Step: 4486  | total loss: [1m[32m0.34089[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34089 - acc: 0.8580 -- iter: 0032/3680
[A[ATraining Step: 4487  | total loss: [1m[32m0.34004[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34004 - acc: 0.8503 -- iter: 0064/3680
[A[ATraining Step: 4488  | total loss: [1m[32m0.33121[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33121 - acc: 0.8590 -- iter: 0096/3680
[A[ATraining Step: 4489  | total loss: [1m[32m0.32554[0m[0m
[2K| Adam | epoch: 040 | loss: 0.32554 - acc: 0.8575 -- iter: 0128/3680
[A[ATraining Step: 4490  | total loss: [1m[32m0.33260[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33260 - acc: 0.8530 -- iter: 0160/3680
[A[ATraining Step: 4491  | total loss: [1m[32m0.34334[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34334 - acc: 0.8521 -- iter: 0192/3680
[A[ATraining Step: 4492  | total loss: [1m[32m0.33141[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33141 - acc: 0.8544 -- iter: 0224/3680
[A[ATraining Step: 4493  | total loss: [1m[32m0.34158[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34158 - acc: 0.8527 -- iter: 0256/3680
[A[ATraining Step: 4494  | total loss: [1m[32m0.33901[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33901 - acc: 0.8527 -- iter: 0288/3680
[A[ATraining Step: 4495  | total loss: [1m[32m0.36239[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36239 - acc: 0.8424 -- iter: 0320/3680
[A[ATraining Step: 4496  | total loss: [1m[32m0.36430[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36430 - acc: 0.8425 -- iter: 0352/3680
[A[ATraining Step: 4497  | total loss: [1m[32m0.35210[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35210 - acc: 0.8520 -- iter: 0384/3680
[A[ATraining Step: 4498  | total loss: [1m[32m0.35331[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35331 - acc: 0.8543 -- iter: 0416/3680
[A[ATraining Step: 4499  | total loss: [1m[32m0.37513[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37513 - acc: 0.8408 -- iter: 0448/3680
[A[ATraining Step: 4500  | total loss: [1m[32m0.37922[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37922 - acc: 0.8379 | val_loss: 0.34617 - val_acc: 0.8621 -- iter: 0480/3680
[A[ATraining Step: 4500  | total loss: [1m[32m0.37922[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37922 - acc: 0.8379 | val_loss: 0.34617 - val_acc: 0.8621 -- iter: 0480/3680
--
Training Step: 4501  | total loss: [1m[32m0.37235[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37235 - acc: 0.8323 -- iter: 0512/3680
[A[ATraining Step: 4502  | total loss: [1m[32m0.37677[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37677 - acc: 0.8303 -- iter: 0544/3680
[A[ATraining Step: 4503  | total loss: [1m[32m0.35953[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35953 - acc: 0.8410 -- iter: 0576/3680
[A[ATraining Step: 4504  | total loss: [1m[32m0.34957[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34957 - acc: 0.8444 -- iter: 0608/3680
[A[ATraining Step: 4505  | total loss: [1m[32m0.34835[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34835 - acc: 0.8443 -- iter: 0640/3680
[A[ATraining Step: 4506  | total loss: [1m[32m0.33965[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33965 - acc: 0.8505 -- iter: 0672/3680
[A[ATraining Step: 4507  | total loss: [1m[32m0.37334[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37334 - acc: 0.8405 -- iter: 0704/3680
[A[ATraining Step: 4508  | total loss: [1m[32m0.36538[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36538 - acc: 0.8439 -- iter: 0736/3680
[A[ATraining Step: 4509  | total loss: [1m[32m0.38677[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38677 - acc: 0.8314 -- iter: 0768/3680
[A[ATraining Step: 4510  | total loss: [1m[32m0.37717[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37717 - acc: 0.8358 -- iter: 0800/3680
[A[ATraining Step: 4511  | total loss: [1m[32m0.37981[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37981 - acc: 0.8303 -- iter: 0832/3680
[A[ATraining Step: 4512  | total loss: [1m[32m0.38855[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38855 - acc: 0.8285 -- iter: 0864/3680
[A[ATraining Step: 4513  | total loss: [1m[32m0.41034[0m[0m
[2K| Adam | epoch: 040 | loss: 0.41034 - acc: 0.8352 -- iter: 0896/3680
[A[ATraining Step: 4514  | total loss: [1m[32m0.40535[0m[0m
[2K| Adam | epoch: 040 | loss: 0.40535 - acc: 0.8352 -- iter: 0928/3680
[A[ATraining Step: 4515  | total loss: [1m[32m0.41621[0m[0m
[2K| Adam | epoch: 040 | loss: 0.41621 - acc: 0.8423 -- iter: 0960/3680
[A[ATraining Step: 4516  | total loss: [1m[32m0.40811[0m[0m
[2K| Adam | epoch: 040 | loss: 0.40811 - acc: 0.8456 -- iter: 0992/3680
[A[ATraining Step: 4517  | total loss: [1m[32m0.38803[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38803 - acc: 0.8548 -- iter: 1024/3680
[A[ATraining Step: 4518  | total loss: [1m[32m0.37732[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37732 - acc: 0.8537 -- iter: 1056/3680
[A[ATraining Step: 4519  | total loss: [1m[32m0.36952[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36952 - acc: 0.8558 -- iter: 1088/3680
[A[ATraining Step: 4520  | total loss: [1m[32m0.36309[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36309 - acc: 0.8608 -- iter: 1120/3680
[A[ATraining Step: 4521  | total loss: [1m[32m0.35919[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35919 - acc: 0.8591 -- iter: 1152/3680
[A[ATraining Step: 4522  | total loss: [1m[32m0.34723[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34723 - acc: 0.8670 -- iter: 1184/3680
[A[ATraining Step: 4523  | total loss: [1m[32m0.33766[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33766 - acc: 0.8740 -- iter: 1216/3680
[A[ATraining Step: 4524  | total loss: [1m[32m0.32645[0m[0m
[2K| Adam | epoch: 040 | loss: 0.32645 - acc: 0.8804 -- iter: 1248/3680
[A[ATraining Step: 4525  | total loss: [1m[32m0.31483[0m[0m
[2K| Adam | epoch: 040 | loss: 0.31483 - acc: 0.8861 -- iter: 1280/3680
[A[ATraining Step: 4526  | total loss: [1m[32m0.31865[0m[0m
[2K| Adam | epoch: 040 | loss: 0.31865 - acc: 0.8787 -- iter: 1312/3680
[A[ATraining Step: 4527  | total loss: [1m[32m0.32056[0m[0m
[2K| Adam | epoch: 040 | loss: 0.32056 - acc: 0.8815 -- iter: 1344/3680
[A[ATraining Step: 4528  | total loss: [1m[32m0.33035[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33035 - acc: 0.8715 -- iter: 1376/3680
[A[ATraining Step: 4529  | total loss: [1m[32m0.33699[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33699 - acc: 0.8624 -- iter: 1408/3680
[A[ATraining Step: 4530  | total loss: [1m[32m0.33746[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33746 - acc: 0.8620 -- iter: 1440/3680
[A[ATraining Step: 4531  | total loss: [1m[32m0.32985[0m[0m
[2K| Adam | epoch: 040 | loss: 0.32985 - acc: 0.8620 -- iter: 1472/3680
[A[ATraining Step: 4532  | total loss: [1m[32m0.33975[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33975 - acc: 0.8571 -- iter: 1504/3680
[A[ATraining Step: 4533  | total loss: [1m[32m0.33689[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33689 - acc: 0.8557 -- iter: 1536/3680
[A[ATraining Step: 4534  | total loss: [1m[32m0.32871[0m[0m
[2K| Adam | epoch: 040 | loss: 0.32871 - acc: 0.8577 -- iter: 1568/3680
[A[ATraining Step: 4535  | total loss: [1m[32m0.34368[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34368 - acc: 0.8469 -- iter: 1600/3680
[A[ATraining Step: 4536  | total loss: [1m[32m0.34681[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34681 - acc: 0.8434 -- iter: 1632/3680
[A[ATraining Step: 4537  | total loss: [1m[32m0.33053[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33053 - acc: 0.8497 -- iter: 1664/3680
[A[ATraining Step: 4538  | total loss: [1m[32m0.33429[0m[0m
[2K| Adam | epoch: 040 | loss: 0.33429 - acc: 0.8491 -- iter: 1696/3680
[A[ATraining Step: 4539  | total loss: [1m[32m0.34857[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34857 - acc: 0.8486 -- iter: 1728/3680
[A[ATraining Step: 4540  | total loss: [1m[32m0.34078[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34078 - acc: 0.8512 -- iter: 1760/3680
[A[ATraining Step: 4541  | total loss: [1m[32m0.35111[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35111 - acc: 0.8474 -- iter: 1792/3680
[A[ATraining Step: 4542  | total loss: [1m[32m0.34243[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34243 - acc: 0.8501 -- iter: 1824/3680
[A[ATraining Step: 4543  | total loss: [1m[32m0.34685[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34685 - acc: 0.8495 -- iter: 1856/3680
[A[ATraining Step: 4544  | total loss: [1m[32m0.35899[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35899 - acc: 0.8395 -- iter: 1888/3680
[A[ATraining Step: 4545  | total loss: [1m[32m0.35523[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35523 - acc: 0.8400 -- iter: 1920/3680
[A[ATraining Step: 4546  | total loss: [1m[32m0.34896[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34896 - acc: 0.8435 -- iter: 1952/3680
[A[ATraining Step: 4547  | total loss: [1m[32m0.36018[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36018 - acc: 0.8354 -- iter: 1984/3680
[A[ATraining Step: 4548  | total loss: [1m[32m0.36018[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36018 - acc: 0.8354 -- iter: 2016/3680
[A[ATraining Step: 4549  | total loss: [1m[32m0.35164[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35164 - acc: 0.8425 -- iter: 2048/3680
[A[ATraining Step: 4550  | total loss: [1m[32m0.37647[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37647 - acc: 0.8301 -- iter: 2080/3680
[A[ATraining Step: 4551  | total loss: [1m[32m0.36159[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36159 - acc: 0.8377 -- iter: 2112/3680
[A[ATraining Step: 4552  | total loss: [1m[32m0.38032[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38032 - acc: 0.8352 -- iter: 2144/3680
[A[ATraining Step: 4553  | total loss: [1m[32m0.36693[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36693 - acc: 0.8423 -- iter: 2176/3680
[A[ATraining Step: 4554  | total loss: [1m[32m0.37804[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37804 - acc: 0.8362 -- iter: 2208/3680
[A[ATraining Step: 4555  | total loss: [1m[32m0.37414[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37414 - acc: 0.8370 -- iter: 2240/3680
[A[ATraining Step: 4556  | total loss: [1m[32m0.37125[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37125 - acc: 0.8345 -- iter: 2272/3680
[A[ATraining Step: 4557  | total loss: [1m[32m0.37552[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37552 - acc: 0.8292 -- iter: 2304/3680
[A[ATraining Step: 4558  | total loss: [1m[32m0.38095[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38095 - acc: 0.8275 -- iter: 2336/3680
[A[ATraining Step: 4559  | total loss: [1m[32m0.38163[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38163 - acc: 0.8260 -- iter: 2368/3680
[A[ATraining Step: 4560  | total loss: [1m[32m0.38518[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38518 - acc: 0.8309 -- iter: 2400/3680
[A[ATraining Step: 4561  | total loss: [1m[32m0.38516[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38516 - acc: 0.8322 -- iter: 2432/3680
[A[ATraining Step: 4562  | total loss: [1m[32m0.40163[0m[0m
[2K| Adam | epoch: 040 | loss: 0.40163 - acc: 0.8271 -- iter: 2464/3680
[A[ATraining Step: 4563  | total loss: [1m[32m0.38300[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38300 - acc: 0.8381 -- iter: 2496/3680
[A[ATraining Step: 4564  | total loss: [1m[32m0.36844[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36844 - acc: 0.8450 -- iter: 2528/3680
[A[ATraining Step: 4565  | total loss: [1m[32m0.36515[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36515 - acc: 0.8417 -- iter: 2560/3680
[A[ATraining Step: 4566  | total loss: [1m[32m0.36383[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36383 - acc: 0.8388 -- iter: 2592/3680
[A[ATraining Step: 4567  | total loss: [1m[32m0.36259[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36259 - acc: 0.8362 -- iter: 2624/3680
[A[ATraining Step: 4568  | total loss: [1m[32m0.34698[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34698 - acc: 0.8432 -- iter: 2656/3680
[A[ATraining Step: 4569  | total loss: [1m[32m0.35799[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35799 - acc: 0.8338 -- iter: 2688/3680
[A[ATraining Step: 4570  | total loss: [1m[32m0.36564[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36564 - acc: 0.8286 -- iter: 2720/3680
[A[ATraining Step: 4571  | total loss: [1m[32m0.35512[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35512 - acc: 0.8395 -- iter: 2752/3680
[A[ATraining Step: 4572  | total loss: [1m[32m0.36590[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36590 - acc: 0.8274 -- iter: 2784/3680
[A[ATraining Step: 4573  | total loss: [1m[32m0.37518[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37518 - acc: 0.8259 -- iter: 2816/3680
[A[ATraining Step: 4574  | total loss: [1m[32m0.36017[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36017 - acc: 0.8252 -- iter: 2848/3680
[A[ATraining Step: 4575  | total loss: [1m[32m0.37742[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37742 - acc: 0.8252 -- iter: 2880/3680
[A[ATraining Step: 4576  | total loss: [1m[32m0.38603[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38603 - acc: 0.8271 -- iter: 2912/3680
[A[ATraining Step: 4577  | total loss: [1m[32m0.38539[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38539 - acc: 0.8225 -- iter: 2944/3680
[A[ATraining Step: 4578  | total loss: [1m[32m0.37747[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37747 - acc: 0.8278 -- iter: 2976/3680
[A[ATraining Step: 4579  | total loss: [1m[32m0.38090[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38090 - acc: 0.8325 -- iter: 3008/3680
[A[ATraining Step: 4580  | total loss: [1m[32m0.36414[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36414 - acc: 0.8430 -- iter: 3040/3680
[A[ATraining Step: 4581  | total loss: [1m[32m0.34847[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34847 - acc: 0.8493 -- iter: 3072/3680
[A[ATraining Step: 4582  | total loss: [1m[32m0.34652[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34652 - acc: 0.8550 -- iter: 3104/3680
[A[ATraining Step: 4583  | total loss: [1m[32m0.34875[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34875 - acc: 0.8570 -- iter: 3136/3680
[A[ATraining Step: 4584  | total loss: [1m[32m0.35276[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35276 - acc: 0.8494 -- iter: 3168/3680
[A[ATraining Step: 4585  | total loss: [1m[32m0.36529[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36529 - acc: 0.8395 -- iter: 3200/3680
[A[ATraining Step: 4586  | total loss: [1m[32m0.36723[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36723 - acc: 0.8368 -- iter: 3232/3680
[A[ATraining Step: 4587  | total loss: [1m[32m0.38299[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38299 - acc: 0.8325 -- iter: 3264/3680
[A[ATraining Step: 4588  | total loss: [1m[32m0.38432[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38432 - acc: 0.8325 -- iter: 3296/3680
[A[ATraining Step: 4589  | total loss: [1m[32m0.37856[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37856 - acc: 0.8367 -- iter: 3328/3680
[A[ATraining Step: 4590  | total loss: [1m[32m0.37624[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37624 - acc: 0.8374 -- iter: 3360/3680
[A[ATraining Step: 4591  | total loss: [1m[32m0.38489[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38489 - acc: 0.8287 -- iter: 3392/3680
[A[ATraining Step: 4592  | total loss: [1m[32m0.38858[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38858 - acc: 0.8302 -- iter: 3424/3680
[A[ATraining Step: 4593  | total loss: [1m[32m0.38314[0m[0m
[2K| Adam | epoch: 040 | loss: 0.38314 - acc: 0.8347 -- iter: 3456/3680
[A[ATraining Step: 4594  | total loss: [1m[32m0.37647[0m[0m
[2K| Adam | epoch: 040 | loss: 0.37647 - acc: 0.8356 -- iter: 3488/3680
[A[ATraining Step: 4595  | total loss: [1m[32m0.36285[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36285 - acc: 0.8458 -- iter: 3520/3680
[A[ATraining Step: 4596  | total loss: [1m[32m0.36324[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36324 - acc: 0.8487 -- iter: 3552/3680
[A[ATraining Step: 4597  | total loss: [1m[32m0.36225[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36225 - acc: 0.8513 -- iter: 3584/3680
[A[ATraining Step: 4598  | total loss: [1m[32m0.36706[0m[0m
[2K| Adam | epoch: 040 | loss: 0.36706 - acc: 0.8506 -- iter: 3616/3680
[A[ATraining Step: 4599  | total loss: [1m[32m0.35967[0m[0m
[2K| Adam | epoch: 040 | loss: 0.35967 - acc: 0.8530 -- iter: 3648/3680
[A[ATraining Step: 4600  | total loss: [1m[32m0.34932[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34932 - acc: 0.8552 | val_loss: 0.32571 - val_acc: 0.8784 -- iter: 3680/3680
[A[ATraining Step: 4600  | total loss: [1m[32m0.34932[0m[0m
[2K| Adam | epoch: 040 | loss: 0.34932 - acc: 0.8552 | val_loss: 0.32571 - val_acc: 0.8784 -- iter: 3680/3680
--
Training Step: 4601  | total loss: [1m[32m0.34331[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34331 - acc: 0.8572 -- iter: 0032/3680
[A[ATraining Step: 4602  | total loss: [1m[32m0.35022[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35022 - acc: 0.8527 -- iter: 0064/3680
[A[ATraining Step: 4603  | total loss: [1m[32m0.34674[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34674 - acc: 0.8518 -- iter: 0096/3680
[A[ATraining Step: 4604  | total loss: [1m[32m0.34990[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34990 - acc: 0.8541 -- iter: 0128/3680
[A[ATraining Step: 4605  | total loss: [1m[32m0.36759[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36759 - acc: 0.8437 -- iter: 0160/3680
[A[ATraining Step: 4606  | total loss: [1m[32m0.37753[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37753 - acc: 0.8375 -- iter: 0192/3680
[A[ATraining Step: 4607  | total loss: [1m[32m0.40614[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40614 - acc: 0.8194 -- iter: 0224/3680
[A[ATraining Step: 4608  | total loss: [1m[32m0.47961[0m[0m
[2K| Adam | epoch: 041 | loss: 0.47961 - acc: 0.7874 -- iter: 0256/3680
[A[ATraining Step: 4609  | total loss: [1m[32m0.45986[0m[0m
[2K| Adam | epoch: 041 | loss: 0.45986 - acc: 0.7993 -- iter: 0288/3680
[A[ATraining Step: 4610  | total loss: [1m[32m0.42324[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42324 - acc: 0.8206 -- iter: 0320/3680
[A[ATraining Step: 4611  | total loss: [1m[32m0.42324[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42324 - acc: 0.8206 -- iter: 0352/3680
[A[ATraining Step: 4612  | total loss: [1m[32m0.40132[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40132 - acc: 0.8354 -- iter: 0384/3680
[A[ATraining Step: 4613  | total loss: [1m[32m0.39669[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39669 - acc: 0.8393 -- iter: 0416/3680
[A[ATraining Step: 4614  | total loss: [1m[32m0.39357[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39357 - acc: 0.8398 -- iter: 0448/3680
[A[ATraining Step: 4615  | total loss: [1m[32m0.38712[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38712 - acc: 0.8433 -- iter: 0480/3680
[A[ATraining Step: 4616  | total loss: [1m[32m0.38057[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38057 - acc: 0.8465 -- iter: 0512/3680
[A[ATraining Step: 4617  | total loss: [1m[32m0.38769[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38769 - acc: 0.8465 -- iter: 0544/3680
[A[ATraining Step: 4618  | total loss: [1m[32m0.38935[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38935 - acc: 0.8400 -- iter: 0576/3680
[A[ATraining Step: 4619  | total loss: [1m[32m0.37405[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37405 - acc: 0.8497 -- iter: 0608/3680
[A[ATraining Step: 4620  | total loss: [1m[32m0.37000[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37000 - acc: 0.8523 -- iter: 0640/3680
[A[ATraining Step: 4621  | total loss: [1m[32m0.37197[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37197 - acc: 0.8545 -- iter: 0672/3680
[A[ATraining Step: 4622  | total loss: [1m[32m0.36405[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36405 - acc: 0.8566 -- iter: 0704/3680
[A[ATraining Step: 4623  | total loss: [1m[32m0.38629[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38629 - acc: 0.8366 -- iter: 0736/3680
[A[ATraining Step: 4624  | total loss: [1m[32m0.38967[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38967 - acc: 0.8407 -- iter: 0768/3680
[A[ATraining Step: 4625  | total loss: [1m[32m0.38701[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38701 - acc: 0.8407 -- iter: 0800/3680
[A[ATraining Step: 4626  | total loss: [1m[32m0.39941[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39941 - acc: 0.8348 -- iter: 0832/3680
[A[ATraining Step: 4627  | total loss: [1m[32m0.40397[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40397 - acc: 0.8294 -- iter: 0864/3680
[A[ATraining Step: 4628  | total loss: [1m[32m0.39407[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39407 - acc: 0.8309 -- iter: 0896/3680
[A[ATraining Step: 4629  | total loss: [1m[32m0.39240[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39240 - acc: 0.8322 -- iter: 0928/3680
[A[ATraining Step: 4630  | total loss: [1m[32m0.38684[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38684 - acc: 0.8302 -- iter: 0960/3680
[A[ATraining Step: 4631  | total loss: [1m[32m0.38531[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38531 - acc: 0.8378 -- iter: 0992/3680
[A[ATraining Step: 4632  | total loss: [1m[32m0.37660[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37660 - acc: 0.8446 -- iter: 1024/3680
[A[ATraining Step: 4633  | total loss: [1m[32m0.37302[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37302 - acc: 0.8508 -- iter: 1056/3680
[A[ATraining Step: 4634  | total loss: [1m[32m0.37847[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37847 - acc: 0.8438 -- iter: 1088/3680
[A[ATraining Step: 4635  | total loss: [1m[32m0.37432[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37432 - acc: 0.8407 -- iter: 1120/3680
[A[ATraining Step: 4636  | total loss: [1m[32m0.36712[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36712 - acc: 0.8441 -- iter: 1152/3680
[A[ATraining Step: 4637  | total loss: [1m[32m0.35266[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35266 - acc: 0.8566 -- iter: 1184/3680
[A[ATraining Step: 4638  | total loss: [1m[32m0.36196[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36196 - acc: 0.8459 -- iter: 1216/3680
[A[ATraining Step: 4639  | total loss: [1m[32m0.36596[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36596 - acc: 0.8488 -- iter: 1248/3680
[A[ATraining Step: 4640  | total loss: [1m[32m0.37348[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37348 - acc: 0.8390 -- iter: 1280/3680
[A[ATraining Step: 4641  | total loss: [1m[32m0.38537[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38537 - acc: 0.8332 -- iter: 1312/3680
[A[ATraining Step: 4642  | total loss: [1m[32m0.38229[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38229 - acc: 0.8311 -- iter: 1344/3680
[A[ATraining Step: 4643  | total loss: [1m[32m0.37529[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37529 - acc: 0.8355 -- iter: 1376/3680
[A[ATraining Step: 4644  | total loss: [1m[32m0.37004[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37004 - acc: 0.8332 -- iter: 1408/3680
[A[ATraining Step: 4645  | total loss: [1m[32m0.37731[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37731 - acc: 0.8249 -- iter: 1440/3680
[A[ATraining Step: 4646  | total loss: [1m[32m0.37964[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37964 - acc: 0.8236 -- iter: 1472/3680
[A[ATraining Step: 4647  | total loss: [1m[32m0.38499[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38499 - acc: 0.8257 -- iter: 1504/3680
[A[ATraining Step: 4648  | total loss: [1m[32m0.38154[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38154 - acc: 0.8275 -- iter: 1536/3680
[A[ATraining Step: 4649  | total loss: [1m[32m0.37428[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37428 - acc: 0.8353 -- iter: 1568/3680
[A[ATraining Step: 4650  | total loss: [1m[32m0.36039[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36039 - acc: 0.8487 -- iter: 1600/3680
[A[ATraining Step: 4651  | total loss: [1m[32m0.34897[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34897 - acc: 0.8607 -- iter: 1632/3680
[A[ATraining Step: 4652  | total loss: [1m[32m0.34524[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34524 - acc: 0.8652 -- iter: 1664/3680
[A[ATraining Step: 4653  | total loss: [1m[32m0.34267[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34267 - acc: 0.8631 -- iter: 1696/3680
[A[ATraining Step: 4654  | total loss: [1m[32m0.34053[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34053 - acc: 0.8643 -- iter: 1728/3680
[A[ATraining Step: 4655  | total loss: [1m[32m0.33817[0m[0m
[2K| Adam | epoch: 041 | loss: 0.33817 - acc: 0.8654 -- iter: 1760/3680
[A[ATraining Step: 4656  | total loss: [1m[32m0.35405[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35405 - acc: 0.8601 -- iter: 1792/3680
[A[ATraining Step: 4657  | total loss: [1m[32m0.36008[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36008 - acc: 0.8553 -- iter: 1824/3680
[A[ATraining Step: 4658  | total loss: [1m[32m0.37505[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37505 - acc: 0.8542 -- iter: 1856/3680
[A[ATraining Step: 4659  | total loss: [1m[32m0.36579[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36579 - acc: 0.8562 -- iter: 1888/3680
[A[ATraining Step: 4660  | total loss: [1m[32m0.35979[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35979 - acc: 0.8581 -- iter: 1920/3680
[A[ATraining Step: 4661  | total loss: [1m[32m0.36337[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36337 - acc: 0.8567 -- iter: 1952/3680
[A[ATraining Step: 4662  | total loss: [1m[32m0.36262[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36262 - acc: 0.8616 -- iter: 1984/3680
[A[ATraining Step: 4663  | total loss: [1m[32m0.37200[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37200 - acc: 0.8505 -- iter: 2016/3680
[A[ATraining Step: 4664  | total loss: [1m[32m0.36211[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36211 - acc: 0.8529 -- iter: 2048/3680
[A[ATraining Step: 4665  | total loss: [1m[32m0.37306[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37306 - acc: 0.8484 -- iter: 2080/3680
[A[ATraining Step: 4666  | total loss: [1m[32m0.37599[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37599 - acc: 0.8484 -- iter: 2112/3680
[A[ATraining Step: 4667  | total loss: [1m[32m0.37754[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37754 - acc: 0.8479 -- iter: 2144/3680
[A[ATraining Step: 4668  | total loss: [1m[32m0.37290[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37290 - acc: 0.8475 -- iter: 2176/3680
[A[ATraining Step: 4669  | total loss: [1m[32m0.35922[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35922 - acc: 0.8534 -- iter: 2208/3680
[A[ATraining Step: 4670  | total loss: [1m[32m0.38249[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38249 - acc: 0.8430 -- iter: 2240/3680
[A[ATraining Step: 4671  | total loss: [1m[32m0.40215[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40215 - acc: 0.8431 -- iter: 2272/3680
[A[ATraining Step: 4672  | total loss: [1m[32m0.40601[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40601 - acc: 0.8400 -- iter: 2304/3680
[A[ATraining Step: 4673  | total loss: [1m[32m0.40964[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40964 - acc: 0.8404 -- iter: 2336/3680
[A[ATraining Step: 4674  | total loss: [1m[32m0.41669[0m[0m
[2K| Adam | epoch: 041 | loss: 0.41669 - acc: 0.8314 -- iter: 2368/3680
[A[ATraining Step: 4675  | total loss: [1m[32m0.42327[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42327 - acc: 0.8264 -- iter: 2400/3680
[A[ATraining Step: 4676  | total loss: [1m[32m0.42885[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42885 - acc: 0.8218 -- iter: 2432/3680
[A[ATraining Step: 4677  | total loss: [1m[32m0.42261[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42261 - acc: 0.8272 -- iter: 2464/3680
[A[ATraining Step: 4678  | total loss: [1m[32m0.42353[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42353 - acc: 0.8257 -- iter: 2496/3680
[A[ATraining Step: 4679  | total loss: [1m[32m0.41993[0m[0m
[2K| Adam | epoch: 041 | loss: 0.41993 - acc: 0.8275 -- iter: 2528/3680
[A[ATraining Step: 4680  | total loss: [1m[32m0.42898[0m[0m
[2K| Adam | epoch: 041 | loss: 0.42898 - acc: 0.8198 -- iter: 2560/3680
[A[ATraining Step: 4681  | total loss: [1m[32m0.43090[0m[0m
[2K| Adam | epoch: 041 | loss: 0.43090 - acc: 0.8097 -- iter: 2592/3680
[A[ATraining Step: 4682  | total loss: [1m[32m0.43214[0m[0m
[2K| Adam | epoch: 041 | loss: 0.43214 - acc: 0.8131 -- iter: 2624/3680
[A[ATraining Step: 4683  | total loss: [1m[32m0.43070[0m[0m
[2K| Adam | epoch: 041 | loss: 0.43070 - acc: 0.8130 -- iter: 2656/3680
[A[ATraining Step: 4684  | total loss: [1m[32m0.43575[0m[0m
[2K| Adam | epoch: 041 | loss: 0.43575 - acc: 0.8098 -- iter: 2688/3680
[A[ATraining Step: 4685  | total loss: [1m[32m0.41691[0m[0m
[2K| Adam | epoch: 041 | loss: 0.41691 - acc: 0.8195 -- iter: 2720/3680
[A[ATraining Step: 4686  | total loss: [1m[32m0.41260[0m[0m
[2K| Adam | epoch: 041 | loss: 0.41260 - acc: 0.8250 -- iter: 2752/3680
[A[ATraining Step: 4687  | total loss: [1m[32m0.41185[0m[0m
[2K| Adam | epoch: 041 | loss: 0.41185 - acc: 0.8238 -- iter: 2784/3680
[A[ATraining Step: 4688  | total loss: [1m[32m0.40957[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40957 - acc: 0.8195 -- iter: 2816/3680
[A[ATraining Step: 4689  | total loss: [1m[32m0.40391[0m[0m
[2K| Adam | epoch: 041 | loss: 0.40391 - acc: 0.8251 -- iter: 2848/3680
[A[ATraining Step: 4690  | total loss: [1m[32m0.38613[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38613 - acc: 0.8363 -- iter: 2880/3680
[A[ATraining Step: 4691  | total loss: [1m[32m0.38872[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38872 - acc: 0.8321 -- iter: 2912/3680
[A[ATraining Step: 4692  | total loss: [1m[32m0.38872[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38872 - acc: 0.8321 -- iter: 2944/3680
[A[ATraining Step: 4693  | total loss: [1m[32m0.36848[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36848 - acc: 0.8458 -- iter: 2976/3680
[A[ATraining Step: 4694  | total loss: [1m[32m0.36580[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36580 - acc: 0.8487 -- iter: 3008/3680
[A[ATraining Step: 4695  | total loss: [1m[32m0.36018[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36018 - acc: 0.8513 -- iter: 3040/3680
[A[ATraining Step: 4696  | total loss: [1m[32m0.35094[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35094 - acc: 0.8537 -- iter: 3072/3680
[A[ATraining Step: 4697  | total loss: [1m[32m0.34475[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34475 - acc: 0.8558 -- iter: 3104/3680
[A[ATraining Step: 4698  | total loss: [1m[32m0.35107[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35107 - acc: 0.8452 -- iter: 3136/3680
[A[ATraining Step: 4699  | total loss: [1m[32m0.36632[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36632 - acc: 0.8357 -- iter: 3168/3680
[A[ATraining Step: 4700  | total loss: [1m[32m0.36884[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36884 - acc: 0.8365 | val_loss: 0.33654 - val_acc: 0.8773 -- iter: 3200/3680
[A[ATraining Step: 4700  | total loss: [1m[32m0.36884[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36884 - acc: 0.8365 | val_loss: 0.33654 - val_acc: 0.8773 -- iter: 3200/3680
--
Training Step: 4701  | total loss: [1m[32m0.36578[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36578 - acc: 0.8372 -- iter: 3232/3680
[A[ATraining Step: 4702  | total loss: [1m[32m0.36483[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36483 - acc: 0.8379 -- iter: 3264/3680
[A[ATraining Step: 4703  | total loss: [1m[32m0.35720[0m[0m
[2K| Adam | epoch: 041 | loss: 0.35720 - acc: 0.8416 -- iter: 3296/3680
[A[ATraining Step: 4704  | total loss: [1m[32m0.34861[0m[0m
[2K| Adam | epoch: 041 | loss: 0.34861 - acc: 0.8481 -- iter: 3328/3680
[A[ATraining Step: 4705  | total loss: [1m[32m0.36419[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36419 - acc: 0.8383 -- iter: 3360/3680
[A[ATraining Step: 4706  | total loss: [1m[32m0.39636[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39636 - acc: 0.8263 -- iter: 3392/3680
[A[ATraining Step: 4707  | total loss: [1m[32m0.39369[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39369 - acc: 0.8312 -- iter: 3424/3680
[A[ATraining Step: 4708  | total loss: [1m[32m0.39321[0m[0m
[2K| Adam | epoch: 041 | loss: 0.39321 - acc: 0.8293 -- iter: 3456/3680
[A[ATraining Step: 4709  | total loss: [1m[32m0.38216[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38216 - acc: 0.8339 -- iter: 3488/3680
[A[ATraining Step: 4710  | total loss: [1m[32m0.37206[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37206 - acc: 0.8411 -- iter: 3520/3680
[A[ATraining Step: 4711  | total loss: [1m[32m0.36070[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36070 - acc: 0.8445 -- iter: 3552/3680
[A[ATraining Step: 4712  | total loss: [1m[32m0.36261[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36261 - acc: 0.8382 -- iter: 3584/3680
[A[ATraining Step: 4713  | total loss: [1m[32m0.38036[0m[0m
[2K| Adam | epoch: 041 | loss: 0.38036 - acc: 0.8399 -- iter: 3616/3680
[A[ATraining Step: 4714  | total loss: [1m[32m0.36819[0m[0m
[2K| Adam | epoch: 041 | loss: 0.36819 - acc: 0.8371 -- iter: 3648/3680
[A[ATraining Step: 4715  | total loss: [1m[32m0.37197[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37197 - acc: 0.8371 | val_loss: 0.33296 - val_acc: 0.8762 -- iter: 3680/3680
[A[ATraining Step: 4715  | total loss: [1m[32m0.37197[0m[0m
[2K| Adam | epoch: 041 | loss: 0.37197 - acc: 0.8371 | val_loss: 0.33296 - val_acc: 0.8762 -- iter: 3680/3680
--
Training Step: 4716  | total loss: [1m[32m0.36951[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36951 - acc: 0.8472 -- iter: 0032/3680
[A[ATraining Step: 4717  | total loss: [1m[32m0.37264[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37264 - acc: 0.8468 -- iter: 0064/3680
[A[ATraining Step: 4718  | total loss: [1m[32m0.36108[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36108 - acc: 0.8496 -- iter: 0096/3680
[A[ATraining Step: 4719  | total loss: [1m[32m0.35669[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35669 - acc: 0.8553 -- iter: 0128/3680
[A[ATraining Step: 4720  | total loss: [1m[32m0.35719[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35719 - acc: 0.8503 -- iter: 0160/3680
[A[ATraining Step: 4721  | total loss: [1m[32m0.35764[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35764 - acc: 0.8503 -- iter: 0192/3680
[A[ATraining Step: 4722  | total loss: [1m[32m0.36241[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36241 - acc: 0.8496 -- iter: 0224/3680
[A[ATraining Step: 4723  | total loss: [1m[32m0.37756[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37756 - acc: 0.8428 -- iter: 0256/3680
[A[ATraining Step: 4724  | total loss: [1m[32m0.36152[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36152 - acc: 0.8491 -- iter: 0288/3680
[A[ATraining Step: 4725  | total loss: [1m[32m0.35055[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35055 - acc: 0.8517 -- iter: 0320/3680
[A[ATraining Step: 4726  | total loss: [1m[32m0.34742[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34742 - acc: 0.8509 -- iter: 0352/3680
[A[ATraining Step: 4727  | total loss: [1m[32m0.36005[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36005 - acc: 0.8471 -- iter: 0384/3680
[A[ATraining Step: 4728  | total loss: [1m[32m0.34874[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34874 - acc: 0.8530 -- iter: 0416/3680
[A[ATraining Step: 4729  | total loss: [1m[32m0.35849[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35849 - acc: 0.8552 -- iter: 0448/3680
[A[ATraining Step: 4730  | total loss: [1m[32m0.35380[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35380 - acc: 0.8562 -- iter: 0480/3680
[A[ATraining Step: 4731  | total loss: [1m[32m0.35380[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35380 - acc: 0.8562 -- iter: 0512/3680
[A[ATraining Step: 4732  | total loss: [1m[32m0.33982[0m[0m
[2K| Adam | epoch: 042 | loss: 0.33982 - acc: 0.8612 -- iter: 0544/3680
[A[ATraining Step: 4733  | total loss: [1m[32m0.33360[0m[0m
[2K| Adam | epoch: 042 | loss: 0.33360 - acc: 0.8688 -- iter: 0576/3680
[A[ATraining Step: 4734  | total loss: [1m[32m0.31901[0m[0m
[2K| Adam | epoch: 042 | loss: 0.31901 - acc: 0.8788 -- iter: 0608/3680
[A[ATraining Step: 4735  | total loss: [1m[32m0.31948[0m[0m
[2K| Adam | epoch: 042 | loss: 0.31948 - acc: 0.8784 -- iter: 0640/3680
[A[ATraining Step: 4736  | total loss: [1m[32m0.31820[0m[0m
[2K| Adam | epoch: 042 | loss: 0.31820 - acc: 0.8812 -- iter: 0672/3680
[A[ATraining Step: 4737  | total loss: [1m[32m0.32606[0m[0m
[2K| Adam | epoch: 042 | loss: 0.32606 - acc: 0.8775 -- iter: 0704/3680
[A[ATraining Step: 4738  | total loss: [1m[32m0.34967[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34967 - acc: 0.8678 -- iter: 0736/3680
[A[ATraining Step: 4739  | total loss: [1m[32m0.35788[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35788 - acc: 0.8560 -- iter: 0768/3680
[A[ATraining Step: 4740  | total loss: [1m[32m0.35662[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35662 - acc: 0.8548 -- iter: 0800/3680
[A[ATraining Step: 4741  | total loss: [1m[32m0.34842[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34842 - acc: 0.8631 -- iter: 0832/3680
[A[ATraining Step: 4742  | total loss: [1m[32m0.35716[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35716 - acc: 0.8580 -- iter: 0864/3680
[A[ATraining Step: 4743  | total loss: [1m[32m0.36207[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36207 - acc: 0.8535 -- iter: 0896/3680
[A[ATraining Step: 4744  | total loss: [1m[32m0.37139[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37139 - acc: 0.8556 -- iter: 0928/3680
[A[ATraining Step: 4745  | total loss: [1m[32m0.36514[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36514 - acc: 0.8576 -- iter: 0960/3680
[A[ATraining Step: 4746  | total loss: [1m[32m0.36237[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36237 - acc: 0.8562 -- iter: 0992/3680
[A[ATraining Step: 4747  | total loss: [1m[32m0.37164[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37164 - acc: 0.8518 -- iter: 1024/3680
[A[ATraining Step: 4748  | total loss: [1m[32m0.37523[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37523 - acc: 0.8479 -- iter: 1056/3680
[A[ATraining Step: 4749  | total loss: [1m[32m0.38211[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38211 - acc: 0.8443 -- iter: 1088/3680
[A[ATraining Step: 4750  | total loss: [1m[32m0.39694[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39694 - acc: 0.8389 -- iter: 1120/3680
[A[ATraining Step: 4751  | total loss: [1m[32m0.39694[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39694 - acc: 0.8389 -- iter: 1152/3680
[A[ATraining Step: 4752  | total loss: [1m[32m0.39360[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39360 - acc: 0.8300 -- iter: 1184/3680
[A[ATraining Step: 4753  | total loss: [1m[32m0.38438[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38438 - acc: 0.8345 -- iter: 1216/3680
[A[ATraining Step: 4754  | total loss: [1m[32m0.39394[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39394 - acc: 0.8261 -- iter: 1248/3680
[A[ATraining Step: 4755  | total loss: [1m[32m0.40099[0m[0m
[2K| Adam | epoch: 042 | loss: 0.40099 - acc: 0.8185 -- iter: 1280/3680
[A[ATraining Step: 4756  | total loss: [1m[32m0.39637[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39637 - acc: 0.8179 -- iter: 1312/3680
[A[ATraining Step: 4757  | total loss: [1m[32m0.39030[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39030 - acc: 0.8142 -- iter: 1344/3680
[A[ATraining Step: 4758  | total loss: [1m[32m0.38322[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38322 - acc: 0.8234 -- iter: 1376/3680
[A[ATraining Step: 4759  | total loss: [1m[32m0.36351[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36351 - acc: 0.8379 -- iter: 1408/3680
[A[ATraining Step: 4760  | total loss: [1m[32m0.37366[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37366 - acc: 0.8356 -- iter: 1440/3680
[A[ATraining Step: 4761  | total loss: [1m[32m0.37366[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37366 - acc: 0.8356 -- iter: 1472/3680
[A[ATraining Step: 4762  | total loss: [1m[32m0.36902[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36902 - acc: 0.8333 -- iter: 1504/3680
[A[ATraining Step: 4763  | total loss: [1m[32m0.36376[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36376 - acc: 0.8343 -- iter: 1536/3680
[A[ATraining Step: 4764  | total loss: [1m[32m0.36056[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36056 - acc: 0.8322 -- iter: 1568/3680
[A[ATraining Step: 4765  | total loss: [1m[32m0.37405[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37405 - acc: 0.8302 -- iter: 1600/3680
[A[ATraining Step: 4766  | total loss: [1m[32m0.37633[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37633 - acc: 0.8315 -- iter: 1632/3680
[A[ATraining Step: 4767  | total loss: [1m[32m0.39983[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39983 - acc: 0.8140 -- iter: 1664/3680
[A[ATraining Step: 4768  | total loss: [1m[32m0.41814[0m[0m
[2K| Adam | epoch: 042 | loss: 0.41814 - acc: 0.8139 -- iter: 1696/3680
[A[ATraining Step: 4769  | total loss: [1m[32m0.42469[0m[0m
[2K| Adam | epoch: 042 | loss: 0.42469 - acc: 0.8106 -- iter: 1728/3680
[A[ATraining Step: 4770  | total loss: [1m[32m0.40865[0m[0m
[2K| Adam | epoch: 042 | loss: 0.40865 - acc: 0.8170 -- iter: 1760/3680
[A[ATraining Step: 4771  | total loss: [1m[32m0.38629[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38629 - acc: 0.8322 -- iter: 1792/3680
[A[ATraining Step: 4772  | total loss: [1m[32m0.38964[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38964 - acc: 0.8302 -- iter: 1824/3680
[A[ATraining Step: 4773  | total loss: [1m[32m0.40313[0m[0m
[2K| Adam | epoch: 042 | loss: 0.40313 - acc: 0.8191 -- iter: 1856/3680
[A[ATraining Step: 4774  | total loss: [1m[32m0.40672[0m[0m
[2K| Adam | epoch: 042 | loss: 0.40672 - acc: 0.8184 -- iter: 1888/3680
[A[ATraining Step: 4775  | total loss: [1m[32m0.40883[0m[0m
[2K| Adam | epoch: 042 | loss: 0.40883 - acc: 0.8210 -- iter: 1920/3680
[A[ATraining Step: 4776  | total loss: [1m[32m0.39855[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39855 - acc: 0.8326 -- iter: 1952/3680
[A[ATraining Step: 4777  | total loss: [1m[32m0.38959[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38959 - acc: 0.8369 -- iter: 1984/3680
[A[ATraining Step: 4778  | total loss: [1m[32m0.38687[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38687 - acc: 0.8441 -- iter: 2016/3680
[A[ATraining Step: 4779  | total loss: [1m[32m0.38129[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38129 - acc: 0.8441 -- iter: 2048/3680
[A[ATraining Step: 4780  | total loss: [1m[32m0.37541[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37541 - acc: 0.8472 -- iter: 2080/3680
[A[ATraining Step: 4781  | total loss: [1m[32m0.37446[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37446 - acc: 0.8500 -- iter: 2112/3680
[A[ATraining Step: 4782  | total loss: [1m[32m0.36805[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36805 - acc: 0.8525 -- iter: 2144/3680
[A[ATraining Step: 4783  | total loss: [1m[32m0.38444[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38444 - acc: 0.8422 -- iter: 2176/3680
[A[ATraining Step: 4784  | total loss: [1m[32m0.39777[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39777 - acc: 0.8361 -- iter: 2208/3680
[A[ATraining Step: 4785  | total loss: [1m[32m0.38351[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38351 - acc: 0.8431 -- iter: 2240/3680
[A[ATraining Step: 4786  | total loss: [1m[32m0.38452[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38452 - acc: 0.8432 -- iter: 2272/3680
[A[ATraining Step: 4787  | total loss: [1m[32m0.36747[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36747 - acc: 0.8495 -- iter: 2304/3680
[A[ATraining Step: 4788  | total loss: [1m[32m0.37398[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37398 - acc: 0.8427 -- iter: 2336/3680
[A[ATraining Step: 4789  | total loss: [1m[32m0.36307[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36307 - acc: 0.8459 -- iter: 2368/3680
[A[ATraining Step: 4790  | total loss: [1m[32m0.37188[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37188 - acc: 0.8363 -- iter: 2400/3680
[A[ATraining Step: 4791  | total loss: [1m[32m0.37195[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37195 - acc: 0.8308 -- iter: 2432/3680
[A[ATraining Step: 4792  | total loss: [1m[32m0.36758[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36758 - acc: 0.8352 -- iter: 2464/3680
[A[ATraining Step: 4793  | total loss: [1m[32m0.36276[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36276 - acc: 0.8361 -- iter: 2496/3680
[A[ATraining Step: 4794  | total loss: [1m[32m0.36330[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36330 - acc: 0.8369 -- iter: 2528/3680
[A[ATraining Step: 4795  | total loss: [1m[32m0.38348[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38348 - acc: 0.8282 -- iter: 2560/3680
[A[ATraining Step: 4796  | total loss: [1m[32m0.37632[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37632 - acc: 0.8297 -- iter: 2592/3680
[A[ATraining Step: 4797  | total loss: [1m[32m0.38330[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38330 - acc: 0.8280 -- iter: 2624/3680
[A[ATraining Step: 4798  | total loss: [1m[32m0.37019[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37019 - acc: 0.8421 -- iter: 2656/3680
[A[ATraining Step: 4799  | total loss: [1m[32m0.35723[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35723 - acc: 0.8454 -- iter: 2688/3680
[A[ATraining Step: 4800  | total loss: [1m[32m0.36024[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36024 - acc: 0.8452 | val_loss: 0.33753 - val_acc: 0.8664 -- iter: 2720/3680
[A[ATraining Step: 4800  | total loss: [1m[32m0.36024[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36024 - acc: 0.8452 | val_loss: 0.33753 - val_acc: 0.8664 -- iter: 2720/3680
--
Training Step: 4801  | total loss: [1m[32m0.36390[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36390 - acc: 0.8482 -- iter: 2752/3680
[A[ATraining Step: 4802  | total loss: [1m[32m0.36020[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36020 - acc: 0.8509 -- iter: 2784/3680
[A[ATraining Step: 4803  | total loss: [1m[32m0.36558[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36558 - acc: 0.8533 -- iter: 2816/3680
[A[ATraining Step: 4804  | total loss: [1m[32m0.37490[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37490 - acc: 0.8398 -- iter: 2848/3680
[A[ATraining Step: 4805  | total loss: [1m[32m0.36999[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36999 - acc: 0.8371 -- iter: 2880/3680
[A[ATraining Step: 4806  | total loss: [1m[32m0.35817[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35817 - acc: 0.8471 -- iter: 2912/3680
[A[ATraining Step: 4807  | total loss: [1m[32m0.35113[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35113 - acc: 0.8471 -- iter: 2944/3680
[A[ATraining Step: 4808  | total loss: [1m[32m0.36832[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36832 - acc: 0.8436 -- iter: 2976/3680
[A[ATraining Step: 4809  | total loss: [1m[32m0.36149[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36149 - acc: 0.8468 -- iter: 3008/3680
[A[ATraining Step: 4810  | total loss: [1m[32m0.35249[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35249 - acc: 0.8465 -- iter: 3040/3680
[A[ATraining Step: 4811  | total loss: [1m[32m0.34860[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34860 - acc: 0.8525 -- iter: 3072/3680
[A[ATraining Step: 4812  | total loss: [1m[32m0.35953[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35953 - acc: 0.8485 -- iter: 3104/3680
[A[ATraining Step: 4813  | total loss: [1m[32m0.34768[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34768 - acc: 0.8510 -- iter: 3136/3680
[A[ATraining Step: 4814  | total loss: [1m[32m0.34768[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34768 - acc: 0.8510 -- iter: 3168/3680
[A[ATraining Step: 4815  | total loss: [1m[32m0.32582[0m[0m
[2K| Adam | epoch: 042 | loss: 0.32582 - acc: 0.8659 -- iter: 3200/3680
[A[ATraining Step: 4816  | total loss: [1m[32m0.31897[0m[0m
[2K| Adam | epoch: 042 | loss: 0.31897 - acc: 0.8731 -- iter: 3232/3680
[A[ATraining Step: 4817  | total loss: [1m[32m0.33087[0m[0m
[2K| Adam | epoch: 042 | loss: 0.33087 - acc: 0.8701 -- iter: 3264/3680
[A[ATraining Step: 4818  | total loss: [1m[32m0.33926[0m[0m
[2K| Adam | epoch: 042 | loss: 0.33926 - acc: 0.8675 -- iter: 3296/3680
[A[ATraining Step: 4819  | total loss: [1m[32m0.33603[0m[0m
[2K| Adam | epoch: 042 | loss: 0.33603 - acc: 0.8682 -- iter: 3328/3680
[A[ATraining Step: 4820  | total loss: [1m[32m0.34865[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34865 - acc: 0.8564 -- iter: 3360/3680
[A[ATraining Step: 4821  | total loss: [1m[32m0.35248[0m[0m
[2K| Adam | epoch: 042 | loss: 0.35248 - acc: 0.8552 -- iter: 3392/3680
[A[ATraining Step: 4822  | total loss: [1m[32m0.34984[0m[0m
[2K| Adam | epoch: 042 | loss: 0.34984 - acc: 0.8571 -- iter: 3424/3680
[A[ATraining Step: 4823  | total loss: [1m[32m0.33502[0m[0m
[2K| Adam | epoch: 042 | loss: 0.33502 - acc: 0.8652 -- iter: 3456/3680
[A[ATraining Step: 4824  | total loss: [1m[32m0.36404[0m[0m
[2K| Adam | epoch: 042 | loss: 0.36404 - acc: 0.8474 -- iter: 3488/3680
[A[ATraining Step: 4825  | total loss: [1m[32m0.37079[0m[0m
[2K| Adam | epoch: 042 | loss: 0.37079 - acc: 0.8408 -- iter: 3520/3680
[A[ATraining Step: 4826  | total loss: [1m[32m0.39674[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39674 - acc: 0.8286 -- iter: 3552/3680
[A[ATraining Step: 4827  | total loss: [1m[32m0.39242[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39242 - acc: 0.8332 -- iter: 3584/3680
[A[ATraining Step: 4828  | total loss: [1m[32m0.38658[0m[0m
[2K| Adam | epoch: 042 | loss: 0.38658 - acc: 0.8343 -- iter: 3616/3680
[A[ATraining Step: 4829  | total loss: [1m[32m0.40180[0m[0m
[2K| Adam | epoch: 042 | loss: 0.40180 - acc: 0.8321 -- iter: 3648/3680
[A[ATraining Step: 4830  | total loss: [1m[32m0.39124[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39124 - acc: 0.8395 | val_loss: 0.34229 - val_acc: 0.8632 -- iter: 3680/3680
[A[ATraining Step: 4830  | total loss: [1m[32m0.39124[0m[0m
[2K| Adam | epoch: 042 | loss: 0.39124 - acc: 0.8395 | val_loss: 0.34229 - val_acc: 0.8632 -- iter: 3680/3680
--
Training Step: 4831  | total loss: [1m[32m0.37382[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37382 - acc: 0.8524 -- iter: 0032/3680
[A[ATraining Step: 4832  | total loss: [1m[32m0.36672[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36672 - acc: 0.8484 -- iter: 0064/3680
[A[ATraining Step: 4833  | total loss: [1m[32m0.37219[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37219 - acc: 0.8480 -- iter: 0096/3680
[A[ATraining Step: 4834  | total loss: [1m[32m0.37923[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37923 - acc: 0.8413 -- iter: 0128/3680
[A[ATraining Step: 4835  | total loss: [1m[32m0.36551[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36551 - acc: 0.8509 -- iter: 0160/3680
[A[ATraining Step: 4836  | total loss: [1m[32m0.34598[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34598 - acc: 0.8627 -- iter: 0192/3680
[A[ATraining Step: 4837  | total loss: [1m[32m0.33255[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33255 - acc: 0.8733 -- iter: 0224/3680
[A[ATraining Step: 4838  | total loss: [1m[32m0.34287[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34287 - acc: 0.8641 -- iter: 0256/3680
[A[ATraining Step: 4839  | total loss: [1m[32m0.33362[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33362 - acc: 0.8714 -- iter: 0288/3680
[A[ATraining Step: 4840  | total loss: [1m[32m0.34313[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34313 - acc: 0.8655 -- iter: 0320/3680
[A[ATraining Step: 4841  | total loss: [1m[32m0.37055[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37055 - acc: 0.8540 -- iter: 0352/3680
[A[ATraining Step: 4842  | total loss: [1m[32m0.36883[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36883 - acc: 0.8520 -- iter: 0384/3680
[A[ATraining Step: 4843  | total loss: [1m[32m0.36883[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36883 - acc: 0.8520 -- iter: 0416/3680
[A[ATraining Step: 4844  | total loss: [1m[32m0.36036[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36036 - acc: 0.8543 -- iter: 0448/3680
[A[ATraining Step: 4845  | total loss: [1m[32m0.35669[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35669 - acc: 0.8533 -- iter: 0480/3680
[A[ATraining Step: 4846  | total loss: [1m[32m0.35705[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35705 - acc: 0.8487 -- iter: 0512/3680
[A[ATraining Step: 4847  | total loss: [1m[32m0.36670[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36670 - acc: 0.8487 -- iter: 0544/3680
[A[ATraining Step: 4848  | total loss: [1m[32m0.35718[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35718 - acc: 0.8544 -- iter: 0576/3680
[A[ATraining Step: 4849  | total loss: [1m[32m0.37757[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37757 - acc: 0.8534 -- iter: 0608/3680
[A[ATraining Step: 4850  | total loss: [1m[32m0.37230[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37230 - acc: 0.8555 -- iter: 0640/3680
[A[ATraining Step: 4851  | total loss: [1m[32m0.38363[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38363 - acc: 0.8450 -- iter: 0672/3680
[A[ATraining Step: 4852  | total loss: [1m[32m0.40031[0m[0m
[2K| Adam | epoch: 043 | loss: 0.40031 - acc: 0.8323 -- iter: 0704/3680
[A[ATraining Step: 4853  | total loss: [1m[32m0.40133[0m[0m
[2K| Adam | epoch: 043 | loss: 0.40133 - acc: 0.8241 -- iter: 0736/3680
[A[ATraining Step: 4854  | total loss: [1m[32m0.40885[0m[0m
[2K| Adam | epoch: 043 | loss: 0.40885 - acc: 0.8229 -- iter: 0768/3680
[A[ATraining Step: 4855  | total loss: [1m[32m0.39310[0m[0m
[2K| Adam | epoch: 043 | loss: 0.39310 - acc: 0.8313 -- iter: 0800/3680
[A[ATraining Step: 4856  | total loss: [1m[32m0.38371[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38371 - acc: 0.8294 -- iter: 0832/3680
[A[ATraining Step: 4857  | total loss: [1m[32m0.39587[0m[0m
[2K| Adam | epoch: 043 | loss: 0.39587 - acc: 0.8246 -- iter: 0864/3680
[A[ATraining Step: 4858  | total loss: [1m[32m0.39507[0m[0m
[2K| Adam | epoch: 043 | loss: 0.39507 - acc: 0.8203 -- iter: 0896/3680
[A[ATraining Step: 4859  | total loss: [1m[32m0.37663[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37663 - acc: 0.8320 -- iter: 0928/3680
[A[ATraining Step: 4860  | total loss: [1m[32m0.35847[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35847 - acc: 0.8425 -- iter: 0960/3680
[A[ATraining Step: 4861  | total loss: [1m[32m0.35061[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35061 - acc: 0.8458 -- iter: 0992/3680
[A[ATraining Step: 4862  | total loss: [1m[32m0.34479[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34479 - acc: 0.8487 -- iter: 1024/3680
[A[ATraining Step: 4863  | total loss: [1m[32m0.32821[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32821 - acc: 0.8576 -- iter: 1056/3680
[A[ATraining Step: 4864  | total loss: [1m[32m0.32425[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32425 - acc: 0.8624 -- iter: 1088/3680
[A[ATraining Step: 4865  | total loss: [1m[32m0.32034[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32034 - acc: 0.8637 -- iter: 1120/3680
[A[ATraining Step: 4866  | total loss: [1m[32m0.31920[0m[0m
[2K| Adam | epoch: 043 | loss: 0.31920 - acc: 0.8648 -- iter: 1152/3680
[A[ATraining Step: 4867  | total loss: [1m[32m0.32014[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32014 - acc: 0.8690 -- iter: 1184/3680
[A[ATraining Step: 4868  | total loss: [1m[32m0.30650[0m[0m
[2K| Adam | epoch: 043 | loss: 0.30650 - acc: 0.8790 -- iter: 1216/3680
[A[ATraining Step: 4869  | total loss: [1m[32m0.32654[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32654 - acc: 0.8754 -- iter: 1248/3680
[A[ATraining Step: 4870  | total loss: [1m[32m0.32254[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32254 - acc: 0.8785 -- iter: 1280/3680
[A[ATraining Step: 4871  | total loss: [1m[32m0.30986[0m[0m
[2K| Adam | epoch: 043 | loss: 0.30986 - acc: 0.8844 -- iter: 1312/3680
[A[ATraining Step: 4872  | total loss: [1m[32m0.31329[0m[0m
[2K| Adam | epoch: 043 | loss: 0.31329 - acc: 0.8835 -- iter: 1344/3680
[A[ATraining Step: 4873  | total loss: [1m[32m0.30449[0m[0m
[2K| Adam | epoch: 043 | loss: 0.30449 - acc: 0.8889 -- iter: 1376/3680
[A[ATraining Step: 4874  | total loss: [1m[32m0.30384[0m[0m
[2K| Adam | epoch: 043 | loss: 0.30384 - acc: 0.8906 -- iter: 1408/3680
[A[ATraining Step: 4875  | total loss: [1m[32m0.30378[0m[0m
[2K| Adam | epoch: 043 | loss: 0.30378 - acc: 0.8859 -- iter: 1440/3680
[A[ATraining Step: 4876  | total loss: [1m[32m0.31955[0m[0m
[2K| Adam | epoch: 043 | loss: 0.31955 - acc: 0.8786 -- iter: 1472/3680
[A[ATraining Step: 4877  | total loss: [1m[32m0.32825[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32825 - acc: 0.8688 -- iter: 1504/3680
[A[ATraining Step: 4878  | total loss: [1m[32m0.32600[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32600 - acc: 0.8726 -- iter: 1536/3680
[A[ATraining Step: 4879  | total loss: [1m[32m0.32121[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32121 - acc: 0.8760 -- iter: 1568/3680
[A[ATraining Step: 4880  | total loss: [1m[32m0.34180[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34180 - acc: 0.8634 -- iter: 1600/3680
[A[ATraining Step: 4881  | total loss: [1m[32m0.36116[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36116 - acc: 0.8458 -- iter: 1632/3680
[A[ATraining Step: 4882  | total loss: [1m[32m0.36231[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36231 - acc: 0.8424 -- iter: 1664/3680
[A[ATraining Step: 4883  | total loss: [1m[32m0.35568[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35568 - acc: 0.8488 -- iter: 1696/3680
[A[ATraining Step: 4884  | total loss: [1m[32m0.36306[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36306 - acc: 0.8452 -- iter: 1728/3680
[A[ATraining Step: 4885  | total loss: [1m[32m0.35408[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35408 - acc: 0.8482 -- iter: 1760/3680
[A[ATraining Step: 4886  | total loss: [1m[32m0.36398[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36398 - acc: 0.8415 -- iter: 1792/3680
[A[ATraining Step: 4887  | total loss: [1m[32m0.35856[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35856 - acc: 0.8480 -- iter: 1824/3680
[A[ATraining Step: 4888  | total loss: [1m[32m0.34712[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34712 - acc: 0.8507 -- iter: 1856/3680
[A[ATraining Step: 4889  | total loss: [1m[32m0.35049[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35049 - acc: 0.8468 -- iter: 1888/3680
[A[ATraining Step: 4890  | total loss: [1m[32m0.32989[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32989 - acc: 0.8622 -- iter: 1920/3680
[A[ATraining Step: 4891  | total loss: [1m[32m0.33131[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33131 - acc: 0.8666 -- iter: 1952/3680
[A[ATraining Step: 4892  | total loss: [1m[32m0.32746[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32746 - acc: 0.8612 -- iter: 1984/3680
[A[ATraining Step: 4893  | total loss: [1m[32m0.35244[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35244 - acc: 0.8532 -- iter: 2016/3680
[A[ATraining Step: 4894  | total loss: [1m[32m0.36700[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36700 - acc: 0.8491 -- iter: 2048/3680
[A[ATraining Step: 4895  | total loss: [1m[32m0.35650[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35650 - acc: 0.8579 -- iter: 2080/3680
[A[ATraining Step: 4896  | total loss: [1m[32m0.36852[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36852 - acc: 0.8472 -- iter: 2112/3680
[A[ATraining Step: 4897  | total loss: [1m[32m0.36079[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36079 - acc: 0.8499 -- iter: 2144/3680
[A[ATraining Step: 4898  | total loss: [1m[32m0.36715[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36715 - acc: 0.8378 -- iter: 2176/3680
[A[ATraining Step: 4899  | total loss: [1m[32m0.37686[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37686 - acc: 0.8378 -- iter: 2208/3680
[A[ATraining Step: 4900  | total loss: [1m[32m0.36366[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36366 - acc: 0.8415 | val_loss: 0.32993 - val_acc: 0.8784 -- iter: 2240/3680
[A[ATraining Step: 4900  | total loss: [1m[32m0.36366[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36366 - acc: 0.8415 | val_loss: 0.32993 - val_acc: 0.8784 -- iter: 2240/3680
--
Training Step: 4901  | total loss: [1m[32m0.37005[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37005 - acc: 0.8386 -- iter: 2272/3680
[A[ATraining Step: 4902  | total loss: [1m[32m0.37550[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37550 - acc: 0.8391 -- iter: 2304/3680
[A[ATraining Step: 4903  | total loss: [1m[32m0.37169[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37169 - acc: 0.8396 -- iter: 2336/3680
[A[ATraining Step: 4904  | total loss: [1m[32m0.35740[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35740 - acc: 0.8494 -- iter: 2368/3680
[A[ATraining Step: 4905  | total loss: [1m[32m0.36368[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36368 - acc: 0.8488 -- iter: 2400/3680
[A[ATraining Step: 4906  | total loss: [1m[32m0.37417[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37417 - acc: 0.8483 -- iter: 2432/3680
[A[ATraining Step: 4907  | total loss: [1m[32m0.36415[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36415 - acc: 0.8510 -- iter: 2464/3680
[A[ATraining Step: 4908  | total loss: [1m[32m0.37489[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37489 - acc: 0.8471 -- iter: 2496/3680
[A[ATraining Step: 4909  | total loss: [1m[32m0.38349[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38349 - acc: 0.8343 -- iter: 2528/3680
[A[ATraining Step: 4910  | total loss: [1m[32m0.39731[0m[0m
[2K| Adam | epoch: 043 | loss: 0.39731 - acc: 0.8259 -- iter: 2560/3680
[A[ATraining Step: 4911  | total loss: [1m[32m0.38675[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38675 - acc: 0.8370 -- iter: 2592/3680
[A[ATraining Step: 4912  | total loss: [1m[32m0.38273[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38273 - acc: 0.8408 -- iter: 2624/3680
[A[ATraining Step: 4913  | total loss: [1m[32m0.38297[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38297 - acc: 0.8411 -- iter: 2656/3680
[A[ATraining Step: 4914  | total loss: [1m[32m0.36922[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36922 - acc: 0.8508 -- iter: 2688/3680
[A[ATraining Step: 4915  | total loss: [1m[32m0.37933[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37933 - acc: 0.8407 -- iter: 2720/3680
[A[ATraining Step: 4916  | total loss: [1m[32m0.37516[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37516 - acc: 0.8441 -- iter: 2752/3680
[A[ATraining Step: 4917  | total loss: [1m[32m0.38322[0m[0m
[2K| Adam | epoch: 043 | loss: 0.38322 - acc: 0.8410 -- iter: 2784/3680
[A[ATraining Step: 4918  | total loss: [1m[32m0.37627[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37627 - acc: 0.8330 -- iter: 2816/3680
[A[ATraining Step: 4919  | total loss: [1m[32m0.37627[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37627 - acc: 0.8330 -- iter: 2848/3680
[A[ATraining Step: 4920  | total loss: [1m[32m0.36415[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36415 - acc: 0.8435 -- iter: 2880/3680
[A[ATraining Step: 4921  | total loss: [1m[32m0.35168[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35168 - acc: 0.8466 -- iter: 2912/3680
[A[ATraining Step: 4922  | total loss: [1m[32m0.36685[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36685 - acc: 0.8339 -- iter: 2944/3680
[A[ATraining Step: 4923  | total loss: [1m[32m0.37777[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37777 - acc: 0.8255 -- iter: 2976/3680
[A[ATraining Step: 4924  | total loss: [1m[32m0.37449[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37449 - acc: 0.8408 -- iter: 3008/3680
[A[ATraining Step: 4925  | total loss: [1m[32m0.37449[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37449 - acc: 0.8408 -- iter: 3040/3680
[A[ATraining Step: 4926  | total loss: [1m[32m0.37136[0m[0m
[2K| Adam | epoch: 043 | loss: 0.37136 - acc: 0.8442 -- iter: 3072/3680
[A[ATraining Step: 4927  | total loss: [1m[32m0.36978[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36978 - acc: 0.8473 -- iter: 3104/3680
[A[ATraining Step: 4928  | total loss: [1m[32m0.36807[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36807 - acc: 0.8532 -- iter: 3136/3680
[A[ATraining Step: 4929  | total loss: [1m[32m0.36808[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36808 - acc: 0.8585 -- iter: 3168/3680
[A[ATraining Step: 4930  | total loss: [1m[32m0.36564[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36564 - acc: 0.8602 -- iter: 3200/3680
[A[ATraining Step: 4931  | total loss: [1m[32m0.35968[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35968 - acc: 0.8679 -- iter: 3232/3680
[A[ATraining Step: 4932  | total loss: [1m[32m0.34797[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34797 - acc: 0.8780 -- iter: 3264/3680
[A[ATraining Step: 4933  | total loss: [1m[32m0.34935[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34935 - acc: 0.8683 -- iter: 3296/3680
[A[ATraining Step: 4934  | total loss: [1m[32m0.33685[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33685 - acc: 0.8721 -- iter: 3328/3680
[A[ATraining Step: 4935  | total loss: [1m[32m0.32956[0m[0m
[2K| Adam | epoch: 043 | loss: 0.32956 - acc: 0.8724 -- iter: 3360/3680
[A[ATraining Step: 4936  | total loss: [1m[32m0.33068[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33068 - acc: 0.8633 -- iter: 3392/3680
[A[ATraining Step: 4937  | total loss: [1m[32m0.35057[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35057 - acc: 0.8519 -- iter: 3424/3680
[A[ATraining Step: 4938  | total loss: [1m[32m0.35394[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35394 - acc: 0.8511 -- iter: 3456/3680
[A[ATraining Step: 4939  | total loss: [1m[32m0.35364[0m[0m
[2K| Adam | epoch: 043 | loss: 0.35364 - acc: 0.8535 -- iter: 3488/3680
[A[ATraining Step: 4940  | total loss: [1m[32m0.34638[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34638 - acc: 0.8525 -- iter: 3520/3680
[A[ATraining Step: 4941  | total loss: [1m[32m0.33861[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33861 - acc: 0.8610 -- iter: 3552/3680
[A[ATraining Step: 4942  | total loss: [1m[32m0.33185[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33185 - acc: 0.8656 -- iter: 3584/3680
[A[ATraining Step: 4943  | total loss: [1m[32m0.33953[0m[0m
[2K| Adam | epoch: 043 | loss: 0.33953 - acc: 0.8603 -- iter: 3616/3680
[A[ATraining Step: 4944  | total loss: [1m[32m0.34364[0m[0m
[2K| Adam | epoch: 043 | loss: 0.34364 - acc: 0.8617 -- iter: 3648/3680
[A[ATraining Step: 4945  | total loss: [1m[32m0.36155[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36155 - acc: 0.8568 | val_loss: 0.32859 - val_acc: 0.8817 -- iter: 3680/3680
[A[ATraining Step: 4945  | total loss: [1m[32m0.36155[0m[0m
[2K| Adam | epoch: 043 | loss: 0.36155 - acc: 0.8568 | val_loss: 0.32859 - val_acc: 0.8817 -- iter: 3680/3680
--
Training Step: 4946  | total loss: [1m[32m0.34806[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34806 - acc: 0.8680 -- iter: 0032/3680
[A[ATraining Step: 4947  | total loss: [1m[32m0.34520[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34520 - acc: 0.8656 -- iter: 0064/3680
[A[ATraining Step: 4948  | total loss: [1m[32m0.33735[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33735 - acc: 0.8696 -- iter: 0096/3680
[A[ATraining Step: 4949  | total loss: [1m[32m0.33482[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33482 - acc: 0.8671 -- iter: 0128/3680
[A[ATraining Step: 4950  | total loss: [1m[32m0.33265[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33265 - acc: 0.8647 -- iter: 0160/3680
[A[ATraining Step: 4951  | total loss: [1m[32m0.34999[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34999 - acc: 0.8501 -- iter: 0192/3680
[A[ATraining Step: 4952  | total loss: [1m[32m0.34695[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34695 - acc: 0.8520 -- iter: 0224/3680
[A[ATraining Step: 4953  | total loss: [1m[32m0.34002[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34002 - acc: 0.8520 -- iter: 0256/3680
[A[ATraining Step: 4954  | total loss: [1m[32m0.35641[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35641 - acc: 0.8418 -- iter: 0288/3680
[A[ATraining Step: 4955  | total loss: [1m[32m0.35930[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35930 - acc: 0.8420 -- iter: 0320/3680
[A[ATraining Step: 4956  | total loss: [1m[32m0.35999[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35999 - acc: 0.8391 -- iter: 0352/3680
[A[ATraining Step: 4957  | total loss: [1m[32m0.35744[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35744 - acc: 0.8427 -- iter: 0384/3680
[A[ATraining Step: 4958  | total loss: [1m[32m0.34781[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34781 - acc: 0.8490 -- iter: 0416/3680
[A[ATraining Step: 4959  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34347 - acc: 0.8516 -- iter: 0448/3680
[A[ATraining Step: 4960  | total loss: [1m[32m0.33807[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33807 - acc: 0.8571 -- iter: 0480/3680
[A[ATraining Step: 4961  | total loss: [1m[32m0.33072[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33072 - acc: 0.8558 -- iter: 0512/3680
[A[ATraining Step: 4962  | total loss: [1m[32m0.32429[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32429 - acc: 0.8639 -- iter: 0544/3680
[A[ATraining Step: 4963  | total loss: [1m[32m0.32560[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32560 - acc: 0.8650 -- iter: 0576/3680
[A[ATraining Step: 4964  | total loss: [1m[32m0.32244[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32244 - acc: 0.8629 -- iter: 0608/3680
[A[ATraining Step: 4965  | total loss: [1m[32m0.33460[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33460 - acc: 0.8641 -- iter: 0640/3680
[A[ATraining Step: 4966  | total loss: [1m[32m0.34520[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34520 - acc: 0.8527 -- iter: 0672/3680
[A[ATraining Step: 4967  | total loss: [1m[32m0.37146[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37146 - acc: 0.8487 -- iter: 0704/3680
[A[ATraining Step: 4968  | total loss: [1m[32m0.37034[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37034 - acc: 0.8482 -- iter: 0736/3680
[A[ATraining Step: 4969  | total loss: [1m[32m0.36400[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36400 - acc: 0.8509 -- iter: 0768/3680
[A[ATraining Step: 4970  | total loss: [1m[32m0.35565[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35565 - acc: 0.8564 -- iter: 0800/3680
[A[ATraining Step: 4971  | total loss: [1m[32m0.36815[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36815 - acc: 0.8551 -- iter: 0832/3680
[A[ATraining Step: 4972  | total loss: [1m[32m0.35765[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35765 - acc: 0.8603 -- iter: 0864/3680
[A[ATraining Step: 4973  | total loss: [1m[32m0.36115[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36115 - acc: 0.8586 -- iter: 0896/3680
[A[ATraining Step: 4974  | total loss: [1m[32m0.36467[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36467 - acc: 0.8571 -- iter: 0928/3680
[A[ATraining Step: 4975  | total loss: [1m[32m0.35901[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35901 - acc: 0.8589 -- iter: 0960/3680
[A[ATraining Step: 4976  | total loss: [1m[32m0.35006[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35006 - acc: 0.8636 -- iter: 0992/3680
[A[ATraining Step: 4977  | total loss: [1m[32m0.33488[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33488 - acc: 0.8742 -- iter: 1024/3680
[A[ATraining Step: 4978  | total loss: [1m[32m0.33528[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33528 - acc: 0.8711 -- iter: 1056/3680
[A[ATraining Step: 4979  | total loss: [1m[32m0.33798[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33798 - acc: 0.8684 -- iter: 1088/3680
[A[ATraining Step: 4980  | total loss: [1m[32m0.36586[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36586 - acc: 0.8503 -- iter: 1120/3680
[A[ATraining Step: 4981  | total loss: [1m[32m0.36955[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36955 - acc: 0.8559 -- iter: 1152/3680
[A[ATraining Step: 4982  | total loss: [1m[32m0.38134[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38134 - acc: 0.8515 -- iter: 1184/3680
[A[ATraining Step: 4983  | total loss: [1m[32m0.37972[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37972 - acc: 0.8539 -- iter: 1216/3680
[A[ATraining Step: 4984  | total loss: [1m[32m0.38644[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38644 - acc: 0.8435 -- iter: 1248/3680
[A[ATraining Step: 4985  | total loss: [1m[32m0.38365[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38365 - acc: 0.8435 -- iter: 1280/3680
[A[ATraining Step: 4986  | total loss: [1m[32m0.38054[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38054 - acc: 0.8435 -- iter: 1312/3680
[A[ATraining Step: 4987  | total loss: [1m[32m0.38294[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38294 - acc: 0.8373 -- iter: 1344/3680
[A[ATraining Step: 4988  | total loss: [1m[32m0.38395[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38395 - acc: 0.8348 -- iter: 1376/3680
[A[ATraining Step: 4989  | total loss: [1m[32m0.39625[0m[0m
[2K| Adam | epoch: 044 | loss: 0.39625 - acc: 0.8201 -- iter: 1408/3680
[A[ATraining Step: 4990  | total loss: [1m[32m0.39555[0m[0m
[2K| Adam | epoch: 044 | loss: 0.39555 - acc: 0.8193 -- iter: 1440/3680
[A[ATraining Step: 4991  | total loss: [1m[32m0.38562[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38562 - acc: 0.8280 -- iter: 1472/3680
[A[ATraining Step: 4992  | total loss: [1m[32m0.39293[0m[0m
[2K| Adam | epoch: 044 | loss: 0.39293 - acc: 0.8265 -- iter: 1504/3680
[A[ATraining Step: 4993  | total loss: [1m[32m0.40135[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40135 - acc: 0.8313 -- iter: 1536/3680
[A[ATraining Step: 4994  | total loss: [1m[32m0.40331[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40331 - acc: 0.8294 -- iter: 1568/3680
[A[ATraining Step: 4995  | total loss: [1m[32m0.40793[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40793 - acc: 0.8246 -- iter: 1600/3680
[A[ATraining Step: 4996  | total loss: [1m[32m0.41651[0m[0m
[2K| Adam | epoch: 044 | loss: 0.41651 - acc: 0.8234 -- iter: 1632/3680
[A[ATraining Step: 4997  | total loss: [1m[32m0.41206[0m[0m
[2K| Adam | epoch: 044 | loss: 0.41206 - acc: 0.8286 -- iter: 1664/3680
[A[ATraining Step: 4998  | total loss: [1m[32m0.40656[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40656 - acc: 0.8270 -- iter: 1696/3680
[A[ATraining Step: 4999  | total loss: [1m[32m0.40705[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40705 - acc: 0.8286 -- iter: 1728/3680
[A[ATraining Step: 5000  | total loss: [1m[32m0.40735[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40735 - acc: 0.8239 | val_loss: 0.32738 - val_acc: 0.8817 -- iter: 1760/3680
[A[ATraining Step: 5000  | total loss: [1m[32m0.40735[0m[0m
[2K| Adam | epoch: 044 | loss: 0.40735 - acc: 0.8239 | val_loss: 0.32738 - val_acc: 0.8817 -- iter: 1760/3680
--
Training Step: 5001  | total loss: [1m[32m0.38884[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38884 - acc: 0.8321 -- iter: 1792/3680
[A[ATraining Step: 5002  | total loss: [1m[32m0.38961[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38961 - acc: 0.8364 -- iter: 1824/3680
[A[ATraining Step: 5003  | total loss: [1m[32m0.37945[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37945 - acc: 0.8434 -- iter: 1856/3680
[A[ATraining Step: 5004  | total loss: [1m[32m0.36863[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36863 - acc: 0.8528 -- iter: 1888/3680
[A[ATraining Step: 5005  | total loss: [1m[32m0.36473[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36473 - acc: 0.8550 -- iter: 1920/3680
[A[ATraining Step: 5006  | total loss: [1m[32m0.36706[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36706 - acc: 0.8623 -- iter: 1952/3680
[A[ATraining Step: 5007  | total loss: [1m[32m0.35483[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35483 - acc: 0.8635 -- iter: 1984/3680
[A[ATraining Step: 5008  | total loss: [1m[32m0.35729[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35729 - acc: 0.8635 -- iter: 2016/3680
[A[ATraining Step: 5009  | total loss: [1m[32m0.35379[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35379 - acc: 0.8647 -- iter: 2048/3680
[A[ATraining Step: 5010  | total loss: [1m[32m0.35513[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35513 - acc: 0.8657 -- iter: 2080/3680
[A[ATraining Step: 5011  | total loss: [1m[32m0.35476[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35476 - acc: 0.8635 -- iter: 2112/3680
[A[ATraining Step: 5012  | total loss: [1m[32m0.35470[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35470 - acc: 0.8615 -- iter: 2144/3680
[A[ATraining Step: 5013  | total loss: [1m[32m0.36699[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36699 - acc: 0.8535 -- iter: 2176/3680
[A[ATraining Step: 5014  | total loss: [1m[32m0.37869[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37869 - acc: 0.8463 -- iter: 2208/3680
[A[ATraining Step: 5015  | total loss: [1m[32m0.38225[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38225 - acc: 0.8492 -- iter: 2240/3680
[A[ATraining Step: 5016  | total loss: [1m[32m0.37433[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37433 - acc: 0.8549 -- iter: 2272/3680
[A[ATraining Step: 5017  | total loss: [1m[32m0.35771[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35771 - acc: 0.8663 -- iter: 2304/3680
[A[ATraining Step: 5018  | total loss: [1m[32m0.34481[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34481 - acc: 0.8703 -- iter: 2336/3680
[A[ATraining Step: 5019  | total loss: [1m[32m0.36099[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36099 - acc: 0.8551 -- iter: 2368/3680
[A[ATraining Step: 5020  | total loss: [1m[32m0.36381[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36381 - acc: 0.8540 -- iter: 2400/3680
[A[ATraining Step: 5021  | total loss: [1m[32m0.37495[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37495 - acc: 0.8529 -- iter: 2432/3680
[A[ATraining Step: 5022  | total loss: [1m[32m0.39665[0m[0m
[2K| Adam | epoch: 044 | loss: 0.39665 - acc: 0.8427 -- iter: 2464/3680
[A[ATraining Step: 5023  | total loss: [1m[32m0.39481[0m[0m
[2K| Adam | epoch: 044 | loss: 0.39481 - acc: 0.8521 -- iter: 2496/3680
[A[ATraining Step: 5024  | total loss: [1m[32m0.38425[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38425 - acc: 0.8575 -- iter: 2528/3680
[A[ATraining Step: 5025  | total loss: [1m[32m0.37263[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37263 - acc: 0.8624 -- iter: 2560/3680
[A[ATraining Step: 5026  | total loss: [1m[32m0.36123[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36123 - acc: 0.8668 -- iter: 2592/3680
[A[ATraining Step: 5027  | total loss: [1m[32m0.36097[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36097 - acc: 0.8676 -- iter: 2624/3680
[A[ATraining Step: 5028  | total loss: [1m[32m0.37364[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37364 - acc: 0.8652 -- iter: 2656/3680
[A[ATraining Step: 5029  | total loss: [1m[32m0.36150[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36150 - acc: 0.8693 -- iter: 2688/3680
[A[ATraining Step: 5030  | total loss: [1m[32m0.35808[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35808 - acc: 0.8699 -- iter: 2720/3680
[A[ATraining Step: 5031  | total loss: [1m[32m0.37367[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37367 - acc: 0.8642 -- iter: 2752/3680
[A[ATraining Step: 5032  | total loss: [1m[32m0.38392[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38392 - acc: 0.8559 -- iter: 2784/3680
[A[ATraining Step: 5033  | total loss: [1m[32m0.38860[0m[0m
[2K| Adam | epoch: 044 | loss: 0.38860 - acc: 0.8515 -- iter: 2816/3680
[A[ATraining Step: 5034  | total loss: [1m[32m0.37004[0m[0m
[2K| Adam | epoch: 044 | loss: 0.37004 - acc: 0.8633 -- iter: 2848/3680
[A[ATraining Step: 5035  | total loss: [1m[32m0.35731[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35731 - acc: 0.8676 -- iter: 2880/3680
[A[ATraining Step: 5036  | total loss: [1m[32m0.36199[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36199 - acc: 0.8620 -- iter: 2912/3680
[A[ATraining Step: 5037  | total loss: [1m[32m0.36178[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36178 - acc: 0.8571 -- iter: 2944/3680
[A[ATraining Step: 5038  | total loss: [1m[32m0.36880[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36880 - acc: 0.8558 -- iter: 2976/3680
[A[ATraining Step: 5039  | total loss: [1m[32m0.36429[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36429 - acc: 0.8546 -- iter: 3008/3680
[A[ATraining Step: 5040  | total loss: [1m[32m0.36064[0m[0m
[2K| Adam | epoch: 044 | loss: 0.36064 - acc: 0.8597 -- iter: 3040/3680
[A[ATraining Step: 5041  | total loss: [1m[32m0.35247[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35247 - acc: 0.8644 -- iter: 3072/3680
[A[ATraining Step: 5042  | total loss: [1m[32m0.33938[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33938 - acc: 0.8686 -- iter: 3104/3680
[A[ATraining Step: 5043  | total loss: [1m[32m0.33388[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33388 - acc: 0.8723 -- iter: 3136/3680
[A[ATraining Step: 5044  | total loss: [1m[32m0.33297[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33297 - acc: 0.8664 -- iter: 3168/3680
[A[ATraining Step: 5045  | total loss: [1m[32m0.33497[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33497 - acc: 0.8672 -- iter: 3200/3680
[A[ATraining Step: 5046  | total loss: [1m[32m0.33711[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33711 - acc: 0.8711 -- iter: 3232/3680
[A[ATraining Step: 5047  | total loss: [1m[32m0.32743[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32743 - acc: 0.8778 -- iter: 3264/3680
[A[ATraining Step: 5048  | total loss: [1m[32m0.32214[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32214 - acc: 0.8806 -- iter: 3296/3680
[A[ATraining Step: 5049  | total loss: [1m[32m0.31970[0m[0m
[2K| Adam | epoch: 044 | loss: 0.31970 - acc: 0.8894 -- iter: 3328/3680
[A[ATraining Step: 5050  | total loss: [1m[32m0.31350[0m[0m
[2K| Adam | epoch: 044 | loss: 0.31350 - acc: 0.8942 -- iter: 3360/3680
[A[ATraining Step: 5051  | total loss: [1m[32m0.31851[0m[0m
[2K| Adam | epoch: 044 | loss: 0.31851 - acc: 0.8923 -- iter: 3392/3680
[A[ATraining Step: 5052  | total loss: [1m[32m0.32778[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32778 - acc: 0.8875 -- iter: 3424/3680
[A[ATraining Step: 5053  | total loss: [1m[32m0.32800[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32800 - acc: 0.8893 -- iter: 3456/3680
[A[ATraining Step: 5054  | total loss: [1m[32m0.32093[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32093 - acc: 0.9004 -- iter: 3488/3680
[A[ATraining Step: 5055  | total loss: [1m[32m0.32280[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32280 - acc: 0.8979 -- iter: 3520/3680
[A[ATraining Step: 5056  | total loss: [1m[32m0.32457[0m[0m
[2K| Adam | epoch: 044 | loss: 0.32457 - acc: 0.8924 -- iter: 3552/3680
[A[ATraining Step: 5057  | total loss: [1m[32m0.34463[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34463 - acc: 0.8813 -- iter: 3584/3680
[A[ATraining Step: 5058  | total loss: [1m[32m0.34023[0m[0m
[2K| Adam | epoch: 044 | loss: 0.34023 - acc: 0.8869 -- iter: 3616/3680
[A[ATraining Step: 5059  | total loss: [1m[32m0.33785[0m[0m
[2K| Adam | epoch: 044 | loss: 0.33785 - acc: 0.8889 -- iter: 3648/3680
[A[ATraining Step: 5060  | total loss: [1m[32m0.35248[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35248 - acc: 0.8750 | val_loss: 0.33217 - val_acc: 0.8849 -- iter: 3680/3680
[A[ATraining Step: 5060  | total loss: [1m[32m0.35248[0m[0m
[2K| Adam | epoch: 044 | loss: 0.35248 - acc: 0.8750 | val_loss: 0.33217 - val_acc: 0.8849 -- iter: 3680/3680
--
Training Step: 5061  | total loss: [1m[32m0.35267[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35267 - acc: 0.8719 -- iter: 0032/3680
[A[ATraining Step: 5062  | total loss: [1m[32m0.33499[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33499 - acc: 0.8847 -- iter: 0064/3680
[A[ATraining Step: 5063  | total loss: [1m[32m0.32614[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32614 - acc: 0.8868 -- iter: 0096/3680
[A[ATraining Step: 5064  | total loss: [1m[32m0.32820[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32820 - acc: 0.8825 -- iter: 0128/3680
[A[ATraining Step: 5065  | total loss: [1m[32m0.31647[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31647 - acc: 0.8880 -- iter: 0160/3680
[A[ATraining Step: 5066  | total loss: [1m[32m0.31733[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31733 - acc: 0.8805 -- iter: 0192/3680
[A[ATraining Step: 5067  | total loss: [1m[32m0.31796[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31796 - acc: 0.8830 -- iter: 0224/3680
[A[ATraining Step: 5068  | total loss: [1m[32m0.32197[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32197 - acc: 0.8791 -- iter: 0256/3680
[A[ATraining Step: 5069  | total loss: [1m[32m0.32217[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32217 - acc: 0.8756 -- iter: 0288/3680
[A[ATraining Step: 5070  | total loss: [1m[32m0.32107[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32107 - acc: 0.8755 -- iter: 0320/3680
[A[ATraining Step: 5071  | total loss: [1m[32m0.32141[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32141 - acc: 0.8661 -- iter: 0352/3680
[A[ATraining Step: 5072  | total loss: [1m[32m0.31146[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31146 - acc: 0.8732 -- iter: 0384/3680
[A[ATraining Step: 5073  | total loss: [1m[32m0.31136[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31136 - acc: 0.8672 -- iter: 0416/3680
[A[ATraining Step: 5074  | total loss: [1m[32m0.31264[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31264 - acc: 0.8711 -- iter: 0448/3680
[A[ATraining Step: 5075  | total loss: [1m[32m0.31052[0m[0m
[2K| Adam | epoch: 045 | loss: 0.31052 - acc: 0.8715 -- iter: 0480/3680
[A[ATraining Step: 5076  | total loss: [1m[32m0.30255[0m[0m
[2K| Adam | epoch: 045 | loss: 0.30255 - acc: 0.8718 -- iter: 0512/3680
[A[ATraining Step: 5077  | total loss: [1m[32m0.30521[0m[0m
[2K| Adam | epoch: 045 | loss: 0.30521 - acc: 0.8659 -- iter: 0544/3680
[A[ATraining Step: 5078  | total loss: [1m[32m0.32090[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32090 - acc: 0.8543 -- iter: 0576/3680
[A[ATraining Step: 5079  | total loss: [1m[32m0.32526[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32526 - acc: 0.8564 -- iter: 0608/3680
[A[ATraining Step: 5080  | total loss: [1m[32m0.33547[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33547 - acc: 0.8582 -- iter: 0640/3680
[A[ATraining Step: 5081  | total loss: [1m[32m0.34935[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34935 - acc: 0.8443 -- iter: 0672/3680
[A[ATraining Step: 5082  | total loss: [1m[32m0.34608[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34608 - acc: 0.8536 -- iter: 0704/3680
[A[ATraining Step: 5083  | total loss: [1m[32m0.33598[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33598 - acc: 0.8620 -- iter: 0736/3680
[A[ATraining Step: 5084  | total loss: [1m[32m0.34230[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34230 - acc: 0.8570 -- iter: 0768/3680
[A[ATraining Step: 5085  | total loss: [1m[32m0.33136[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33136 - acc: 0.8651 -- iter: 0800/3680
[A[ATraining Step: 5086  | total loss: [1m[32m0.32734[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32734 - acc: 0.8661 -- iter: 0832/3680
[A[ATraining Step: 5087  | total loss: [1m[32m0.32784[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32784 - acc: 0.8638 -- iter: 0864/3680
[A[ATraining Step: 5088  | total loss: [1m[32m0.34743[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34743 - acc: 0.8556 -- iter: 0896/3680
[A[ATraining Step: 5089  | total loss: [1m[32m0.33820[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33820 - acc: 0.8607 -- iter: 0928/3680
[A[ATraining Step: 5090  | total loss: [1m[32m0.35650[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35650 - acc: 0.8465 -- iter: 0960/3680
[A[ATraining Step: 5091  | total loss: [1m[32m0.35664[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35664 - acc: 0.8493 -- iter: 0992/3680
[A[ATraining Step: 5092  | total loss: [1m[32m0.35753[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35753 - acc: 0.8488 -- iter: 1024/3680
[A[ATraining Step: 5093  | total loss: [1m[32m0.34968[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34968 - acc: 0.8545 -- iter: 1056/3680
[A[ATraining Step: 5094  | total loss: [1m[32m0.34490[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34490 - acc: 0.8566 -- iter: 1088/3680
[A[ATraining Step: 5095  | total loss: [1m[32m0.35836[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35836 - acc: 0.8553 -- iter: 1120/3680
[A[ATraining Step: 5096  | total loss: [1m[32m0.36103[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36103 - acc: 0.8541 -- iter: 1152/3680
[A[ATraining Step: 5097  | total loss: [1m[32m0.34360[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34360 - acc: 0.8656 -- iter: 1184/3680
[A[ATraining Step: 5098  | total loss: [1m[32m0.33253[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33253 - acc: 0.8759 -- iter: 1216/3680
[A[ATraining Step: 5099  | total loss: [1m[32m0.33431[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33431 - acc: 0.8727 -- iter: 1248/3680
[A[ATraining Step: 5100  | total loss: [1m[32m0.35485[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35485 - acc: 0.8604 | val_loss: 0.31820 - val_acc: 0.8827 -- iter: 1280/3680
[A[ATraining Step: 5100  | total loss: [1m[32m0.35485[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35485 - acc: 0.8604 | val_loss: 0.31820 - val_acc: 0.8827 -- iter: 1280/3680
--
Training Step: 5101  | total loss: [1m[32m0.35068[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35068 - acc: 0.8681 -- iter: 1312/3680
[A[ATraining Step: 5102  | total loss: [1m[32m0.35482[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35482 - acc: 0.8697 -- iter: 1344/3680
[A[ATraining Step: 5103  | total loss: [1m[32m0.35106[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35106 - acc: 0.8697 -- iter: 1376/3680
[A[ATraining Step: 5104  | total loss: [1m[32m0.35295[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35295 - acc: 0.8703 -- iter: 1408/3680
[A[ATraining Step: 5105  | total loss: [1m[32m0.35805[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35805 - acc: 0.8707 -- iter: 1440/3680
[A[ATraining Step: 5106  | total loss: [1m[32m0.37091[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37091 - acc: 0.8649 -- iter: 1472/3680
[A[ATraining Step: 5107  | total loss: [1m[32m0.35555[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35555 - acc: 0.8722 -- iter: 1504/3680
[A[ATraining Step: 5108  | total loss: [1m[32m0.37775[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37775 - acc: 0.8693 -- iter: 1536/3680
[A[ATraining Step: 5109  | total loss: [1m[32m0.37422[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37422 - acc: 0.8637 -- iter: 1568/3680
[A[ATraining Step: 5110  | total loss: [1m[32m0.36868[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36868 - acc: 0.8648 -- iter: 1600/3680
[A[ATraining Step: 5111  | total loss: [1m[32m0.36071[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36071 - acc: 0.8658 -- iter: 1632/3680
[A[ATraining Step: 5112  | total loss: [1m[32m0.38279[0m[0m
[2K| Adam | epoch: 045 | loss: 0.38279 - acc: 0.8511 -- iter: 1664/3680
[A[ATraining Step: 5113  | total loss: [1m[32m0.37737[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37737 - acc: 0.8566 -- iter: 1696/3680
[A[ATraining Step: 5114  | total loss: [1m[32m0.35706[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35706 - acc: 0.8678 -- iter: 1728/3680
[A[ATraining Step: 5115  | total loss: [1m[32m0.34543[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34543 - acc: 0.8779 -- iter: 1760/3680
[A[ATraining Step: 5116  | total loss: [1m[32m0.34839[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34839 - acc: 0.8745 -- iter: 1792/3680
[A[ATraining Step: 5117  | total loss: [1m[32m0.33700[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33700 - acc: 0.8777 -- iter: 1824/3680
[A[ATraining Step: 5118  | total loss: [1m[32m0.34009[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34009 - acc: 0.8712 -- iter: 1856/3680
[A[ATraining Step: 5119  | total loss: [1m[32m0.32993[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32993 - acc: 0.8747 -- iter: 1888/3680
[A[ATraining Step: 5120  | total loss: [1m[32m0.32816[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32816 - acc: 0.8807 -- iter: 1920/3680
[A[ATraining Step: 5121  | total loss: [1m[32m0.32816[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32816 - acc: 0.8807 -- iter: 1952/3680
[A[ATraining Step: 5122  | total loss: [1m[32m0.32454[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32454 - acc: 0.8770 -- iter: 1984/3680
[A[ATraining Step: 5123  | total loss: [1m[32m0.33829[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33829 - acc: 0.8643 -- iter: 2016/3680
[A[ATraining Step: 5124  | total loss: [1m[32m0.33252[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33252 - acc: 0.8685 -- iter: 2048/3680
[A[ATraining Step: 5125  | total loss: [1m[32m0.35249[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35249 - acc: 0.8598 -- iter: 2080/3680
[A[ATraining Step: 5126  | total loss: [1m[32m0.34371[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34371 - acc: 0.8644 -- iter: 2112/3680
[A[ATraining Step: 5127  | total loss: [1m[32m0.35621[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35621 - acc: 0.8498 -- iter: 2144/3680
[A[ATraining Step: 5128  | total loss: [1m[32m0.35435[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35435 - acc: 0.8524 -- iter: 2176/3680
[A[ATraining Step: 5129  | total loss: [1m[32m0.35461[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35461 - acc: 0.8515 -- iter: 2208/3680
[A[ATraining Step: 5130  | total loss: [1m[32m0.34295[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34295 - acc: 0.8538 -- iter: 2240/3680
[A[ATraining Step: 5131  | total loss: [1m[32m0.33165[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33165 - acc: 0.8591 -- iter: 2272/3680
[A[ATraining Step: 5132  | total loss: [1m[32m0.32254[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32254 - acc: 0.8638 -- iter: 2304/3680
[A[ATraining Step: 5133  | total loss: [1m[32m0.32285[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32285 - acc: 0.8712 -- iter: 2336/3680
[A[ATraining Step: 5134  | total loss: [1m[32m0.32561[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32561 - acc: 0.8716 -- iter: 2368/3680
[A[ATraining Step: 5135  | total loss: [1m[32m0.32145[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32145 - acc: 0.8781 -- iter: 2400/3680
[A[ATraining Step: 5136  | total loss: [1m[32m0.32941[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32941 - acc: 0.8716 -- iter: 2432/3680
[A[ATraining Step: 5137  | total loss: [1m[32m0.32916[0m[0m
[2K| Adam | epoch: 045 | loss: 0.32916 - acc: 0.8719 -- iter: 2464/3680
[A[ATraining Step: 5138  | total loss: [1m[32m0.33585[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33585 - acc: 0.8722 -- iter: 2496/3680
[A[ATraining Step: 5139  | total loss: [1m[32m0.33420[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33420 - acc: 0.8725 -- iter: 2528/3680
[A[ATraining Step: 5140  | total loss: [1m[32m0.33355[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33355 - acc: 0.8696 -- iter: 2560/3680
[A[ATraining Step: 5141  | total loss: [1m[32m0.35195[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35195 - acc: 0.8545 -- iter: 2592/3680
[A[ATraining Step: 5142  | total loss: [1m[32m0.35187[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35187 - acc: 0.8503 -- iter: 2624/3680
[A[ATraining Step: 5143  | total loss: [1m[32m0.36031[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36031 - acc: 0.8466 -- iter: 2656/3680
[A[ATraining Step: 5144  | total loss: [1m[32m0.37558[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37558 - acc: 0.8307 -- iter: 2688/3680
[A[ATraining Step: 5145  | total loss: [1m[32m0.35850[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35850 - acc: 0.8382 -- iter: 2720/3680
[A[ATraining Step: 5146  | total loss: [1m[32m0.35538[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35538 - acc: 0.8513 -- iter: 2752/3680
[A[ATraining Step: 5147  | total loss: [1m[32m0.36691[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36691 - acc: 0.8474 -- iter: 2784/3680
[A[ATraining Step: 5148  | total loss: [1m[32m0.35891[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35891 - acc: 0.8533 -- iter: 2816/3680
[A[ATraining Step: 5149  | total loss: [1m[32m0.35678[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35678 - acc: 0.8523 -- iter: 2848/3680
[A[ATraining Step: 5150  | total loss: [1m[32m0.34580[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34580 - acc: 0.8608 -- iter: 2880/3680
[A[ATraining Step: 5151  | total loss: [1m[32m0.36164[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36164 - acc: 0.8591 -- iter: 2912/3680
[A[ATraining Step: 5152  | total loss: [1m[32m0.37133[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37133 - acc: 0.8576 -- iter: 2944/3680
[A[ATraining Step: 5153  | total loss: [1m[32m0.38257[0m[0m
[2K| Adam | epoch: 045 | loss: 0.38257 - acc: 0.8500 -- iter: 2976/3680
[A[ATraining Step: 5154  | total loss: [1m[32m0.38874[0m[0m
[2K| Adam | epoch: 045 | loss: 0.38874 - acc: 0.8400 -- iter: 3008/3680
[A[ATraining Step: 5155  | total loss: [1m[32m0.38283[0m[0m
[2K| Adam | epoch: 045 | loss: 0.38283 - acc: 0.8435 -- iter: 3040/3680
[A[ATraining Step: 5156  | total loss: [1m[32m0.38155[0m[0m
[2K| Adam | epoch: 045 | loss: 0.38155 - acc: 0.8466 -- iter: 3072/3680
[A[ATraining Step: 5157  | total loss: [1m[32m0.38669[0m[0m
[2K| Adam | epoch: 045 | loss: 0.38669 - acc: 0.8495 -- iter: 3104/3680
[A[ATraining Step: 5158  | total loss: [1m[32m0.37374[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37374 - acc: 0.8489 -- iter: 3136/3680
[A[ATraining Step: 5159  | total loss: [1m[32m0.36300[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36300 - acc: 0.8515 -- iter: 3168/3680
[A[ATraining Step: 5160  | total loss: [1m[32m0.37248[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37248 - acc: 0.8476 -- iter: 3200/3680
[A[ATraining Step: 5161  | total loss: [1m[32m0.36083[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36083 - acc: 0.8494 -- iter: 3232/3680
[A[ATraining Step: 5162  | total loss: [1m[32m0.36083[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36083 - acc: 0.8494 -- iter: 3264/3680
[A[ATraining Step: 5163  | total loss: [1m[32m0.36335[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36335 - acc: 0.8457 -- iter: 3296/3680
[A[ATraining Step: 5164  | total loss: [1m[32m0.37035[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37035 - acc: 0.8424 -- iter: 3328/3680
[A[ATraining Step: 5165  | total loss: [1m[32m0.37076[0m[0m
[2K| Adam | epoch: 045 | loss: 0.37076 - acc: 0.8363 -- iter: 3360/3680
[A[ATraining Step: 5166  | total loss: [1m[32m0.35814[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35814 - acc: 0.8433 -- iter: 3392/3680
[A[ATraining Step: 5167  | total loss: [1m[32m0.36351[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36351 - acc: 0.8402 -- iter: 3424/3680
[A[ATraining Step: 5168  | total loss: [1m[32m0.36854[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36854 - acc: 0.8374 -- iter: 3456/3680
[A[ATraining Step: 5169  | total loss: [1m[32m0.35976[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35976 - acc: 0.8380 -- iter: 3488/3680
[A[ATraining Step: 5170  | total loss: [1m[32m0.34860[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34860 - acc: 0.8449 -- iter: 3520/3680
[A[ATraining Step: 5171  | total loss: [1m[32m0.33404[0m[0m
[2K| Adam | epoch: 045 | loss: 0.33404 - acc: 0.8541 -- iter: 3552/3680
[A[ATraining Step: 5172  | total loss: [1m[32m0.35002[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35002 - acc: 0.8531 -- iter: 3584/3680
[A[ATraining Step: 5173  | total loss: [1m[32m0.34127[0m[0m
[2K| Adam | epoch: 045 | loss: 0.34127 - acc: 0.8584 -- iter: 3616/3680
[A[ATraining Step: 5174  | total loss: [1m[32m0.35826[0m[0m
[2K| Adam | epoch: 045 | loss: 0.35826 - acc: 0.8507 -- iter: 3648/3680
[A[ATraining Step: 5175  | total loss: [1m[32m0.36252[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36252 - acc: 0.8562 | val_loss: 0.34834 - val_acc: 0.8567 -- iter: 3680/3680
[A[ATraining Step: 5175  | total loss: [1m[32m0.36252[0m[0m
[2K| Adam | epoch: 045 | loss: 0.36252 - acc: 0.8562 | val_loss: 0.34834 - val_acc: 0.8567 -- iter: 3680/3680
--
Training Step: 5176  | total loss: [1m[32m0.36031[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36031 - acc: 0.8519 -- iter: 0032/3680
[A[ATraining Step: 5177  | total loss: [1m[32m0.37227[0m[0m
[2K| Adam | epoch: 046 | loss: 0.37227 - acc: 0.8448 -- iter: 0064/3680
[A[ATraining Step: 5178  | total loss: [1m[32m0.36380[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36380 - acc: 0.8447 -- iter: 0096/3680
[A[ATraining Step: 5179  | total loss: [1m[32m0.36954[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36954 - acc: 0.8477 -- iter: 0128/3680
[A[ATraining Step: 5180  | total loss: [1m[32m0.36847[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36847 - acc: 0.8473 -- iter: 0160/3680
[A[ATraining Step: 5181  | total loss: [1m[32m0.35874[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35874 - acc: 0.8501 -- iter: 0192/3680
[A[ATraining Step: 5182  | total loss: [1m[32m0.35443[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35443 - acc: 0.8557 -- iter: 0224/3680
[A[ATraining Step: 5183  | total loss: [1m[32m0.34255[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34255 - acc: 0.8576 -- iter: 0256/3680
[A[ATraining Step: 5184  | total loss: [1m[32m0.33935[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33935 - acc: 0.8625 -- iter: 0288/3680
[A[ATraining Step: 5185  | total loss: [1m[32m0.34385[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34385 - acc: 0.8606 -- iter: 0320/3680
[A[ATraining Step: 5186  | total loss: [1m[32m0.35563[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35563 - acc: 0.8527 -- iter: 0352/3680
[A[ATraining Step: 5187  | total loss: [1m[32m0.37358[0m[0m
[2K| Adam | epoch: 046 | loss: 0.37358 - acc: 0.8424 -- iter: 0384/3680
[A[ATraining Step: 5188  | total loss: [1m[32m0.46044[0m[0m
[2K| Adam | epoch: 046 | loss: 0.46044 - acc: 0.8051 -- iter: 0416/3680
[A[ATraining Step: 5189  | total loss: [1m[32m0.45105[0m[0m
[2K| Adam | epoch: 046 | loss: 0.45105 - acc: 0.8058 -- iter: 0448/3680
[A[ATraining Step: 5190  | total loss: [1m[32m0.44806[0m[0m
[2K| Adam | epoch: 046 | loss: 0.44806 - acc: 0.8002 -- iter: 0480/3680
[A[ATraining Step: 5191  | total loss: [1m[32m0.44093[0m[0m
[2K| Adam | epoch: 046 | loss: 0.44093 - acc: 0.8046 -- iter: 0512/3680
[A[ATraining Step: 5192  | total loss: [1m[32m0.42958[0m[0m
[2K| Adam | epoch: 046 | loss: 0.42958 - acc: 0.8147 -- iter: 0544/3680
[A[ATraining Step: 5193  | total loss: [1m[32m0.41826[0m[0m
[2K| Adam | epoch: 046 | loss: 0.41826 - acc: 0.8145 -- iter: 0576/3680
[A[ATraining Step: 5194  | total loss: [1m[32m0.41428[0m[0m
[2K| Adam | epoch: 046 | loss: 0.41428 - acc: 0.8081 -- iter: 0608/3680
[A[ATraining Step: 5195  | total loss: [1m[32m0.42597[0m[0m
[2K| Adam | epoch: 046 | loss: 0.42597 - acc: 0.8023 -- iter: 0640/3680
[A[ATraining Step: 5196  | total loss: [1m[32m0.40995[0m[0m
[2K| Adam | epoch: 046 | loss: 0.40995 - acc: 0.8127 -- iter: 0672/3680
[A[ATraining Step: 5197  | total loss: [1m[32m0.41228[0m[0m
[2K| Adam | epoch: 046 | loss: 0.41228 - acc: 0.8158 -- iter: 0704/3680
[A[ATraining Step: 5198  | total loss: [1m[32m0.41510[0m[0m
[2K| Adam | epoch: 046 | loss: 0.41510 - acc: 0.8154 -- iter: 0736/3680
[A[ATraining Step: 5199  | total loss: [1m[32m0.42571[0m[0m
[2K| Adam | epoch: 046 | loss: 0.42571 - acc: 0.8120 -- iter: 0768/3680
[A[ATraining Step: 5200  | total loss: [1m[32m0.42364[0m[0m
[2K| Adam | epoch: 046 | loss: 0.42364 - acc: 0.8121 | val_loss: 0.32356 - val_acc: 0.8838 -- iter: 0800/3680
[A[ATraining Step: 5200  | total loss: [1m[32m0.42364[0m[0m
[2K| Adam | epoch: 046 | loss: 0.42364 - acc: 0.8121 | val_loss: 0.32356 - val_acc: 0.8838 -- iter: 0800/3680
--
Training Step: 5201  | total loss: [1m[32m0.41727[0m[0m
[2K| Adam | epoch: 046 | loss: 0.41727 - acc: 0.8152 -- iter: 0832/3680
[A[ATraining Step: 5202  | total loss: [1m[32m0.40689[0m[0m
[2K| Adam | epoch: 046 | loss: 0.40689 - acc: 0.8275 -- iter: 0864/3680
[A[ATraining Step: 5203  | total loss: [1m[32m0.40094[0m[0m
[2K| Adam | epoch: 046 | loss: 0.40094 - acc: 0.8291 -- iter: 0896/3680
[A[ATraining Step: 5204  | total loss: [1m[32m0.39756[0m[0m
[2K| Adam | epoch: 046 | loss: 0.39756 - acc: 0.8337 -- iter: 0928/3680
[A[ATraining Step: 5205  | total loss: [1m[32m0.38899[0m[0m
[2K| Adam | epoch: 046 | loss: 0.38899 - acc: 0.8378 -- iter: 0960/3680
[A[ATraining Step: 5206  | total loss: [1m[32m0.38771[0m[0m
[2K| Adam | epoch: 046 | loss: 0.38771 - acc: 0.8384 -- iter: 0992/3680
[A[ATraining Step: 5207  | total loss: [1m[32m0.38865[0m[0m
[2K| Adam | epoch: 046 | loss: 0.38865 - acc: 0.8358 -- iter: 1024/3680
[A[ATraining Step: 5208  | total loss: [1m[32m0.37507[0m[0m
[2K| Adam | epoch: 046 | loss: 0.37507 - acc: 0.8460 -- iter: 1056/3680
[A[ATraining Step: 5209  | total loss: [1m[32m0.37749[0m[0m
[2K| Adam | epoch: 046 | loss: 0.37749 - acc: 0.8395 -- iter: 1088/3680
[A[ATraining Step: 5210  | total loss: [1m[32m0.36330[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36330 - acc: 0.8493 -- iter: 1120/3680
[A[ATraining Step: 5211  | total loss: [1m[32m0.37409[0m[0m
[2K| Adam | epoch: 046 | loss: 0.37409 - acc: 0.8456 -- iter: 1152/3680
[A[ATraining Step: 5212  | total loss: [1m[32m0.36969[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36969 - acc: 0.8486 -- iter: 1184/3680
[A[ATraining Step: 5213  | total loss: [1m[32m0.36325[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36325 - acc: 0.8512 -- iter: 1216/3680
[A[ATraining Step: 5214  | total loss: [1m[32m0.35004[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35004 - acc: 0.8598 -- iter: 1248/3680
[A[ATraining Step: 5215  | total loss: [1m[32m0.35726[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35726 - acc: 0.8551 -- iter: 1280/3680
[A[ATraining Step: 5216  | total loss: [1m[32m0.36107[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36107 - acc: 0.8540 -- iter: 1312/3680
[A[ATraining Step: 5217  | total loss: [1m[32m0.34488[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34488 - acc: 0.8623 -- iter: 1344/3680
[A[ATraining Step: 5218  | total loss: [1m[32m0.33886[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33886 - acc: 0.8605 -- iter: 1376/3680
[A[ATraining Step: 5219  | total loss: [1m[32m0.32827[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32827 - acc: 0.8682 -- iter: 1408/3680
[A[ATraining Step: 5220  | total loss: [1m[32m0.31978[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31978 - acc: 0.8751 -- iter: 1440/3680
[A[ATraining Step: 5221  | total loss: [1m[32m0.31682[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31682 - acc: 0.8813 -- iter: 1472/3680
[A[ATraining Step: 5222  | total loss: [1m[32m0.32327[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32327 - acc: 0.8807 -- iter: 1504/3680
[A[ATraining Step: 5223  | total loss: [1m[32m0.31307[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31307 - acc: 0.8864 -- iter: 1536/3680
[A[ATraining Step: 5224  | total loss: [1m[32m0.31113[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31113 - acc: 0.8852 -- iter: 1568/3680
[A[ATraining Step: 5225  | total loss: [1m[32m0.33092[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33092 - acc: 0.8717 -- iter: 1600/3680
[A[ATraining Step: 5226  | total loss: [1m[32m0.33308[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33308 - acc: 0.8689 -- iter: 1632/3680
[A[ATraining Step: 5227  | total loss: [1m[32m0.33158[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33158 - acc: 0.8727 -- iter: 1664/3680
[A[ATraining Step: 5228  | total loss: [1m[32m0.31785[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31785 - acc: 0.8791 -- iter: 1696/3680
[A[ATraining Step: 5229  | total loss: [1m[32m0.31760[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31760 - acc: 0.8787 -- iter: 1728/3680
[A[ATraining Step: 5230  | total loss: [1m[32m0.32752[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32752 - acc: 0.8721 -- iter: 1760/3680
[A[ATraining Step: 5231  | total loss: [1m[32m0.33275[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33275 - acc: 0.8661 -- iter: 1792/3680
[A[ATraining Step: 5232  | total loss: [1m[32m0.33906[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33906 - acc: 0.8670 -- iter: 1824/3680
[A[ATraining Step: 5233  | total loss: [1m[32m0.33908[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33908 - acc: 0.8647 -- iter: 1856/3680
[A[ATraining Step: 5234  | total loss: [1m[32m0.35362[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35362 - acc: 0.8564 -- iter: 1888/3680
[A[ATraining Step: 5235  | total loss: [1m[32m0.34741[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34741 - acc: 0.8582 -- iter: 1920/3680
[A[ATraining Step: 5236  | total loss: [1m[32m0.34826[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34826 - acc: 0.8536 -- iter: 1952/3680
[A[ATraining Step: 5237  | total loss: [1m[32m0.36777[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36777 - acc: 0.8433 -- iter: 1984/3680
[A[ATraining Step: 5238  | total loss: [1m[32m0.36394[0m[0m
[2K| Adam | epoch: 046 | loss: 0.36394 - acc: 0.8465 -- iter: 2016/3680
[A[ATraining Step: 5239  | total loss: [1m[32m0.34998[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34998 - acc: 0.8587 -- iter: 2048/3680
[A[ATraining Step: 5240  | total loss: [1m[32m0.34516[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34516 - acc: 0.8603 -- iter: 2080/3680
[A[ATraining Step: 5241  | total loss: [1m[32m0.33449[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33449 - acc: 0.8712 -- iter: 2112/3680
[A[ATraining Step: 5242  | total loss: [1m[32m0.32915[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32915 - acc: 0.8747 -- iter: 2144/3680
[A[ATraining Step: 5243  | total loss: [1m[32m0.32199[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32199 - acc: 0.8778 -- iter: 2176/3680
[A[ATraining Step: 5244  | total loss: [1m[32m0.32924[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32924 - acc: 0.8682 -- iter: 2208/3680
[A[ATraining Step: 5245  | total loss: [1m[32m0.32164[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32164 - acc: 0.8751 -- iter: 2240/3680
[A[ATraining Step: 5246  | total loss: [1m[32m0.32363[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32363 - acc: 0.8813 -- iter: 2272/3680
[A[ATraining Step: 5247  | total loss: [1m[32m0.33854[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33854 - acc: 0.8713 -- iter: 2304/3680
[A[ATraining Step: 5248  | total loss: [1m[32m0.34820[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34820 - acc: 0.8686 -- iter: 2336/3680
[A[ATraining Step: 5249  | total loss: [1m[32m0.34955[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34955 - acc: 0.8630 -- iter: 2368/3680
[A[ATraining Step: 5250  | total loss: [1m[32m0.34162[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34162 - acc: 0.8642 -- iter: 2400/3680
[A[ATraining Step: 5251  | total loss: [1m[32m0.34217[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34217 - acc: 0.8621 -- iter: 2432/3680
[A[ATraining Step: 5252  | total loss: [1m[32m0.33234[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33234 - acc: 0.8665 -- iter: 2464/3680
[A[ATraining Step: 5253  | total loss: [1m[32m0.32327[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32327 - acc: 0.8703 -- iter: 2496/3680
[A[ATraining Step: 5254  | total loss: [1m[32m0.32327[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32327 - acc: 0.8703 -- iter: 2528/3680
[A[ATraining Step: 5255  | total loss: [1m[32m0.32453[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32453 - acc: 0.8677 -- iter: 2560/3680
[A[ATraining Step: 5256  | total loss: [1m[32m0.31942[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31942 - acc: 0.8747 -- iter: 2592/3680
[A[ATraining Step: 5257  | total loss: [1m[32m0.32472[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32472 - acc: 0.8747 -- iter: 2624/3680
[A[ATraining Step: 5258  | total loss: [1m[32m0.31322[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31322 - acc: 0.8778 -- iter: 2656/3680
[A[ATraining Step: 5259  | total loss: [1m[32m0.30397[0m[0m
[2K| Adam | epoch: 046 | loss: 0.30397 - acc: 0.8807 -- iter: 2688/3680
[A[ATraining Step: 5260  | total loss: [1m[32m0.31542[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31542 - acc: 0.8770 -- iter: 2720/3680
[A[ATraining Step: 5261  | total loss: [1m[32m0.31768[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31768 - acc: 0.8705 -- iter: 2752/3680
[A[ATraining Step: 5262  | total loss: [1m[32m0.32281[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32281 - acc: 0.8679 -- iter: 2784/3680
[A[ATraining Step: 5263  | total loss: [1m[32m0.32554[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32554 - acc: 0.8655 -- iter: 2816/3680
[A[ATraining Step: 5264  | total loss: [1m[32m0.33922[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33922 - acc: 0.8602 -- iter: 2848/3680
[A[ATraining Step: 5265  | total loss: [1m[32m0.35340[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35340 - acc: 0.8523 -- iter: 2880/3680
[A[ATraining Step: 5266  | total loss: [1m[32m0.35088[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35088 - acc: 0.8545 -- iter: 2912/3680
[A[ATraining Step: 5267  | total loss: [1m[32m0.34456[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34456 - acc: 0.8535 -- iter: 2944/3680
[A[ATraining Step: 5268  | total loss: [1m[32m0.35698[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35698 - acc: 0.8525 -- iter: 2976/3680
[A[ATraining Step: 5269  | total loss: [1m[32m0.35651[0m[0m
[2K| Adam | epoch: 046 | loss: 0.35651 - acc: 0.8547 -- iter: 3008/3680
[A[ATraining Step: 5270  | total loss: [1m[32m0.34746[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34746 - acc: 0.8568 -- iter: 3040/3680
[A[ATraining Step: 5271  | total loss: [1m[32m0.33395[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33395 - acc: 0.8680 -- iter: 3072/3680
[A[ATraining Step: 5272  | total loss: [1m[32m0.32951[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32951 - acc: 0.8655 -- iter: 3104/3680
[A[ATraining Step: 5273  | total loss: [1m[32m0.32840[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32840 - acc: 0.8696 -- iter: 3136/3680
[A[ATraining Step: 5274  | total loss: [1m[32m0.33175[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33175 - acc: 0.8670 -- iter: 3168/3680
[A[ATraining Step: 5275  | total loss: [1m[32m0.32331[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32331 - acc: 0.8741 -- iter: 3200/3680
[A[ATraining Step: 5276  | total loss: [1m[32m0.32674[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32674 - acc: 0.8679 -- iter: 3232/3680
[A[ATraining Step: 5277  | total loss: [1m[32m0.31858[0m[0m
[2K| Adam | epoch: 046 | loss: 0.31858 - acc: 0.8749 -- iter: 3264/3680
[A[ATraining Step: 5278  | total loss: [1m[32m0.32905[0m[0m
[2K| Adam | epoch: 046 | loss: 0.32905 - acc: 0.8686 -- iter: 3296/3680
[A[ATraining Step: 5279  | total loss: [1m[32m0.34285[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34285 - acc: 0.8599 -- iter: 3328/3680
[A[ATraining Step: 5280  | total loss: [1m[32m0.33883[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33883 - acc: 0.8614 -- iter: 3360/3680
[A[ATraining Step: 5281  | total loss: [1m[32m0.33489[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33489 - acc: 0.8690 -- iter: 3392/3680
[A[ATraining Step: 5282  | total loss: [1m[32m0.33417[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33417 - acc: 0.8696 -- iter: 3424/3680
[A[ATraining Step: 5283  | total loss: [1m[32m0.33256[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33256 - acc: 0.8702 -- iter: 3456/3680
[A[ATraining Step: 5284  | total loss: [1m[32m0.33629[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33629 - acc: 0.8675 -- iter: 3488/3680
[A[ATraining Step: 5285  | total loss: [1m[32m0.34163[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34163 - acc: 0.8683 -- iter: 3520/3680
[A[ATraining Step: 5286  | total loss: [1m[32m0.33205[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33205 - acc: 0.8752 -- iter: 3552/3680
[A[ATraining Step: 5287  | total loss: [1m[32m0.33982[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33982 - acc: 0.8689 -- iter: 3584/3680
[A[ATraining Step: 5288  | total loss: [1m[32m0.33796[0m[0m
[2K| Adam | epoch: 046 | loss: 0.33796 - acc: 0.8695 -- iter: 3616/3680
[A[ATraining Step: 5289  | total loss: [1m[32m0.34915[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34915 - acc: 0.8669 -- iter: 3648/3680
[A[ATraining Step: 5290  | total loss: [1m[32m0.34428[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34428 - acc: 0.8709 | val_loss: 0.32803 - val_acc: 0.8784 -- iter: 3680/3680
[A[ATraining Step: 5290  | total loss: [1m[32m0.34428[0m[0m
[2K| Adam | epoch: 046 | loss: 0.34428 - acc: 0.8709 | val_loss: 0.32803 - val_acc: 0.8784 -- iter: 3680/3680
--
Training Step: 5291  | total loss: [1m[32m0.34081[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34081 - acc: 0.8650 -- iter: 0032/3680
[A[ATraining Step: 5292  | total loss: [1m[32m0.34695[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34695 - acc: 0.8567 -- iter: 0064/3680
[A[ATraining Step: 5293  | total loss: [1m[32m0.34195[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34195 - acc: 0.8616 -- iter: 0096/3680
[A[ATraining Step: 5294  | total loss: [1m[32m0.33964[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33964 - acc: 0.8630 -- iter: 0128/3680
[A[ATraining Step: 5295  | total loss: [1m[32m0.33756[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33756 - acc: 0.8579 -- iter: 0160/3680
[A[ATraining Step: 5296  | total loss: [1m[32m0.32652[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32652 - acc: 0.8690 -- iter: 0192/3680
[A[ATraining Step: 5297  | total loss: [1m[32m0.31752[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31752 - acc: 0.8696 -- iter: 0224/3680
[A[ATraining Step: 5298  | total loss: [1m[32m0.31545[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31545 - acc: 0.8701 -- iter: 0256/3680
[A[ATraining Step: 5299  | total loss: [1m[32m0.31771[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31771 - acc: 0.8675 -- iter: 0288/3680
[A[ATraining Step: 5300  | total loss: [1m[32m0.31473[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31473 - acc: 0.8682 | val_loss: 0.33541 - val_acc: 0.8751 -- iter: 0320/3680
[A[ATraining Step: 5300  | total loss: [1m[32m0.31473[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31473 - acc: 0.8682 | val_loss: 0.33541 - val_acc: 0.8751 -- iter: 0320/3680
--
Training Step: 5301  | total loss: [1m[32m0.30907[0m[0m
[2K| Adam | epoch: 047 | loss: 0.30907 - acc: 0.8720 -- iter: 0352/3680
[A[ATraining Step: 5302  | total loss: [1m[32m0.31181[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31181 - acc: 0.8755 -- iter: 0384/3680
[A[ATraining Step: 5303  | total loss: [1m[32m0.30423[0m[0m
[2K| Adam | epoch: 047 | loss: 0.30423 - acc: 0.8785 -- iter: 0416/3680
[A[ATraining Step: 5304  | total loss: [1m[32m0.39978[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39978 - acc: 0.8376 -- iter: 0448/3680
[A[ATraining Step: 5305  | total loss: [1m[32m0.40209[0m[0m
[2K| Adam | epoch: 047 | loss: 0.40209 - acc: 0.8382 -- iter: 0480/3680
[A[ATraining Step: 5306  | total loss: [1m[32m0.39165[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39165 - acc: 0.8419 -- iter: 0512/3680
[A[ATraining Step: 5307  | total loss: [1m[32m0.37813[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37813 - acc: 0.8483 -- iter: 0544/3680
[A[ATraining Step: 5308  | total loss: [1m[32m0.36976[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36976 - acc: 0.8478 -- iter: 0576/3680
[A[ATraining Step: 5309  | total loss: [1m[32m0.36098[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36098 - acc: 0.8537 -- iter: 0608/3680
[A[ATraining Step: 5310  | total loss: [1m[32m0.35307[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35307 - acc: 0.8558 -- iter: 0640/3680
[A[ATraining Step: 5311  | total loss: [1m[32m0.35154[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35154 - acc: 0.8546 -- iter: 0672/3680
[A[ATraining Step: 5312  | total loss: [1m[32m0.34341[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34341 - acc: 0.8660 -- iter: 0704/3680
[A[ATraining Step: 5313  | total loss: [1m[32m0.36084[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36084 - acc: 0.8513 -- iter: 0736/3680
[A[ATraining Step: 5314  | total loss: [1m[32m0.37736[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37736 - acc: 0.8412 -- iter: 0768/3680
[A[ATraining Step: 5315  | total loss: [1m[32m0.38305[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38305 - acc: 0.8383 -- iter: 0800/3680
[A[ATraining Step: 5316  | total loss: [1m[32m0.38973[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38973 - acc: 0.8326 -- iter: 0832/3680
[A[ATraining Step: 5317  | total loss: [1m[32m0.39205[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39205 - acc: 0.8368 -- iter: 0864/3680
[A[ATraining Step: 5318  | total loss: [1m[32m0.39282[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39282 - acc: 0.8407 -- iter: 0896/3680
[A[ATraining Step: 5319  | total loss: [1m[32m0.38906[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38906 - acc: 0.8441 -- iter: 0928/3680
[A[ATraining Step: 5320  | total loss: [1m[32m0.39914[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39914 - acc: 0.8347 -- iter: 0960/3680
[A[ATraining Step: 5321  | total loss: [1m[32m0.39982[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39982 - acc: 0.8293 -- iter: 0992/3680
[A[ATraining Step: 5322  | total loss: [1m[32m0.39302[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39302 - acc: 0.8308 -- iter: 1024/3680
[A[ATraining Step: 5323  | total loss: [1m[32m0.38818[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38818 - acc: 0.8258 -- iter: 1056/3680
[A[ATraining Step: 5324  | total loss: [1m[32m0.39552[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39552 - acc: 0.8182 -- iter: 1088/3680
[A[ATraining Step: 5325  | total loss: [1m[32m0.38141[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38141 - acc: 0.8270 -- iter: 1120/3680
[A[ATraining Step: 5326  | total loss: [1m[32m0.36992[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36992 - acc: 0.8350 -- iter: 1152/3680
[A[ATraining Step: 5327  | total loss: [1m[32m0.37861[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37861 - acc: 0.8265 -- iter: 1184/3680
[A[ATraining Step: 5328  | total loss: [1m[32m0.36791[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36791 - acc: 0.8376 -- iter: 1216/3680
[A[ATraining Step: 5329  | total loss: [1m[32m0.38493[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38493 - acc: 0.8257 -- iter: 1248/3680
[A[ATraining Step: 5330  | total loss: [1m[32m0.37127[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37127 - acc: 0.8306 -- iter: 1280/3680
[A[ATraining Step: 5331  | total loss: [1m[32m0.37200[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37200 - acc: 0.8319 -- iter: 1312/3680
[A[ATraining Step: 5332  | total loss: [1m[32m0.37063[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37063 - acc: 0.8300 -- iter: 1344/3680
[A[ATraining Step: 5333  | total loss: [1m[32m0.37296[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37296 - acc: 0.8282 -- iter: 1376/3680
[A[ATraining Step: 5334  | total loss: [1m[32m0.37662[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37662 - acc: 0.8267 -- iter: 1408/3680
[A[ATraining Step: 5335  | total loss: [1m[32m0.38265[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38265 - acc: 0.8252 -- iter: 1440/3680
[A[ATraining Step: 5336  | total loss: [1m[32m0.38763[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38763 - acc: 0.8271 -- iter: 1472/3680
[A[ATraining Step: 5337  | total loss: [1m[32m0.38910[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38910 - acc: 0.8319 -- iter: 1504/3680
[A[ATraining Step: 5338  | total loss: [1m[32m0.40354[0m[0m
[2K| Adam | epoch: 047 | loss: 0.40354 - acc: 0.8175 -- iter: 1536/3680
[A[ATraining Step: 5339  | total loss: [1m[32m0.39000[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39000 - acc: 0.8263 -- iter: 1568/3680
[A[ATraining Step: 5340  | total loss: [1m[32m0.39967[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39967 - acc: 0.8249 -- iter: 1600/3680
[A[ATraining Step: 5341  | total loss: [1m[32m0.40278[0m[0m
[2K| Adam | epoch: 047 | loss: 0.40278 - acc: 0.8237 -- iter: 1632/3680
[A[ATraining Step: 5342  | total loss: [1m[32m0.41144[0m[0m
[2K| Adam | epoch: 047 | loss: 0.41144 - acc: 0.8195 -- iter: 1664/3680
[A[ATraining Step: 5343  | total loss: [1m[32m0.41040[0m[0m
[2K| Adam | epoch: 047 | loss: 0.41040 - acc: 0.8219 -- iter: 1696/3680
[A[ATraining Step: 5344  | total loss: [1m[32m0.40550[0m[0m
[2K| Adam | epoch: 047 | loss: 0.40550 - acc: 0.8272 -- iter: 1728/3680
[A[ATraining Step: 5345  | total loss: [1m[32m0.40331[0m[0m
[2K| Adam | epoch: 047 | loss: 0.40331 - acc: 0.8257 -- iter: 1760/3680
[A[ATraining Step: 5346  | total loss: [1m[32m0.39609[0m[0m
[2K| Adam | epoch: 047 | loss: 0.39609 - acc: 0.8244 -- iter: 1792/3680
[A[ATraining Step: 5347  | total loss: [1m[32m0.38944[0m[0m
[2K| Adam | epoch: 047 | loss: 0.38944 - acc: 0.8201 -- iter: 1824/3680
[A[ATraining Step: 5348  | total loss: [1m[32m0.37246[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37246 - acc: 0.8318 -- iter: 1856/3680
[A[ATraining Step: 5349  | total loss: [1m[32m0.37179[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37179 - acc: 0.8330 -- iter: 1888/3680
[A[ATraining Step: 5350  | total loss: [1m[32m0.36161[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36161 - acc: 0.8435 -- iter: 1920/3680
[A[ATraining Step: 5351  | total loss: [1m[32m0.35529[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35529 - acc: 0.8466 -- iter: 1952/3680
[A[ATraining Step: 5352  | total loss: [1m[32m0.34768[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34768 - acc: 0.8557 -- iter: 1984/3680
[A[ATraining Step: 5353  | total loss: [1m[32m0.34393[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34393 - acc: 0.8576 -- iter: 2016/3680
[A[ATraining Step: 5354  | total loss: [1m[32m0.33972[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33972 - acc: 0.8594 -- iter: 2048/3680
[A[ATraining Step: 5355  | total loss: [1m[32m0.33631[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33631 - acc: 0.8641 -- iter: 2080/3680
[A[ATraining Step: 5356  | total loss: [1m[32m0.33796[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33796 - acc: 0.8620 -- iter: 2112/3680
[A[ATraining Step: 5357  | total loss: [1m[32m0.34000[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34000 - acc: 0.8602 -- iter: 2144/3680
[A[ATraining Step: 5358  | total loss: [1m[32m0.34453[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34453 - acc: 0.8617 -- iter: 2176/3680
[A[ATraining Step: 5359  | total loss: [1m[32m0.33709[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33709 - acc: 0.8661 -- iter: 2208/3680
[A[ATraining Step: 5360  | total loss: [1m[32m0.33294[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33294 - acc: 0.8670 -- iter: 2240/3680
[A[ATraining Step: 5361  | total loss: [1m[32m0.34008[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34008 - acc: 0.8584 -- iter: 2272/3680
[A[ATraining Step: 5362  | total loss: [1m[32m0.32818[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32818 - acc: 0.8664 -- iter: 2304/3680
[A[ATraining Step: 5363  | total loss: [1m[32m0.32555[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32555 - acc: 0.8672 -- iter: 2336/3680
[A[ATraining Step: 5364  | total loss: [1m[32m0.32081[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32081 - acc: 0.8680 -- iter: 2368/3680
[A[ATraining Step: 5365  | total loss: [1m[32m0.33120[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33120 - acc: 0.8718 -- iter: 2400/3680
[A[ATraining Step: 5366  | total loss: [1m[32m0.31521[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31521 - acc: 0.8815 -- iter: 2432/3680
[A[ATraining Step: 5367  | total loss: [1m[32m0.33295[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33295 - acc: 0.8746 -- iter: 2464/3680
[A[ATraining Step: 5368  | total loss: [1m[32m0.32444[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32444 - acc: 0.8747 -- iter: 2496/3680
[A[ATraining Step: 5369  | total loss: [1m[32m0.32972[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32972 - acc: 0.8747 -- iter: 2528/3680
[A[ATraining Step: 5370  | total loss: [1m[32m0.33196[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33196 - acc: 0.8747 -- iter: 2560/3680
[A[ATraining Step: 5371  | total loss: [1m[32m0.31804[0m[0m
[2K| Adam | epoch: 047 | loss: 0.31804 - acc: 0.8841 -- iter: 2592/3680
[A[ATraining Step: 5372  | total loss: [1m[32m0.34128[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34128 - acc: 0.8738 -- iter: 2624/3680
[A[ATraining Step: 5373  | total loss: [1m[32m0.34460[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34460 - acc: 0.8740 -- iter: 2656/3680
[A[ATraining Step: 5374  | total loss: [1m[32m0.34334[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34334 - acc: 0.8741 -- iter: 2688/3680
[A[ATraining Step: 5375  | total loss: [1m[32m0.35778[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35778 - acc: 0.8585 -- iter: 2720/3680
[A[ATraining Step: 5376  | total loss: [1m[32m0.36457[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36457 - acc: 0.8633 -- iter: 2752/3680
[A[ATraining Step: 5377  | total loss: [1m[32m0.36764[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36764 - acc: 0.8551 -- iter: 2784/3680
[A[ATraining Step: 5378  | total loss: [1m[32m0.37084[0m[0m
[2K| Adam | epoch: 047 | loss: 0.37084 - acc: 0.8540 -- iter: 2816/3680
[A[ATraining Step: 5379  | total loss: [1m[32m0.36342[0m[0m
[2K| Adam | epoch: 047 | loss: 0.36342 - acc: 0.8561 -- iter: 2848/3680
[A[ATraining Step: 5380  | total loss: [1m[32m0.35794[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35794 - acc: 0.8548 -- iter: 2880/3680
[A[ATraining Step: 5381  | total loss: [1m[32m0.35966[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35966 - acc: 0.8537 -- iter: 2912/3680
[A[ATraining Step: 5382  | total loss: [1m[32m0.34661[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34661 - acc: 0.8621 -- iter: 2944/3680
[A[ATraining Step: 5383  | total loss: [1m[32m0.34596[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34596 - acc: 0.8634 -- iter: 2976/3680
[A[ATraining Step: 5384  | total loss: [1m[32m0.34149[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34149 - acc: 0.8677 -- iter: 3008/3680
[A[ATraining Step: 5385  | total loss: [1m[32m0.33324[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33324 - acc: 0.8747 -- iter: 3040/3680
[A[ATraining Step: 5386  | total loss: [1m[32m0.33107[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33107 - acc: 0.8719 -- iter: 3072/3680
[A[ATraining Step: 5387  | total loss: [1m[32m0.33133[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33133 - acc: 0.8719 -- iter: 3104/3680
[A[ATraining Step: 5388  | total loss: [1m[32m0.32537[0m[0m
[2K| Adam | epoch: 047 | loss: 0.32537 - acc: 0.8785 -- iter: 3136/3680
[A[ATraining Step: 5389  | total loss: [1m[32m0.33401[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33401 - acc: 0.8719 -- iter: 3168/3680
[A[ATraining Step: 5390  | total loss: [1m[32m0.33844[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33844 - acc: 0.8628 -- iter: 3200/3680
[A[ATraining Step: 5391  | total loss: [1m[32m0.35711[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35711 - acc: 0.8547 -- iter: 3232/3680
[A[ATraining Step: 5392  | total loss: [1m[32m0.35483[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35483 - acc: 0.8567 -- iter: 3264/3680
[A[ATraining Step: 5393  | total loss: [1m[32m0.34725[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34725 - acc: 0.8648 -- iter: 3296/3680
[A[ATraining Step: 5394  | total loss: [1m[32m0.35108[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35108 - acc: 0.8595 -- iter: 3328/3680
[A[ATraining Step: 5395  | total loss: [1m[32m0.35623[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35623 - acc: 0.8580 -- iter: 3360/3680
[A[ATraining Step: 5396  | total loss: [1m[32m0.34771[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34771 - acc: 0.8640 -- iter: 3392/3680
[A[ATraining Step: 5397  | total loss: [1m[32m0.33779[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33779 - acc: 0.8640 -- iter: 3424/3680
[A[ATraining Step: 5398  | total loss: [1m[32m0.33615[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33615 - acc: 0.8682 -- iter: 3456/3680
[A[ATraining Step: 5399  | total loss: [1m[32m0.33669[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33669 - acc: 0.8627 -- iter: 3488/3680
[A[ATraining Step: 5400  | total loss: [1m[32m0.33964[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33964 - acc: 0.8608 | val_loss: 0.32583 - val_acc: 0.8817 -- iter: 3520/3680
[A[ATraining Step: 5400  | total loss: [1m[32m0.33964[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33964 - acc: 0.8608 | val_loss: 0.32583 - val_acc: 0.8817 -- iter: 3520/3680
--
Training Step: 5401  | total loss: [1m[32m0.35662[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35662 - acc: 0.8528 -- iter: 3552/3680
[A[ATraining Step: 5402  | total loss: [1m[32m0.35738[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35738 - acc: 0.8582 -- iter: 3584/3680
[A[ATraining Step: 5403  | total loss: [1m[32m0.35028[0m[0m
[2K| Adam | epoch: 047 | loss: 0.35028 - acc: 0.8598 -- iter: 3616/3680
[A[ATraining Step: 5404  | total loss: [1m[32m0.34131[0m[0m
[2K| Adam | epoch: 047 | loss: 0.34131 - acc: 0.8645 -- iter: 3648/3680
[A[ATraining Step: 5405  | total loss: [1m[32m0.33302[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33302 - acc: 0.8718 | val_loss: 0.31948 - val_acc: 0.8795 -- iter: 3680/3680
[A[ATraining Step: 5405  | total loss: [1m[32m0.33302[0m[0m
[2K| Adam | epoch: 047 | loss: 0.33302 - acc: 0.8718 | val_loss: 0.31948 - val_acc: 0.8795 -- iter: 3680/3680
--
Training Step: 5406  | total loss: [1m[32m0.33400[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33400 - acc: 0.8721 -- iter: 0032/3680
[A[ATraining Step: 5407  | total loss: [1m[32m0.35421[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35421 - acc: 0.8661 -- iter: 0064/3680
[A[ATraining Step: 5408  | total loss: [1m[32m0.36794[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36794 - acc: 0.8577 -- iter: 0096/3680
[A[ATraining Step: 5409  | total loss: [1m[32m0.35130[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35130 - acc: 0.8656 -- iter: 0128/3680
[A[ATraining Step: 5410  | total loss: [1m[32m0.33716[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33716 - acc: 0.8728 -- iter: 0160/3680
[A[ATraining Step: 5411  | total loss: [1m[32m0.33889[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33889 - acc: 0.8730 -- iter: 0192/3680
[A[ATraining Step: 5412  | total loss: [1m[32m0.33898[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33898 - acc: 0.8670 -- iter: 0224/3680
[A[ATraining Step: 5413  | total loss: [1m[32m0.34854[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34854 - acc: 0.8615 -- iter: 0256/3680
[A[ATraining Step: 5414  | total loss: [1m[32m0.35575[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35575 - acc: 0.8566 -- iter: 0288/3680
[A[ATraining Step: 5415  | total loss: [1m[32m0.36604[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36604 - acc: 0.8460 -- iter: 0320/3680
[A[ATraining Step: 5416  | total loss: [1m[32m0.35534[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35534 - acc: 0.8489 -- iter: 0352/3680
[A[ATraining Step: 5417  | total loss: [1m[32m0.35330[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35330 - acc: 0.8484 -- iter: 0384/3680
[A[ATraining Step: 5418  | total loss: [1m[32m0.34087[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34087 - acc: 0.8542 -- iter: 0416/3680
[A[ATraining Step: 5419  | total loss: [1m[32m0.34000[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34000 - acc: 0.8594 -- iter: 0448/3680
[A[ATraining Step: 5420  | total loss: [1m[32m0.34825[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34825 - acc: 0.8516 -- iter: 0480/3680
[A[ATraining Step: 5421  | total loss: [1m[32m0.37966[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37966 - acc: 0.8383 -- iter: 0512/3680
[A[ATraining Step: 5422  | total loss: [1m[32m0.38096[0m[0m
[2K| Adam | epoch: 048 | loss: 0.38096 - acc: 0.8388 -- iter: 0544/3680
[A[ATraining Step: 5423  | total loss: [1m[32m0.37101[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37101 - acc: 0.8393 -- iter: 0576/3680
[A[ATraining Step: 5424  | total loss: [1m[32m0.37072[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37072 - acc: 0.8429 -- iter: 0608/3680
[A[ATraining Step: 5425  | total loss: [1m[32m0.37994[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37994 - acc: 0.8398 -- iter: 0640/3680
[A[ATraining Step: 5426  | total loss: [1m[32m0.38733[0m[0m
[2K| Adam | epoch: 048 | loss: 0.38733 - acc: 0.8340 -- iter: 0672/3680
[A[ATraining Step: 5427  | total loss: [1m[32m0.38766[0m[0m
[2K| Adam | epoch: 048 | loss: 0.38766 - acc: 0.8381 -- iter: 0704/3680
[A[ATraining Step: 5428  | total loss: [1m[32m0.39693[0m[0m
[2K| Adam | epoch: 048 | loss: 0.39693 - acc: 0.8387 -- iter: 0736/3680
[A[ATraining Step: 5429  | total loss: [1m[32m0.40439[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40439 - acc: 0.8423 -- iter: 0768/3680
[A[ATraining Step: 5430  | total loss: [1m[32m0.41373[0m[0m
[2K| Adam | epoch: 048 | loss: 0.41373 - acc: 0.8424 -- iter: 0800/3680
[A[ATraining Step: 5431  | total loss: [1m[32m0.40057[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40057 - acc: 0.8457 -- iter: 0832/3680
[A[ATraining Step: 5432  | total loss: [1m[32m0.39285[0m[0m
[2K| Adam | epoch: 048 | loss: 0.39285 - acc: 0.8517 -- iter: 0864/3680
[A[ATraining Step: 5433  | total loss: [1m[32m0.40137[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40137 - acc: 0.8416 -- iter: 0896/3680
[A[ATraining Step: 5434  | total loss: [1m[32m0.40613[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40613 - acc: 0.8324 -- iter: 0928/3680
[A[ATraining Step: 5435  | total loss: [1m[32m0.40811[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40811 - acc: 0.8335 -- iter: 0960/3680
[A[ATraining Step: 5436  | total loss: [1m[32m0.39442[0m[0m
[2K| Adam | epoch: 048 | loss: 0.39442 - acc: 0.8346 -- iter: 0992/3680
[A[ATraining Step: 5437  | total loss: [1m[32m0.37801[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37801 - acc: 0.8454 -- iter: 1024/3680
[A[ATraining Step: 5438  | total loss: [1m[32m0.37439[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37439 - acc: 0.8454 -- iter: 1056/3680
[A[ATraining Step: 5439  | total loss: [1m[32m0.36997[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36997 - acc: 0.8452 -- iter: 1088/3680
[A[ATraining Step: 5440  | total loss: [1m[32m0.36507[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36507 - acc: 0.8482 -- iter: 1120/3680
[A[ATraining Step: 5441  | total loss: [1m[32m0.36845[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36845 - acc: 0.8384 -- iter: 1152/3680
[A[ATraining Step: 5442  | total loss: [1m[32m0.36220[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36220 - acc: 0.8420 -- iter: 1184/3680
[A[ATraining Step: 5443  | total loss: [1m[32m0.35029[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35029 - acc: 0.8516 -- iter: 1216/3680
[A[ATraining Step: 5444  | total loss: [1m[32m0.34642[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34642 - acc: 0.8539 -- iter: 1248/3680
[A[ATraining Step: 5445  | total loss: [1m[32m0.35019[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35019 - acc: 0.8498 -- iter: 1280/3680
[A[ATraining Step: 5446  | total loss: [1m[32m0.34245[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34245 - acc: 0.8523 -- iter: 1312/3680
[A[ATraining Step: 5447  | total loss: [1m[32m0.35124[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35124 - acc: 0.8483 -- iter: 1344/3680
[A[ATraining Step: 5448  | total loss: [1m[32m0.34719[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34719 - acc: 0.8510 -- iter: 1376/3680
[A[ATraining Step: 5449  | total loss: [1m[32m0.33448[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33448 - acc: 0.8565 -- iter: 1408/3680
[A[ATraining Step: 5450  | total loss: [1m[32m0.34328[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34328 - acc: 0.8490 -- iter: 1440/3680
[A[ATraining Step: 5451  | total loss: [1m[32m0.35804[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35804 - acc: 0.8453 -- iter: 1472/3680
[A[ATraining Step: 5452  | total loss: [1m[32m0.35621[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35621 - acc: 0.8514 -- iter: 1504/3680
[A[ATraining Step: 5453  | total loss: [1m[32m0.34723[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34723 - acc: 0.8538 -- iter: 1536/3680
[A[ATraining Step: 5454  | total loss: [1m[32m0.34499[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34499 - acc: 0.8559 -- iter: 1568/3680
[A[ATraining Step: 5455  | total loss: [1m[32m0.34257[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34257 - acc: 0.8578 -- iter: 1600/3680
[A[ATraining Step: 5456  | total loss: [1m[32m0.34020[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34020 - acc: 0.8564 -- iter: 1632/3680
[A[ATraining Step: 5457  | total loss: [1m[32m0.33023[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33023 - acc: 0.8645 -- iter: 1664/3680
[A[ATraining Step: 5458  | total loss: [1m[32m0.34132[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34132 - acc: 0.8593 -- iter: 1696/3680
[A[ATraining Step: 5459  | total loss: [1m[32m0.33858[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33858 - acc: 0.8609 -- iter: 1728/3680
[A[ATraining Step: 5460  | total loss: [1m[32m0.35018[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35018 - acc: 0.8560 -- iter: 1760/3680
[A[ATraining Step: 5461  | total loss: [1m[32m0.35595[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35595 - acc: 0.8517 -- iter: 1792/3680
[A[ATraining Step: 5462  | total loss: [1m[32m0.34285[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34285 - acc: 0.8571 -- iter: 1824/3680
[A[ATraining Step: 5463  | total loss: [1m[32m0.36767[0m[0m
[2K| Adam | epoch: 048 | loss: 0.36767 - acc: 0.8464 -- iter: 1856/3680
[A[ATraining Step: 5464  | total loss: [1m[32m0.37729[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37729 - acc: 0.8337 -- iter: 1888/3680
[A[ATraining Step: 5465  | total loss: [1m[32m0.38876[0m[0m
[2K| Adam | epoch: 048 | loss: 0.38876 - acc: 0.8315 -- iter: 1920/3680
[A[ATraining Step: 5466  | total loss: [1m[32m0.40184[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40184 - acc: 0.8296 -- iter: 1952/3680
[A[ATraining Step: 5467  | total loss: [1m[32m0.40796[0m[0m
[2K| Adam | epoch: 048 | loss: 0.40796 - acc: 0.8279 -- iter: 1984/3680
[A[ATraining Step: 5468  | total loss: [1m[32m0.39801[0m[0m
[2K| Adam | epoch: 048 | loss: 0.39801 - acc: 0.8358 -- iter: 2016/3680
[A[ATraining Step: 5469  | total loss: [1m[32m0.39126[0m[0m
[2K| Adam | epoch: 048 | loss: 0.39126 - acc: 0.8366 -- iter: 2048/3680
[A[ATraining Step: 5470  | total loss: [1m[32m0.37674[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37674 - acc: 0.8435 -- iter: 2080/3680
[A[ATraining Step: 5471  | total loss: [1m[32m0.39029[0m[0m
[2K| Adam | epoch: 048 | loss: 0.39029 - acc: 0.8311 -- iter: 2112/3680
[A[ATraining Step: 5472  | total loss: [1m[32m0.38667[0m[0m
[2K| Adam | epoch: 048 | loss: 0.38667 - acc: 0.8386 -- iter: 2144/3680
[A[ATraining Step: 5473  | total loss: [1m[32m0.38552[0m[0m
[2K| Adam | epoch: 048 | loss: 0.38552 - acc: 0.8328 -- iter: 2176/3680
[A[ATraining Step: 5474  | total loss: [1m[32m0.37291[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37291 - acc: 0.8402 -- iter: 2208/3680
[A[ATraining Step: 5475  | total loss: [1m[32m0.35941[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35941 - acc: 0.8499 -- iter: 2240/3680
[A[ATraining Step: 5476  | total loss: [1m[32m0.34233[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34233 - acc: 0.8587 -- iter: 2272/3680
[A[ATraining Step: 5477  | total loss: [1m[32m0.33758[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33758 - acc: 0.8603 -- iter: 2304/3680
[A[ATraining Step: 5478  | total loss: [1m[32m0.33177[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33177 - acc: 0.8649 -- iter: 2336/3680
[A[ATraining Step: 5479  | total loss: [1m[32m0.34554[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34554 - acc: 0.8565 -- iter: 2368/3680
[A[ATraining Step: 5480  | total loss: [1m[32m0.33300[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33300 - acc: 0.8646 -- iter: 2400/3680
[A[ATraining Step: 5481  | total loss: [1m[32m0.31812[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31812 - acc: 0.8719 -- iter: 2432/3680
[A[ATraining Step: 5482  | total loss: [1m[32m0.31061[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31061 - acc: 0.8722 -- iter: 2464/3680
[A[ATraining Step: 5483  | total loss: [1m[32m0.32030[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32030 - acc: 0.8694 -- iter: 2496/3680
[A[ATraining Step: 5484  | total loss: [1m[32m0.32683[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32683 - acc: 0.8668 -- iter: 2528/3680
[A[ATraining Step: 5485  | total loss: [1m[32m0.32229[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32229 - acc: 0.8739 -- iter: 2560/3680
[A[ATraining Step: 5486  | total loss: [1m[32m0.31134[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31134 - acc: 0.8802 -- iter: 2592/3680
[A[ATraining Step: 5487  | total loss: [1m[32m0.31437[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31437 - acc: 0.8828 -- iter: 2624/3680
[A[ATraining Step: 5488  | total loss: [1m[32m0.31725[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31725 - acc: 0.8852 -- iter: 2656/3680
[A[ATraining Step: 5489  | total loss: [1m[32m0.32743[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32743 - acc: 0.8779 -- iter: 2688/3680
[A[ATraining Step: 5490  | total loss: [1m[32m0.33202[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33202 - acc: 0.8683 -- iter: 2720/3680
[A[ATraining Step: 5491  | total loss: [1m[32m0.33272[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33272 - acc: 0.8658 -- iter: 2752/3680
[A[ATraining Step: 5492  | total loss: [1m[32m0.33206[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33206 - acc: 0.8636 -- iter: 2784/3680
[A[ATraining Step: 5493  | total loss: [1m[32m0.35302[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35302 - acc: 0.8522 -- iter: 2816/3680
[A[ATraining Step: 5494  | total loss: [1m[32m0.34641[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34641 - acc: 0.8576 -- iter: 2848/3680
[A[ATraining Step: 5495  | total loss: [1m[32m0.34324[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34324 - acc: 0.8594 -- iter: 2880/3680
[A[ATraining Step: 5496  | total loss: [1m[32m0.34400[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34400 - acc: 0.8609 -- iter: 2912/3680
[A[ATraining Step: 5497  | total loss: [1m[32m0.33265[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33265 - acc: 0.8623 -- iter: 2944/3680
[A[ATraining Step: 5498  | total loss: [1m[32m0.32377[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32377 - acc: 0.8699 -- iter: 2976/3680
[A[ATraining Step: 5499  | total loss: [1m[32m0.32269[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32269 - acc: 0.8672 -- iter: 3008/3680
[A[ATraining Step: 5500  | total loss: [1m[32m0.33174[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33174 - acc: 0.8618 | val_loss: 0.35673 - val_acc: 0.8643 -- iter: 3040/3680
[A[ATraining Step: 5500  | total loss: [1m[32m0.33174[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33174 - acc: 0.8618 | val_loss: 0.35673 - val_acc: 0.8643 -- iter: 3040/3680
--
Training Step: 5501  | total loss: [1m[32m0.31641[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31641 - acc: 0.8725 -- iter: 3072/3680
[A[ATraining Step: 5502  | total loss: [1m[32m0.34529[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34529 - acc: 0.8633 -- iter: 3104/3680
[A[ATraining Step: 5503  | total loss: [1m[32m0.33067[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33067 - acc: 0.8739 -- iter: 3136/3680
[A[ATraining Step: 5504  | total loss: [1m[32m0.31600[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31600 - acc: 0.8802 -- iter: 3168/3680
[A[ATraining Step: 5505  | total loss: [1m[32m0.30510[0m[0m
[2K| Adam | epoch: 048 | loss: 0.30510 - acc: 0.8828 -- iter: 3200/3680
[A[ATraining Step: 5506  | total loss: [1m[32m0.32824[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32824 - acc: 0.8664 -- iter: 3232/3680
[A[ATraining Step: 5507  | total loss: [1m[32m0.31525[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31525 - acc: 0.8767 -- iter: 3264/3680
[A[ATraining Step: 5508  | total loss: [1m[32m0.30666[0m[0m
[2K| Adam | epoch: 048 | loss: 0.30666 - acc: 0.8796 -- iter: 3296/3680
[A[ATraining Step: 5509  | total loss: [1m[32m0.31609[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31609 - acc: 0.8667 -- iter: 3328/3680
[A[ATraining Step: 5510  | total loss: [1m[32m0.31613[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31613 - acc: 0.8748 -- iter: 3360/3680
[A[ATraining Step: 5511  | total loss: [1m[32m0.30632[0m[0m
[2K| Adam | epoch: 048 | loss: 0.30632 - acc: 0.8748 -- iter: 3392/3680
[A[ATraining Step: 5512  | total loss: [1m[32m0.31206[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31206 - acc: 0.8748 -- iter: 3424/3680
[A[ATraining Step: 5513  | total loss: [1m[32m0.31508[0m[0m
[2K| Adam | epoch: 048 | loss: 0.31508 - acc: 0.8748 -- iter: 3456/3680
[A[ATraining Step: 5514  | total loss: [1m[32m0.32441[0m[0m
[2K| Adam | epoch: 048 | loss: 0.32441 - acc: 0.8661 -- iter: 3488/3680
[A[ATraining Step: 5515  | total loss: [1m[32m0.33230[0m[0m
[2K| Adam | epoch: 048 | loss: 0.33230 - acc: 0.8483 -- iter: 3520/3680
[A[ATraining Step: 5516  | total loss: [1m[32m0.35490[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35490 - acc: 0.8483 -- iter: 3552/3680
[A[ATraining Step: 5517  | total loss: [1m[32m0.35512[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35512 - acc: 0.8447 -- iter: 3584/3680
[A[ATraining Step: 5518  | total loss: [1m[32m0.37103[0m[0m
[2K| Adam | epoch: 048 | loss: 0.37103 - acc: 0.8383 -- iter: 3616/3680
[A[ATraining Step: 5519  | total loss: [1m[32m0.35647[0m[0m
[2K| Adam | epoch: 048 | loss: 0.35647 - acc: 0.8572 -- iter: 3648/3680
[A[ATraining Step: 5520  | total loss: [1m[32m0.34423[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34423 - acc: 0.8572 | val_loss: 0.34400 - val_acc: 0.8654 -- iter: 3680/3680
[A[ATraining Step: 5520  | total loss: [1m[32m0.34423[0m[0m
[2K| Adam | epoch: 048 | loss: 0.34423 - acc: 0.8572 | val_loss: 0.34400 - val_acc: 0.8654 -- iter: 3680/3680
--
Training Step: 5521  | total loss: [1m[32m0.34392[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34392 - acc: 0.8558 -- iter: 0032/3680
[A[ATraining Step: 5522  | total loss: [1m[32m0.33178[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33178 - acc: 0.8578 -- iter: 0064/3680
[A[ATraining Step: 5523  | total loss: [1m[32m0.31711[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31711 - acc: 0.8657 -- iter: 0096/3680
[A[ATraining Step: 5524  | total loss: [1m[32m0.33272[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33272 - acc: 0.8573 -- iter: 0128/3680
[A[ATraining Step: 5525  | total loss: [1m[32m0.34301[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34301 - acc: 0.8497 -- iter: 0160/3680
[A[ATraining Step: 5526  | total loss: [1m[32m0.34789[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34789 - acc: 0.8522 -- iter: 0192/3680
[A[ATraining Step: 5527  | total loss: [1m[32m0.34844[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34844 - acc: 0.8482 -- iter: 0224/3680
[A[ATraining Step: 5528  | total loss: [1m[32m0.34199[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34199 - acc: 0.8509 -- iter: 0256/3680
[A[ATraining Step: 5529  | total loss: [1m[32m0.33944[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33944 - acc: 0.8502 -- iter: 0288/3680
[A[ATraining Step: 5530  | total loss: [1m[32m0.33692[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33692 - acc: 0.8527 -- iter: 0320/3680
[A[ATraining Step: 5531  | total loss: [1m[32m0.32543[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32543 - acc: 0.8580 -- iter: 0352/3680
[A[ATraining Step: 5532  | total loss: [1m[32m0.32002[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32002 - acc: 0.8629 -- iter: 0384/3680
[A[ATraining Step: 5533  | total loss: [1m[32m0.30989[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30989 - acc: 0.8703 -- iter: 0416/3680
[A[ATraining Step: 5534  | total loss: [1m[32m0.32838[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32838 - acc: 0.8583 -- iter: 0448/3680
[A[ATraining Step: 5535  | total loss: [1m[32m0.33251[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33251 - acc: 0.8568 -- iter: 0480/3680
[A[ATraining Step: 5536  | total loss: [1m[32m0.33646[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33646 - acc: 0.8524 -- iter: 0512/3680
[A[ATraining Step: 5537  | total loss: [1m[32m0.33371[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33371 - acc: 0.8547 -- iter: 0544/3680
[A[ATraining Step: 5538  | total loss: [1m[32m0.34535[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34535 - acc: 0.8463 -- iter: 0576/3680
[A[ATraining Step: 5539  | total loss: [1m[32m0.36982[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36982 - acc: 0.8463 -- iter: 0608/3680
[A[ATraining Step: 5540  | total loss: [1m[32m0.35858[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35858 - acc: 0.8555 -- iter: 0640/3680
[A[ATraining Step: 5541  | total loss: [1m[32m0.35913[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35913 - acc: 0.8543 -- iter: 0672/3680
[A[ATraining Step: 5542  | total loss: [1m[32m0.35422[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35422 - acc: 0.8595 -- iter: 0704/3680
[A[ATraining Step: 5543  | total loss: [1m[32m0.35870[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35870 - acc: 0.8579 -- iter: 0736/3680
[A[ATraining Step: 5544  | total loss: [1m[32m0.35727[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35727 - acc: 0.8596 -- iter: 0768/3680
[A[ATraining Step: 5545  | total loss: [1m[32m0.35682[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35682 - acc: 0.8580 -- iter: 0800/3680
[A[ATraining Step: 5546  | total loss: [1m[32m0.34562[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34562 - acc: 0.8629 -- iter: 0832/3680
[A[ATraining Step: 5547  | total loss: [1m[32m0.35730[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35730 - acc: 0.8547 -- iter: 0864/3680
[A[ATraining Step: 5548  | total loss: [1m[32m0.36459[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36459 - acc: 0.8473 -- iter: 0896/3680
[A[ATraining Step: 5549  | total loss: [1m[32m0.36329[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36329 - acc: 0.8439 -- iter: 0928/3680
[A[ATraining Step: 5550  | total loss: [1m[32m0.36441[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36441 - acc: 0.8407 -- iter: 0960/3680
[A[ATraining Step: 5551  | total loss: [1m[32m0.35338[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35338 - acc: 0.8504 -- iter: 0992/3680
[A[ATraining Step: 5552  | total loss: [1m[32m0.34854[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34854 - acc: 0.8529 -- iter: 1024/3680
[A[ATraining Step: 5553  | total loss: [1m[32m0.36038[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36038 - acc: 0.8488 -- iter: 1056/3680
[A[ATraining Step: 5554  | total loss: [1m[32m0.36183[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36183 - acc: 0.8483 -- iter: 1088/3680
[A[ATraining Step: 5555  | total loss: [1m[32m0.36850[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36850 - acc: 0.8447 -- iter: 1120/3680
[A[ATraining Step: 5556  | total loss: [1m[32m0.37018[0m[0m
[2K| Adam | epoch: 049 | loss: 0.37018 - acc: 0.8415 -- iter: 1152/3680
[A[ATraining Step: 5557  | total loss: [1m[32m0.36596[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36596 - acc: 0.8449 -- iter: 1184/3680
[A[ATraining Step: 5558  | total loss: [1m[32m0.35985[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35985 - acc: 0.8510 -- iter: 1216/3680
[A[ATraining Step: 5559  | total loss: [1m[32m0.34707[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34707 - acc: 0.8565 -- iter: 1248/3680
[A[ATraining Step: 5560  | total loss: [1m[32m0.33199[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33199 - acc: 0.8677 -- iter: 1280/3680
[A[ATraining Step: 5561  | total loss: [1m[32m0.31741[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31741 - acc: 0.8778 -- iter: 1312/3680
[A[ATraining Step: 5562  | total loss: [1m[32m0.31971[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31971 - acc: 0.8744 -- iter: 1344/3680
[A[ATraining Step: 5563  | total loss: [1m[32m0.32872[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32872 - acc: 0.8620 -- iter: 1376/3680
[A[ATraining Step: 5564  | total loss: [1m[32m0.32170[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32170 - acc: 0.8664 -- iter: 1408/3680
[A[ATraining Step: 5565  | total loss: [1m[32m0.32380[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32380 - acc: 0.8610 -- iter: 1440/3680
[A[ATraining Step: 5566  | total loss: [1m[32m0.32405[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32405 - acc: 0.8593 -- iter: 1472/3680
[A[ATraining Step: 5567  | total loss: [1m[32m0.32463[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32463 - acc: 0.8577 -- iter: 1504/3680
[A[ATraining Step: 5568  | total loss: [1m[32m0.32801[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32801 - acc: 0.8563 -- iter: 1536/3680
[A[ATraining Step: 5569  | total loss: [1m[32m0.33358[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33358 - acc: 0.8551 -- iter: 1568/3680
[A[ATraining Step: 5570  | total loss: [1m[32m0.33246[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33246 - acc: 0.8508 -- iter: 1600/3680
[A[ATraining Step: 5571  | total loss: [1m[32m0.31830[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31830 - acc: 0.8626 -- iter: 1632/3680
[A[ATraining Step: 5572  | total loss: [1m[32m0.32158[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32158 - acc: 0.8545 -- iter: 1664/3680
[A[ATraining Step: 5573  | total loss: [1m[32m0.32592[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32592 - acc: 0.8534 -- iter: 1696/3680
[A[ATraining Step: 5574  | total loss: [1m[32m0.33566[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33566 - acc: 0.8493 -- iter: 1728/3680
[A[ATraining Step: 5575  | total loss: [1m[32m0.33884[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33884 - acc: 0.8425 -- iter: 1760/3680
[A[ATraining Step: 5576  | total loss: [1m[32m0.33316[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33316 - acc: 0.8489 -- iter: 1792/3680
[A[ATraining Step: 5577  | total loss: [1m[32m0.32746[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32746 - acc: 0.8546 -- iter: 1824/3680
[A[ATraining Step: 5578  | total loss: [1m[32m0.34001[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34001 - acc: 0.8410 -- iter: 1856/3680
[A[ATraining Step: 5579  | total loss: [1m[32m0.33534[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33534 - acc: 0.8538 -- iter: 1888/3680
[A[ATraining Step: 5580  | total loss: [1m[32m0.33475[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33475 - acc: 0.8559 -- iter: 1920/3680
[A[ATraining Step: 5581  | total loss: [1m[32m0.32472[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32472 - acc: 0.8610 -- iter: 1952/3680
[A[ATraining Step: 5582  | total loss: [1m[32m0.31219[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31219 - acc: 0.8686 -- iter: 1984/3680
[A[ATraining Step: 5583  | total loss: [1m[32m0.33043[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33043 - acc: 0.8568 -- iter: 2016/3680
[A[ATraining Step: 5584  | total loss: [1m[32m0.31836[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31836 - acc: 0.8648 -- iter: 2048/3680
[A[ATraining Step: 5585  | total loss: [1m[32m0.31176[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31176 - acc: 0.8658 -- iter: 2080/3680
[A[ATraining Step: 5586  | total loss: [1m[32m0.30738[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30738 - acc: 0.8699 -- iter: 2112/3680
[A[ATraining Step: 5587  | total loss: [1m[32m0.33655[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33655 - acc: 0.8548 -- iter: 2144/3680
[A[ATraining Step: 5588  | total loss: [1m[32m0.34026[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34026 - acc: 0.8537 -- iter: 2176/3680
[A[ATraining Step: 5589  | total loss: [1m[32m0.34063[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34063 - acc: 0.8496 -- iter: 2208/3680
[A[ATraining Step: 5590  | total loss: [1m[32m0.32871[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32871 - acc: 0.8583 -- iter: 2240/3680
[A[ATraining Step: 5591  | total loss: [1m[32m0.32035[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32035 - acc: 0.8631 -- iter: 2272/3680
[A[ATraining Step: 5592  | total loss: [1m[32m0.31694[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31694 - acc: 0.8612 -- iter: 2304/3680
[A[ATraining Step: 5593  | total loss: [1m[32m0.31940[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31940 - acc: 0.8626 -- iter: 2336/3680
[A[ATraining Step: 5594  | total loss: [1m[32m0.31119[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31119 - acc: 0.8669 -- iter: 2368/3680
[A[ATraining Step: 5595  | total loss: [1m[32m0.31301[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31301 - acc: 0.8584 -- iter: 2400/3680
[A[ATraining Step: 5596  | total loss: [1m[32m0.33035[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33035 - acc: 0.8538 -- iter: 2432/3680
[A[ATraining Step: 5597  | total loss: [1m[32m0.33071[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33071 - acc: 0.8559 -- iter: 2464/3680
[A[ATraining Step: 5598  | total loss: [1m[32m0.33012[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33012 - acc: 0.8609 -- iter: 2496/3680
[A[ATraining Step: 5599  | total loss: [1m[32m0.32147[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32147 - acc: 0.8655 -- iter: 2528/3680
[A[ATraining Step: 5600  | total loss: [1m[32m0.32078[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32078 - acc: 0.8664 | val_loss: 0.31365 - val_acc: 0.8871 -- iter: 2560/3680
[A[ATraining Step: 5600  | total loss: [1m[32m0.32078[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32078 - acc: 0.8664 | val_loss: 0.31365 - val_acc: 0.8871 -- iter: 2560/3680
--
Training Step: 5601  | total loss: [1m[32m0.32256[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32256 - acc: 0.8673 -- iter: 2592/3680
[A[ATraining Step: 5602  | total loss: [1m[32m0.31459[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31459 - acc: 0.8681 -- iter: 2624/3680
[A[ATraining Step: 5603  | total loss: [1m[32m0.30947[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30947 - acc: 0.8750 -- iter: 2656/3680
[A[ATraining Step: 5604  | total loss: [1m[32m0.30521[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30521 - acc: 0.8781 -- iter: 2688/3680
[A[ATraining Step: 5605  | total loss: [1m[32m0.32574[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32574 - acc: 0.8684 -- iter: 2720/3680
[A[ATraining Step: 5606  | total loss: [1m[32m0.31519[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31519 - acc: 0.8722 -- iter: 2752/3680
[A[ATraining Step: 5607  | total loss: [1m[32m0.30921[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30921 - acc: 0.8787 -- iter: 2784/3680
[A[ATraining Step: 5608  | total loss: [1m[32m0.30997[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30997 - acc: 0.8815 -- iter: 2816/3680
[A[ATraining Step: 5609  | total loss: [1m[32m0.32544[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32544 - acc: 0.8683 -- iter: 2848/3680
[A[ATraining Step: 5610  | total loss: [1m[32m0.33490[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33490 - acc: 0.8565 -- iter: 2880/3680
[A[ATraining Step: 5611  | total loss: [1m[32m0.32467[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32467 - acc: 0.8615 -- iter: 2912/3680
[A[ATraining Step: 5612  | total loss: [1m[32m0.31481[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31481 - acc: 0.8660 -- iter: 2944/3680
[A[ATraining Step: 5613  | total loss: [1m[32m0.31516[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31516 - acc: 0.8575 -- iter: 2976/3680
[A[ATraining Step: 5614  | total loss: [1m[32m0.31085[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31085 - acc: 0.8624 -- iter: 3008/3680
[A[ATraining Step: 5615  | total loss: [1m[32m0.33545[0m[0m
[2K| Adam | epoch: 049 | loss: 0.33545 - acc: 0.8574 -- iter: 3040/3680
[A[ATraining Step: 5616  | total loss: [1m[32m0.32625[0m[0m
[2K| Adam | epoch: 049 | loss: 0.32625 - acc: 0.8623 -- iter: 3072/3680
[A[ATraining Step: 5617  | total loss: [1m[32m0.30871[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30871 - acc: 0.8698 -- iter: 3104/3680
[A[ATraining Step: 5618  | total loss: [1m[32m0.31005[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31005 - acc: 0.8703 -- iter: 3136/3680
[A[ATraining Step: 5619  | total loss: [1m[32m0.30471[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30471 - acc: 0.8739 -- iter: 3168/3680
[A[ATraining Step: 5620  | total loss: [1m[32m0.31354[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31354 - acc: 0.8709 -- iter: 3200/3680
[A[ATraining Step: 5621  | total loss: [1m[32m0.31023[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31023 - acc: 0.8682 -- iter: 3232/3680
[A[ATraining Step: 5622  | total loss: [1m[32m0.30335[0m[0m
[2K| Adam | epoch: 049 | loss: 0.30335 - acc: 0.8720 -- iter: 3264/3680
[A[ATraining Step: 5623  | total loss: [1m[32m0.31501[0m[0m
[2K| Adam | epoch: 049 | loss: 0.31501 - acc: 0.8629 -- iter: 3296/3680
[A[ATraining Step: 5624  | total loss: [1m[32m0.34311[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34311 - acc: 0.8516 -- iter: 3328/3680
[A[ATraining Step: 5625  | total loss: [1m[32m0.34848[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34848 - acc: 0.8540 -- iter: 3360/3680
[A[ATraining Step: 5626  | total loss: [1m[32m0.35418[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35418 - acc: 0.8436 -- iter: 3392/3680
[A[ATraining Step: 5627  | total loss: [1m[32m0.35013[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35013 - acc: 0.8467 -- iter: 3424/3680
[A[ATraining Step: 5628  | total loss: [1m[32m0.34609[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34609 - acc: 0.8433 -- iter: 3456/3680
[A[ATraining Step: 5629  | total loss: [1m[32m0.35491[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35491 - acc: 0.8402 -- iter: 3488/3680
[A[ATraining Step: 5630  | total loss: [1m[32m0.34636[0m[0m
[2K| Adam | epoch: 049 | loss: 0.34636 - acc: 0.8468 -- iter: 3520/3680
[A[ATraining Step: 5631  | total loss: [1m[32m0.35069[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35069 - acc: 0.8528 -- iter: 3552/3680
[A[ATraining Step: 5632  | total loss: [1m[32m0.35331[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35331 - acc: 0.8519 -- iter: 3584/3680
[A[ATraining Step: 5633  | total loss: [1m[32m0.37014[0m[0m
[2K| Adam | epoch: 049 | loss: 0.37014 - acc: 0.8448 -- iter: 3616/3680
[A[ATraining Step: 5634  | total loss: [1m[32m0.36010[0m[0m
[2K| Adam | epoch: 049 | loss: 0.36010 - acc: 0.8509 -- iter: 3648/3680
[A[ATraining Step: 5635  | total loss: [1m[32m0.35574[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35574 - acc: 0.8596 | val_loss: 0.34343 - val_acc: 0.8621 -- iter: 3680/3680
[A[ATraining Step: 5635  | total loss: [1m[32m0.35574[0m[0m
[2K| Adam | epoch: 049 | loss: 0.35574 - acc: 0.8596 | val_loss: 0.34343 - val_acc: 0.8621 -- iter: 3680/3680
--
Training Step: 5636  | total loss: [1m[32m0.34575[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34575 - acc: 0.8643 -- iter: 0032/3680
[A[ATraining Step: 5637  | total loss: [1m[32m0.33076[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33076 - acc: 0.8747 -- iter: 0064/3680
[A[ATraining Step: 5638  | total loss: [1m[32m0.33136[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33136 - acc: 0.8716 -- iter: 0096/3680
[A[ATraining Step: 5639  | total loss: [1m[32m0.36374[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36374 - acc: 0.8532 -- iter: 0128/3680
[A[ATraining Step: 5640  | total loss: [1m[32m0.37847[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37847 - acc: 0.8460 -- iter: 0160/3680
[A[ATraining Step: 5641  | total loss: [1m[32m0.35967[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35967 - acc: 0.8571 -- iter: 0192/3680
[A[ATraining Step: 5642  | total loss: [1m[32m0.35844[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35844 - acc: 0.8571 -- iter: 0224/3680
[A[ATraining Step: 5643  | total loss: [1m[32m0.36589[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36589 - acc: 0.8464 -- iter: 0256/3680
[A[ATraining Step: 5644  | total loss: [1m[32m0.37488[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37488 - acc: 0.8430 -- iter: 0288/3680
[A[ATraining Step: 5645  | total loss: [1m[32m0.37508[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37508 - acc: 0.8494 -- iter: 0320/3680
[A[ATraining Step: 5646  | total loss: [1m[32m0.37462[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37462 - acc: 0.8457 -- iter: 0352/3680
[A[ATraining Step: 5647  | total loss: [1m[32m0.36708[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36708 - acc: 0.8486 -- iter: 0384/3680
[A[ATraining Step: 5648  | total loss: [1m[32m0.35958[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35958 - acc: 0.8544 -- iter: 0416/3680
[A[ATraining Step: 5649  | total loss: [1m[32m0.39890[0m[0m
[2K| Adam | epoch: 050 | loss: 0.39890 - acc: 0.8471 -- iter: 0448/3680
[A[ATraining Step: 5650  | total loss: [1m[32m0.40396[0m[0m
[2K| Adam | epoch: 050 | loss: 0.40396 - acc: 0.8436 -- iter: 0480/3680
[A[ATraining Step: 5651  | total loss: [1m[32m0.38382[0m[0m
[2K| Adam | epoch: 050 | loss: 0.38382 - acc: 0.8499 -- iter: 0512/3680
[A[ATraining Step: 5652  | total loss: [1m[32m0.44311[0m[0m
[2K| Adam | epoch: 050 | loss: 0.44311 - acc: 0.8336 -- iter: 0544/3680
[A[ATraining Step: 5653  | total loss: [1m[32m0.42510[0m[0m
[2K| Adam | epoch: 050 | loss: 0.42510 - acc: 0.8378 -- iter: 0576/3680
[A[ATraining Step: 5654  | total loss: [1m[32m0.41356[0m[0m
[2K| Adam | epoch: 050 | loss: 0.41356 - acc: 0.8415 -- iter: 0608/3680
[A[ATraining Step: 5655  | total loss: [1m[32m0.39351[0m[0m
[2K| Adam | epoch: 050 | loss: 0.39351 - acc: 0.8511 -- iter: 0640/3680
[A[ATraining Step: 5656  | total loss: [1m[32m0.41118[0m[0m
[2K| Adam | epoch: 050 | loss: 0.41118 - acc: 0.8379 -- iter: 0672/3680
[A[ATraining Step: 5657  | total loss: [1m[32m0.40395[0m[0m
[2K| Adam | epoch: 050 | loss: 0.40395 - acc: 0.8384 -- iter: 0704/3680
[A[ATraining Step: 5658  | total loss: [1m[32m0.38150[0m[0m
[2K| Adam | epoch: 050 | loss: 0.38150 - acc: 0.8484 -- iter: 0736/3680
[A[ATraining Step: 5659  | total loss: [1m[32m0.36898[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36898 - acc: 0.8573 -- iter: 0768/3680
[A[ATraining Step: 5660  | total loss: [1m[32m0.36382[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36382 - acc: 0.8622 -- iter: 0800/3680
[A[ATraining Step: 5661  | total loss: [1m[32m0.36384[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36384 - acc: 0.8541 -- iter: 0832/3680
[A[ATraining Step: 5662  | total loss: [1m[32m0.35833[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35833 - acc: 0.8562 -- iter: 0864/3680
[A[ATraining Step: 5663  | total loss: [1m[32m0.35233[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35233 - acc: 0.8580 -- iter: 0896/3680
[A[ATraining Step: 5664  | total loss: [1m[32m0.34483[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34483 - acc: 0.8629 -- iter: 0928/3680
[A[ATraining Step: 5665  | total loss: [1m[32m0.33147[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33147 - acc: 0.8735 -- iter: 0960/3680
[A[ATraining Step: 5666  | total loss: [1m[32m0.35614[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35614 - acc: 0.8611 -- iter: 0992/3680
[A[ATraining Step: 5667  | total loss: [1m[32m0.34812[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34812 - acc: 0.8625 -- iter: 1024/3680
[A[ATraining Step: 5668  | total loss: [1m[32m0.36098[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36098 - acc: 0.8544 -- iter: 1056/3680
[A[ATraining Step: 5669  | total loss: [1m[32m0.34960[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34960 - acc: 0.8596 -- iter: 1088/3680
[A[ATraining Step: 5670  | total loss: [1m[32m0.35662[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35662 - acc: 0.8549 -- iter: 1120/3680
[A[ATraining Step: 5671  | total loss: [1m[32m0.36269[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36269 - acc: 0.8475 -- iter: 1152/3680
[A[ATraining Step: 5672  | total loss: [1m[32m0.35993[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35993 - acc: 0.8502 -- iter: 1184/3680
[A[ATraining Step: 5673  | total loss: [1m[32m0.34934[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34934 - acc: 0.8558 -- iter: 1216/3680
[A[ATraining Step: 5674  | total loss: [1m[32m0.34324[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34324 - acc: 0.8532 -- iter: 1248/3680
[A[ATraining Step: 5675  | total loss: [1m[32m0.34373[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34373 - acc: 0.8532 -- iter: 1280/3680
[A[ATraining Step: 5676  | total loss: [1m[32m0.34475[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34475 - acc: 0.8492 -- iter: 1312/3680
[A[ATraining Step: 5677  | total loss: [1m[32m0.37401[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37401 - acc: 0.8330 -- iter: 1344/3680
[A[ATraining Step: 5678  | total loss: [1m[32m0.37668[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37668 - acc: 0.8341 -- iter: 1376/3680
[A[ATraining Step: 5679  | total loss: [1m[32m0.36248[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36248 - acc: 0.8413 -- iter: 1408/3680
[A[ATraining Step: 5680  | total loss: [1m[32m0.35708[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35708 - acc: 0.8447 -- iter: 1440/3680
[A[ATraining Step: 5681  | total loss: [1m[32m0.36106[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36106 - acc: 0.8414 -- iter: 1472/3680
[A[ATraining Step: 5682  | total loss: [1m[32m0.37305[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37305 - acc: 0.8323 -- iter: 1504/3680
[A[ATraining Step: 5683  | total loss: [1m[32m0.37734[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37734 - acc: 0.8334 -- iter: 1536/3680
[A[ATraining Step: 5684  | total loss: [1m[32m0.35978[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35978 - acc: 0.8470 -- iter: 1568/3680
[A[ATraining Step: 5685  | total loss: [1m[32m0.35795[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35795 - acc: 0.8467 -- iter: 1600/3680
[A[ATraining Step: 5686  | total loss: [1m[32m0.37120[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37120 - acc: 0.8432 -- iter: 1632/3680
[A[ATraining Step: 5687  | total loss: [1m[32m0.36913[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36913 - acc: 0.8464 -- iter: 1664/3680
[A[ATraining Step: 5688  | total loss: [1m[32m0.36890[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36890 - acc: 0.8430 -- iter: 1696/3680
[A[ATraining Step: 5689  | total loss: [1m[32m0.35293[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35293 - acc: 0.8556 -- iter: 1728/3680
[A[ATraining Step: 5690  | total loss: [1m[32m0.35575[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35575 - acc: 0.8513 -- iter: 1760/3680
[A[ATraining Step: 5691  | total loss: [1m[32m0.35771[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35771 - acc: 0.8568 -- iter: 1792/3680
[A[ATraining Step: 5692  | total loss: [1m[32m0.37573[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37573 - acc: 0.8524 -- iter: 1824/3680
[A[ATraining Step: 5693  | total loss: [1m[32m0.37206[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37206 - acc: 0.8515 -- iter: 1856/3680
[A[ATraining Step: 5694  | total loss: [1m[32m0.37028[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37028 - acc: 0.8570 -- iter: 1888/3680
[A[ATraining Step: 5695  | total loss: [1m[32m0.36239[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36239 - acc: 0.8650 -- iter: 1920/3680
[A[ATraining Step: 5696  | total loss: [1m[32m0.35927[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35927 - acc: 0.8629 -- iter: 1952/3680
[A[ATraining Step: 5697  | total loss: [1m[32m0.34269[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34269 - acc: 0.8735 -- iter: 1984/3680
[A[ATraining Step: 5698  | total loss: [1m[32m0.34598[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34598 - acc: 0.8611 -- iter: 2016/3680
[A[ATraining Step: 5699  | total loss: [1m[32m0.35113[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35113 - acc: 0.8625 -- iter: 2048/3680
[A[ATraining Step: 5700  | total loss: [1m[32m0.34821[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34821 - acc: 0.8606 | val_loss: 0.33325 - val_acc: 0.8740 -- iter: 2080/3680
[A[ATraining Step: 5700  | total loss: [1m[32m0.34821[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34821 - acc: 0.8606 | val_loss: 0.33325 - val_acc: 0.8740 -- iter: 2080/3680
--
Training Step: 5701  | total loss: [1m[32m0.34398[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34398 - acc: 0.8621 -- iter: 2112/3680
[A[ATraining Step: 5702  | total loss: [1m[32m0.34337[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34337 - acc: 0.8727 -- iter: 2144/3680
[A[ATraining Step: 5703  | total loss: [1m[32m0.33445[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33445 - acc: 0.8761 -- iter: 2176/3680
[A[ATraining Step: 5704  | total loss: [1m[32m0.37048[0m[0m
[2K| Adam | epoch: 050 | loss: 0.37048 - acc: 0.8572 -- iter: 2208/3680
[A[ATraining Step: 5705  | total loss: [1m[32m0.36759[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36759 - acc: 0.8496 -- iter: 2240/3680
[A[ATraining Step: 5706  | total loss: [1m[32m0.38161[0m[0m
[2K| Adam | epoch: 050 | loss: 0.38161 - acc: 0.8490 -- iter: 2272/3680
[A[ATraining Step: 5707  | total loss: [1m[32m0.38704[0m[0m
[2K| Adam | epoch: 050 | loss: 0.38704 - acc: 0.8359 -- iter: 2304/3680
[A[ATraining Step: 5708  | total loss: [1m[32m0.38310[0m[0m
[2K| Adam | epoch: 050 | loss: 0.38310 - acc: 0.8359 -- iter: 2336/3680
[A[ATraining Step: 5709  | total loss: [1m[32m0.36773[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36773 - acc: 0.8460 -- iter: 2368/3680
[A[ATraining Step: 5710  | total loss: [1m[32m0.35695[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35695 - acc: 0.8520 -- iter: 2400/3680
[A[ATraining Step: 5711  | total loss: [1m[32m0.34649[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34649 - acc: 0.8543 -- iter: 2432/3680
[A[ATraining Step: 5712  | total loss: [1m[32m0.36468[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36468 - acc: 0.8470 -- iter: 2464/3680
[A[ATraining Step: 5713  | total loss: [1m[32m0.35873[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35873 - acc: 0.8467 -- iter: 2496/3680
[A[ATraining Step: 5714  | total loss: [1m[32m0.34491[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34491 - acc: 0.8558 -- iter: 2528/3680
[A[ATraining Step: 5715  | total loss: [1m[32m0.33447[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33447 - acc: 0.8640 -- iter: 2560/3680
[A[ATraining Step: 5716  | total loss: [1m[32m0.35215[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35215 - acc: 0.8526 -- iter: 2592/3680
[A[ATraining Step: 5717  | total loss: [1m[32m0.35900[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35900 - acc: 0.8486 -- iter: 2624/3680
[A[ATraining Step: 5718  | total loss: [1m[32m0.36203[0m[0m
[2K| Adam | epoch: 050 | loss: 0.36203 - acc: 0.8512 -- iter: 2656/3680
[A[ATraining Step: 5719  | total loss: [1m[32m0.35158[0m[0m
[2K| Adam | epoch: 050 | loss: 0.35158 - acc: 0.8567 -- iter: 2688/3680
[A[ATraining Step: 5720  | total loss: [1m[32m0.34708[0m[0m
[2K| Adam | epoch: 050 | loss: 0.34708 - acc: 0.8617 -- iter: 2720/3680
[A[ATraining Step: 5721  | total loss: [1m[32m0.33784[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33784 - acc: 0.8692 -- iter: 2752/3680
[A[ATraining Step: 5722  | total loss: [1m[32m0.33967[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33967 - acc: 0.8667 -- iter: 2784/3680
[A[ATraining Step: 5723  | total loss: [1m[32m0.32957[0m[0m
[2K| Adam | epoch: 050 | loss: 0.32957 - acc: 0.8738 -- iter: 2816/3680
[A[ATraining Step: 5724  | total loss: [1m[32m0.33045[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33045 - acc: 0.8770 -- iter: 2848/3680
[A[ATraining Step: 5725  | total loss: [1m[32m0.31591[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31591 - acc: 0.8831 -- iter: 2880/3680
[A[ATraining Step: 5726  | total loss: [1m[32m0.31592[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31592 - acc: 0.8854 -- iter: 2912/3680
[A[ATraining Step: 5727  | total loss: [1m[32m0.31095[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31095 - acc: 0.8875 -- iter: 2944/3680
[A[ATraining Step: 5728  | total loss: [1m[32m0.29482[0m[0m
[2K| Adam | epoch: 050 | loss: 0.29482 - acc: 0.8894 -- iter: 2976/3680
[A[ATraining Step: 5729  | total loss: [1m[32m0.30839[0m[0m
[2K| Adam | epoch: 050 | loss: 0.30839 - acc: 0.8848 -- iter: 3008/3680
[A[ATraining Step: 5730  | total loss: [1m[32m0.31859[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31859 - acc: 0.8744 -- iter: 3040/3680
[A[ATraining Step: 5731  | total loss: [1m[32m0.31251[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31251 - acc: 0.8745 -- iter: 3072/3680
[A[ATraining Step: 5732  | total loss: [1m[32m0.30278[0m[0m
[2K| Adam | epoch: 050 | loss: 0.30278 - acc: 0.8808 -- iter: 3104/3680
[A[ATraining Step: 5733  | total loss: [1m[32m0.29738[0m[0m
[2K| Adam | epoch: 050 | loss: 0.29738 - acc: 0.8865 -- iter: 3136/3680
[A[ATraining Step: 5734  | total loss: [1m[32m0.31084[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31084 - acc: 0.8853 -- iter: 3168/3680
[A[ATraining Step: 5735  | total loss: [1m[32m0.30786[0m[0m
[2K| Adam | epoch: 050 | loss: 0.30786 - acc: 0.8812 -- iter: 3200/3680
[A[ATraining Step: 5736  | total loss: [1m[32m0.30303[0m[0m
[2K| Adam | epoch: 050 | loss: 0.30303 - acc: 0.8837 -- iter: 3232/3680
[A[ATraining Step: 5737  | total loss: [1m[32m0.31215[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31215 - acc: 0.8766 -- iter: 3264/3680
[A[ATraining Step: 5738  | total loss: [1m[32m0.31842[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31842 - acc: 0.8733 -- iter: 3296/3680
[A[ATraining Step: 5739  | total loss: [1m[32m0.32508[0m[0m
[2K| Adam | epoch: 050 | loss: 0.32508 - acc: 0.8703 -- iter: 3328/3680
[A[ATraining Step: 5740  | total loss: [1m[32m0.32767[0m[0m
[2K| Adam | epoch: 050 | loss: 0.32767 - acc: 0.8645 -- iter: 3360/3680
[A[ATraining Step: 5741  | total loss: [1m[32m0.33528[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33528 - acc: 0.8687 -- iter: 3392/3680
[A[ATraining Step: 5742  | total loss: [1m[32m0.32062[0m[0m
[2K| Adam | epoch: 050 | loss: 0.32062 - acc: 0.8787 -- iter: 3424/3680
[A[ATraining Step: 5743  | total loss: [1m[32m0.31630[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31630 - acc: 0.8783 -- iter: 3456/3680
[A[ATraining Step: 5744  | total loss: [1m[32m0.30721[0m[0m
[2K| Adam | epoch: 050 | loss: 0.30721 - acc: 0.8843 -- iter: 3488/3680
[A[ATraining Step: 5745  | total loss: [1m[32m0.31721[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31721 - acc: 0.8771 -- iter: 3520/3680
[A[ATraining Step: 5746  | total loss: [1m[32m0.33401[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33401 - acc: 0.8644 -- iter: 3552/3680
[A[ATraining Step: 5747  | total loss: [1m[32m0.33043[0m[0m
[2K| Adam | epoch: 050 | loss: 0.33043 - acc: 0.8654 -- iter: 3584/3680
[A[ATraining Step: 5748  | total loss: [1m[32m0.31388[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31388 - acc: 0.8726 -- iter: 3616/3680
[A[ATraining Step: 5749  | total loss: [1m[32m0.31194[0m[0m
[2K| Adam | epoch: 050 | loss: 0.31194 - acc: 0.8760 -- iter: 3648/3680
[A[ATraining Step: 5750  | total loss: [1m[32m0.32112[0m[0m
[2K| Adam | epoch: 050 | loss: 0.32112 - acc: 0.8665 | val_loss: 0.32869 - val_acc: 0.8806 -- iter: 3680/3680
[A[ATraining Step: 5750  | total loss: [1m[32m0.32112[0m[0m
[2K| Adam | epoch: 050 | loss: 0.32112 - acc: 0.8665 | val_loss: 0.32869 - val_acc: 0.8806 -- iter: 3680/3680
--
Training Step: 5751  | total loss: [1m[32m0.33074[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33074 - acc: 0.8580 -- iter: 0032/3680
[A[ATraining Step: 5752  | total loss: [1m[32m0.33173[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33173 - acc: 0.8597 -- iter: 0064/3680
[A[ATraining Step: 5753  | total loss: [1m[32m0.31519[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31519 - acc: 0.8644 -- iter: 0096/3680
[A[ATraining Step: 5754  | total loss: [1m[32m0.32701[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32701 - acc: 0.8592 -- iter: 0128/3680
[A[ATraining Step: 5755  | total loss: [1m[32m0.32560[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32560 - acc: 0.8576 -- iter: 0160/3680
[A[ATraining Step: 5756  | total loss: [1m[32m0.32066[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32066 - acc: 0.8625 -- iter: 0192/3680
[A[ATraining Step: 5757  | total loss: [1m[32m0.33410[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33410 - acc: 0.8606 -- iter: 0224/3680
[A[ATraining Step: 5758  | total loss: [1m[32m0.33255[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33255 - acc: 0.8621 -- iter: 0256/3680
[A[ATraining Step: 5759  | total loss: [1m[32m0.34598[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34598 - acc: 0.8571 -- iter: 0288/3680
[A[ATraining Step: 5760  | total loss: [1m[32m0.35137[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35137 - acc: 0.8620 -- iter: 0320/3680
[A[ATraining Step: 5761  | total loss: [1m[32m0.35142[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35142 - acc: 0.8633 -- iter: 0352/3680
[A[ATraining Step: 5762  | total loss: [1m[32m0.35749[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35749 - acc: 0.8537 -- iter: 0384/3680
[A[ATraining Step: 5763  | total loss: [1m[32m0.36815[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36815 - acc: 0.8537 -- iter: 0416/3680
[A[ATraining Step: 5764  | total loss: [1m[32m0.38892[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38892 - acc: 0.8527 -- iter: 0448/3680
[A[ATraining Step: 5765  | total loss: [1m[32m0.38145[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38145 - acc: 0.8518 -- iter: 0480/3680
[A[ATraining Step: 5766  | total loss: [1m[32m0.38689[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38689 - acc: 0.8541 -- iter: 0512/3680
[A[ATraining Step: 5767  | total loss: [1m[32m0.37210[0m[0m
[2K| Adam | epoch: 051 | loss: 0.37210 - acc: 0.8624 -- iter: 0544/3680
[A[ATraining Step: 5768  | total loss: [1m[32m0.46417[0m[0m
[2K| Adam | epoch: 051 | loss: 0.46417 - acc: 0.8262 -- iter: 0576/3680
[A[ATraining Step: 5769  | total loss: [1m[32m0.44833[0m[0m
[2K| Adam | epoch: 051 | loss: 0.44833 - acc: 0.8311 -- iter: 0608/3680
[A[ATraining Step: 5770  | total loss: [1m[32m0.43340[0m[0m
[2K| Adam | epoch: 051 | loss: 0.43340 - acc: 0.8355 -- iter: 0640/3680
[A[ATraining Step: 5771  | total loss: [1m[32m0.43678[0m[0m
[2K| Adam | epoch: 051 | loss: 0.43678 - acc: 0.8363 -- iter: 0672/3680
[A[ATraining Step: 5772  | total loss: [1m[32m0.43664[0m[0m
[2K| Adam | epoch: 051 | loss: 0.43664 - acc: 0.8370 -- iter: 0704/3680
[A[ATraining Step: 5773  | total loss: [1m[32m0.43787[0m[0m
[2K| Adam | epoch: 051 | loss: 0.43787 - acc: 0.8377 -- iter: 0736/3680
[A[ATraining Step: 5774  | total loss: [1m[32m0.44355[0m[0m
[2K| Adam | epoch: 051 | loss: 0.44355 - acc: 0.8352 -- iter: 0768/3680
[A[ATraining Step: 5775  | total loss: [1m[32m0.42502[0m[0m
[2K| Adam | epoch: 051 | loss: 0.42502 - acc: 0.8392 -- iter: 0800/3680
[A[ATraining Step: 5776  | total loss: [1m[32m0.41117[0m[0m
[2K| Adam | epoch: 051 | loss: 0.41117 - acc: 0.8459 -- iter: 0832/3680
[A[ATraining Step: 5777  | total loss: [1m[32m0.40448[0m[0m
[2K| Adam | epoch: 051 | loss: 0.40448 - acc: 0.8486 -- iter: 0864/3680
[A[ATraining Step: 5778  | total loss: [1m[32m0.39914[0m[0m
[2K| Adam | epoch: 051 | loss: 0.39914 - acc: 0.8486 -- iter: 0896/3680
[A[ATraining Step: 5779  | total loss: [1m[32m0.39187[0m[0m
[2K| Adam | epoch: 051 | loss: 0.39187 - acc: 0.8512 -- iter: 0928/3680
[A[ATraining Step: 5780  | total loss: [1m[32m0.38601[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38601 - acc: 0.8536 -- iter: 0960/3680
[A[ATraining Step: 5781  | total loss: [1m[32m0.37219[0m[0m
[2K| Adam | epoch: 051 | loss: 0.37219 - acc: 0.8589 -- iter: 0992/3680
[A[ATraining Step: 5782  | total loss: [1m[32m0.35440[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35440 - acc: 0.8667 -- iter: 1024/3680
[A[ATraining Step: 5783  | total loss: [1m[32m0.36578[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36578 - acc: 0.8644 -- iter: 1056/3680
[A[ATraining Step: 5784  | total loss: [1m[32m0.36358[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36358 - acc: 0.8624 -- iter: 1088/3680
[A[ATraining Step: 5785  | total loss: [1m[32m0.34879[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34879 - acc: 0.8699 -- iter: 1120/3680
[A[ATraining Step: 5786  | total loss: [1m[32m0.32649[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32649 - acc: 0.8829 -- iter: 1152/3680
[A[ATraining Step: 5787  | total loss: [1m[32m0.31617[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31617 - acc: 0.8852 -- iter: 1184/3680
[A[ATraining Step: 5788  | total loss: [1m[32m0.32528[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32528 - acc: 0.8811 -- iter: 1216/3680
[A[ATraining Step: 5789  | total loss: [1m[32m0.31709[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31709 - acc: 0.8836 -- iter: 1248/3680
[A[ATraining Step: 5790  | total loss: [1m[32m0.34527[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34527 - acc: 0.8671 -- iter: 1280/3680
[A[ATraining Step: 5791  | total loss: [1m[32m0.34534[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34534 - acc: 0.8648 -- iter: 1312/3680
[A[ATraining Step: 5792  | total loss: [1m[32m0.35106[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35106 - acc: 0.8627 -- iter: 1344/3680
[A[ATraining Step: 5793  | total loss: [1m[32m0.34053[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34053 - acc: 0.8670 -- iter: 1376/3680
[A[ATraining Step: 5794  | total loss: [1m[32m0.34226[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34226 - acc: 0.8616 -- iter: 1408/3680
[A[ATraining Step: 5795  | total loss: [1m[32m0.35183[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35183 - acc: 0.8567 -- iter: 1440/3680
[A[ATraining Step: 5796  | total loss: [1m[32m0.35329[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35329 - acc: 0.8585 -- iter: 1472/3680
[A[ATraining Step: 5797  | total loss: [1m[32m0.35844[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35844 - acc: 0.8539 -- iter: 1504/3680
[A[ATraining Step: 5798  | total loss: [1m[32m0.36493[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36493 - acc: 0.8560 -- iter: 1536/3680
[A[ATraining Step: 5799  | total loss: [1m[32m0.36449[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36449 - acc: 0.8579 -- iter: 1568/3680
[A[ATraining Step: 5800  | total loss: [1m[32m0.37571[0m[0m
[2K| Adam | epoch: 051 | loss: 0.37571 - acc: 0.8471 | val_loss: 0.31946 - val_acc: 0.8806 -- iter: 1600/3680
[A[ATraining Step: 5800  | total loss: [1m[32m0.37571[0m[0m
[2K| Adam | epoch: 051 | loss: 0.37571 - acc: 0.8471 | val_loss: 0.31946 - val_acc: 0.8806 -- iter: 1600/3680
--
Training Step: 5801  | total loss: [1m[32m0.38550[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38550 - acc: 0.8405 -- iter: 1632/3680
[A[ATraining Step: 5802  | total loss: [1m[32m0.39122[0m[0m
[2K| Adam | epoch: 051 | loss: 0.39122 - acc: 0.8409 -- iter: 1664/3680
[A[ATraining Step: 5803  | total loss: [1m[32m0.37694[0m[0m
[2K| Adam | epoch: 051 | loss: 0.37694 - acc: 0.8443 -- iter: 1696/3680
[A[ATraining Step: 5804  | total loss: [1m[32m0.36236[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36236 - acc: 0.8536 -- iter: 1728/3680
[A[ATraining Step: 5805  | total loss: [1m[32m0.35691[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35691 - acc: 0.8526 -- iter: 1760/3680
[A[ATraining Step: 5806  | total loss: [1m[32m0.35947[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35947 - acc: 0.8486 -- iter: 1792/3680
[A[ATraining Step: 5807  | total loss: [1m[32m0.35427[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35427 - acc: 0.8512 -- iter: 1824/3680
[A[ATraining Step: 5808  | total loss: [1m[32m0.34960[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34960 - acc: 0.8536 -- iter: 1856/3680
[A[ATraining Step: 5809  | total loss: [1m[32m0.35650[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35650 - acc: 0.8495 -- iter: 1888/3680
[A[ATraining Step: 5810  | total loss: [1m[32m0.35787[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35787 - acc: 0.8427 -- iter: 1920/3680
[A[ATraining Step: 5811  | total loss: [1m[32m0.36893[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36893 - acc: 0.8240 -- iter: 1952/3680
[A[ATraining Step: 5812  | total loss: [1m[32m0.36953[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36953 - acc: 0.8260 -- iter: 1984/3680
[A[ATraining Step: 5813  | total loss: [1m[32m0.35658[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35658 - acc: 0.8372 -- iter: 2016/3680
[A[ATraining Step: 5814  | total loss: [1m[32m0.36108[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36108 - acc: 0.8316 -- iter: 2048/3680
[A[ATraining Step: 5815  | total loss: [1m[32m0.35546[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35546 - acc: 0.8390 -- iter: 2080/3680
[A[ATraining Step: 5816  | total loss: [1m[32m0.35045[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35045 - acc: 0.8458 -- iter: 2112/3680
[A[ATraining Step: 5817  | total loss: [1m[32m0.34339[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34339 - acc: 0.8487 -- iter: 2144/3680
[A[ATraining Step: 5818  | total loss: [1m[32m0.34498[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34498 - acc: 0.8513 -- iter: 2176/3680
[A[ATraining Step: 5819  | total loss: [1m[32m0.35616[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35616 - acc: 0.8443 -- iter: 2208/3680
[A[ATraining Step: 5820  | total loss: [1m[32m0.35361[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35361 - acc: 0.8474 -- iter: 2240/3680
[A[ATraining Step: 5821  | total loss: [1m[32m0.34312[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34312 - acc: 0.8564 -- iter: 2272/3680
[A[ATraining Step: 5822  | total loss: [1m[32m0.35596[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35596 - acc: 0.8489 -- iter: 2304/3680
[A[ATraining Step: 5823  | total loss: [1m[32m0.35734[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35734 - acc: 0.8515 -- iter: 2336/3680
[A[ATraining Step: 5824  | total loss: [1m[32m0.36373[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36373 - acc: 0.8476 -- iter: 2368/3680
[A[ATraining Step: 5825  | total loss: [1m[32m0.35982[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35982 - acc: 0.8503 -- iter: 2400/3680
[A[ATraining Step: 5826  | total loss: [1m[32m0.36243[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36243 - acc: 0.8528 -- iter: 2432/3680
[A[ATraining Step: 5827  | total loss: [1m[32m0.35501[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35501 - acc: 0.8581 -- iter: 2464/3680
[A[ATraining Step: 5828  | total loss: [1m[32m0.35410[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35410 - acc: 0.8630 -- iter: 2496/3680
[A[ATraining Step: 5829  | total loss: [1m[32m0.35243[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35243 - acc: 0.8642 -- iter: 2528/3680
[A[ATraining Step: 5830  | total loss: [1m[32m0.35470[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35470 - acc: 0.8590 -- iter: 2560/3680
[A[ATraining Step: 5831  | total loss: [1m[32m0.36274[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36274 - acc: 0.8543 -- iter: 2592/3680
[A[ATraining Step: 5832  | total loss: [1m[32m0.37738[0m[0m
[2K| Adam | epoch: 051 | loss: 0.37738 - acc: 0.8502 -- iter: 2624/3680
[A[ATraining Step: 5833  | total loss: [1m[32m0.38102[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38102 - acc: 0.8464 -- iter: 2656/3680
[A[ATraining Step: 5834  | total loss: [1m[32m0.36975[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36975 - acc: 0.8524 -- iter: 2688/3680
[A[ATraining Step: 5835  | total loss: [1m[32m0.36075[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36075 - acc: 0.8578 -- iter: 2720/3680
[A[ATraining Step: 5836  | total loss: [1m[32m0.38329[0m[0m
[2K| Adam | epoch: 051 | loss: 0.38329 - acc: 0.8470 -- iter: 2752/3680
[A[ATraining Step: 5837  | total loss: [1m[32m0.36927[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36927 - acc: 0.8529 -- iter: 2784/3680
[A[ATraining Step: 5838  | total loss: [1m[32m0.36300[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36300 - acc: 0.8693 -- iter: 2816/3680
[A[ATraining Step: 5839  | total loss: [1m[32m0.34483[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34483 - acc: 0.8693 -- iter: 2848/3680
[A[ATraining Step: 5840  | total loss: [1m[32m0.35560[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35560 - acc: 0.8636 -- iter: 2880/3680
[A[ATraining Step: 5841  | total loss: [1m[32m0.36911[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36911 - acc: 0.8585 -- iter: 2912/3680
[A[ATraining Step: 5842  | total loss: [1m[32m0.36747[0m[0m
[2K| Adam | epoch: 051 | loss: 0.36747 - acc: 0.8570 -- iter: 2944/3680
[A[ATraining Step: 5843  | total loss: [1m[32m0.35354[0m[0m
[2K| Adam | epoch: 051 | loss: 0.35354 - acc: 0.8651 -- iter: 2976/3680
[A[ATraining Step: 5844  | total loss: [1m[32m0.34575[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34575 - acc: 0.8692 -- iter: 3008/3680
[A[ATraining Step: 5845  | total loss: [1m[32m0.34811[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34811 - acc: 0.8635 -- iter: 3040/3680
[A[ATraining Step: 5846  | total loss: [1m[32m0.34395[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34395 - acc: 0.8647 -- iter: 3072/3680
[A[ATraining Step: 5847  | total loss: [1m[32m0.34531[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34531 - acc: 0.8595 -- iter: 3104/3680
[A[ATraining Step: 5848  | total loss: [1m[32m0.34051[0m[0m
[2K| Adam | epoch: 051 | loss: 0.34051 - acc: 0.8610 -- iter: 3136/3680
[A[ATraining Step: 5849  | total loss: [1m[32m0.33967[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33967 - acc: 0.8593 -- iter: 3168/3680
[A[ATraining Step: 5850  | total loss: [1m[32m0.33820[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33820 - acc: 0.8609 -- iter: 3200/3680
[A[ATraining Step: 5851  | total loss: [1m[32m0.32522[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32522 - acc: 0.8654 -- iter: 3232/3680
[A[ATraining Step: 5852  | total loss: [1m[32m0.31536[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31536 - acc: 0.8726 -- iter: 3264/3680
[A[ATraining Step: 5853  | total loss: [1m[32m0.31982[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31982 - acc: 0.8697 -- iter: 3296/3680
[A[ATraining Step: 5854  | total loss: [1m[32m0.32359[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32359 - acc: 0.8640 -- iter: 3328/3680
[A[ATraining Step: 5855  | total loss: [1m[32m0.31473[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31473 - acc: 0.8620 -- iter: 3360/3680
[A[ATraining Step: 5856  | total loss: [1m[32m0.31927[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31927 - acc: 0.8602 -- iter: 3392/3680
[A[ATraining Step: 5857  | total loss: [1m[32m0.32375[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32375 - acc: 0.8585 -- iter: 3424/3680
[A[ATraining Step: 5858  | total loss: [1m[32m0.32246[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32246 - acc: 0.8602 -- iter: 3456/3680
[A[ATraining Step: 5859  | total loss: [1m[32m0.33054[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33054 - acc: 0.8554 -- iter: 3488/3680
[A[ATraining Step: 5860  | total loss: [1m[32m0.31956[0m[0m
[2K| Adam | epoch: 051 | loss: 0.31956 - acc: 0.8605 -- iter: 3520/3680
[A[ATraining Step: 5861  | total loss: [1m[32m0.32286[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32286 - acc: 0.8557 -- iter: 3552/3680
[A[ATraining Step: 5862  | total loss: [1m[32m0.32203[0m[0m
[2K| Adam | epoch: 051 | loss: 0.32203 - acc: 0.8576 -- iter: 3584/3680
[A[ATraining Step: 5863  | total loss: [1m[32m0.33156[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33156 - acc: 0.8531 -- iter: 3616/3680
[A[ATraining Step: 5864  | total loss: [1m[32m0.33696[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33696 - acc: 0.8553 -- iter: 3648/3680
[A[ATraining Step: 5865  | total loss: [1m[32m0.33325[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33325 - acc: 0.8573 | val_loss: 0.31715 - val_acc: 0.8806 -- iter: 3680/3680
[A[ATraining Step: 5865  | total loss: [1m[32m0.33325[0m[0m
[2K| Adam | epoch: 051 | loss: 0.33325 - acc: 0.8573 | val_loss: 0.31715 - val_acc: 0.8806 -- iter: 3680/3680
--
Training Step: 5866  | total loss: [1m[32m0.32910[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32910 - acc: 0.8590 -- iter: 0032/3680
[A[ATraining Step: 5867  | total loss: [1m[32m0.32474[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32474 - acc: 0.8606 -- iter: 0064/3680
[A[ATraining Step: 5868  | total loss: [1m[32m0.32991[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32991 - acc: 0.8621 -- iter: 0096/3680
[A[ATraining Step: 5869  | total loss: [1m[32m0.33593[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33593 - acc: 0.8634 -- iter: 0128/3680
[A[ATraining Step: 5870  | total loss: [1m[32m0.35592[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35592 - acc: 0.8520 -- iter: 0160/3680
[A[ATraining Step: 5871  | total loss: [1m[32m0.34181[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34181 - acc: 0.8606 -- iter: 0192/3680
[A[ATraining Step: 5872  | total loss: [1m[32m0.34380[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34380 - acc: 0.8589 -- iter: 0224/3680
[A[ATraining Step: 5873  | total loss: [1m[32m0.34132[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34132 - acc: 0.8574 -- iter: 0256/3680
[A[ATraining Step: 5874  | total loss: [1m[32m0.35068[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35068 - acc: 0.8498 -- iter: 0288/3680
[A[ATraining Step: 5875  | total loss: [1m[32m0.34078[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34078 - acc: 0.8554 -- iter: 0320/3680
[A[ATraining Step: 5876  | total loss: [1m[32m0.33935[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33935 - acc: 0.8598 -- iter: 0352/3680
[A[ATraining Step: 5877  | total loss: [1m[32m0.33935[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33935 - acc: 0.8707 -- iter: 0384/3680
[A[ATraining Step: 5878  | total loss: [1m[32m0.32610[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32610 - acc: 0.8707 -- iter: 0416/3680
[A[ATraining Step: 5879  | total loss: [1m[32m0.32190[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32190 - acc: 0.8805 -- iter: 0448/3680
[A[ATraining Step: 5880  | total loss: [1m[32m0.33193[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33193 - acc: 0.8612 -- iter: 0480/3680
[A[ATraining Step: 5881  | total loss: [1m[32m0.33193[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33193 - acc: 0.8612 -- iter: 0512/3680
[A[ATraining Step: 5882  | total loss: [1m[32m0.32668[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32668 - acc: 0.8626 -- iter: 0544/3680
[A[ATraining Step: 5883  | total loss: [1m[32m0.33310[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33310 - acc: 0.8576 -- iter: 0576/3680
[A[ATraining Step: 5884  | total loss: [1m[32m0.32667[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32667 - acc: 0.8656 -- iter: 0608/3680
[A[ATraining Step: 5885  | total loss: [1m[32m0.33022[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33022 - acc: 0.8634 -- iter: 0640/3680
[A[ATraining Step: 5886  | total loss: [1m[32m0.34474[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34474 - acc: 0.8614 -- iter: 0672/3680
[A[ATraining Step: 5887  | total loss: [1m[32m0.33559[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33559 - acc: 0.8659 -- iter: 0704/3680
[A[ATraining Step: 5888  | total loss: [1m[32m0.34112[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34112 - acc: 0.8586 -- iter: 0736/3680
[A[ATraining Step: 5889  | total loss: [1m[32m0.34154[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34154 - acc: 0.8586 -- iter: 0768/3680
[A[ATraining Step: 5890  | total loss: [1m[32m0.37277[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37277 - acc: 0.8509 -- iter: 0800/3680
[A[ATraining Step: 5891  | total loss: [1m[32m0.36727[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36727 - acc: 0.8533 -- iter: 0832/3680
[A[ATraining Step: 5892  | total loss: [1m[32m0.35237[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35237 - acc: 0.8586 -- iter: 0864/3680
[A[ATraining Step: 5893  | total loss: [1m[32m0.34902[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34902 - acc: 0.8602 -- iter: 0896/3680
[A[ATraining Step: 5894  | total loss: [1m[32m0.33807[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33807 - acc: 0.8648 -- iter: 0928/3680
[A[ATraining Step: 5895  | total loss: [1m[32m0.34408[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34408 - acc: 0.8690 -- iter: 0960/3680
[A[ATraining Step: 5896  | total loss: [1m[32m0.32829[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32829 - acc: 0.8789 -- iter: 0992/3680
[A[ATraining Step: 5897  | total loss: [1m[32m0.34245[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34245 - acc: 0.8666 -- iter: 1024/3680
[A[ATraining Step: 5898  | total loss: [1m[32m0.34245[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34245 - acc: 0.8666 -- iter: 1056/3680
[A[ATraining Step: 5899  | total loss: [1m[32m0.35134[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35134 - acc: 0.8643 -- iter: 1088/3680
[A[ATraining Step: 5900  | total loss: [1m[32m0.34105[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34105 - acc: 0.8685 | val_loss: 0.31181 - val_acc: 0.8925 -- iter: 1120/3680
[A[ATraining Step: 5900  | total loss: [1m[32m0.34105[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34105 - acc: 0.8685 | val_loss: 0.31181 - val_acc: 0.8925 -- iter: 1120/3680
--
Training Step: 5901  | total loss: [1m[32m0.36306[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36306 - acc: 0.8548 -- iter: 1152/3680
[A[ATraining Step: 5902  | total loss: [1m[32m0.36512[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36512 - acc: 0.8548 -- iter: 1184/3680
[A[ATraining Step: 5903  | total loss: [1m[32m0.34989[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34989 - acc: 0.8630 -- iter: 1216/3680
[A[ATraining Step: 5904  | total loss: [1m[32m0.33376[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33376 - acc: 0.8674 -- iter: 1248/3680
[A[ATraining Step: 5905  | total loss: [1m[32m0.33649[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33649 - acc: 0.8712 -- iter: 1280/3680
[A[ATraining Step: 5906  | total loss: [1m[32m0.34853[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34853 - acc: 0.8622 -- iter: 1312/3680
[A[ATraining Step: 5907  | total loss: [1m[32m0.35241[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35241 - acc: 0.8573 -- iter: 1344/3680
[A[ATraining Step: 5908  | total loss: [1m[32m0.34422[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34422 - acc: 0.8622 -- iter: 1376/3680
[A[ATraining Step: 5909  | total loss: [1m[32m0.34296[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34296 - acc: 0.8603 -- iter: 1408/3680
[A[ATraining Step: 5910  | total loss: [1m[32m0.32896[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32896 - acc: 0.8743 -- iter: 1440/3680
[A[ATraining Step: 5911  | total loss: [1m[32m0.31753[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31753 - acc: 0.8837 -- iter: 1472/3680
[A[ATraining Step: 5912  | total loss: [1m[32m0.32088[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32088 - acc: 0.8860 -- iter: 1504/3680
[A[ATraining Step: 5913  | total loss: [1m[32m0.31832[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31832 - acc: 0.8880 -- iter: 1536/3680
[A[ATraining Step: 5914  | total loss: [1m[32m0.31181[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31181 - acc: 0.8898 -- iter: 1568/3680
[A[ATraining Step: 5915  | total loss: [1m[32m0.32298[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32298 - acc: 0.8790 -- iter: 1600/3680
[A[ATraining Step: 5916  | total loss: [1m[32m0.33725[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33725 - acc: 0.8692 -- iter: 1632/3680
[A[ATraining Step: 5917  | total loss: [1m[32m0.35504[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35504 - acc: 0.8635 -- iter: 1664/3680
[A[ATraining Step: 5918  | total loss: [1m[32m0.35167[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35167 - acc: 0.8678 -- iter: 1696/3680
[A[ATraining Step: 5919  | total loss: [1m[32m0.34221[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34221 - acc: 0.8654 -- iter: 1728/3680
[A[ATraining Step: 5920  | total loss: [1m[32m0.33198[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33198 - acc: 0.8695 -- iter: 1760/3680
[A[ATraining Step: 5921  | total loss: [1m[32m0.35655[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35655 - acc: 0.8575 -- iter: 1792/3680
[A[ATraining Step: 5922  | total loss: [1m[32m0.35181[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35181 - acc: 0.8593 -- iter: 1824/3680
[A[ATraining Step: 5923  | total loss: [1m[32m0.37317[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37317 - acc: 0.8390 -- iter: 1856/3680
[A[ATraining Step: 5924  | total loss: [1m[32m0.37054[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37054 - acc: 0.8395 -- iter: 1888/3680
[A[ATraining Step: 5925  | total loss: [1m[32m0.38263[0m[0m
[2K| Adam | epoch: 052 | loss: 0.38263 - acc: 0.8336 -- iter: 1920/3680
[A[ATraining Step: 5926  | total loss: [1m[32m0.37789[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37789 - acc: 0.8315 -- iter: 1952/3680
[A[ATraining Step: 5927  | total loss: [1m[32m0.39167[0m[0m
[2K| Adam | epoch: 052 | loss: 0.39167 - acc: 0.8234 -- iter: 1984/3680
[A[ATraining Step: 5928  | total loss: [1m[32m0.40904[0m[0m
[2K| Adam | epoch: 052 | loss: 0.40904 - acc: 0.8223 -- iter: 2016/3680
[A[ATraining Step: 5929  | total loss: [1m[32m0.39570[0m[0m
[2K| Adam | epoch: 052 | loss: 0.39570 - acc: 0.8276 -- iter: 2048/3680
[A[ATraining Step: 5930  | total loss: [1m[32m0.38142[0m[0m
[2K| Adam | epoch: 052 | loss: 0.38142 - acc: 0.8386 -- iter: 2080/3680
[A[ATraining Step: 5931  | total loss: [1m[32m0.37548[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37548 - acc: 0.8391 -- iter: 2112/3680
[A[ATraining Step: 5932  | total loss: [1m[32m0.38383[0m[0m
[2K| Adam | epoch: 052 | loss: 0.38383 - acc: 0.8489 -- iter: 2144/3680
[A[ATraining Step: 5933  | total loss: [1m[32m0.37986[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37986 - acc: 0.8515 -- iter: 2176/3680
[A[ATraining Step: 5934  | total loss: [1m[32m0.38417[0m[0m
[2K| Adam | epoch: 052 | loss: 0.38417 - acc: 0.8414 -- iter: 2208/3680
[A[ATraining Step: 5935  | total loss: [1m[32m0.36480[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36480 - acc: 0.8510 -- iter: 2240/3680
[A[ATraining Step: 5936  | total loss: [1m[32m0.35587[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35587 - acc: 0.8503 -- iter: 2272/3680
[A[ATraining Step: 5937  | total loss: [1m[32m0.36457[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36457 - acc: 0.8465 -- iter: 2304/3680
[A[ATraining Step: 5938  | total loss: [1m[32m0.35679[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35679 - acc: 0.8525 -- iter: 2336/3680
[A[ATraining Step: 5939  | total loss: [1m[32m0.36697[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36697 - acc: 0.8422 -- iter: 2368/3680
[A[ATraining Step: 5940  | total loss: [1m[32m0.36515[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36515 - acc: 0.8424 -- iter: 2400/3680
[A[ATraining Step: 5941  | total loss: [1m[32m0.36985[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36985 - acc: 0.8394 -- iter: 2432/3680
[A[ATraining Step: 5942  | total loss: [1m[32m0.37469[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37469 - acc: 0.8367 -- iter: 2464/3680
[A[ATraining Step: 5943  | total loss: [1m[32m0.37437[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37437 - acc: 0.8311 -- iter: 2496/3680
[A[ATraining Step: 5944  | total loss: [1m[32m0.37360[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37360 - acc: 0.8293 -- iter: 2528/3680
[A[ATraining Step: 5945  | total loss: [1m[32m0.36489[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36489 - acc: 0.8339 -- iter: 2560/3680
[A[ATraining Step: 5946  | total loss: [1m[32m0.36383[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36383 - acc: 0.8348 -- iter: 2592/3680
[A[ATraining Step: 5947  | total loss: [1m[32m0.37770[0m[0m
[2K| Adam | epoch: 052 | loss: 0.37770 - acc: 0.8218 -- iter: 2624/3680
[A[ATraining Step: 5948  | total loss: [1m[32m0.38215[0m[0m
[2K| Adam | epoch: 052 | loss: 0.38215 - acc: 0.8272 -- iter: 2656/3680
[A[ATraining Step: 5949  | total loss: [1m[32m0.38215[0m[0m
[2K| Adam | epoch: 052 | loss: 0.38215 - acc: 0.8319 -- iter: 2688/3680
[A[ATraining Step: 5950  | total loss: [1m[32m0.36922[0m[0m
[2K| Adam | epoch: 052 | loss: 0.36922 - acc: 0.8319 -- iter: 2720/3680
[A[ATraining Step: 5951  | total loss: [1m[32m0.35573[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35573 - acc: 0.8425 -- iter: 2752/3680
[A[ATraining Step: 5952  | total loss: [1m[32m0.35429[0m[0m
[2K| Adam | epoch: 052 | loss: 0.35429 - acc: 0.8426 -- iter: 2784/3680
[A[ATraining Step: 5953  | total loss: [1m[32m0.34849[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34849 - acc: 0.8521 -- iter: 2816/3680
[A[ATraining Step: 5954  | total loss: [1m[32m0.34178[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34178 - acc: 0.8544 -- iter: 2848/3680
[A[ATraining Step: 5955  | total loss: [1m[32m0.34082[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34082 - acc: 0.8533 -- iter: 2880/3680
[A[ATraining Step: 5956  | total loss: [1m[32m0.34210[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34210 - acc: 0.8555 -- iter: 2912/3680
[A[ATraining Step: 5957  | total loss: [1m[32m0.34267[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34267 - acc: 0.8543 -- iter: 2944/3680
[A[ATraining Step: 5958  | total loss: [1m[32m0.34109[0m[0m
[2K| Adam | epoch: 052 | loss: 0.34109 - acc: 0.8564 -- iter: 2976/3680
[A[ATraining Step: 5959  | total loss: [1m[32m0.32891[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32891 - acc: 0.8645 -- iter: 3008/3680
[A[ATraining Step: 5960  | total loss: [1m[32m0.33480[0m[0m
[2K| Adam | epoch: 052 | loss: 0.33480 - acc: 0.8624 -- iter: 3040/3680
[A[ATraining Step: 5961  | total loss: [1m[32m0.31908[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31908 - acc: 0.8699 -- iter: 3072/3680
[A[ATraining Step: 5962  | total loss: [1m[32m0.31425[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31425 - acc: 0.8673 -- iter: 3104/3680
[A[ATraining Step: 5963  | total loss: [1m[32m0.31797[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31797 - acc: 0.8618 -- iter: 3136/3680
[A[ATraining Step: 5964  | total loss: [1m[32m0.30868[0m[0m
[2K| Adam | epoch: 052 | loss: 0.30868 - acc: 0.8694 -- iter: 3168/3680
[A[ATraining Step: 5965  | total loss: [1m[32m0.30110[0m[0m
[2K| Adam | epoch: 052 | loss: 0.30110 - acc: 0.8731 -- iter: 3200/3680
[A[ATraining Step: 5966  | total loss: [1m[32m0.29592[0m[0m
[2K| Adam | epoch: 052 | loss: 0.29592 - acc: 0.8764 -- iter: 3232/3680
[A[ATraining Step: 5967  | total loss: [1m[32m0.30293[0m[0m
[2K| Adam | epoch: 052 | loss: 0.30293 - acc: 0.8794 -- iter: 3264/3680
[A[ATraining Step: 5968  | total loss: [1m[32m0.29333[0m[0m
[2K| Adam | epoch: 052 | loss: 0.29333 - acc: 0.8821 -- iter: 3296/3680
[A[ATraining Step: 5969  | total loss: [1m[32m0.30251[0m[0m
[2K| Adam | epoch: 052 | loss: 0.30251 - acc: 0.8751 -- iter: 3328/3680
[A[ATraining Step: 5970  | total loss: [1m[32m0.30022[0m[0m
[2K| Adam | epoch: 052 | loss: 0.30022 - acc: 0.8782 -- iter: 3360/3680
[A[ATraining Step: 5971  | total loss: [1m[32m0.28918[0m[0m
[2K| Adam | epoch: 052 | loss: 0.28918 - acc: 0.8873 -- iter: 3392/3680
[A[ATraining Step: 5972  | total loss: [1m[32m0.28993[0m[0m
[2K| Adam | epoch: 052 | loss: 0.28993 - acc: 0.8829 -- iter: 3424/3680
[A[ATraining Step: 5973  | total loss: [1m[32m0.29316[0m[0m
[2K| Adam | epoch: 052 | loss: 0.29316 - acc: 0.8884 -- iter: 3456/3680
[A[ATraining Step: 5974  | total loss: [1m[32m0.31015[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31015 - acc: 0.8777 -- iter: 3488/3680
[A[ATraining Step: 5975  | total loss: [1m[32m0.32718[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32718 - acc: 0.8649 -- iter: 3520/3680
[A[ATraining Step: 5976  | total loss: [1m[32m0.32292[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32292 - acc: 0.8628 -- iter: 3552/3680
[A[ATraining Step: 5977  | total loss: [1m[32m0.31492[0m[0m
[2K| Adam | epoch: 052 | loss: 0.31492 - acc: 0.8671 -- iter: 3584/3680
[A[ATraining Step: 5978  | total loss: [1m[32m0.32174[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32174 - acc: 0.8679 -- iter: 3616/3680
[A[ATraining Step: 5979  | total loss: [1m[32m0.32172[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32172 - acc: 0.8655 -- iter: 3648/3680
[A[ATraining Step: 5980  | total loss: [1m[32m0.32654[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32654 - acc: 0.8696 | val_loss: 0.31242 - val_acc: 0.8817 -- iter: 3680/3680
[A[ATraining Step: 5980  | total loss: [1m[32m0.32654[0m[0m
[2K| Adam | epoch: 052 | loss: 0.32654 - acc: 0.8696 | val_loss: 0.31242 - val_acc: 0.8817 -- iter: 3680/3680
--
Training Step: 5981  | total loss: [1m[32m0.32702[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32702 - acc: 0.8701 -- iter: 0032/3680
[A[ATraining Step: 5982  | total loss: [1m[32m0.31630[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31630 - acc: 0.8769 -- iter: 0064/3680
[A[ATraining Step: 5983  | total loss: [1m[32m0.32646[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32646 - acc: 0.8735 -- iter: 0096/3680
[A[ATraining Step: 5984  | total loss: [1m[32m0.31543[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31543 - acc: 0.8768 -- iter: 0128/3680
[A[ATraining Step: 5985  | total loss: [1m[32m0.30814[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30814 - acc: 0.8798 -- iter: 0160/3680
[A[ATraining Step: 5986  | total loss: [1m[32m0.33329[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33329 - acc: 0.8699 -- iter: 0192/3680
[A[ATraining Step: 5987  | total loss: [1m[32m0.32538[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32538 - acc: 0.8767 -- iter: 0224/3680
[A[ATraining Step: 5988  | total loss: [1m[32m0.35876[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35876 - acc: 0.8609 -- iter: 0256/3680
[A[ATraining Step: 5989  | total loss: [1m[32m0.34174[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34174 - acc: 0.8717 -- iter: 0288/3680
[A[ATraining Step: 5990  | total loss: [1m[32m0.33401[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33401 - acc: 0.8720 -- iter: 0320/3680
[A[ATraining Step: 5991  | total loss: [1m[32m0.33780[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33780 - acc: 0.8729 -- iter: 0352/3680
[A[ATraining Step: 5992  | total loss: [1m[32m0.32551[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32551 - acc: 0.8762 -- iter: 0384/3680
[A[ATraining Step: 5993  | total loss: [1m[32m0.32551[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32551 - acc: 0.8762 -- iter: 0416/3680
[A[ATraining Step: 5994  | total loss: [1m[32m0.31994[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31994 - acc: 0.8792 -- iter: 0448/3680
[A[ATraining Step: 5995  | total loss: [1m[32m0.31623[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31623 - acc: 0.8788 -- iter: 0480/3680
[A[ATraining Step: 5996  | total loss: [1m[32m0.31164[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31164 - acc: 0.8815 -- iter: 0512/3680
[A[ATraining Step: 5997  | total loss: [1m[32m0.30909[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30909 - acc: 0.8809 -- iter: 0544/3680
[A[ATraining Step: 5998  | total loss: [1m[32m0.30257[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30257 - acc: 0.8834 -- iter: 0576/3680
[A[ATraining Step: 5999  | total loss: [1m[32m0.30149[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30149 - acc: 0.8826 -- iter: 0608/3680
[A[ATraining Step: 6000  | total loss: [1m[32m0.30668[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30668 - acc: 0.8818 | val_loss: 0.31184 - val_acc: 0.8849 -- iter: 0640/3680
[A[ATraining Step: 6000  | total loss: [1m[32m0.30668[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30668 - acc: 0.8818 | val_loss: 0.31184 - val_acc: 0.8849 -- iter: 0640/3680
--
Training Step: 6001  | total loss: [1m[32m0.30314[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30314 - acc: 0.8843 -- iter: 0672/3680
[A[ATraining Step: 6002  | total loss: [1m[32m0.29847[0m[0m
[2K| Adam | epoch: 053 | loss: 0.29847 - acc: 0.8865 -- iter: 0704/3680
[A[ATraining Step: 6003  | total loss: [1m[32m0.31023[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31023 - acc: 0.8759 -- iter: 0736/3680
[A[ATraining Step: 6004  | total loss: [1m[32m0.30782[0m[0m
[2K| Adam | epoch: 053 | loss: 0.30782 - acc: 0.8758 -- iter: 0768/3680
[A[ATraining Step: 6005  | total loss: [1m[32m0.29960[0m[0m
[2K| Adam | epoch: 053 | loss: 0.29960 - acc: 0.8789 -- iter: 0800/3680
[A[ATraining Step: 6006  | total loss: [1m[32m0.31941[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31941 - acc: 0.8723 -- iter: 0832/3680
[A[ATraining Step: 6007  | total loss: [1m[32m0.31950[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31950 - acc: 0.8694 -- iter: 0864/3680
[A[ATraining Step: 6008  | total loss: [1m[32m0.32411[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32411 - acc: 0.8762 -- iter: 0896/3680
[A[ATraining Step: 6009  | total loss: [1m[32m0.31532[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31532 - acc: 0.8761 -- iter: 0928/3680
[A[ATraining Step: 6010  | total loss: [1m[32m0.35724[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35724 - acc: 0.8791 -- iter: 0960/3680
[A[ATraining Step: 6011  | total loss: [1m[32m0.36567[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36567 - acc: 0.8693 -- iter: 0992/3680
[A[ATraining Step: 6012  | total loss: [1m[32m0.36378[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36378 - acc: 0.8636 -- iter: 1024/3680
[A[ATraining Step: 6013  | total loss: [1m[32m0.35995[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35995 - acc: 0.8648 -- iter: 1056/3680
[A[ATraining Step: 6014  | total loss: [1m[32m0.34467[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34467 - acc: 0.8720 -- iter: 1088/3680
[A[ATraining Step: 6015  | total loss: [1m[32m0.35041[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35041 - acc: 0.8661 -- iter: 1120/3680
[A[ATraining Step: 6016  | total loss: [1m[32m0.34247[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34247 - acc: 0.8639 -- iter: 1152/3680
[A[ATraining Step: 6017  | total loss: [1m[32m0.36020[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36020 - acc: 0.8587 -- iter: 1184/3680
[A[ATraining Step: 6018  | total loss: [1m[32m0.34302[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34302 - acc: 0.8674 -- iter: 1216/3680
[A[ATraining Step: 6019  | total loss: [1m[32m0.34522[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34522 - acc: 0.8674 -- iter: 1248/3680
[A[ATraining Step: 6020  | total loss: [1m[32m0.34681[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34681 - acc: 0.8682 -- iter: 1280/3680
[A[ATraining Step: 6021  | total loss: [1m[32m0.35134[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35134 - acc: 0.8658 -- iter: 1312/3680
[A[ATraining Step: 6022  | total loss: [1m[32m0.34624[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34624 - acc: 0.8636 -- iter: 1344/3680
[A[ATraining Step: 6023  | total loss: [1m[32m0.33083[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33083 - acc: 0.8709 -- iter: 1376/3680
[A[ATraining Step: 6024  | total loss: [1m[32m0.32724[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32724 - acc: 0.8682 -- iter: 1408/3680
[A[ATraining Step: 6025  | total loss: [1m[32m0.33453[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33453 - acc: 0.8658 -- iter: 1440/3680
[A[ATraining Step: 6026  | total loss: [1m[32m0.34329[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34329 - acc: 0.8619 -- iter: 1472/3680
[A[ATraining Step: 6027  | total loss: [1m[32m0.34484[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34484 - acc: 0.8619 -- iter: 1504/3680
[A[ATraining Step: 6028  | total loss: [1m[32m0.35343[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35343 - acc: 0.8570 -- iter: 1536/3680
[A[ATraining Step: 6029  | total loss: [1m[32m0.36072[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36072 - acc: 0.8525 -- iter: 1568/3680
[A[ATraining Step: 6030  | total loss: [1m[32m0.35220[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35220 - acc: 0.8579 -- iter: 1600/3680
[A[ATraining Step: 6031  | total loss: [1m[32m0.35350[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35350 - acc: 0.8596 -- iter: 1632/3680
[A[ATraining Step: 6032  | total loss: [1m[32m0.35911[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35911 - acc: 0.8538 -- iter: 1664/3680
[A[ATraining Step: 6033  | total loss: [1m[32m0.36997[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36997 - acc: 0.8653 -- iter: 1696/3680
[A[ATraining Step: 6034  | total loss: [1m[32m0.35141[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35141 - acc: 0.8653 -- iter: 1728/3680
[A[ATraining Step: 6035  | total loss: [1m[32m0.35022[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35022 - acc: 0.8600 -- iter: 1760/3680
[A[ATraining Step: 6036  | total loss: [1m[32m0.36514[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36514 - acc: 0.8552 -- iter: 1792/3680
[A[ATraining Step: 6037  | total loss: [1m[32m0.35932[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35932 - acc: 0.8510 -- iter: 1824/3680
[A[ATraining Step: 6038  | total loss: [1m[32m0.36686[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36686 - acc: 0.8440 -- iter: 1856/3680
[A[ATraining Step: 6039  | total loss: [1m[32m0.36798[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36798 - acc: 0.8471 -- iter: 1888/3680
[A[ATraining Step: 6040  | total loss: [1m[32m0.37605[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37605 - acc: 0.8405 -- iter: 1920/3680
[A[ATraining Step: 6041  | total loss: [1m[32m0.37559[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37559 - acc: 0.8471 -- iter: 1952/3680
[A[ATraining Step: 6042  | total loss: [1m[32m0.35674[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35674 - acc: 0.8561 -- iter: 1984/3680
[A[ATraining Step: 6043  | total loss: [1m[32m0.34446[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34446 - acc: 0.8611 -- iter: 2016/3680
[A[ATraining Step: 6044  | total loss: [1m[32m0.33049[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33049 - acc: 0.8657 -- iter: 2048/3680
[A[ATraining Step: 6045  | total loss: [1m[32m0.35359[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35359 - acc: 0.8541 -- iter: 2080/3680
[A[ATraining Step: 6046  | total loss: [1m[32m0.34373[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34373 - acc: 0.8624 -- iter: 2112/3680
[A[ATraining Step: 6047  | total loss: [1m[32m0.32443[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32443 - acc: 0.8699 -- iter: 2144/3680
[A[ATraining Step: 6048  | total loss: [1m[32m0.33109[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33109 - acc: 0.8771 -- iter: 2176/3680
[A[ATraining Step: 6049  | total loss: [1m[32m0.31547[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31547 - acc: 0.8771 -- iter: 2208/3680
[A[ATraining Step: 6050  | total loss: [1m[32m0.32386[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32386 - acc: 0.8644 -- iter: 2240/3680
[A[ATraining Step: 6051  | total loss: [1m[32m0.32258[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32258 - acc: 0.8624 -- iter: 2272/3680
[A[ATraining Step: 6052  | total loss: [1m[32m0.31987[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31987 - acc: 0.8605 -- iter: 2304/3680
[A[ATraining Step: 6053  | total loss: [1m[32m0.32338[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32338 - acc: 0.8588 -- iter: 2336/3680
[A[ATraining Step: 6054  | total loss: [1m[32m0.34478[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34478 - acc: 0.8511 -- iter: 2368/3680
[A[ATraining Step: 6055  | total loss: [1m[32m0.35385[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35385 - acc: 0.8472 -- iter: 2400/3680
[A[ATraining Step: 6056  | total loss: [1m[32m0.35934[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35934 - acc: 0.8375 -- iter: 2432/3680
[A[ATraining Step: 6057  | total loss: [1m[32m0.37012[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37012 - acc: 0.8381 -- iter: 2464/3680
[A[ATraining Step: 6058  | total loss: [1m[32m0.36227[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36227 - acc: 0.8449 -- iter: 2496/3680
[A[ATraining Step: 6059  | total loss: [1m[32m0.36524[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36524 - acc: 0.8448 -- iter: 2528/3680
[A[ATraining Step: 6060  | total loss: [1m[32m0.37539[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37539 - acc: 0.8322 -- iter: 2560/3680
[A[ATraining Step: 6061  | total loss: [1m[32m0.37690[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37690 - acc: 0.8334 -- iter: 2592/3680
[A[ATraining Step: 6062  | total loss: [1m[32m0.37282[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37282 - acc: 0.8375 -- iter: 2624/3680
[A[ATraining Step: 6063  | total loss: [1m[32m0.36581[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36581 - acc: 0.8413 -- iter: 2656/3680
[A[ATraining Step: 6064  | total loss: [1m[32m0.37231[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37231 - acc: 0.8384 -- iter: 2688/3680
[A[ATraining Step: 6065  | total loss: [1m[32m0.37218[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37218 - acc: 0.8389 -- iter: 2720/3680
[A[ATraining Step: 6066  | total loss: [1m[32m0.36673[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36673 - acc: 0.8457 -- iter: 2752/3680
[A[ATraining Step: 6067  | total loss: [1m[32m0.37415[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37415 - acc: 0.8455 -- iter: 2784/3680
[A[ATraining Step: 6068  | total loss: [1m[32m0.37130[0m[0m
[2K| Adam | epoch: 053 | loss: 0.37130 - acc: 0.8453 -- iter: 2816/3680
[A[ATraining Step: 6069  | total loss: [1m[32m0.35559[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35559 - acc: 0.8514 -- iter: 2848/3680
[A[ATraining Step: 6070  | total loss: [1m[32m0.35185[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35185 - acc: 0.8506 -- iter: 2880/3680
[A[ATraining Step: 6071  | total loss: [1m[32m0.34778[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34778 - acc: 0.8499 -- iter: 2912/3680
[A[ATraining Step: 6072  | total loss: [1m[32m0.35744[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35744 - acc: 0.8493 -- iter: 2944/3680
[A[ATraining Step: 6073  | total loss: [1m[32m0.35292[0m[0m
[2K| Adam | epoch: 053 | loss: 0.35292 - acc: 0.8488 -- iter: 2976/3680
[A[ATraining Step: 6074  | total loss: [1m[32m0.34011[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34011 - acc: 0.8545 -- iter: 3008/3680
[A[ATraining Step: 6075  | total loss: [1m[32m0.32471[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32471 - acc: 0.8697 -- iter: 3040/3680
[A[ATraining Step: 6076  | total loss: [1m[32m0.32471[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32471 - acc: 0.8764 -- iter: 3072/3680
[A[ATraining Step: 6077  | total loss: [1m[32m0.31050[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31050 - acc: 0.8764 -- iter: 3104/3680
[A[ATraining Step: 6078  | total loss: [1m[32m0.31364[0m[0m
[2K| Adam | epoch: 053 | loss: 0.31364 - acc: 0.8699 -- iter: 3136/3680
[A[ATraining Step: 6079  | total loss: [1m[32m0.32098[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32098 - acc: 0.8699 -- iter: 3168/3680
[A[ATraining Step: 6080  | total loss: [1m[32m0.34623[0m[0m
[2K| Adam | epoch: 053 | loss: 0.34623 - acc: 0.8548 -- iter: 3200/3680
[A[ATraining Step: 6081  | total loss: [1m[32m0.33601[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33601 - acc: 0.8599 -- iter: 3232/3680
[A[ATraining Step: 6082  | total loss: [1m[32m0.33288[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33288 - acc: 0.8615 -- iter: 3264/3680
[A[ATraining Step: 6083  | total loss: [1m[32m0.33560[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33560 - acc: 0.8659 -- iter: 3296/3680
[A[ATraining Step: 6084  | total loss: [1m[32m0.32587[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32587 - acc: 0.8731 -- iter: 3328/3680
[A[ATraining Step: 6085  | total loss: [1m[32m0.33682[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33682 - acc: 0.8608 -- iter: 3360/3680
[A[ATraining Step: 6086  | total loss: [1m[32m0.32320[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32320 - acc: 0.8716 -- iter: 3392/3680
[A[ATraining Step: 6087  | total loss: [1m[32m0.32971[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32971 - acc: 0.8691 -- iter: 3424/3680
[A[ATraining Step: 6088  | total loss: [1m[32m0.32971[0m[0m
[2K| Adam | epoch: 053 | loss: 0.32971 - acc: 0.8691 -- iter: 3456/3680
[A[ATraining Step: 6089  | total loss: [1m[32m0.33990[0m[0m
[2K| Adam | epoch: 053 | loss: 0.33990 - acc: 0.8603 -- iter: 3488/3680
[A[ATraining Step: 6090  | total loss: [1m[32m0.36276[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36276 - acc: 0.8524 -- iter: 3520/3680
[A[ATraining Step: 6091  | total loss: [1m[32m0.36885[0m[0m
[2K| Adam | epoch: 053 | loss: 0.36885 - acc: 0.8484 -- iter: 3552/3680
[A[ATraining Step: 6092  | total loss: [1m[32m0.38216[0m[0m
[2K| Adam | epoch: 053 | loss: 0.38216 - acc: 0.8355 -- iter: 3584/3680
[A[ATraining Step: 6093  | total loss: [1m[32m0.40674[0m[0m
[2K| Adam | epoch: 053 | loss: 0.40674 - acc: 0.8207 -- iter: 3616/3680
[A[ATraining Step: 6094  | total loss: [1m[32m0.39699[0m[0m
[2K| Adam | epoch: 053 | loss: 0.39699 - acc: 0.8261 -- iter: 3648/3680
[A[ATraining Step: 6095  | total loss: [1m[32m0.38808[0m[0m
[2K| Adam | epoch: 053 | loss: 0.38808 - acc: 0.8310 | val_loss: 0.31298 - val_acc: 0.8882 -- iter: 3680/3680
[A[ATraining Step: 6095  | total loss: [1m[32m0.38808[0m[0m
[2K| Adam | epoch: 053 | loss: 0.38808 - acc: 0.8310 | val_loss: 0.31298 - val_acc: 0.8882 -- iter: 3680/3680
--
Training Step: 6096  | total loss: [1m[32m0.37148[0m[0m
[2K| Adam | epoch: 054 | loss: 0.37148 - acc: 0.8385 -- iter: 0032/3680
[A[ATraining Step: 6097  | total loss: [1m[32m0.35381[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35381 - acc: 0.8484 -- iter: 0064/3680
[A[ATraining Step: 6098  | total loss: [1m[32m0.35951[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35951 - acc: 0.8417 -- iter: 0096/3680
[A[ATraining Step: 6099  | total loss: [1m[32m0.34828[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34828 - acc: 0.8481 -- iter: 0128/3680
[A[ATraining Step: 6100  | total loss: [1m[32m0.34439[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34439 - acc: 0.8508 | val_loss: 0.31393 - val_acc: 0.8806 -- iter: 0160/3680
[A[ATraining Step: 6100  | total loss: [1m[32m0.34439[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34439 - acc: 0.8508 | val_loss: 0.31393 - val_acc: 0.8806 -- iter: 0160/3680
--
Training Step: 6101  | total loss: [1m[32m0.34153[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34153 - acc: 0.8501 -- iter: 0192/3680
[A[ATraining Step: 6102  | total loss: [1m[32m0.34397[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34397 - acc: 0.8495 -- iter: 0224/3680
[A[ATraining Step: 6103  | total loss: [1m[32m0.33428[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33428 - acc: 0.8552 -- iter: 0256/3680
[A[ATraining Step: 6104  | total loss: [1m[32m0.32508[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32508 - acc: 0.8634 -- iter: 0288/3680
[A[ATraining Step: 6105  | total loss: [1m[32m0.33381[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33381 - acc: 0.8646 -- iter: 0320/3680
[A[ATraining Step: 6106  | total loss: [1m[32m0.33338[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33338 - acc: 0.8687 -- iter: 0352/3680
[A[ATraining Step: 6107  | total loss: [1m[32m0.32659[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32659 - acc: 0.8694 -- iter: 0384/3680
[A[ATraining Step: 6108  | total loss: [1m[32m0.35125[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35125 - acc: 0.8668 -- iter: 0416/3680
[A[ATraining Step: 6109  | total loss: [1m[32m0.36582[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36582 - acc: 0.8614 -- iter: 0448/3680
[A[ATraining Step: 6110  | total loss: [1m[32m0.35467[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35467 - acc: 0.8596 -- iter: 0480/3680
[A[ATraining Step: 6111  | total loss: [1m[32m0.34994[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34994 - acc: 0.8611 -- iter: 0512/3680
[A[ATraining Step: 6112  | total loss: [1m[32m0.37082[0m[0m
[2K| Adam | epoch: 054 | loss: 0.37082 - acc: 0.8500 -- iter: 0544/3680
[A[ATraining Step: 6113  | total loss: [1m[32m0.37427[0m[0m
[2K| Adam | epoch: 054 | loss: 0.37427 - acc: 0.8432 -- iter: 0576/3680
[A[ATraining Step: 6114  | total loss: [1m[32m0.36988[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36988 - acc: 0.8432 -- iter: 0608/3680
[A[ATraining Step: 6115  | total loss: [1m[32m0.38436[0m[0m
[2K| Adam | epoch: 054 | loss: 0.38436 - acc: 0.8436 -- iter: 0640/3680
[A[ATraining Step: 6116  | total loss: [1m[32m0.37522[0m[0m
[2K| Adam | epoch: 054 | loss: 0.37522 - acc: 0.8436 -- iter: 0672/3680
[A[ATraining Step: 6117  | total loss: [1m[32m0.35568[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35568 - acc: 0.8436 -- iter: 0704/3680
[A[ATraining Step: 6118  | total loss: [1m[32m0.35568[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35568 - acc: 0.8530 -- iter: 0736/3680
[A[ATraining Step: 6119  | total loss: [1m[32m0.34705[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34705 - acc: 0.8552 -- iter: 0768/3680
[A[ATraining Step: 6120  | total loss: [1m[32m0.32727[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32727 - acc: 0.8634 -- iter: 0800/3680
[A[ATraining Step: 6121  | total loss: [1m[32m0.32228[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32228 - acc: 0.8677 -- iter: 0832/3680
[A[ATraining Step: 6122  | total loss: [1m[32m0.33364[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33364 - acc: 0.8622 -- iter: 0864/3680
[A[ATraining Step: 6123  | total loss: [1m[32m0.33554[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33554 - acc: 0.8604 -- iter: 0896/3680
[A[ATraining Step: 6124  | total loss: [1m[32m0.32752[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32752 - acc: 0.8681 -- iter: 0928/3680
[A[ATraining Step: 6125  | total loss: [1m[32m0.34170[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34170 - acc: 0.8656 -- iter: 0960/3680
[A[ATraining Step: 6126  | total loss: [1m[32m0.33636[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33636 - acc: 0.8728 -- iter: 0992/3680
[A[ATraining Step: 6127  | total loss: [1m[32m0.34111[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34111 - acc: 0.8730 -- iter: 1024/3680
[A[ATraining Step: 6128  | total loss: [1m[32m0.34263[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34263 - acc: 0.8764 -- iter: 1056/3680
[A[ATraining Step: 6129  | total loss: [1m[32m0.33064[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33064 - acc: 0.8789 -- iter: 1088/3680
[A[ATraining Step: 6130  | total loss: [1m[32m0.33064[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33064 - acc: 0.8789 -- iter: 1120/3680
[A[ATraining Step: 6131  | total loss: [1m[32m0.31472[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31472 - acc: 0.8879 -- iter: 1152/3680
[A[ATraining Step: 6132  | total loss: [1m[32m0.34340[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34340 - acc: 0.8710 -- iter: 1184/3680
[A[ATraining Step: 6133  | total loss: [1m[32m0.32738[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32738 - acc: 0.8839 -- iter: 1216/3680
[A[ATraining Step: 6134  | total loss: [1m[32m0.33239[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33239 - acc: 0.8830 -- iter: 1248/3680
[A[ATraining Step: 6135  | total loss: [1m[32m0.33535[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33535 - acc: 0.8822 -- iter: 1280/3680
[A[ATraining Step: 6136  | total loss: [1m[32m0.34126[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34126 - acc: 0.8752 -- iter: 1312/3680
[A[ATraining Step: 6137  | total loss: [1m[32m0.33221[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33221 - acc: 0.8752 -- iter: 1344/3680
[A[ATraining Step: 6138  | total loss: [1m[32m0.33576[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33576 - acc: 0.8721 -- iter: 1376/3680
[A[ATraining Step: 6139  | total loss: [1m[32m0.34561[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34561 - acc: 0.8724 -- iter: 1408/3680
[A[ATraining Step: 6140  | total loss: [1m[32m0.33763[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33763 - acc: 0.8757 -- iter: 1440/3680
[A[ATraining Step: 6141  | total loss: [1m[32m0.32542[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32542 - acc: 0.8819 -- iter: 1472/3680
[A[ATraining Step: 6142  | total loss: [1m[32m0.33480[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33480 - acc: 0.8719 -- iter: 1504/3680
[A[ATraining Step: 6143  | total loss: [1m[32m0.33136[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33136 - acc: 0.8722 -- iter: 1536/3680
[A[ATraining Step: 6144  | total loss: [1m[32m0.33989[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33989 - acc: 0.8708 -- iter: 1568/3680
[A[ATraining Step: 6145  | total loss: [1m[32m0.35048[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35048 - acc: 0.8587 -- iter: 1600/3680
[A[ATraining Step: 6146  | total loss: [1m[32m0.35048[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35048 - acc: 0.8587 -- iter: 1632/3680
[A[ATraining Step: 6147  | total loss: [1m[32m0.33893[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33893 - acc: 0.8666 -- iter: 1664/3680
[A[ATraining Step: 6148  | total loss: [1m[32m0.33806[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33806 - acc: 0.8706 -- iter: 1696/3680
[A[ATraining Step: 6149  | total loss: [1m[32m0.33084[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33084 - acc: 0.8742 -- iter: 1728/3680
[A[ATraining Step: 6150  | total loss: [1m[32m0.32267[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32267 - acc: 0.8805 -- iter: 1760/3680
[A[ATraining Step: 6151  | total loss: [1m[32m0.33247[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33247 - acc: 0.8737 -- iter: 1792/3680
[A[ATraining Step: 6152  | total loss: [1m[32m0.33353[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33353 - acc: 0.8707 -- iter: 1824/3680
[A[ATraining Step: 6153  | total loss: [1m[32m0.33377[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33377 - acc: 0.8711 -- iter: 1856/3680
[A[ATraining Step: 6154  | total loss: [1m[32m0.31798[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31798 - acc: 0.8809 -- iter: 1888/3680
[A[ATraining Step: 6155  | total loss: [1m[32m0.31898[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31898 - acc: 0.8834 -- iter: 1920/3680
[A[ATraining Step: 6156  | total loss: [1m[32m0.30984[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30984 - acc: 0.8826 -- iter: 1952/3680
[A[ATraining Step: 6157  | total loss: [1m[32m0.30489[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30489 - acc: 0.8818 -- iter: 1984/3680
[A[ATraining Step: 6158  | total loss: [1m[32m0.30869[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30869 - acc: 0.8780 -- iter: 2016/3680
[A[ATraining Step: 6159  | total loss: [1m[32m0.31234[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31234 - acc: 0.8715 -- iter: 2048/3680
[A[ATraining Step: 6160  | total loss: [1m[32m0.30524[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30524 - acc: 0.8781 -- iter: 2080/3680
[A[ATraining Step: 6161  | total loss: [1m[32m0.30588[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30588 - acc: 0.8778 -- iter: 2112/3680
[A[ATraining Step: 6162  | total loss: [1m[32m0.29898[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29898 - acc: 0.8829 -- iter: 2144/3680
[A[ATraining Step: 6163  | total loss: [1m[32m0.29052[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29052 - acc: 0.8829 -- iter: 2176/3680
[A[ATraining Step: 6164  | total loss: [1m[32m0.29767[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29767 - acc: 0.8821 -- iter: 2208/3680
[A[ATraining Step: 6165  | total loss: [1m[32m0.29502[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29502 - acc: 0.8814 -- iter: 2240/3680
[A[ATraining Step: 6166  | total loss: [1m[32m0.30614[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30614 - acc: 0.8807 -- iter: 2272/3680
[A[ATraining Step: 6167  | total loss: [1m[32m0.29929[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29929 - acc: 0.8833 -- iter: 2304/3680
[A[ATraining Step: 6168  | total loss: [1m[32m0.32607[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32607 - acc: 0.8731 -- iter: 2336/3680
[A[ATraining Step: 6169  | total loss: [1m[32m0.31629[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31629 - acc: 0.8764 -- iter: 2368/3680
[A[ATraining Step: 6170  | total loss: [1m[32m0.30316[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30316 - acc: 0.8825 -- iter: 2400/3680
[A[ATraining Step: 6171  | total loss: [1m[32m0.29693[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29693 - acc: 0.8880 -- iter: 2432/3680
[A[ATraining Step: 6172  | total loss: [1m[32m0.29281[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29281 - acc: 0.8930 -- iter: 2464/3680
[A[ATraining Step: 6173  | total loss: [1m[32m0.30856[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30856 - acc: 0.8787 -- iter: 2496/3680
[A[ATraining Step: 6174  | total loss: [1m[32m0.30056[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30056 - acc: 0.8814 -- iter: 2528/3680
[A[ATraining Step: 6175  | total loss: [1m[32m0.29441[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29441 - acc: 0.8839 -- iter: 2560/3680
[A[ATraining Step: 6176  | total loss: [1m[32m0.28721[0m[0m
[2K| Adam | epoch: 054 | loss: 0.28721 - acc: 0.8861 -- iter: 2592/3680
[A[ATraining Step: 6177  | total loss: [1m[32m0.29912[0m[0m
[2K| Adam | epoch: 054 | loss: 0.29912 - acc: 0.8725 -- iter: 2624/3680
[A[ATraining Step: 6178  | total loss: [1m[32m0.31128[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31128 - acc: 0.8696 -- iter: 2656/3680
[A[ATraining Step: 6179  | total loss: [1m[32m0.30331[0m[0m
[2K| Adam | epoch: 054 | loss: 0.30331 - acc: 0.8733 -- iter: 2688/3680
[A[ATraining Step: 6180  | total loss: [1m[32m0.31001[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31001 - acc: 0.8704 -- iter: 2720/3680
[A[ATraining Step: 6181  | total loss: [1m[32m0.32179[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32179 - acc: 0.8614 -- iter: 2752/3680
[A[ATraining Step: 6182  | total loss: [1m[32m0.31965[0m[0m
[2K| Adam | epoch: 054 | loss: 0.31965 - acc: 0.8628 -- iter: 2784/3680
[A[ATraining Step: 6183  | total loss: [1m[32m0.32782[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32782 - acc: 0.8609 -- iter: 2816/3680
[A[ATraining Step: 6184  | total loss: [1m[32m0.33257[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33257 - acc: 0.8623 -- iter: 2848/3680
[A[ATraining Step: 6185  | total loss: [1m[32m0.33898[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33898 - acc: 0.8542 -- iter: 2880/3680
[A[ATraining Step: 6186  | total loss: [1m[32m0.34444[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34444 - acc: 0.8563 -- iter: 2912/3680
[A[ATraining Step: 6187  | total loss: [1m[32m0.34370[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34370 - acc: 0.8581 -- iter: 2944/3680
[A[ATraining Step: 6188  | total loss: [1m[32m0.34705[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34705 - acc: 0.8505 -- iter: 2976/3680
[A[ATraining Step: 6189  | total loss: [1m[32m0.33582[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33582 - acc: 0.8592 -- iter: 3008/3680
[A[ATraining Step: 6190  | total loss: [1m[32m0.34783[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34783 - acc: 0.8576 -- iter: 3040/3680
[A[ATraining Step: 6191  | total loss: [1m[32m0.35859[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35859 - acc: 0.8562 -- iter: 3072/3680
[A[ATraining Step: 6192  | total loss: [1m[32m0.36325[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36325 - acc: 0.8519 -- iter: 3104/3680
[A[ATraining Step: 6193  | total loss: [1m[32m0.36863[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36863 - acc: 0.8511 -- iter: 3136/3680
[A[ATraining Step: 6194  | total loss: [1m[32m0.36594[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36594 - acc: 0.8597 -- iter: 3168/3680
[A[ATraining Step: 6195  | total loss: [1m[32m0.37101[0m[0m
[2K| Adam | epoch: 054 | loss: 0.37101 - acc: 0.8576 -- iter: 3200/3680
[A[ATraining Step: 6196  | total loss: [1m[32m0.35936[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35936 - acc: 0.8576 -- iter: 3232/3680
[A[ATraining Step: 6197  | total loss: [1m[32m0.36389[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36389 - acc: 0.8562 -- iter: 3264/3680
[A[ATraining Step: 6198  | total loss: [1m[32m0.35199[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35199 - acc: 0.8581 -- iter: 3296/3680
[A[ATraining Step: 6199  | total loss: [1m[32m0.35683[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35683 - acc: 0.8535 -- iter: 3328/3680
[A[ATraining Step: 6200  | total loss: [1m[32m0.35558[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35558 - acc: 0.8557 | val_loss: 0.30772 - val_acc: 0.8958 -- iter: 3360/3680
[A[ATraining Step: 6200  | total loss: [1m[32m0.35558[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35558 - acc: 0.8557 | val_loss: 0.30772 - val_acc: 0.8958 -- iter: 3360/3680
--
Training Step: 6201  | total loss: [1m[32m0.35343[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35343 - acc: 0.8545 -- iter: 3392/3680
[A[ATraining Step: 6202  | total loss: [1m[32m0.35115[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35115 - acc: 0.8628 -- iter: 3424/3680
[A[ATraining Step: 6203  | total loss: [1m[32m0.35127[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35127 - acc: 0.8609 -- iter: 3456/3680
[A[ATraining Step: 6204  | total loss: [1m[32m0.36505[0m[0m
[2K| Adam | epoch: 054 | loss: 0.36505 - acc: 0.8560 -- iter: 3488/3680
[A[ATraining Step: 6205  | total loss: [1m[32m0.35920[0m[0m
[2K| Adam | epoch: 054 | loss: 0.35920 - acc: 0.8642 -- iter: 3520/3680
[A[ATraining Step: 6206  | total loss: [1m[32m0.34798[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34798 - acc: 0.8746 -- iter: 3552/3680
[A[ATraining Step: 6207  | total loss: [1m[32m0.34937[0m[0m
[2K| Adam | epoch: 054 | loss: 0.34937 - acc: 0.8716 -- iter: 3584/3680
[A[ATraining Step: 6208  | total loss: [1m[32m0.33666[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33666 - acc: 0.8750 -- iter: 3616/3680
[A[ATraining Step: 6209  | total loss: [1m[32m0.33632[0m[0m
[2K| Adam | epoch: 054 | loss: 0.33632 - acc: 0.8782 -- iter: 3648/3680
[A[ATraining Step: 6210  | total loss: [1m[32m0.32849[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32849 - acc: 0.8778 | val_loss: 0.31062 - val_acc: 0.8893 -- iter: 3680/3680
[A[ATraining Step: 6210  | total loss: [1m[32m0.32849[0m[0m
[2K| Adam | epoch: 054 | loss: 0.32849 - acc: 0.8778 | val_loss: 0.31062 - val_acc: 0.8893 -- iter: 3680/3680
--
Training Step: 6211  | total loss: [1m[32m0.32934[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32934 - acc: 0.8776 -- iter: 0032/3680
[A[ATraining Step: 6212  | total loss: [1m[32m0.34094[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34094 - acc: 0.8742 -- iter: 0064/3680
[A[ATraining Step: 6213  | total loss: [1m[32m0.32636[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32636 - acc: 0.8805 -- iter: 0096/3680
[A[ATraining Step: 6214  | total loss: [1m[32m0.31977[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31977 - acc: 0.8862 -- iter: 0128/3680
[A[ATraining Step: 6215  | total loss: [1m[32m0.32753[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32753 - acc: 0.8820 -- iter: 0160/3680
[A[ATraining Step: 6216  | total loss: [1m[32m0.31949[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31949 - acc: 0.8875 -- iter: 0192/3680
[A[ATraining Step: 6217  | total loss: [1m[32m0.32818[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32818 - acc: 0.8769 -- iter: 0224/3680
[A[ATraining Step: 6218  | total loss: [1m[32m0.32215[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32215 - acc: 0.8798 -- iter: 0256/3680
[A[ATraining Step: 6219  | total loss: [1m[32m0.31981[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31981 - acc: 0.8856 -- iter: 0288/3680
[A[ATraining Step: 6220  | total loss: [1m[32m0.33590[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33590 - acc: 0.8689 -- iter: 0320/3680
[A[ATraining Step: 6221  | total loss: [1m[32m0.35896[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35896 - acc: 0.8476 -- iter: 0352/3680
[A[ATraining Step: 6222  | total loss: [1m[32m0.36471[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36471 - acc: 0.8441 -- iter: 0384/3680
[A[ATraining Step: 6223  | total loss: [1m[32m0.36343[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36343 - acc: 0.8441 -- iter: 0416/3680
[A[ATraining Step: 6224  | total loss: [1m[32m0.35930[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35930 - acc: 0.8472 -- iter: 0448/3680
[A[ATraining Step: 6225  | total loss: [1m[32m0.35804[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35804 - acc: 0.8500 -- iter: 0480/3680
[A[ATraining Step: 6226  | total loss: [1m[32m0.35602[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35602 - acc: 0.8493 -- iter: 0512/3680
[A[ATraining Step: 6227  | total loss: [1m[32m0.35374[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35374 - acc: 0.8519 -- iter: 0544/3680
[A[ATraining Step: 6228  | total loss: [1m[32m0.33689[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33689 - acc: 0.8636 -- iter: 0576/3680
[A[ATraining Step: 6229  | total loss: [1m[32m0.32911[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32911 - acc: 0.8679 -- iter: 0608/3680
[A[ATraining Step: 6230  | total loss: [1m[32m0.33023[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33023 - acc: 0.8623 -- iter: 0640/3680
[A[ATraining Step: 6231  | total loss: [1m[32m0.32548[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32548 - acc: 0.8636 -- iter: 0672/3680
[A[ATraining Step: 6232  | total loss: [1m[32m0.34448[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34448 - acc: 0.8522 -- iter: 0704/3680
[A[ATraining Step: 6233  | total loss: [1m[32m0.33770[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33770 - acc: 0.8576 -- iter: 0736/3680
[A[ATraining Step: 6234  | total loss: [1m[32m0.34046[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34046 - acc: 0.8594 -- iter: 0768/3680
[A[ATraining Step: 6235  | total loss: [1m[32m0.34460[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34460 - acc: 0.8578 -- iter: 0800/3680
[A[ATraining Step: 6236  | total loss: [1m[32m0.34196[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34196 - acc: 0.8564 -- iter: 0832/3680
[A[ATraining Step: 6237  | total loss: [1m[32m0.34349[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34349 - acc: 0.8489 -- iter: 0864/3680
[A[ATraining Step: 6238  | total loss: [1m[32m0.33493[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33493 - acc: 0.8515 -- iter: 0896/3680
[A[ATraining Step: 6239  | total loss: [1m[32m0.33640[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33640 - acc: 0.8507 -- iter: 0928/3680
[A[ATraining Step: 6240  | total loss: [1m[32m0.33867[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33867 - acc: 0.8469 -- iter: 0960/3680
[A[ATraining Step: 6241  | total loss: [1m[32m0.34836[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34836 - acc: 0.8372 -- iter: 0992/3680
[A[ATraining Step: 6242  | total loss: [1m[32m0.34162[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34162 - acc: 0.8441 -- iter: 1024/3680
[A[ATraining Step: 6243  | total loss: [1m[32m0.34685[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34685 - acc: 0.8441 -- iter: 1056/3680
[A[ATraining Step: 6244  | total loss: [1m[32m0.34048[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34048 - acc: 0.8472 -- iter: 1088/3680
[A[ATraining Step: 6245  | total loss: [1m[32m0.34894[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34894 - acc: 0.8406 -- iter: 1120/3680
[A[ATraining Step: 6246  | total loss: [1m[32m0.34890[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34890 - acc: 0.8471 -- iter: 1152/3680
[A[ATraining Step: 6247  | total loss: [1m[32m0.34154[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34154 - acc: 0.8468 -- iter: 1184/3680
[A[ATraining Step: 6248  | total loss: [1m[32m0.32500[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32500 - acc: 0.8590 -- iter: 1216/3680
[A[ATraining Step: 6249  | total loss: [1m[32m0.32400[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32400 - acc: 0.8575 -- iter: 1248/3680
[A[ATraining Step: 6250  | total loss: [1m[32m0.32231[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32231 - acc: 0.8624 -- iter: 1280/3680
[A[ATraining Step: 6251  | total loss: [1m[32m0.33394[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33394 - acc: 0.8542 -- iter: 1312/3680
[A[ATraining Step: 6252  | total loss: [1m[32m0.32573[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32573 - acc: 0.8563 -- iter: 1344/3680
[A[ATraining Step: 6253  | total loss: [1m[32m0.32142[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32142 - acc: 0.8613 -- iter: 1376/3680
[A[ATraining Step: 6254  | total loss: [1m[32m0.32857[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32857 - acc: 0.8564 -- iter: 1408/3680
[A[ATraining Step: 6255  | total loss: [1m[32m0.35099[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35099 - acc: 0.8458 -- iter: 1440/3680
[A[ATraining Step: 6256  | total loss: [1m[32m0.34931[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34931 - acc: 0.8456 -- iter: 1472/3680
[A[ATraining Step: 6257  | total loss: [1m[32m0.34775[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34775 - acc: 0.8392 -- iter: 1504/3680
[A[ATraining Step: 6258  | total loss: [1m[32m0.33957[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33957 - acc: 0.8459 -- iter: 1536/3680
[A[ATraining Step: 6259  | total loss: [1m[32m0.34742[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34742 - acc: 0.8519 -- iter: 1568/3680
[A[ATraining Step: 6260  | total loss: [1m[32m0.34483[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34483 - acc: 0.8542 -- iter: 1600/3680
[A[ATraining Step: 6261  | total loss: [1m[32m0.33450[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33450 - acc: 0.8625 -- iter: 1632/3680
[A[ATraining Step: 6262  | total loss: [1m[32m0.34699[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34699 - acc: 0.8575 -- iter: 1664/3680
[A[ATraining Step: 6263  | total loss: [1m[32m0.34913[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34913 - acc: 0.8562 -- iter: 1696/3680
[A[ATraining Step: 6264  | total loss: [1m[32m0.35180[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35180 - acc: 0.8518 -- iter: 1728/3680
[A[ATraining Step: 6265  | total loss: [1m[32m0.34743[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34743 - acc: 0.8572 -- iter: 1760/3680
[A[ATraining Step: 6266  | total loss: [1m[32m0.32763[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32763 - acc: 0.8715 -- iter: 1792/3680
[A[ATraining Step: 6267  | total loss: [1m[32m0.32620[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32620 - acc: 0.8687 -- iter: 1824/3680
[A[ATraining Step: 6268  | total loss: [1m[32m0.33705[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33705 - acc: 0.8569 -- iter: 1856/3680
[A[ATraining Step: 6269  | total loss: [1m[32m0.32858[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32858 - acc: 0.8587 -- iter: 1888/3680
[A[ATraining Step: 6270  | total loss: [1m[32m0.31274[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31274 - acc: 0.8666 -- iter: 1920/3680
[A[ATraining Step: 6271  | total loss: [1m[32m0.31351[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31351 - acc: 0.8705 -- iter: 1952/3680
[A[ATraining Step: 6272  | total loss: [1m[32m0.31932[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31932 - acc: 0.8741 -- iter: 1984/3680
[A[ATraining Step: 6273  | total loss: [1m[32m0.31912[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31912 - acc: 0.8742 -- iter: 2016/3680
[A[ATraining Step: 6274  | total loss: [1m[32m0.33456[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33456 - acc: 0.8649 -- iter: 2048/3680
[A[ATraining Step: 6275  | total loss: [1m[32m0.32695[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32695 - acc: 0.8690 -- iter: 2080/3680
[A[ATraining Step: 6276  | total loss: [1m[32m0.33395[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33395 - acc: 0.8634 -- iter: 2112/3680
[A[ATraining Step: 6277  | total loss: [1m[32m0.34367[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34367 - acc: 0.8552 -- iter: 2144/3680
[A[ATraining Step: 6278  | total loss: [1m[32m0.33060[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33060 - acc: 0.8665 -- iter: 2176/3680
[A[ATraining Step: 6279  | total loss: [1m[32m0.33474[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33474 - acc: 0.8611 -- iter: 2208/3680
[A[ATraining Step: 6280  | total loss: [1m[32m0.33091[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33091 - acc: 0.8625 -- iter: 2240/3680
[A[ATraining Step: 6281  | total loss: [1m[32m0.32934[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32934 - acc: 0.8638 -- iter: 2272/3680
[A[ATraining Step: 6282  | total loss: [1m[32m0.32383[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32383 - acc: 0.8649 -- iter: 2304/3680
[A[ATraining Step: 6283  | total loss: [1m[32m0.32180[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32180 - acc: 0.8690 -- iter: 2336/3680
[A[ATraining Step: 6284  | total loss: [1m[32m0.31692[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31692 - acc: 0.8696 -- iter: 2368/3680
[A[ATraining Step: 6285  | total loss: [1m[32m0.30371[0m[0m
[2K| Adam | epoch: 055 | loss: 0.30371 - acc: 0.8827 -- iter: 2400/3680
[A[ATraining Step: 6286  | total loss: [1m[32m0.32643[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32643 - acc: 0.8663 -- iter: 2432/3680
[A[ATraining Step: 6287  | total loss: [1m[32m0.32680[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32680 - acc: 0.8703 -- iter: 2464/3680
[A[ATraining Step: 6288  | total loss: [1m[32m0.32057[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32057 - acc: 0.8707 -- iter: 2496/3680
[A[ATraining Step: 6289  | total loss: [1m[32m0.32615[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32615 - acc: 0.8712 -- iter: 2528/3680
[A[ATraining Step: 6290  | total loss: [1m[32m0.33760[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33760 - acc: 0.8622 -- iter: 2560/3680
[A[ATraining Step: 6291  | total loss: [1m[32m0.34181[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34181 - acc: 0.8603 -- iter: 2592/3680
[A[ATraining Step: 6292  | total loss: [1m[32m0.33115[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33115 - acc: 0.8680 -- iter: 2624/3680
[A[ATraining Step: 6293  | total loss: [1m[32m0.32462[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32462 - acc: 0.8687 -- iter: 2656/3680
[A[ATraining Step: 6294  | total loss: [1m[32m0.33951[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33951 - acc: 0.8600 -- iter: 2688/3680
[A[ATraining Step: 6295  | total loss: [1m[32m0.33473[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33473 - acc: 0.8552 -- iter: 2720/3680
[A[ATraining Step: 6296  | total loss: [1m[32m0.33311[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33311 - acc: 0.8541 -- iter: 2752/3680
[A[ATraining Step: 6297  | total loss: [1m[32m0.34075[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34075 - acc: 0.8531 -- iter: 2784/3680
[A[ATraining Step: 6298  | total loss: [1m[32m0.33680[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33680 - acc: 0.8553 -- iter: 2816/3680
[A[ATraining Step: 6299  | total loss: [1m[32m0.32510[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32510 - acc: 0.8604 -- iter: 2848/3680
[A[ATraining Step: 6300  | total loss: [1m[32m0.33074[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33074 - acc: 0.8556 | val_loss: 0.33927 - val_acc: 0.8719 -- iter: 2880/3680
[A[ATraining Step: 6300  | total loss: [1m[32m0.33074[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33074 - acc: 0.8556 | val_loss: 0.33927 - val_acc: 0.8719 -- iter: 2880/3680
--
Training Step: 6301  | total loss: [1m[32m0.33345[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33345 - acc: 0.8513 -- iter: 2912/3680
[A[ATraining Step: 6302  | total loss: [1m[32m0.33579[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33579 - acc: 0.8505 -- iter: 2944/3680
[A[ATraining Step: 6303  | total loss: [1m[32m0.33116[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33116 - acc: 0.8561 -- iter: 2976/3680
[A[ATraining Step: 6304  | total loss: [1m[32m0.32670[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32670 - acc: 0.8549 -- iter: 3008/3680
[A[ATraining Step: 6305  | total loss: [1m[32m0.32624[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32624 - acc: 0.8600 -- iter: 3040/3680
[A[ATraining Step: 6306  | total loss: [1m[32m0.32483[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32483 - acc: 0.8677 -- iter: 3072/3680
[A[ATraining Step: 6307  | total loss: [1m[32m0.32812[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32812 - acc: 0.8653 -- iter: 3104/3680
[A[ATraining Step: 6308  | total loss: [1m[32m0.33292[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33292 - acc: 0.8632 -- iter: 3136/3680
[A[ATraining Step: 6309  | total loss: [1m[32m0.33136[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33136 - acc: 0.8644 -- iter: 3168/3680
[A[ATraining Step: 6310  | total loss: [1m[32m0.32972[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32972 - acc: 0.8654 -- iter: 3200/3680
[A[ATraining Step: 6311  | total loss: [1m[32m0.31501[0m[0m
[2K| Adam | epoch: 055 | loss: 0.31501 - acc: 0.8695 -- iter: 3232/3680
[A[ATraining Step: 6312  | total loss: [1m[32m0.32210[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32210 - acc: 0.8701 -- iter: 3264/3680
[A[ATraining Step: 6313  | total loss: [1m[32m0.33062[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33062 - acc: 0.8612 -- iter: 3296/3680
[A[ATraining Step: 6314  | total loss: [1m[32m0.32901[0m[0m
[2K| Adam | epoch: 055 | loss: 0.32901 - acc: 0.8594 -- iter: 3328/3680
[A[ATraining Step: 6315  | total loss: [1m[32m0.33764[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33764 - acc: 0.8516 -- iter: 3360/3680
[A[ATraining Step: 6316  | total loss: [1m[32m0.34886[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34886 - acc: 0.8477 -- iter: 3392/3680
[A[ATraining Step: 6317  | total loss: [1m[32m0.34509[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34509 - acc: 0.8504 -- iter: 3424/3680
[A[ATraining Step: 6318  | total loss: [1m[32m0.34799[0m[0m
[2K| Adam | epoch: 055 | loss: 0.34799 - acc: 0.8529 -- iter: 3456/3680
[A[ATraining Step: 6319  | total loss: [1m[32m0.33915[0m[0m
[2K| Adam | epoch: 055 | loss: 0.33915 - acc: 0.8582 -- iter: 3488/3680
[A[ATraining Step: 6320  | total loss: [1m[32m0.35789[0m[0m
[2K| Adam | epoch: 055 | loss: 0.35789 - acc: 0.8505 -- iter: 3520/3680
[A[ATraining Step: 6321  | total loss: [1m[32m0.36497[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36497 - acc: 0.8467 -- iter: 3552/3680
[A[ATraining Step: 6322  | total loss: [1m[32m0.36799[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36799 - acc: 0.8483 -- iter: 3584/3680
[A[ATraining Step: 6323  | total loss: [1m[32m0.36799[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36799 - acc: 0.8483 -- iter: 3616/3680
[A[ATraining Step: 6324  | total loss: [1m[32m0.36618[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36618 - acc: 0.8479 -- iter: 3648/3680
[A[ATraining Step: 6325  | total loss: [1m[32m0.36621[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36621 - acc: 0.8475 | val_loss: 0.32990 - val_acc: 0.8730 -- iter: 3680/3680
[A[ATraining Step: 6325  | total loss: [1m[32m0.36621[0m[0m
[2K| Adam | epoch: 055 | loss: 0.36621 - acc: 0.8475 | val_loss: 0.32990 - val_acc: 0.8730 -- iter: 3680/3680
--
Training Step: 6326  | total loss: [1m[32m0.36762[0m[0m
[2K| Adam | epoch: 056 | loss: 0.36762 - acc: 0.8471 -- iter: 0032/3680
[A[ATraining Step: 6327  | total loss: [1m[32m0.38219[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38219 - acc: 0.8405 -- iter: 0064/3680
[A[ATraining Step: 6328  | total loss: [1m[32m0.37488[0m[0m
[2K| Adam | epoch: 056 | loss: 0.37488 - acc: 0.8471 -- iter: 0096/3680
[A[ATraining Step: 6329  | total loss: [1m[32m0.38512[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38512 - acc: 0.8436 -- iter: 0128/3680
[A[ATraining Step: 6330  | total loss: [1m[32m0.39295[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39295 - acc: 0.8311 -- iter: 0160/3680
[A[ATraining Step: 6331  | total loss: [1m[32m0.38884[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38884 - acc: 0.8387 -- iter: 0192/3680
[A[ATraining Step: 6332  | total loss: [1m[32m0.38343[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38343 - acc: 0.8423 -- iter: 0224/3680
[A[ATraining Step: 6333  | total loss: [1m[32m0.37901[0m[0m
[2K| Adam | epoch: 056 | loss: 0.37901 - acc: 0.8487 -- iter: 0256/3680
[A[ATraining Step: 6334  | total loss: [1m[32m0.38263[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38263 - acc: 0.8451 -- iter: 0288/3680
[A[ATraining Step: 6335  | total loss: [1m[32m0.36584[0m[0m
[2K| Adam | epoch: 056 | loss: 0.36584 - acc: 0.8543 -- iter: 0320/3680
[A[ATraining Step: 6336  | total loss: [1m[32m0.38655[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38655 - acc: 0.8470 -- iter: 0352/3680
[A[ATraining Step: 6337  | total loss: [1m[32m0.37447[0m[0m
[2K| Adam | epoch: 056 | loss: 0.37447 - acc: 0.8561 -- iter: 0384/3680
[A[ATraining Step: 6338  | total loss: [1m[32m0.35378[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35378 - acc: 0.8673 -- iter: 0416/3680
[A[ATraining Step: 6339  | total loss: [1m[32m0.33643[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33643 - acc: 0.8806 -- iter: 0448/3680
[A[ATraining Step: 6340  | total loss: [1m[32m0.31906[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31906 - acc: 0.8894 -- iter: 0480/3680
[A[ATraining Step: 6341  | total loss: [1m[32m0.30173[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30173 - acc: 0.8942 -- iter: 0512/3680
[A[ATraining Step: 6342  | total loss: [1m[32m0.30963[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30963 - acc: 0.8892 -- iter: 0544/3680
[A[ATraining Step: 6343  | total loss: [1m[32m0.30959[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30959 - acc: 0.8878 -- iter: 0576/3680
[A[ATraining Step: 6344  | total loss: [1m[32m0.30508[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30508 - acc: 0.8834 -- iter: 0608/3680
[A[ATraining Step: 6345  | total loss: [1m[32m0.31703[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31703 - acc: 0.8794 -- iter: 0640/3680
[A[ATraining Step: 6346  | total loss: [1m[32m0.34754[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34754 - acc: 0.8727 -- iter: 0672/3680
[A[ATraining Step: 6347  | total loss: [1m[32m0.34689[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34689 - acc: 0.8729 -- iter: 0704/3680
[A[ATraining Step: 6348  | total loss: [1m[32m0.34021[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34021 - acc: 0.8669 -- iter: 0736/3680
[A[ATraining Step: 6349  | total loss: [1m[32m0.33103[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33103 - acc: 0.8677 -- iter: 0768/3680
[A[ATraining Step: 6350  | total loss: [1m[32m0.32446[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32446 - acc: 0.8684 -- iter: 0800/3680
[A[ATraining Step: 6351  | total loss: [1m[32m0.31738[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31738 - acc: 0.8753 -- iter: 0832/3680
[A[ATraining Step: 6352  | total loss: [1m[32m0.32418[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32418 - acc: 0.8691 -- iter: 0864/3680
[A[ATraining Step: 6353  | total loss: [1m[32m0.32346[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32346 - acc: 0.8665 -- iter: 0896/3680
[A[ATraining Step: 6354  | total loss: [1m[32m0.33793[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33793 - acc: 0.8580 -- iter: 0928/3680
[A[ATraining Step: 6355  | total loss: [1m[32m0.34273[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34273 - acc: 0.8503 -- iter: 0960/3680
[A[ATraining Step: 6356  | total loss: [1m[32m0.36456[0m[0m
[2K| Adam | epoch: 056 | loss: 0.36456 - acc: 0.8403 -- iter: 0992/3680
[A[ATraining Step: 6357  | total loss: [1m[32m0.35451[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35451 - acc: 0.8438 -- iter: 1024/3680
[A[ATraining Step: 6358  | total loss: [1m[32m0.34501[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34501 - acc: 0.8500 -- iter: 1056/3680
[A[ATraining Step: 6359  | total loss: [1m[32m0.34690[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34690 - acc: 0.8556 -- iter: 1088/3680
[A[ATraining Step: 6360  | total loss: [1m[32m0.35219[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35219 - acc: 0.8506 -- iter: 1120/3680
[A[ATraining Step: 6361  | total loss: [1m[32m0.36345[0m[0m
[2K| Adam | epoch: 056 | loss: 0.36345 - acc: 0.8506 -- iter: 1152/3680
[A[ATraining Step: 6362  | total loss: [1m[32m0.37868[0m[0m
[2K| Adam | epoch: 056 | loss: 0.37868 - acc: 0.8405 -- iter: 1184/3680
[A[ATraining Step: 6363  | total loss: [1m[32m0.38335[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38335 - acc: 0.8346 -- iter: 1216/3680
[A[ATraining Step: 6364  | total loss: [1m[32m0.36944[0m[0m
[2K| Adam | epoch: 056 | loss: 0.36944 - acc: 0.8449 -- iter: 1248/3680
[A[ATraining Step: 6365  | total loss: [1m[32m0.36705[0m[0m
[2K| Adam | epoch: 056 | loss: 0.36705 - acc: 0.8479 -- iter: 1280/3680
[A[ATraining Step: 6366  | total loss: [1m[32m0.37259[0m[0m
[2K| Adam | epoch: 056 | loss: 0.37259 - acc: 0.8412 -- iter: 1312/3680
[A[ATraining Step: 6367  | total loss: [1m[32m0.35917[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35917 - acc: 0.8446 -- iter: 1344/3680
[A[ATraining Step: 6368  | total loss: [1m[32m0.35148[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35148 - acc: 0.8508 -- iter: 1376/3680
[A[ATraining Step: 6369  | total loss: [1m[32m0.33519[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33519 - acc: 0.8594 -- iter: 1408/3680
[A[ATraining Step: 6370  | total loss: [1m[32m0.32900[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32900 - acc: 0.8610 -- iter: 1440/3680
[A[ATraining Step: 6371  | total loss: [1m[32m0.32807[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32807 - acc: 0.8624 -- iter: 1472/3680
[A[ATraining Step: 6372  | total loss: [1m[32m0.31979[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31979 - acc: 0.8668 -- iter: 1504/3680
[A[ATraining Step: 6373  | total loss: [1m[32m0.32408[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32408 - acc: 0.8676 -- iter: 1536/3680
[A[ATraining Step: 6374  | total loss: [1m[32m0.32856[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32856 - acc: 0.8652 -- iter: 1568/3680
[A[ATraining Step: 6375  | total loss: [1m[32m0.32328[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32328 - acc: 0.8693 -- iter: 1600/3680
[A[ATraining Step: 6376  | total loss: [1m[32m0.32719[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32719 - acc: 0.8668 -- iter: 1632/3680
[A[ATraining Step: 6377  | total loss: [1m[32m0.33576[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33576 - acc: 0.8613 -- iter: 1664/3680
[A[ATraining Step: 6378  | total loss: [1m[32m0.32748[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32748 - acc: 0.8658 -- iter: 1696/3680
[A[ATraining Step: 6379  | total loss: [1m[32m0.34578[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34578 - acc: 0.8574 -- iter: 1728/3680
[A[ATraining Step: 6380  | total loss: [1m[32m0.35778[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35778 - acc: 0.8560 -- iter: 1760/3680
[A[ATraining Step: 6381  | total loss: [1m[32m0.35568[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35568 - acc: 0.8517 -- iter: 1792/3680
[A[ATraining Step: 6382  | total loss: [1m[32m0.34788[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34788 - acc: 0.8571 -- iter: 1824/3680
[A[ATraining Step: 6383  | total loss: [1m[32m0.34274[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34274 - acc: 0.8589 -- iter: 1856/3680
[A[ATraining Step: 6384  | total loss: [1m[32m0.33071[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33071 - acc: 0.8668 -- iter: 1888/3680
[A[ATraining Step: 6385  | total loss: [1m[32m0.32742[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32742 - acc: 0.8676 -- iter: 1920/3680
[A[ATraining Step: 6386  | total loss: [1m[32m0.32194[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32194 - acc: 0.8683 -- iter: 1952/3680
[A[ATraining Step: 6387  | total loss: [1m[32m0.31406[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31406 - acc: 0.8721 -- iter: 1984/3680
[A[ATraining Step: 6388  | total loss: [1m[32m0.35393[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35393 - acc: 0.8537 -- iter: 2016/3680
[A[ATraining Step: 6389  | total loss: [1m[32m0.35394[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35394 - acc: 0.8558 -- iter: 2048/3680
[A[ATraining Step: 6390  | total loss: [1m[32m0.34270[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34270 - acc: 0.8608 -- iter: 2080/3680
[A[ATraining Step: 6391  | total loss: [1m[32m0.33467[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33467 - acc: 0.8623 -- iter: 2112/3680
[A[ATraining Step: 6392  | total loss: [1m[32m0.33725[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33725 - acc: 0.8604 -- iter: 2144/3680
[A[ATraining Step: 6393  | total loss: [1m[32m0.31650[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31650 - acc: 0.8744 -- iter: 2176/3680
[A[ATraining Step: 6394  | total loss: [1m[32m0.31224[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31224 - acc: 0.8835 -- iter: 2208/3680
[A[ATraining Step: 6395  | total loss: [1m[32m0.29889[0m[0m
[2K| Adam | epoch: 056 | loss: 0.29889 - acc: 0.8835 -- iter: 2240/3680
[A[ATraining Step: 6396  | total loss: [1m[32m0.29837[0m[0m
[2K| Adam | epoch: 056 | loss: 0.29837 - acc: 0.8858 -- iter: 2272/3680
[A[ATraining Step: 6397  | total loss: [1m[32m0.29831[0m[0m
[2K| Adam | epoch: 056 | loss: 0.29831 - acc: 0.8847 -- iter: 2304/3680
[A[ATraining Step: 6398  | total loss: [1m[32m0.30280[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30280 - acc: 0.8838 -- iter: 2336/3680
[A[ATraining Step: 6399  | total loss: [1m[32m0.30124[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30124 - acc: 0.8829 -- iter: 2368/3680
[A[ATraining Step: 6400  | total loss: [1m[32m0.34354[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34354 - acc: 0.8696 | val_loss: 0.30576 - val_acc: 0.8914 -- iter: 2400/3680
[A[ATraining Step: 6400  | total loss: [1m[32m0.34354[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34354 - acc: 0.8696 | val_loss: 0.30576 - val_acc: 0.8914 -- iter: 2400/3680
--
Training Step: 6401  | total loss: [1m[32m0.33383[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33383 - acc: 0.8701 -- iter: 2432/3680
[A[ATraining Step: 6402  | total loss: [1m[32m0.32698[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32698 - acc: 0.8706 -- iter: 2464/3680
[A[ATraining Step: 6403  | total loss: [1m[32m0.30693[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30693 - acc: 0.8804 -- iter: 2496/3680
[A[ATraining Step: 6404  | total loss: [1m[32m0.31591[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31591 - acc: 0.8705 -- iter: 2528/3680
[A[ATraining Step: 6405  | total loss: [1m[32m0.33733[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33733 - acc: 0.8616 -- iter: 2560/3680
[A[ATraining Step: 6406  | total loss: [1m[32m0.34466[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34466 - acc: 0.8629 -- iter: 2592/3680
[A[ATraining Step: 6407  | total loss: [1m[32m0.33736[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33736 - acc: 0.8641 -- iter: 2624/3680
[A[ATraining Step: 6408  | total loss: [1m[32m0.32082[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32082 - acc: 0.8746 -- iter: 2656/3680
[A[ATraining Step: 6409  | total loss: [1m[32m0.32131[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32131 - acc: 0.8746 -- iter: 2688/3680
[A[ATraining Step: 6410  | total loss: [1m[32m0.32401[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32401 - acc: 0.8716 -- iter: 2720/3680
[A[ATraining Step: 6411  | total loss: [1m[32m0.31906[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31906 - acc: 0.8719 -- iter: 2752/3680
[A[ATraining Step: 6412  | total loss: [1m[32m0.32310[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32310 - acc: 0.8628 -- iter: 2784/3680
[A[ATraining Step: 6413  | total loss: [1m[32m0.32191[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32191 - acc: 0.8609 -- iter: 2816/3680
[A[ATraining Step: 6414  | total loss: [1m[32m0.33037[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33037 - acc: 0.8592 -- iter: 2848/3680
[A[ATraining Step: 6415  | total loss: [1m[32m0.33262[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33262 - acc: 0.8577 -- iter: 2880/3680
[A[ATraining Step: 6416  | total loss: [1m[32m0.33782[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33782 - acc: 0.8563 -- iter: 2912/3680
[A[ATraining Step: 6417  | total loss: [1m[32m0.33423[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33423 - acc: 0.8550 -- iter: 2944/3680
[A[ATraining Step: 6418  | total loss: [1m[32m0.32884[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32884 - acc: 0.8633 -- iter: 2976/3680
[A[ATraining Step: 6419  | total loss: [1m[32m0.33703[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33703 - acc: 0.8582 -- iter: 3008/3680
[A[ATraining Step: 6420  | total loss: [1m[32m0.35204[0m[0m
[2K| Adam | epoch: 056 | loss: 0.35204 - acc: 0.8536 -- iter: 3040/3680
[A[ATraining Step: 6421  | total loss: [1m[32m0.33500[0m[0m
[2K| Adam | epoch: 056 | loss: 0.33500 - acc: 0.8651 -- iter: 3072/3680
[A[ATraining Step: 6422  | total loss: [1m[32m0.32256[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32256 - acc: 0.8724 -- iter: 3104/3680
[A[ATraining Step: 6423  | total loss: [1m[32m0.31087[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31087 - acc: 0.8820 -- iter: 3136/3680
[A[ATraining Step: 6424  | total loss: [1m[32m0.30213[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30213 - acc: 0.8907 -- iter: 3168/3680
[A[ATraining Step: 6425  | total loss: [1m[32m0.30803[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30803 - acc: 0.8860 -- iter: 3200/3680
[A[ATraining Step: 6426  | total loss: [1m[32m0.31094[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31094 - acc: 0.8880 -- iter: 3232/3680
[A[ATraining Step: 6427  | total loss: [1m[32m0.31025[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31025 - acc: 0.8898 -- iter: 3264/3680
[A[ATraining Step: 6428  | total loss: [1m[32m0.31127[0m[0m
[2K| Adam | epoch: 056 | loss: 0.31127 - acc: 0.8884 -- iter: 3296/3680
[A[ATraining Step: 6429  | total loss: [1m[32m0.29989[0m[0m
[2K| Adam | epoch: 056 | loss: 0.29989 - acc: 0.8901 -- iter: 3328/3680
[A[ATraining Step: 6430  | total loss: [1m[32m0.30030[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30030 - acc: 0.8918 -- iter: 3360/3680
[A[ATraining Step: 6431  | total loss: [1m[32m0.30945[0m[0m
[2K| Adam | epoch: 056 | loss: 0.30945 - acc: 0.8838 -- iter: 3392/3680
[A[ATraining Step: 6432  | total loss: [1m[32m0.32514[0m[0m
[2K| Adam | epoch: 056 | loss: 0.32514 - acc: 0.8736 -- iter: 3424/3680
[A[ATraining Step: 6433  | total loss: [1m[32m0.34293[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34293 - acc: 0.8595 -- iter: 3456/3680
[A[ATraining Step: 6434  | total loss: [1m[32m0.34370[0m[0m
[2K| Adam | epoch: 056 | loss: 0.34370 - acc: 0.8595 -- iter: 3488/3680
[A[ATraining Step: 6435  | total loss: [1m[32m0.39413[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39413 - acc: 0.8548 -- iter: 3520/3680
[A[ATraining Step: 6436  | total loss: [1m[32m0.39462[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39462 - acc: 0.8599 -- iter: 3552/3680
[A[ATraining Step: 6437  | total loss: [1m[32m0.38687[0m[0m
[2K| Adam | epoch: 056 | loss: 0.38687 - acc: 0.8583 -- iter: 3584/3680
[A[ATraining Step: 6438  | total loss: [1m[32m0.39091[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39091 - acc: 0.8537 -- iter: 3616/3680
[A[ATraining Step: 6439  | total loss: [1m[32m0.39150[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39150 - acc: 0.8527 -- iter: 3648/3680
[A[ATraining Step: 6440  | total loss: [1m[32m0.39508[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39508 - acc: 0.8456 | val_loss: 0.32253 - val_acc: 0.8817 -- iter: 3680/3680
[A[ATraining Step: 6440  | total loss: [1m[32m0.39508[0m[0m
[2K| Adam | epoch: 056 | loss: 0.39508 - acc: 0.8456 | val_loss: 0.32253 - val_acc: 0.8817 -- iter: 3680/3680
--
Training Step: 6441  | total loss: [1m[32m0.38600[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38600 - acc: 0.8454 -- iter: 0032/3680
[A[ATraining Step: 6442  | total loss: [1m[32m0.40522[0m[0m
[2K| Adam | epoch: 057 | loss: 0.40522 - acc: 0.8359 -- iter: 0064/3680
[A[ATraining Step: 6443  | total loss: [1m[32m0.38465[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38465 - acc: 0.8523 -- iter: 0096/3680
[A[ATraining Step: 6444  | total loss: [1m[32m0.39898[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39898 - acc: 0.8452 -- iter: 0128/3680
[A[ATraining Step: 6445  | total loss: [1m[32m0.39368[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39368 - acc: 0.8450 -- iter: 0160/3680
[A[ATraining Step: 6446  | total loss: [1m[32m0.39901[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39901 - acc: 0.8480 -- iter: 0192/3680
[A[ATraining Step: 6447  | total loss: [1m[32m0.39355[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39355 - acc: 0.8445 -- iter: 0224/3680
[A[ATraining Step: 6448  | total loss: [1m[32m0.38620[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38620 - acc: 0.8444 -- iter: 0256/3680
[A[ATraining Step: 6449  | total loss: [1m[32m0.38022[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38022 - acc: 0.8506 -- iter: 0288/3680
[A[ATraining Step: 6450  | total loss: [1m[32m0.37998[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37998 - acc: 0.8530 -- iter: 0320/3680
[A[ATraining Step: 6451  | total loss: [1m[32m0.37444[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37444 - acc: 0.8552 -- iter: 0352/3680
[A[ATraining Step: 6452  | total loss: [1m[32m0.38895[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38895 - acc: 0.8447 -- iter: 0384/3680
[A[ATraining Step: 6453  | total loss: [1m[32m0.37758[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37758 - acc: 0.8509 -- iter: 0416/3680
[A[ATraining Step: 6454  | total loss: [1m[32m0.38616[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38616 - acc: 0.8533 -- iter: 0448/3680
[A[ATraining Step: 6455  | total loss: [1m[32m0.37392[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37392 - acc: 0.8586 -- iter: 0480/3680
[A[ATraining Step: 6456  | total loss: [1m[32m0.37191[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37191 - acc: 0.8508 -- iter: 0512/3680
[A[ATraining Step: 6457  | total loss: [1m[32m0.36381[0m[0m
[2K| Adam | epoch: 057 | loss: 0.36381 - acc: 0.8470 -- iter: 0544/3680
[A[ATraining Step: 6458  | total loss: [1m[32m0.34275[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34275 - acc: 0.8623 -- iter: 0576/3680
[A[ATraining Step: 6459  | total loss: [1m[32m0.34539[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34539 - acc: 0.8636 -- iter: 0608/3680
[A[ATraining Step: 6460  | total loss: [1m[32m0.34095[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34095 - acc: 0.8710 -- iter: 0640/3680
[A[ATraining Step: 6461  | total loss: [1m[32m0.34135[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34135 - acc: 0.8682 -- iter: 0672/3680
[A[ATraining Step: 6462  | total loss: [1m[32m0.33157[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33157 - acc: 0.8783 -- iter: 0704/3680
[A[ATraining Step: 6463  | total loss: [1m[32m0.32817[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32817 - acc: 0.8811 -- iter: 0736/3680
[A[ATraining Step: 6464  | total loss: [1m[32m0.40323[0m[0m
[2K| Adam | epoch: 057 | loss: 0.40323 - acc: 0.8367 -- iter: 0768/3680
[A[ATraining Step: 6465  | total loss: [1m[32m0.39566[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39566 - acc: 0.8374 -- iter: 0800/3680
[A[ATraining Step: 6466  | total loss: [1m[32m0.40566[0m[0m
[2K| Adam | epoch: 057 | loss: 0.40566 - acc: 0.8318 -- iter: 0832/3680
[A[ATraining Step: 6467  | total loss: [1m[32m0.39836[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39836 - acc: 0.8393 -- iter: 0864/3680
[A[ATraining Step: 6468  | total loss: [1m[32m0.38492[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38492 - acc: 0.8428 -- iter: 0896/3680
[A[ATraining Step: 6469  | total loss: [1m[32m0.40388[0m[0m
[2K| Adam | epoch: 057 | loss: 0.40388 - acc: 0.8398 -- iter: 0928/3680
[A[ATraining Step: 6470  | total loss: [1m[32m0.39257[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39257 - acc: 0.8464 -- iter: 0960/3680
[A[ATraining Step: 6471  | total loss: [1m[32m0.40095[0m[0m
[2K| Adam | epoch: 057 | loss: 0.40095 - acc: 0.8337 -- iter: 0992/3680
[A[ATraining Step: 6472  | total loss: [1m[32m0.38342[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38342 - acc: 0.8441 -- iter: 1024/3680
[A[ATraining Step: 6473  | total loss: [1m[32m0.38045[0m[0m
[2K| Adam | epoch: 057 | loss: 0.38045 - acc: 0.8440 -- iter: 1056/3680
[A[ATraining Step: 6474  | total loss: [1m[32m0.36669[0m[0m
[2K| Adam | epoch: 057 | loss: 0.36669 - acc: 0.8502 -- iter: 1088/3680
[A[ATraining Step: 6475  | total loss: [1m[32m0.36071[0m[0m
[2K| Adam | epoch: 057 | loss: 0.36071 - acc: 0.8527 -- iter: 1120/3680
[A[ATraining Step: 6476  | total loss: [1m[32m0.35632[0m[0m
[2K| Adam | epoch: 057 | loss: 0.35632 - acc: 0.8581 -- iter: 1152/3680
[A[ATraining Step: 6477  | total loss: [1m[32m0.43573[0m[0m
[2K| Adam | epoch: 057 | loss: 0.43573 - acc: 0.8566 -- iter: 1184/3680
[A[ATraining Step: 6478  | total loss: [1m[32m0.41228[0m[0m
[2K| Adam | epoch: 057 | loss: 0.41228 - acc: 0.8511 -- iter: 1216/3680
[A[ATraining Step: 6479  | total loss: [1m[32m0.41228[0m[0m
[2K| Adam | epoch: 057 | loss: 0.41228 - acc: 0.8511 -- iter: 1248/3680
[A[ATraining Step: 6480  | total loss: [1m[32m0.42022[0m[0m
[2K| Adam | epoch: 057 | loss: 0.42022 - acc: 0.8472 -- iter: 1280/3680
[A[ATraining Step: 6481  | total loss: [1m[32m0.40357[0m[0m
[2K| Adam | epoch: 057 | loss: 0.40357 - acc: 0.8500 -- iter: 1312/3680
[A[ATraining Step: 6482  | total loss: [1m[32m0.39997[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39997 - acc: 0.8462 -- iter: 1344/3680
[A[ATraining Step: 6483  | total loss: [1m[32m0.39967[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39967 - acc: 0.8460 -- iter: 1376/3680
[A[ATraining Step: 6484  | total loss: [1m[32m0.39225[0m[0m
[2K| Adam | epoch: 057 | loss: 0.39225 - acc: 0.8458 -- iter: 1408/3680
[A[ATraining Step: 6485  | total loss: [1m[32m0.37647[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37647 - acc: 0.8518 -- iter: 1440/3680
[A[ATraining Step: 6486  | total loss: [1m[32m0.37348[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37348 - acc: 0.8541 -- iter: 1472/3680
[A[ATraining Step: 6487  | total loss: [1m[32m0.37595[0m[0m
[2K| Adam | epoch: 057 | loss: 0.37595 - acc: 0.8468 -- iter: 1504/3680
[A[ATraining Step: 6488  | total loss: [1m[32m0.36049[0m[0m
[2K| Adam | epoch: 057 | loss: 0.36049 - acc: 0.8497 -- iter: 1536/3680
[A[ATraining Step: 6489  | total loss: [1m[32m0.34445[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34445 - acc: 0.8584 -- iter: 1568/3680
[A[ATraining Step: 6490  | total loss: [1m[32m0.34243[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34243 - acc: 0.8632 -- iter: 1600/3680
[A[ATraining Step: 6491  | total loss: [1m[32m0.32833[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32833 - acc: 0.8707 -- iter: 1632/3680
[A[ATraining Step: 6492  | total loss: [1m[32m0.32635[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32635 - acc: 0.8711 -- iter: 1664/3680
[A[ATraining Step: 6493  | total loss: [1m[32m0.32002[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32002 - acc: 0.8777 -- iter: 1696/3680
[A[ATraining Step: 6494  | total loss: [1m[32m0.31798[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31798 - acc: 0.8775 -- iter: 1728/3680
[A[ATraining Step: 6495  | total loss: [1m[32m0.31188[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31188 - acc: 0.8835 -- iter: 1760/3680
[A[ATraining Step: 6496  | total loss: [1m[32m0.31911[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31911 - acc: 0.8732 -- iter: 1792/3680
[A[ATraining Step: 6497  | total loss: [1m[32m0.32258[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32258 - acc: 0.8734 -- iter: 1824/3680
[A[ATraining Step: 6498  | total loss: [1m[32m0.31198[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31198 - acc: 0.8767 -- iter: 1856/3680
[A[ATraining Step: 6499  | total loss: [1m[32m0.32040[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32040 - acc: 0.8703 -- iter: 1888/3680
[A[ATraining Step: 6500  | total loss: [1m[32m0.32712[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32712 - acc: 0.8645 | val_loss: 0.31136 - val_acc: 0.8806 -- iter: 1920/3680
[A[ATraining Step: 6500  | total loss: [1m[32m0.32712[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32712 - acc: 0.8645 | val_loss: 0.31136 - val_acc: 0.8806 -- iter: 1920/3680
--
Training Step: 6501  | total loss: [1m[32m0.31382[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31382 - acc: 0.8718 -- iter: 1952/3680
[A[ATraining Step: 6502  | total loss: [1m[32m0.30405[0m[0m
[2K| Adam | epoch: 057 | loss: 0.30405 - acc: 0.8815 -- iter: 1984/3680
[A[ATraining Step: 6503  | total loss: [1m[32m0.29167[0m[0m
[2K| Adam | epoch: 057 | loss: 0.29167 - acc: 0.8902 -- iter: 2016/3680
[A[ATraining Step: 6504  | total loss: [1m[32m0.30122[0m[0m
[2K| Adam | epoch: 057 | loss: 0.30122 - acc: 0.8887 -- iter: 2048/3680
[A[ATraining Step: 6505  | total loss: [1m[32m0.31351[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31351 - acc: 0.8842 -- iter: 2080/3680
[A[ATraining Step: 6506  | total loss: [1m[32m0.30348[0m[0m
[2K| Adam | epoch: 057 | loss: 0.30348 - acc: 0.8895 -- iter: 2112/3680
[A[ATraining Step: 6507  | total loss: [1m[32m0.30434[0m[0m
[2K| Adam | epoch: 057 | loss: 0.30434 - acc: 0.8818 -- iter: 2144/3680
[A[ATraining Step: 6508  | total loss: [1m[32m0.31433[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31433 - acc: 0.8843 -- iter: 2176/3680
[A[ATraining Step: 6509  | total loss: [1m[32m0.31587[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31587 - acc: 0.8833 -- iter: 2208/3680
[A[ATraining Step: 6510  | total loss: [1m[32m0.34030[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34030 - acc: 0.8638 -- iter: 2240/3680
[A[ATraining Step: 6511  | total loss: [1m[32m0.33742[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33742 - acc: 0.8649 -- iter: 2272/3680
[A[ATraining Step: 6512  | total loss: [1m[32m0.34162[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34162 - acc: 0.8609 -- iter: 2304/3680
[A[ATraining Step: 6513  | total loss: [1m[32m0.34162[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34162 - acc: 0.8609 -- iter: 2336/3680
[A[ATraining Step: 6514  | total loss: [1m[32m0.34274[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34274 - acc: 0.8623 -- iter: 2368/3680
[A[ATraining Step: 6515  | total loss: [1m[32m0.34207[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34207 - acc: 0.8667 -- iter: 2400/3680
[A[ATraining Step: 6516  | total loss: [1m[32m0.34149[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34149 - acc: 0.8644 -- iter: 2432/3680
[A[ATraining Step: 6517  | total loss: [1m[32m0.32465[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32465 - acc: 0.8717 -- iter: 2464/3680
[A[ATraining Step: 6518  | total loss: [1m[32m0.31148[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31148 - acc: 0.8783 -- iter: 2496/3680
[A[ATraining Step: 6519  | total loss: [1m[32m0.31007[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31007 - acc: 0.8811 -- iter: 2528/3680
[A[ATraining Step: 6520  | total loss: [1m[32m0.32652[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32652 - acc: 0.8711 -- iter: 2560/3680
[A[ATraining Step: 6521  | total loss: [1m[32m0.32643[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32643 - acc: 0.8746 -- iter: 2592/3680
[A[ATraining Step: 6522  | total loss: [1m[32m0.32389[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32389 - acc: 0.8715 -- iter: 2624/3680
[A[ATraining Step: 6523  | total loss: [1m[32m0.31865[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31865 - acc: 0.8719 -- iter: 2656/3680
[A[ATraining Step: 6524  | total loss: [1m[32m0.32080[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32080 - acc: 0.8753 -- iter: 2688/3680
[A[ATraining Step: 6525  | total loss: [1m[32m0.31612[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31612 - acc: 0.8722 -- iter: 2720/3680
[A[ATraining Step: 6526  | total loss: [1m[32m0.32066[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32066 - acc: 0.8724 -- iter: 2752/3680
[A[ATraining Step: 6527  | total loss: [1m[32m0.31859[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31859 - acc: 0.8727 -- iter: 2784/3680
[A[ATraining Step: 6528  | total loss: [1m[32m0.32605[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32605 - acc: 0.8667 -- iter: 2816/3680
[A[ATraining Step: 6529  | total loss: [1m[32m0.32092[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32092 - acc: 0.8526 -- iter: 2848/3680
[A[ATraining Step: 6530  | total loss: [1m[32m0.34163[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34163 - acc: 0.8526 -- iter: 2880/3680
[A[ATraining Step: 6531  | total loss: [1m[32m0.35222[0m[0m
[2K| Adam | epoch: 057 | loss: 0.35222 - acc: 0.8424 -- iter: 2912/3680
[A[ATraining Step: 6532  | total loss: [1m[32m0.35140[0m[0m
[2K| Adam | epoch: 057 | loss: 0.35140 - acc: 0.8456 -- iter: 2944/3680
[A[ATraining Step: 6533  | total loss: [1m[32m0.33740[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33740 - acc: 0.8548 -- iter: 2976/3680
[A[ATraining Step: 6534  | total loss: [1m[32m0.34096[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34096 - acc: 0.8600 -- iter: 3008/3680
[A[ATraining Step: 6535  | total loss: [1m[32m0.33746[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33746 - acc: 0.8615 -- iter: 3040/3680
[A[ATraining Step: 6536  | total loss: [1m[32m0.33275[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33275 - acc: 0.8628 -- iter: 3072/3680
[A[ATraining Step: 6537  | total loss: [1m[32m0.31556[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31556 - acc: 0.8734 -- iter: 3104/3680
[A[ATraining Step: 6538  | total loss: [1m[32m0.33929[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33929 - acc: 0.8642 -- iter: 3136/3680
[A[ATraining Step: 6539  | total loss: [1m[32m0.34450[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34450 - acc: 0.8622 -- iter: 3168/3680
[A[ATraining Step: 6540  | total loss: [1m[32m0.35119[0m[0m
[2K| Adam | epoch: 057 | loss: 0.35119 - acc: 0.8572 -- iter: 3200/3680
[A[ATraining Step: 6541  | total loss: [1m[32m0.34955[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34955 - acc: 0.8527 -- iter: 3232/3680
[A[ATraining Step: 6542  | total loss: [1m[32m0.35090[0m[0m
[2K| Adam | epoch: 057 | loss: 0.35090 - acc: 0.8549 -- iter: 3264/3680
[A[ATraining Step: 6543  | total loss: [1m[32m0.35338[0m[0m
[2K| Adam | epoch: 057 | loss: 0.35338 - acc: 0.8476 -- iter: 3296/3680
[A[ATraining Step: 6544  | total loss: [1m[32m0.34671[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34671 - acc: 0.8472 -- iter: 3328/3680
[A[ATraining Step: 6545  | total loss: [1m[32m0.32532[0m[0m
[2K| Adam | epoch: 057 | loss: 0.32532 - acc: 0.8625 -- iter: 3360/3680
[A[ATraining Step: 6546  | total loss: [1m[32m0.31231[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31231 - acc: 0.8700 -- iter: 3392/3680
[A[ATraining Step: 6547  | total loss: [1m[32m0.31325[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31325 - acc: 0.8736 -- iter: 3424/3680
[A[ATraining Step: 6548  | total loss: [1m[32m0.31269[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31269 - acc: 0.8737 -- iter: 3456/3680
[A[ATraining Step: 6549  | total loss: [1m[32m0.31583[0m[0m
[2K| Adam | epoch: 057 | loss: 0.31583 - acc: 0.8770 -- iter: 3488/3680
[A[ATraining Step: 6550  | total loss: [1m[32m0.34328[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34328 - acc: 0.8580 -- iter: 3520/3680
[A[ATraining Step: 6551  | total loss: [1m[32m0.34445[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34445 - acc: 0.8566 -- iter: 3552/3680
[A[ATraining Step: 6552  | total loss: [1m[32m0.34003[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34003 - acc: 0.8585 -- iter: 3584/3680
[A[ATraining Step: 6553  | total loss: [1m[32m0.33688[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33688 - acc: 0.8570 -- iter: 3616/3680
[A[ATraining Step: 6554  | total loss: [1m[32m0.33870[0m[0m
[2K| Adam | epoch: 057 | loss: 0.33870 - acc: 0.8557 -- iter: 3648/3680
[A[ATraining Step: 6555  | total loss: [1m[32m0.34504[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34504 - acc: 0.8576 | val_loss: 0.30413 - val_acc: 0.8893 -- iter: 3680/3680
[A[ATraining Step: 6555  | total loss: [1m[32m0.34504[0m[0m
[2K| Adam | epoch: 057 | loss: 0.34504 - acc: 0.8576 | val_loss: 0.30413 - val_acc: 0.8893 -- iter: 3680/3680
--
Training Step: 6556  | total loss: [1m[32m0.34885[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34885 - acc: 0.8531 -- iter: 0032/3680
[A[ATraining Step: 6557  | total loss: [1m[32m0.34323[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34323 - acc: 0.8584 -- iter: 0064/3680
[A[ATraining Step: 6558  | total loss: [1m[32m0.32694[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32694 - acc: 0.8663 -- iter: 0096/3680
[A[ATraining Step: 6559  | total loss: [1m[32m0.33349[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33349 - acc: 0.8641 -- iter: 0128/3680
[A[ATraining Step: 6560  | total loss: [1m[32m0.32889[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32889 - acc: 0.8651 -- iter: 0160/3680
[A[ATraining Step: 6561  | total loss: [1m[32m0.31533[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31533 - acc: 0.8724 -- iter: 0192/3680
[A[ATraining Step: 6562  | total loss: [1m[32m0.31386[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31386 - acc: 0.8726 -- iter: 0224/3680
[A[ATraining Step: 6563  | total loss: [1m[32m0.30829[0m[0m
[2K| Adam | epoch: 058 | loss: 0.30829 - acc: 0.8722 -- iter: 0256/3680
[A[ATraining Step: 6564  | total loss: [1m[32m0.32364[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32364 - acc: 0.8722 -- iter: 0288/3680
[A[ATraining Step: 6565  | total loss: [1m[32m0.33377[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33377 - acc: 0.8693 -- iter: 0320/3680
[A[ATraining Step: 6566  | total loss: [1m[32m0.33906[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33906 - acc: 0.8699 -- iter: 0352/3680
[A[ATraining Step: 6567  | total loss: [1m[32m0.32578[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32578 - acc: 0.8765 -- iter: 0384/3680
[A[ATraining Step: 6568  | total loss: [1m[32m0.32578[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32578 - acc: 0.8765 -- iter: 0416/3680
[A[ATraining Step: 6569  | total loss: [1m[32m0.31998[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31998 - acc: 0.8732 -- iter: 0448/3680
[A[ATraining Step: 6570  | total loss: [1m[32m0.32555[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32555 - acc: 0.8703 -- iter: 0480/3680
[A[ATraining Step: 6571  | total loss: [1m[32m0.35103[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35103 - acc: 0.8520 -- iter: 0512/3680
[A[ATraining Step: 6572  | total loss: [1m[32m0.35450[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35450 - acc: 0.8480 -- iter: 0544/3680
[A[ATraining Step: 6573  | total loss: [1m[32m0.34238[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34238 - acc: 0.8539 -- iter: 0576/3680
[A[ATraining Step: 6574  | total loss: [1m[32m0.34225[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34225 - acc: 0.8528 -- iter: 0608/3680
[A[ATraining Step: 6575  | total loss: [1m[32m0.32760[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32760 - acc: 0.8644 -- iter: 0640/3680
[A[ATraining Step: 6576  | total loss: [1m[32m0.34300[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34300 - acc: 0.8592 -- iter: 0672/3680
[A[ATraining Step: 6577  | total loss: [1m[32m0.36315[0m[0m
[2K| Adam | epoch: 058 | loss: 0.36315 - acc: 0.8546 -- iter: 0704/3680
[A[ATraining Step: 6578  | total loss: [1m[32m0.35627[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35627 - acc: 0.8566 -- iter: 0736/3680
[A[ATraining Step: 6579  | total loss: [1m[32m0.36053[0m[0m
[2K| Adam | epoch: 058 | loss: 0.36053 - acc: 0.8553 -- iter: 0768/3680
[A[ATraining Step: 6580  | total loss: [1m[32m0.45085[0m[0m
[2K| Adam | epoch: 058 | loss: 0.45085 - acc: 0.8292 -- iter: 0800/3680
[A[ATraining Step: 6581  | total loss: [1m[32m0.45711[0m[0m
[2K| Adam | epoch: 058 | loss: 0.45711 - acc: 0.8213 -- iter: 0832/3680
[A[ATraining Step: 6582  | total loss: [1m[32m0.42806[0m[0m
[2K| Adam | epoch: 058 | loss: 0.42806 - acc: 0.8329 -- iter: 0864/3680
[A[ATraining Step: 6583  | total loss: [1m[32m0.43078[0m[0m
[2K| Adam | epoch: 058 | loss: 0.43078 - acc: 0.8340 -- iter: 0896/3680
[A[ATraining Step: 6584  | total loss: [1m[32m0.42000[0m[0m
[2K| Adam | epoch: 058 | loss: 0.42000 - acc: 0.8412 -- iter: 0928/3680
[A[ATraining Step: 6585  | total loss: [1m[32m0.41430[0m[0m
[2K| Adam | epoch: 058 | loss: 0.41430 - acc: 0.8446 -- iter: 0960/3680
[A[ATraining Step: 6586  | total loss: [1m[32m0.41608[0m[0m
[2K| Adam | epoch: 058 | loss: 0.41608 - acc: 0.8351 -- iter: 0992/3680
[A[ATraining Step: 6587  | total loss: [1m[32m0.40827[0m[0m
[2K| Adam | epoch: 058 | loss: 0.40827 - acc: 0.8391 -- iter: 1024/3680
[A[ATraining Step: 6588  | total loss: [1m[32m0.38650[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38650 - acc: 0.8575 -- iter: 1056/3680
[A[ATraining Step: 6589  | total loss: [1m[32m0.37485[0m[0m
[2K| Adam | epoch: 058 | loss: 0.37485 - acc: 0.8575 -- iter: 1088/3680
[A[ATraining Step: 6590  | total loss: [1m[32m0.37278[0m[0m
[2K| Adam | epoch: 058 | loss: 0.37278 - acc: 0.8561 -- iter: 1120/3680
[A[ATraining Step: 6591  | total loss: [1m[32m0.38088[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38088 - acc: 0.8486 -- iter: 1152/3680
[A[ATraining Step: 6592  | total loss: [1m[32m0.38903[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38903 - acc: 0.8419 -- iter: 1184/3680
[A[ATraining Step: 6593  | total loss: [1m[32m0.39832[0m[0m
[2K| Adam | epoch: 058 | loss: 0.39832 - acc: 0.8390 -- iter: 1216/3680
[A[ATraining Step: 6594  | total loss: [1m[32m0.40547[0m[0m
[2K| Adam | epoch: 058 | loss: 0.40547 - acc: 0.8332 -- iter: 1248/3680
[A[ATraining Step: 6595  | total loss: [1m[32m0.39949[0m[0m
[2K| Adam | epoch: 058 | loss: 0.39949 - acc: 0.8280 -- iter: 1280/3680
[A[ATraining Step: 6596  | total loss: [1m[32m0.38347[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38347 - acc: 0.8389 -- iter: 1312/3680
[A[ATraining Step: 6597  | total loss: [1m[32m0.38481[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38481 - acc: 0.8363 -- iter: 1344/3680
[A[ATraining Step: 6598  | total loss: [1m[32m0.39611[0m[0m
[2K| Adam | epoch: 058 | loss: 0.39611 - acc: 0.8308 -- iter: 1376/3680
[A[ATraining Step: 6599  | total loss: [1m[32m0.39664[0m[0m
[2K| Adam | epoch: 058 | loss: 0.39664 - acc: 0.8290 -- iter: 1408/3680
[A[ATraining Step: 6600  | total loss: [1m[32m0.38717[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38717 - acc: 0.8398 | val_loss: 0.31861 - val_acc: 0.8860 -- iter: 1440/3680
[A[ATraining Step: 6600  | total loss: [1m[32m0.38717[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38717 - acc: 0.8398 | val_loss: 0.31861 - val_acc: 0.8860 -- iter: 1440/3680
--
Training Step: 6601  | total loss: [1m[32m0.38200[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38200 - acc: 0.8433 -- iter: 1472/3680
[A[ATraining Step: 6602  | total loss: [1m[32m0.38590[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38590 - acc: 0.8434 -- iter: 1504/3680
[A[ATraining Step: 6603  | total loss: [1m[32m0.38540[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38540 - acc: 0.8403 -- iter: 1536/3680
[A[ATraining Step: 6604  | total loss: [1m[32m0.40744[0m[0m
[2K| Adam | epoch: 058 | loss: 0.40744 - acc: 0.8403 -- iter: 1568/3680
[A[ATraining Step: 6605  | total loss: [1m[32m0.39496[0m[0m
[2K| Adam | epoch: 058 | loss: 0.39496 - acc: 0.8469 -- iter: 1600/3680
[A[ATraining Step: 6606  | total loss: [1m[32m0.37837[0m[0m
[2K| Adam | epoch: 058 | loss: 0.37837 - acc: 0.8591 -- iter: 1632/3680
[A[ATraining Step: 6607  | total loss: [1m[32m0.36213[0m[0m
[2K| Adam | epoch: 058 | loss: 0.36213 - acc: 0.8638 -- iter: 1664/3680
[A[ATraining Step: 6608  | total loss: [1m[32m0.35299[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35299 - acc: 0.8681 -- iter: 1696/3680
[A[ATraining Step: 6609  | total loss: [1m[32m0.34836[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34836 - acc: 0.8688 -- iter: 1728/3680
[A[ATraining Step: 6610  | total loss: [1m[32m0.34108[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34108 - acc: 0.8663 -- iter: 1760/3680
[A[ATraining Step: 6611  | total loss: [1m[32m0.34182[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34182 - acc: 0.8640 -- iter: 1792/3680
[A[ATraining Step: 6612  | total loss: [1m[32m0.34064[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34064 - acc: 0.8620 -- iter: 1824/3680
[A[ATraining Step: 6613  | total loss: [1m[32m0.34770[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34770 - acc: 0.8539 -- iter: 1856/3680
[A[ATraining Step: 6614  | total loss: [1m[32m0.33681[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33681 - acc: 0.8551 -- iter: 1888/3680
[A[ATraining Step: 6615  | total loss: [1m[32m0.33681[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33681 - acc: 0.8551 -- iter: 1920/3680
[A[ATraining Step: 6616  | total loss: [1m[32m0.34900[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34900 - acc: 0.8508 -- iter: 1952/3680
[A[ATraining Step: 6617  | total loss: [1m[32m0.34963[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34963 - acc: 0.8533 -- iter: 1984/3680
[A[ATraining Step: 6618  | total loss: [1m[32m0.33210[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33210 - acc: 0.8648 -- iter: 2016/3680
[A[ATraining Step: 6619  | total loss: [1m[32m0.32773[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32773 - acc: 0.8689 -- iter: 2048/3680
[A[ATraining Step: 6620  | total loss: [1m[32m0.32146[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32146 - acc: 0.8664 -- iter: 2080/3680
[A[ATraining Step: 6621  | total loss: [1m[32m0.31695[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31695 - acc: 0.8704 -- iter: 2112/3680
[A[ATraining Step: 6622  | total loss: [1m[32m0.40115[0m[0m
[2K| Adam | epoch: 058 | loss: 0.40115 - acc: 0.8646 -- iter: 2144/3680
[A[ATraining Step: 6623  | total loss: [1m[32m0.38882[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38882 - acc: 0.8657 -- iter: 2176/3680
[A[ATraining Step: 6624  | total loss: [1m[32m0.39120[0m[0m
[2K| Adam | epoch: 058 | loss: 0.39120 - acc: 0.8603 -- iter: 2208/3680
[A[ATraining Step: 6625  | total loss: [1m[32m0.38583[0m[0m
[2K| Adam | epoch: 058 | loss: 0.38583 - acc: 0.8649 -- iter: 2240/3680
[A[ATraining Step: 6626  | total loss: [1m[32m0.37233[0m[0m
[2K| Adam | epoch: 058 | loss: 0.37233 - acc: 0.8659 -- iter: 2272/3680
[A[ATraining Step: 6627  | total loss: [1m[32m0.37375[0m[0m
[2K| Adam | epoch: 058 | loss: 0.37375 - acc: 0.8575 -- iter: 2304/3680
[A[ATraining Step: 6628  | total loss: [1m[32m0.36759[0m[0m
[2K| Adam | epoch: 058 | loss: 0.36759 - acc: 0.8623 -- iter: 2336/3680
[A[ATraining Step: 6629  | total loss: [1m[32m0.36063[0m[0m
[2K| Adam | epoch: 058 | loss: 0.36063 - acc: 0.8636 -- iter: 2368/3680
[A[ATraining Step: 6630  | total loss: [1m[32m0.35158[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35158 - acc: 0.8679 -- iter: 2400/3680
[A[ATraining Step: 6631  | total loss: [1m[32m0.34573[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34573 - acc: 0.8686 -- iter: 2432/3680
[A[ATraining Step: 6632  | total loss: [1m[32m0.35269[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35269 - acc: 0.8661 -- iter: 2464/3680
[A[ATraining Step: 6633  | total loss: [1m[32m0.34580[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34580 - acc: 0.8670 -- iter: 2496/3680
[A[ATraining Step: 6634  | total loss: [1m[32m0.34758[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34758 - acc: 0.8678 -- iter: 2528/3680
[A[ATraining Step: 6635  | total loss: [1m[32m0.33940[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33940 - acc: 0.8720 -- iter: 2560/3680
[A[ATraining Step: 6636  | total loss: [1m[32m0.34242[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34242 - acc: 0.8720 -- iter: 2592/3680
[A[ATraining Step: 6637  | total loss: [1m[32m0.35945[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35945 - acc: 0.8598 -- iter: 2624/3680
[A[ATraining Step: 6638  | total loss: [1m[32m0.34588[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34588 - acc: 0.8676 -- iter: 2656/3680
[A[ATraining Step: 6639  | total loss: [1m[32m0.34450[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34450 - acc: 0.8620 -- iter: 2688/3680
[A[ATraining Step: 6640  | total loss: [1m[32m0.35166[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35166 - acc: 0.8540 -- iter: 2720/3680
[A[ATraining Step: 6641  | total loss: [1m[32m0.35236[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35236 - acc: 0.8561 -- iter: 2752/3680
[A[ATraining Step: 6642  | total loss: [1m[32m0.34326[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34326 - acc: 0.8548 -- iter: 2784/3680
[A[ATraining Step: 6643  | total loss: [1m[32m0.34402[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34402 - acc: 0.8506 -- iter: 2816/3680
[A[ATraining Step: 6644  | total loss: [1m[32m0.34702[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34702 - acc: 0.8499 -- iter: 2848/3680
[A[ATraining Step: 6645  | total loss: [1m[32m0.35173[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35173 - acc: 0.8493 -- iter: 2880/3680
[A[ATraining Step: 6646  | total loss: [1m[32m0.33958[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33958 - acc: 0.8612 -- iter: 2912/3680
[A[ATraining Step: 6647  | total loss: [1m[32m0.33090[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33090 - acc: 0.8626 -- iter: 2944/3680
[A[ATraining Step: 6648  | total loss: [1m[32m0.33099[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33099 - acc: 0.8639 -- iter: 2976/3680
[A[ATraining Step: 6649  | total loss: [1m[32m0.32719[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32719 - acc: 0.8650 -- iter: 3008/3680
[A[ATraining Step: 6650  | total loss: [1m[32m0.31310[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31310 - acc: 0.8754 -- iter: 3040/3680
[A[ATraining Step: 6651  | total loss: [1m[32m0.30397[0m[0m
[2K| Adam | epoch: 058 | loss: 0.30397 - acc: 0.8784 -- iter: 3072/3680
[A[ATraining Step: 6652  | total loss: [1m[32m0.29788[0m[0m
[2K| Adam | epoch: 058 | loss: 0.29788 - acc: 0.8812 -- iter: 3104/3680
[A[ATraining Step: 6653  | total loss: [1m[32m0.28919[0m[0m
[2K| Adam | epoch: 058 | loss: 0.28919 - acc: 0.8900 -- iter: 3136/3680
[A[ATraining Step: 6654  | total loss: [1m[32m0.28341[0m[0m
[2K| Adam | epoch: 058 | loss: 0.28341 - acc: 0.8947 -- iter: 3168/3680
[A[ATraining Step: 6655  | total loss: [1m[32m0.28857[0m[0m
[2K| Adam | epoch: 058 | loss: 0.28857 - acc: 0.8896 -- iter: 3200/3680
[A[ATraining Step: 6656  | total loss: [1m[32m0.27883[0m[0m
[2K| Adam | epoch: 058 | loss: 0.27883 - acc: 0.8975 -- iter: 3232/3680
[A[ATraining Step: 6657  | total loss: [1m[32m0.28948[0m[0m
[2K| Adam | epoch: 058 | loss: 0.28948 - acc: 0.8953 -- iter: 3264/3680
[A[ATraining Step: 6658  | total loss: [1m[32m0.30103[0m[0m
[2K| Adam | epoch: 058 | loss: 0.30103 - acc: 0.8799 -- iter: 3296/3680
[A[ATraining Step: 6659  | total loss: [1m[32m0.31550[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31550 - acc: 0.8799 -- iter: 3328/3680
[A[ATraining Step: 6660  | total loss: [1m[32m0.33286[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33286 - acc: 0.8763 -- iter: 3360/3680
[A[ATraining Step: 6661  | total loss: [1m[32m0.33230[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33230 - acc: 0.8730 -- iter: 3392/3680
[A[ATraining Step: 6662  | total loss: [1m[32m0.33089[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33089 - acc: 0.8763 -- iter: 3424/3680
[A[ATraining Step: 6663  | total loss: [1m[32m0.34161[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34161 - acc: 0.8637 -- iter: 3456/3680
[A[ATraining Step: 6664  | total loss: [1m[32m0.33925[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33925 - acc: 0.8617 -- iter: 3488/3680
[A[ATraining Step: 6665  | total loss: [1m[32m0.33471[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33471 - acc: 0.8630 -- iter: 3520/3680
[A[ATraining Step: 6666  | total loss: [1m[32m0.35260[0m[0m
[2K| Adam | epoch: 058 | loss: 0.35260 - acc: 0.8603 -- iter: 3552/3680
[A[ATraining Step: 6667  | total loss: [1m[32m0.34329[0m[0m
[2K| Adam | epoch: 058 | loss: 0.34329 - acc: 0.8603 -- iter: 3584/3680
[A[ATraining Step: 6668  | total loss: [1m[32m0.33404[0m[0m
[2K| Adam | epoch: 058 | loss: 0.33404 - acc: 0.8712 -- iter: 3616/3680
[A[ATraining Step: 6669  | total loss: [1m[32m0.32040[0m[0m
[2K| Adam | epoch: 058 | loss: 0.32040 - acc: 0.8778 -- iter: 3648/3680
[A[ATraining Step: 6670  | total loss: [1m[32m0.31648[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31648 - acc: 0.8838 | val_loss: 0.29979 - val_acc: 0.8936 -- iter: 3680/3680
[A[ATraining Step: 6670  | total loss: [1m[32m0.31648[0m[0m
[2K| Adam | epoch: 058 | loss: 0.31648 - acc: 0.8838 | val_loss: 0.29979 - val_acc: 0.8936 -- iter: 3680/3680
--
Training Step: 6671  | total loss: [1m[32m0.31952[0m[0m
[2K| Adam | epoch: 059 | loss: 0.31952 - acc: 0.8829 -- iter: 0032/3680
[A[ATraining Step: 6672  | total loss: [1m[32m0.34545[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34545 - acc: 0.8790 -- iter: 0064/3680
[A[ATraining Step: 6673  | total loss: [1m[32m0.34113[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34113 - acc: 0.8786 -- iter: 0096/3680
[A[ATraining Step: 6674  | total loss: [1m[32m0.35151[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35151 - acc: 0.8688 -- iter: 0128/3680
[A[ATraining Step: 6675  | total loss: [1m[32m0.34104[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34104 - acc: 0.8695 -- iter: 0160/3680
[A[ATraining Step: 6676  | total loss: [1m[32m0.33575[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33575 - acc: 0.8700 -- iter: 0192/3680
[A[ATraining Step: 6677  | total loss: [1m[32m0.34512[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34512 - acc: 0.8643 -- iter: 0224/3680
[A[ATraining Step: 6678  | total loss: [1m[32m0.34161[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34161 - acc: 0.8653 -- iter: 0256/3680
[A[ATraining Step: 6679  | total loss: [1m[32m0.33341[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33341 - acc: 0.8725 -- iter: 0288/3680
[A[ATraining Step: 6680  | total loss: [1m[32m0.33741[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33741 - acc: 0.8634 -- iter: 0320/3680
[A[ATraining Step: 6681  | total loss: [1m[32m0.34370[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34370 - acc: 0.8646 -- iter: 0352/3680
[A[ATraining Step: 6682  | total loss: [1m[32m0.32876[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32876 - acc: 0.8719 -- iter: 0384/3680
[A[ATraining Step: 6683  | total loss: [1m[32m0.32721[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32721 - acc: 0.8691 -- iter: 0416/3680
[A[ATraining Step: 6684  | total loss: [1m[32m0.32706[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32706 - acc: 0.8665 -- iter: 0448/3680
[A[ATraining Step: 6685  | total loss: [1m[32m0.31124[0m[0m
[2K| Adam | epoch: 059 | loss: 0.31124 - acc: 0.8713 -- iter: 0480/3680
[A[ATraining Step: 6686  | total loss: [1m[32m0.31124[0m[0m
[2K| Adam | epoch: 059 | loss: 0.31124 - acc: 0.8713 -- iter: 0512/3680
[A[ATraining Step: 6687  | total loss: [1m[32m0.32746[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32746 - acc: 0.8654 -- iter: 0544/3680
[A[ATraining Step: 6688  | total loss: [1m[32m0.31438[0m[0m
[2K| Adam | epoch: 059 | loss: 0.31438 - acc: 0.8726 -- iter: 0576/3680
[A[ATraining Step: 6689  | total loss: [1m[32m0.32393[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32393 - acc: 0.8666 -- iter: 0608/3680
[A[ATraining Step: 6690  | total loss: [1m[32m0.32325[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32325 - acc: 0.8706 -- iter: 0640/3680
[A[ATraining Step: 6691  | total loss: [1m[32m0.32482[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32482 - acc: 0.8679 -- iter: 0672/3680
[A[ATraining Step: 6692  | total loss: [1m[32m0.33882[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33882 - acc: 0.8655 -- iter: 0704/3680
[A[ATraining Step: 6693  | total loss: [1m[32m0.33025[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33025 - acc: 0.8664 -- iter: 0736/3680
[A[ATraining Step: 6694  | total loss: [1m[32m0.32035[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32035 - acc: 0.8704 -- iter: 0768/3680
[A[ATraining Step: 6695  | total loss: [1m[32m0.32213[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32213 - acc: 0.8709 -- iter: 0800/3680
[A[ATraining Step: 6696  | total loss: [1m[32m0.33204[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33204 - acc: 0.8681 -- iter: 0832/3680
[A[ATraining Step: 6697  | total loss: [1m[32m0.32463[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32463 - acc: 0.8688 -- iter: 0864/3680
[A[ATraining Step: 6698  | total loss: [1m[32m0.33716[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33716 - acc: 0.8601 -- iter: 0896/3680
[A[ATraining Step: 6699  | total loss: [1m[32m0.34662[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34662 - acc: 0.8553 -- iter: 0928/3680
[A[ATraining Step: 6700  | total loss: [1m[32m0.35354[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35354 - acc: 0.8510 | val_loss: 0.34685 - val_acc: 0.8621 -- iter: 0960/3680
[A[ATraining Step: 6700  | total loss: [1m[32m0.35354[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35354 - acc: 0.8510 | val_loss: 0.34685 - val_acc: 0.8621 -- iter: 0960/3680
--
Training Step: 6701  | total loss: [1m[32m0.34346[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34346 - acc: 0.8534 -- iter: 0992/3680
[A[ATraining Step: 6702  | total loss: [1m[32m0.35434[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35434 - acc: 0.8556 -- iter: 1024/3680
[A[ATraining Step: 6703  | total loss: [1m[32m0.35415[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35415 - acc: 0.8482 -- iter: 1056/3680
[A[ATraining Step: 6704  | total loss: [1m[32m0.36444[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36444 - acc: 0.8446 -- iter: 1088/3680
[A[ATraining Step: 6705  | total loss: [1m[32m0.35259[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35259 - acc: 0.8539 -- iter: 1120/3680
[A[ATraining Step: 6706  | total loss: [1m[32m0.37505[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37505 - acc: 0.8466 -- iter: 1152/3680
[A[ATraining Step: 6707  | total loss: [1m[32m0.36964[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36964 - acc: 0.8526 -- iter: 1184/3680
[A[ATraining Step: 6708  | total loss: [1m[32m0.36397[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36397 - acc: 0.8611 -- iter: 1216/3680
[A[ATraining Step: 6709  | total loss: [1m[32m0.35530[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35530 - acc: 0.8656 -- iter: 1248/3680
[A[ATraining Step: 6710  | total loss: [1m[32m0.36349[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36349 - acc: 0.8603 -- iter: 1280/3680
[A[ATraining Step: 6711  | total loss: [1m[32m0.36800[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36800 - acc: 0.8524 -- iter: 1312/3680
[A[ATraining Step: 6712  | total loss: [1m[32m0.37140[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37140 - acc: 0.8546 -- iter: 1344/3680
[A[ATraining Step: 6713  | total loss: [1m[32m0.38024[0m[0m
[2K| Adam | epoch: 059 | loss: 0.38024 - acc: 0.8504 -- iter: 1376/3680
[A[ATraining Step: 6714  | total loss: [1m[32m0.37466[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37466 - acc: 0.8529 -- iter: 1408/3680
[A[ATraining Step: 6715  | total loss: [1m[32m0.38097[0m[0m
[2K| Adam | epoch: 059 | loss: 0.38097 - acc: 0.8426 -- iter: 1440/3680
[A[ATraining Step: 6716  | total loss: [1m[32m0.37094[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37094 - acc: 0.8490 -- iter: 1472/3680
[A[ATraining Step: 6717  | total loss: [1m[32m0.37344[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37344 - acc: 0.8391 -- iter: 1504/3680
[A[ATraining Step: 6718  | total loss: [1m[32m0.36264[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36264 - acc: 0.8458 -- iter: 1536/3680
[A[ATraining Step: 6719  | total loss: [1m[32m0.36845[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36845 - acc: 0.8456 -- iter: 1568/3680
[A[ATraining Step: 6720  | total loss: [1m[32m0.37920[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37920 - acc: 0.8454 -- iter: 1600/3680
[A[ATraining Step: 6721  | total loss: [1m[32m0.37679[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37679 - acc: 0.8510 -- iter: 1632/3680
[A[ATraining Step: 6722  | total loss: [1m[32m0.37501[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37501 - acc: 0.8534 -- iter: 1664/3680
[A[ATraining Step: 6723  | total loss: [1m[32m0.37232[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37232 - acc: 0.8534 -- iter: 1696/3680
[A[ATraining Step: 6724  | total loss: [1m[32m0.37967[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37967 - acc: 0.8462 -- iter: 1728/3680
[A[ATraining Step: 6725  | total loss: [1m[32m0.39070[0m[0m
[2K| Adam | epoch: 059 | loss: 0.39070 - acc: 0.8460 -- iter: 1760/3680
[A[ATraining Step: 6726  | total loss: [1m[32m0.37967[0m[0m
[2K| Adam | epoch: 059 | loss: 0.37967 - acc: 0.8489 -- iter: 1792/3680
[A[ATraining Step: 6727  | total loss: [1m[32m0.36608[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36608 - acc: 0.8577 -- iter: 1824/3680
[A[ATraining Step: 6728  | total loss: [1m[32m0.35245[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35245 - acc: 0.8626 -- iter: 1856/3680
[A[ATraining Step: 6729  | total loss: [1m[32m0.33735[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33735 - acc: 0.8701 -- iter: 1888/3680
[A[ATraining Step: 6730  | total loss: [1m[32m0.33620[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33620 - acc: 0.8612 -- iter: 1920/3680
[A[ATraining Step: 6731  | total loss: [1m[32m0.33468[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33468 - acc: 0.8657 -- iter: 1952/3680
[A[ATraining Step: 6732  | total loss: [1m[32m0.32488[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32488 - acc: 0.8666 -- iter: 1984/3680
[A[ATraining Step: 6733  | total loss: [1m[32m0.35218[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35218 - acc: 0.8487 -- iter: 2016/3680
[A[ATraining Step: 6734  | total loss: [1m[32m0.34088[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34088 - acc: 0.8545 -- iter: 2048/3680
[A[ATraining Step: 6735  | total loss: [1m[32m0.33542[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33542 - acc: 0.8534 -- iter: 2080/3680
[A[ATraining Step: 6736  | total loss: [1m[32m0.34337[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34337 - acc: 0.8493 -- iter: 2112/3680
[A[ATraining Step: 6737  | total loss: [1m[32m0.34509[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34509 - acc: 0.8519 -- iter: 2144/3680
[A[ATraining Step: 6738  | total loss: [1m[32m0.35251[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35251 - acc: 0.8511 -- iter: 2176/3680
[A[ATraining Step: 6739  | total loss: [1m[32m0.35204[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35204 - acc: 0.8597 -- iter: 2208/3680
[A[ATraining Step: 6740  | total loss: [1m[32m0.34917[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34917 - acc: 0.8612 -- iter: 2240/3680
[A[ATraining Step: 6741  | total loss: [1m[32m0.34192[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34192 - acc: 0.8689 -- iter: 2272/3680
[A[ATraining Step: 6742  | total loss: [1m[32m0.34547[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34547 - acc: 0.8664 -- iter: 2304/3680
[A[ATraining Step: 6743  | total loss: [1m[32m0.34362[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34362 - acc: 0.8672 -- iter: 2336/3680
[A[ATraining Step: 6744  | total loss: [1m[32m0.35201[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35201 - acc: 0.8617 -- iter: 2368/3680
[A[ATraining Step: 6745  | total loss: [1m[32m0.33689[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33689 - acc: 0.8693 -- iter: 2400/3680
[A[ATraining Step: 6746  | total loss: [1m[32m0.34684[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34684 - acc: 0.8668 -- iter: 2432/3680
[A[ATraining Step: 6747  | total loss: [1m[32m0.34095[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34095 - acc: 0.8770 -- iter: 2464/3680
[A[ATraining Step: 6748  | total loss: [1m[32m0.33935[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33935 - acc: 0.8768 -- iter: 2496/3680
[A[ATraining Step: 6749  | total loss: [1m[32m0.34264[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34264 - acc: 0.8703 -- iter: 2528/3680
[A[ATraining Step: 6750  | total loss: [1m[32m0.34438[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34438 - acc: 0.8708 -- iter: 2560/3680
[A[ATraining Step: 6751  | total loss: [1m[32m0.34295[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34295 - acc: 0.8712 -- iter: 2592/3680
[A[ATraining Step: 6752  | total loss: [1m[32m0.33975[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33975 - acc: 0.8747 -- iter: 2624/3680
[A[ATraining Step: 6753  | total loss: [1m[32m0.34374[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34374 - acc: 0.8654 -- iter: 2656/3680
[A[ATraining Step: 6754  | total loss: [1m[32m0.34147[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34147 - acc: 0.8695 -- iter: 2688/3680
[A[ATraining Step: 6755  | total loss: [1m[32m0.34212[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34212 - acc: 0.8669 -- iter: 2720/3680
[A[ATraining Step: 6756  | total loss: [1m[32m0.34504[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34504 - acc: 0.8615 -- iter: 2752/3680
[A[ATraining Step: 6757  | total loss: [1m[32m0.34515[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34515 - acc: 0.8597 -- iter: 2784/3680
[A[ATraining Step: 6758  | total loss: [1m[32m0.33177[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33177 - acc: 0.8706 -- iter: 2816/3680
[A[ATraining Step: 6759  | total loss: [1m[32m0.33006[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33006 - acc: 0.8710 -- iter: 2848/3680
[A[ATraining Step: 6760  | total loss: [1m[32m0.32961[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32961 - acc: 0.8746 -- iter: 2880/3680
[A[ATraining Step: 6761  | total loss: [1m[32m0.31918[0m[0m
[2K| Adam | epoch: 059 | loss: 0.31918 - acc: 0.8777 -- iter: 2912/3680
[A[ATraining Step: 6762  | total loss: [1m[32m0.31798[0m[0m
[2K| Adam | epoch: 059 | loss: 0.31798 - acc: 0.8775 -- iter: 2944/3680
[A[ATraining Step: 6763  | total loss: [1m[32m0.32212[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32212 - acc: 0.8710 -- iter: 2976/3680
[A[ATraining Step: 6764  | total loss: [1m[32m0.32858[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32858 - acc: 0.8620 -- iter: 3008/3680
[A[ATraining Step: 6765  | total loss: [1m[32m0.35703[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35703 - acc: 0.8477 -- iter: 3040/3680
[A[ATraining Step: 6766  | total loss: [1m[32m0.34584[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34584 - acc: 0.8566 -- iter: 3072/3680
[A[ATraining Step: 6767  | total loss: [1m[32m0.33375[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33375 - acc: 0.8616 -- iter: 3104/3680
[A[ATraining Step: 6768  | total loss: [1m[32m0.32439[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32439 - acc: 0.8661 -- iter: 3136/3680
[A[ATraining Step: 6769  | total loss: [1m[32m0.34535[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34535 - acc: 0.8513 -- iter: 3168/3680
[A[ATraining Step: 6770  | total loss: [1m[32m0.34750[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34750 - acc: 0.8568 -- iter: 3200/3680
[A[ATraining Step: 6771  | total loss: [1m[32m0.34000[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34000 - acc: 0.8649 -- iter: 3232/3680
[A[ATraining Step: 6772  | total loss: [1m[32m0.33244[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33244 - acc: 0.8690 -- iter: 3264/3680
[A[ATraining Step: 6773  | total loss: [1m[32m0.33620[0m[0m
[2K| Adam | epoch: 059 | loss: 0.33620 - acc: 0.8634 -- iter: 3296/3680
[A[ATraining Step: 6774  | total loss: [1m[32m0.34184[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34184 - acc: 0.8552 -- iter: 3328/3680
[A[ATraining Step: 6775  | total loss: [1m[32m0.34126[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34126 - acc: 0.8540 -- iter: 3360/3680
[A[ATraining Step: 6776  | total loss: [1m[32m0.32903[0m[0m
[2K| Adam | epoch: 059 | loss: 0.32903 - acc: 0.8592 -- iter: 3392/3680
[A[ATraining Step: 6777  | total loss: [1m[32m0.35731[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35731 - acc: 0.8421 -- iter: 3424/3680
[A[ATraining Step: 6778  | total loss: [1m[32m0.38822[0m[0m
[2K| Adam | epoch: 059 | loss: 0.38822 - acc: 0.8297 -- iter: 3456/3680
[A[ATraining Step: 6779  | total loss: [1m[32m0.38271[0m[0m
[2K| Adam | epoch: 059 | loss: 0.38271 - acc: 0.8280 -- iter: 3488/3680
[A[ATraining Step: 6780  | total loss: [1m[32m0.36956[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36956 - acc: 0.8327 -- iter: 3520/3680
[A[ATraining Step: 6781  | total loss: [1m[32m0.36602[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36602 - acc: 0.8401 -- iter: 3552/3680
[A[ATraining Step: 6782  | total loss: [1m[32m0.38210[0m[0m
[2K| Adam | epoch: 059 | loss: 0.38210 - acc: 0.8373 -- iter: 3584/3680
[A[ATraining Step: 6783  | total loss: [1m[32m0.36778[0m[0m
[2K| Adam | epoch: 059 | loss: 0.36778 - acc: 0.8442 -- iter: 3616/3680
[A[ATraining Step: 6784  | total loss: [1m[32m0.35686[0m[0m
[2K| Adam | epoch: 059 | loss: 0.35686 - acc: 0.8535 -- iter: 3648/3680
[A[ATraining Step: 6785  | total loss: [1m[32m0.34255[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34255 - acc: 0.8588 | val_loss: 0.29974 - val_acc: 0.8947 -- iter: 3680/3680
[A[ATraining Step: 6785  | total loss: [1m[32m0.34255[0m[0m
[2K| Adam | epoch: 059 | loss: 0.34255 - acc: 0.8588 | val_loss: 0.29974 - val_acc: 0.8947 -- iter: 3680/3680
--
Training Step: 6786  | total loss: [1m[32m0.34484[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34484 - acc: 0.8506 -- iter: 0032/3680
[A[ATraining Step: 6787  | total loss: [1m[32m0.34484[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34484 - acc: 0.8506 -- iter: 0064/3680
[A[ATraining Step: 6788  | total loss: [1m[32m0.33447[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33447 - acc: 0.8562 -- iter: 0096/3680
[A[ATraining Step: 6789  | total loss: [1m[32m0.31993[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31993 - acc: 0.8675 -- iter: 0128/3680
[A[ATraining Step: 6790  | total loss: [1m[32m0.33022[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33022 - acc: 0.8588 -- iter: 0160/3680
[A[ATraining Step: 6791  | total loss: [1m[32m0.32626[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32626 - acc: 0.8573 -- iter: 0192/3680
[A[ATraining Step: 6792  | total loss: [1m[32m0.34068[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34068 - acc: 0.8560 -- iter: 0224/3680
[A[ATraining Step: 6793  | total loss: [1m[32m0.34636[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34636 - acc: 0.8516 -- iter: 0256/3680
[A[ATraining Step: 6794  | total loss: [1m[32m0.33323[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33323 - acc: 0.8633 -- iter: 0288/3680
[A[ATraining Step: 6795  | total loss: [1m[32m0.33931[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33931 - acc: 0.8582 -- iter: 0320/3680
[A[ATraining Step: 6796  | total loss: [1m[32m0.33883[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33883 - acc: 0.8599 -- iter: 0352/3680
[A[ATraining Step: 6797  | total loss: [1m[32m0.35678[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35678 - acc: 0.8521 -- iter: 0384/3680
[A[ATraining Step: 6798  | total loss: [1m[32m0.35727[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35727 - acc: 0.8544 -- iter: 0416/3680
[A[ATraining Step: 6799  | total loss: [1m[32m0.35604[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35604 - acc: 0.8533 -- iter: 0448/3680
[A[ATraining Step: 6800  | total loss: [1m[32m0.34737[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34737 - acc: 0.8555 | val_loss: 0.31696 - val_acc: 0.8849 -- iter: 0480/3680
[A[ATraining Step: 6800  | total loss: [1m[32m0.34737[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34737 - acc: 0.8555 | val_loss: 0.31696 - val_acc: 0.8849 -- iter: 0480/3680
--
Training Step: 6801  | total loss: [1m[32m0.34258[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34258 - acc: 0.8574 -- iter: 0512/3680
[A[ATraining Step: 6802  | total loss: [1m[32m0.33871[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33871 - acc: 0.8592 -- iter: 0544/3680
[A[ATraining Step: 6803  | total loss: [1m[32m0.33745[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33745 - acc: 0.8545 -- iter: 0576/3680
[A[ATraining Step: 6804  | total loss: [1m[32m0.32822[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32822 - acc: 0.8566 -- iter: 0608/3680
[A[ATraining Step: 6805  | total loss: [1m[32m0.31947[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31947 - acc: 0.8647 -- iter: 0640/3680
[A[ATraining Step: 6806  | total loss: [1m[32m0.31618[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31618 - acc: 0.8626 -- iter: 0672/3680
[A[ATraining Step: 6807  | total loss: [1m[32m0.31386[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31386 - acc: 0.8669 -- iter: 0704/3680
[A[ATraining Step: 6808  | total loss: [1m[32m0.31140[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31140 - acc: 0.8677 -- iter: 0736/3680
[A[ATraining Step: 6809  | total loss: [1m[32m0.31110[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31110 - acc: 0.8685 -- iter: 0768/3680
[A[ATraining Step: 6810  | total loss: [1m[32m0.30387[0m[0m
[2K| Adam | epoch: 060 | loss: 0.30387 - acc: 0.8691 -- iter: 0800/3680
[A[ATraining Step: 6811  | total loss: [1m[32m0.30427[0m[0m
[2K| Adam | epoch: 060 | loss: 0.30427 - acc: 0.8697 -- iter: 0832/3680
[A[ATraining Step: 6812  | total loss: [1m[32m0.40784[0m[0m
[2K| Adam | epoch: 060 | loss: 0.40784 - acc: 0.8296 -- iter: 0864/3680
[A[ATraining Step: 6813  | total loss: [1m[32m0.40357[0m[0m
[2K| Adam | epoch: 060 | loss: 0.40357 - acc: 0.8310 -- iter: 0896/3680
[A[ATraining Step: 6814  | total loss: [1m[32m0.42324[0m[0m
[2K| Adam | epoch: 060 | loss: 0.42324 - acc: 0.8229 -- iter: 0928/3680
[A[ATraining Step: 6815  | total loss: [1m[32m0.42004[0m[0m
[2K| Adam | epoch: 060 | loss: 0.42004 - acc: 0.8272 -- iter: 0960/3680
[A[ATraining Step: 6816  | total loss: [1m[32m0.41272[0m[0m
[2K| Adam | epoch: 060 | loss: 0.41272 - acc: 0.8272 -- iter: 0992/3680
[A[ATraining Step: 6817  | total loss: [1m[32m0.41186[0m[0m
[2K| Adam | epoch: 060 | loss: 0.41186 - acc: 0.8257 -- iter: 1024/3680
[A[ATraining Step: 6818  | total loss: [1m[32m0.40344[0m[0m
[2K| Adam | epoch: 060 | loss: 0.40344 - acc: 0.8275 -- iter: 1056/3680
[A[ATraining Step: 6819  | total loss: [1m[32m0.39744[0m[0m
[2K| Adam | epoch: 060 | loss: 0.39744 - acc: 0.8323 -- iter: 1088/3680
[A[ATraining Step: 6820  | total loss: [1m[32m0.37370[0m[0m
[2K| Adam | epoch: 060 | loss: 0.37370 - acc: 0.8490 -- iter: 1120/3680
[A[ATraining Step: 6821  | total loss: [1m[32m0.37319[0m[0m
[2K| Adam | epoch: 060 | loss: 0.37319 - acc: 0.8516 -- iter: 1152/3680
[A[ATraining Step: 6822  | total loss: [1m[32m0.37992[0m[0m
[2K| Adam | epoch: 060 | loss: 0.37992 - acc: 0.8446 -- iter: 1184/3680
[A[ATraining Step: 6823  | total loss: [1m[32m0.36379[0m[0m
[2K| Adam | epoch: 060 | loss: 0.36379 - acc: 0.8508 -- iter: 1216/3680
[A[ATraining Step: 6824  | total loss: [1m[32m0.34538[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34538 - acc: 0.8594 -- iter: 1248/3680
[A[ATraining Step: 6825  | total loss: [1m[32m0.34979[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34979 - acc: 0.8579 -- iter: 1280/3680
[A[ATraining Step: 6826  | total loss: [1m[32m0.34413[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34413 - acc: 0.8627 -- iter: 1312/3680
[A[ATraining Step: 6827  | total loss: [1m[32m0.34433[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34433 - acc: 0.8639 -- iter: 1344/3680
[A[ATraining Step: 6828  | total loss: [1m[32m0.33926[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33926 - acc: 0.8682 -- iter: 1376/3680
[A[ATraining Step: 6829  | total loss: [1m[32m0.34330[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34330 - acc: 0.8657 -- iter: 1408/3680
[A[ATraining Step: 6830  | total loss: [1m[32m0.35006[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35006 - acc: 0.8604 -- iter: 1440/3680
[A[ATraining Step: 6831  | total loss: [1m[32m0.34482[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34482 - acc: 0.8619 -- iter: 1472/3680
[A[ATraining Step: 6832  | total loss: [1m[32m0.34911[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34911 - acc: 0.8569 -- iter: 1504/3680
[A[ATraining Step: 6833  | total loss: [1m[32m0.33792[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33792 - acc: 0.8619 -- iter: 1536/3680
[A[ATraining Step: 6834  | total loss: [1m[32m0.33573[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33573 - acc: 0.8632 -- iter: 1568/3680
[A[ATraining Step: 6835  | total loss: [1m[32m0.36921[0m[0m
[2K| Adam | epoch: 060 | loss: 0.36921 - acc: 0.8581 -- iter: 1600/3680
[A[ATraining Step: 6836  | total loss: [1m[32m0.36855[0m[0m
[2K| Adam | epoch: 060 | loss: 0.36855 - acc: 0.8567 -- iter: 1632/3680
[A[ATraining Step: 6837  | total loss: [1m[32m0.36113[0m[0m
[2K| Adam | epoch: 060 | loss: 0.36113 - acc: 0.8616 -- iter: 1664/3680
[A[ATraining Step: 6838  | total loss: [1m[32m0.34530[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34530 - acc: 0.8692 -- iter: 1696/3680
[A[ATraining Step: 6839  | total loss: [1m[32m0.33456[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33456 - acc: 0.8729 -- iter: 1728/3680
[A[ATraining Step: 6840  | total loss: [1m[32m0.34043[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34043 - acc: 0.8700 -- iter: 1760/3680
[A[ATraining Step: 6841  | total loss: [1m[32m0.34593[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34593 - acc: 0.8674 -- iter: 1792/3680
[A[ATraining Step: 6842  | total loss: [1m[32m0.33471[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33471 - acc: 0.8744 -- iter: 1824/3680
[A[ATraining Step: 6843  | total loss: [1m[32m0.32771[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32771 - acc: 0.8720 -- iter: 1856/3680
[A[ATraining Step: 6844  | total loss: [1m[32m0.32771[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32771 - acc: 0.8720 -- iter: 1888/3680
[A[ATraining Step: 6845  | total loss: [1m[32m0.32712[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32712 - acc: 0.8723 -- iter: 1920/3680
[A[ATraining Step: 6846  | total loss: [1m[32m0.32134[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32134 - acc: 0.8634 -- iter: 1952/3680
[A[ATraining Step: 6847  | total loss: [1m[32m0.34395[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34395 - acc: 0.8634 -- iter: 1984/3680
[A[ATraining Step: 6848  | total loss: [1m[32m0.32782[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32782 - acc: 0.8740 -- iter: 2016/3680
[A[ATraining Step: 6849  | total loss: [1m[32m0.32123[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32123 - acc: 0.8710 -- iter: 2048/3680
[A[ATraining Step: 6850  | total loss: [1m[32m0.35363[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35363 - acc: 0.8620 -- iter: 2080/3680
[A[ATraining Step: 6851  | total loss: [1m[32m0.34756[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34756 - acc: 0.8695 -- iter: 2112/3680
[A[ATraining Step: 6852  | total loss: [1m[32m0.34465[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34465 - acc: 0.8701 -- iter: 2144/3680
[A[ATraining Step: 6853  | total loss: [1m[32m0.35445[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35445 - acc: 0.8643 -- iter: 2176/3680
[A[ATraining Step: 6854  | total loss: [1m[32m0.34348[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34348 - acc: 0.8685 -- iter: 2208/3680
[A[ATraining Step: 6855  | total loss: [1m[32m0.34074[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34074 - acc: 0.8723 -- iter: 2240/3680
[A[ATraining Step: 6856  | total loss: [1m[32m0.34968[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34968 - acc: 0.8694 -- iter: 2272/3680
[A[ATraining Step: 6857  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34347 - acc: 0.8669 -- iter: 2304/3680
[A[ATraining Step: 6858  | total loss: [1m[32m0.33965[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33965 - acc: 0.8677 -- iter: 2336/3680
[A[ATraining Step: 6859  | total loss: [1m[32m0.34626[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34626 - acc: 0.8653 -- iter: 2368/3680
[A[ATraining Step: 6860  | total loss: [1m[32m0.33786[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33786 - acc: 0.8725 -- iter: 2400/3680
[A[ATraining Step: 6861  | total loss: [1m[32m0.35333[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35333 - acc: 0.8670 -- iter: 2432/3680
[A[ATraining Step: 6862  | total loss: [1m[32m0.35333[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35333 - acc: 0.8670 -- iter: 2464/3680
[A[ATraining Step: 6863  | total loss: [1m[32m0.35956[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35956 - acc: 0.8647 -- iter: 2496/3680
[A[ATraining Step: 6864  | total loss: [1m[32m0.35322[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35322 - acc: 0.8657 -- iter: 2528/3680
[A[ATraining Step: 6865  | total loss: [1m[32m0.35766[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35766 - acc: 0.8604 -- iter: 2560/3680
[A[ATraining Step: 6866  | total loss: [1m[32m0.34639[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34639 - acc: 0.8650 -- iter: 2592/3680
[A[ATraining Step: 6867  | total loss: [1m[32m0.33852[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33852 - acc: 0.8754 -- iter: 2624/3680
[A[ATraining Step: 6868  | total loss: [1m[32m0.34200[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34200 - acc: 0.8660 -- iter: 2656/3680
[A[ATraining Step: 6869  | total loss: [1m[32m0.34274[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34274 - acc: 0.8677 -- iter: 2688/3680
[A[ATraining Step: 6870  | total loss: [1m[32m0.34584[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34584 - acc: 0.8677 -- iter: 2720/3680
[A[ATraining Step: 6871  | total loss: [1m[32m0.36340[0m[0m
[2K| Adam | epoch: 060 | loss: 0.36340 - acc: 0.8465 -- iter: 2752/3680
[A[ATraining Step: 6872  | total loss: [1m[32m0.37473[0m[0m
[2K| Adam | epoch: 060 | loss: 0.37473 - acc: 0.8431 -- iter: 2784/3680
[A[ATraining Step: 6873  | total loss: [1m[32m0.36952[0m[0m
[2K| Adam | epoch: 060 | loss: 0.36952 - acc: 0.8463 -- iter: 2816/3680
[A[ATraining Step: 6874  | total loss: [1m[32m0.35202[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35202 - acc: 0.8586 -- iter: 2848/3680
[A[ATraining Step: 6875  | total loss: [1m[32m0.35599[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35599 - acc: 0.8508 -- iter: 2880/3680
[A[ATraining Step: 6876  | total loss: [1m[32m0.34413[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34413 - acc: 0.8532 -- iter: 2912/3680
[A[ATraining Step: 6877  | total loss: [1m[32m0.35010[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35010 - acc: 0.8523 -- iter: 2944/3680
[A[ATraining Step: 6878  | total loss: [1m[32m0.33491[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33491 - acc: 0.8639 -- iter: 2976/3680
[A[ATraining Step: 6879  | total loss: [1m[32m0.33378[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33378 - acc: 0.8650 -- iter: 3008/3680
[A[ATraining Step: 6880  | total loss: [1m[32m0.33657[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33657 - acc: 0.8567 -- iter: 3040/3680
[A[ATraining Step: 6881  | total loss: [1m[32m0.34791[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34791 - acc: 0.8460 -- iter: 3072/3680
[A[ATraining Step: 6882  | total loss: [1m[32m0.33895[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33895 - acc: 0.8520 -- iter: 3104/3680
[A[ATraining Step: 6883  | total loss: [1m[32m0.33590[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33590 - acc: 0.8512 -- iter: 3136/3680
[A[ATraining Step: 6884  | total loss: [1m[32m0.32613[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32613 - acc: 0.8536 -- iter: 3168/3680
[A[ATraining Step: 6885  | total loss: [1m[32m0.34593[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34593 - acc: 0.8526 -- iter: 3200/3680
[A[ATraining Step: 6886  | total loss: [1m[32m0.34641[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34641 - acc: 0.8517 -- iter: 3232/3680
[A[ATraining Step: 6887  | total loss: [1m[32m0.35582[0m[0m
[2K| Adam | epoch: 060 | loss: 0.35582 - acc: 0.8384 -- iter: 3264/3680
[A[ATraining Step: 6888  | total loss: [1m[32m0.34443[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34443 - acc: 0.8483 -- iter: 3296/3680
[A[ATraining Step: 6889  | total loss: [1m[32m0.33635[0m[0m
[2K| Adam | epoch: 060 | loss: 0.33635 - acc: 0.8541 -- iter: 3328/3680
[A[ATraining Step: 6890  | total loss: [1m[32m0.32895[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32895 - acc: 0.8625 -- iter: 3360/3680
[A[ATraining Step: 6891  | total loss: [1m[32m0.32395[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32395 - acc: 0.8700 -- iter: 3392/3680
[A[ATraining Step: 6892  | total loss: [1m[32m0.31685[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31685 - acc: 0.8736 -- iter: 3424/3680
[A[ATraining Step: 6893  | total loss: [1m[32m0.32549[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32549 - acc: 0.8675 -- iter: 3456/3680
[A[ATraining Step: 6894  | total loss: [1m[32m0.32226[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32226 - acc: 0.8682 -- iter: 3488/3680
[A[ATraining Step: 6895  | total loss: [1m[32m0.30798[0m[0m
[2K| Adam | epoch: 060 | loss: 0.30798 - acc: 0.8783 -- iter: 3520/3680
[A[ATraining Step: 6896  | total loss: [1m[32m0.31714[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31714 - acc: 0.8780 -- iter: 3552/3680
[A[ATraining Step: 6897  | total loss: [1m[32m0.34594[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34594 - acc: 0.8589 -- iter: 3584/3680
[A[ATraining Step: 6898  | total loss: [1m[32m0.34109[0m[0m
[2K| Adam | epoch: 060 | loss: 0.34109 - acc: 0.8574 -- iter: 3616/3680
[A[ATraining Step: 6899  | total loss: [1m[32m0.32868[0m[0m
[2K| Adam | epoch: 060 | loss: 0.32868 - acc: 0.8623 -- iter: 3648/3680
[A[ATraining Step: 6900  | total loss: [1m[32m0.31715[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31715 - acc: 0.8698 | val_loss: 0.30790 - val_acc: 0.8817 -- iter: 3680/3680
[A[ATraining Step: 6900  | total loss: [1m[32m0.31715[0m[0m
[2K| Adam | epoch: 060 | loss: 0.31715 - acc: 0.8698 | val_loss: 0.30790 - val_acc: 0.8817 -- iter: 3680/3680
--
Training Step: 6901  | total loss: [1m[32m0.32929[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32929 - acc: 0.8609 -- iter: 0032/3680
[A[ATraining Step: 6902  | total loss: [1m[32m0.32297[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32297 - acc: 0.8717 -- iter: 0064/3680
[A[ATraining Step: 6903  | total loss: [1m[32m0.32280[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32280 - acc: 0.8658 -- iter: 0096/3680
[A[ATraining Step: 6904  | total loss: [1m[32m0.32783[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32783 - acc: 0.8667 -- iter: 0128/3680
[A[ATraining Step: 6905  | total loss: [1m[32m0.32427[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32427 - acc: 0.8676 -- iter: 0160/3680
[A[ATraining Step: 6906  | total loss: [1m[32m0.33082[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33082 - acc: 0.8620 -- iter: 0192/3680
[A[ATraining Step: 6907  | total loss: [1m[32m0.32909[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32909 - acc: 0.8696 -- iter: 0224/3680
[A[ATraining Step: 6908  | total loss: [1m[32m0.32021[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32021 - acc: 0.8764 -- iter: 0256/3680
[A[ATraining Step: 6909  | total loss: [1m[32m0.32366[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32366 - acc: 0.8762 -- iter: 0288/3680
[A[ATraining Step: 6910  | total loss: [1m[32m0.33982[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33982 - acc: 0.8667 -- iter: 0320/3680
[A[ATraining Step: 6911  | total loss: [1m[32m0.32423[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32423 - acc: 0.8801 -- iter: 0352/3680
[A[ATraining Step: 6912  | total loss: [1m[32m0.32047[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32047 - acc: 0.8796 -- iter: 0384/3680
[A[ATraining Step: 6913  | total loss: [1m[32m0.31517[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31517 - acc: 0.8822 -- iter: 0416/3680
[A[ATraining Step: 6914  | total loss: [1m[32m0.33348[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33348 - acc: 0.8690 -- iter: 0448/3680
[A[ATraining Step: 6915  | total loss: [1m[32m0.32199[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32199 - acc: 0.8790 -- iter: 0480/3680
[A[ATraining Step: 6916  | total loss: [1m[32m0.32020[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32020 - acc: 0.8755 -- iter: 0512/3680
[A[ATraining Step: 6917  | total loss: [1m[32m0.32404[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32404 - acc: 0.8785 -- iter: 0544/3680
[A[ATraining Step: 6918  | total loss: [1m[32m0.31073[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31073 - acc: 0.8844 -- iter: 0576/3680
[A[ATraining Step: 6919  | total loss: [1m[32m0.31420[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31420 - acc: 0.8835 -- iter: 0608/3680
[A[ATraining Step: 6920  | total loss: [1m[32m0.31429[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31429 - acc: 0.8889 -- iter: 0640/3680
[A[ATraining Step: 6921  | total loss: [1m[32m0.30376[0m[0m
[2K| Adam | epoch: 061 | loss: 0.30376 - acc: 0.8938 -- iter: 0672/3680
[A[ATraining Step: 6922  | total loss: [1m[32m0.29712[0m[0m
[2K| Adam | epoch: 061 | loss: 0.29712 - acc: 0.8950 -- iter: 0704/3680
[A[ATraining Step: 6923  | total loss: [1m[32m0.29601[0m[0m
[2K| Adam | epoch: 061 | loss: 0.29601 - acc: 0.8961 -- iter: 0736/3680
[A[ATraining Step: 6924  | total loss: [1m[32m0.29905[0m[0m
[2K| Adam | epoch: 061 | loss: 0.29905 - acc: 0.8940 -- iter: 0768/3680
[A[ATraining Step: 6925  | total loss: [1m[32m0.29227[0m[0m
[2K| Adam | epoch: 061 | loss: 0.29227 - acc: 0.8984 -- iter: 0800/3680
[A[ATraining Step: 6926  | total loss: [1m[32m0.29907[0m[0m
[2K| Adam | epoch: 061 | loss: 0.29907 - acc: 0.8936 -- iter: 0832/3680
[A[ATraining Step: 6927  | total loss: [1m[32m0.29907[0m[0m
[2K| Adam | epoch: 061 | loss: 0.29907 - acc: 0.8936 -- iter: 0864/3680
[A[ATraining Step: 6928  | total loss: [1m[32m0.42315[0m[0m
[2K| Adam | epoch: 061 | loss: 0.42315 - acc: 0.8511 -- iter: 0896/3680
[A[ATraining Step: 6929  | total loss: [1m[32m0.41740[0m[0m
[2K| Adam | epoch: 061 | loss: 0.41740 - acc: 0.8535 -- iter: 0928/3680
[A[ATraining Step: 6930  | total loss: [1m[32m0.41690[0m[0m
[2K| Adam | epoch: 061 | loss: 0.41690 - acc: 0.8463 -- iter: 0960/3680
[A[ATraining Step: 6931  | total loss: [1m[32m0.43060[0m[0m
[2K| Adam | epoch: 061 | loss: 0.43060 - acc: 0.8429 -- iter: 0992/3680
[A[ATraining Step: 6932  | total loss: [1m[32m0.41230[0m[0m
[2K| Adam | epoch: 061 | loss: 0.41230 - acc: 0.8492 -- iter: 1024/3680
[A[ATraining Step: 6933  | total loss: [1m[32m0.40896[0m[0m
[2K| Adam | epoch: 061 | loss: 0.40896 - acc: 0.8393 -- iter: 1056/3680
[A[ATraining Step: 6934  | total loss: [1m[32m0.40256[0m[0m
[2K| Adam | epoch: 061 | loss: 0.40256 - acc: 0.8460 -- iter: 1088/3680
[A[ATraining Step: 6935  | total loss: [1m[32m0.38042[0m[0m
[2K| Adam | epoch: 061 | loss: 0.38042 - acc: 0.8552 -- iter: 1120/3680
[A[ATraining Step: 6936  | total loss: [1m[32m0.36732[0m[0m
[2K| Adam | epoch: 061 | loss: 0.36732 - acc: 0.8540 -- iter: 1152/3680
[A[ATraining Step: 6937  | total loss: [1m[32m0.36808[0m[0m
[2K| Adam | epoch: 061 | loss: 0.36808 - acc: 0.8467 -- iter: 1184/3680
[A[ATraining Step: 6938  | total loss: [1m[32m0.35068[0m[0m
[2K| Adam | epoch: 061 | loss: 0.35068 - acc: 0.8558 -- iter: 1216/3680
[A[ATraining Step: 6939  | total loss: [1m[32m0.33677[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33677 - acc: 0.8671 -- iter: 1248/3680
[A[ATraining Step: 6940  | total loss: [1m[32m0.33163[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33163 - acc: 0.8679 -- iter: 1280/3680
[A[ATraining Step: 6941  | total loss: [1m[32m0.33789[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33789 - acc: 0.8624 -- iter: 1312/3680
[A[ATraining Step: 6942  | total loss: [1m[32m0.33586[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33586 - acc: 0.8667 -- iter: 1344/3680
[A[ATraining Step: 6943  | total loss: [1m[32m0.33895[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33895 - acc: 0.8644 -- iter: 1376/3680
[A[ATraining Step: 6944  | total loss: [1m[32m0.31972[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31972 - acc: 0.8780 -- iter: 1408/3680
[A[ATraining Step: 6945  | total loss: [1m[32m0.33712[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33712 - acc: 0.8746 -- iter: 1440/3680
[A[ATraining Step: 6946  | total loss: [1m[32m0.32940[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32940 - acc: 0.8746 -- iter: 1472/3680
[A[ATraining Step: 6947  | total loss: [1m[32m0.31630[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31630 - acc: 0.8872 -- iter: 1504/3680
[A[ATraining Step: 6948  | total loss: [1m[32m0.31609[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31609 - acc: 0.8891 -- iter: 1536/3680
[A[ATraining Step: 6949  | total loss: [1m[32m0.32391[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32391 - acc: 0.8814 -- iter: 1568/3680
[A[ATraining Step: 6950  | total loss: [1m[32m0.33106[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33106 - acc: 0.8808 -- iter: 1600/3680
[A[ATraining Step: 6951  | total loss: [1m[32m0.32399[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32399 - acc: 0.8833 -- iter: 1632/3680
[A[ATraining Step: 6952  | total loss: [1m[32m0.32040[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32040 - acc: 0.8856 -- iter: 1664/3680
[A[ATraining Step: 6953  | total loss: [1m[32m0.30958[0m[0m
[2K| Adam | epoch: 061 | loss: 0.30958 - acc: 0.8908 -- iter: 1696/3680
[A[ATraining Step: 6954  | total loss: [1m[32m0.31427[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31427 - acc: 0.8892 -- iter: 1728/3680
[A[ATraining Step: 6955  | total loss: [1m[32m0.31853[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31853 - acc: 0.8909 -- iter: 1760/3680
[A[ATraining Step: 6956  | total loss: [1m[32m0.31790[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31790 - acc: 0.8893 -- iter: 1792/3680
[A[ATraining Step: 6957  | total loss: [1m[32m0.32786[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32786 - acc: 0.8785 -- iter: 1824/3680
[A[ATraining Step: 6958  | total loss: [1m[32m0.32270[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32270 - acc: 0.8844 -- iter: 1856/3680
[A[ATraining Step: 6959  | total loss: [1m[32m0.31958[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31958 - acc: 0.8804 -- iter: 1888/3680
[A[ATraining Step: 6960  | total loss: [1m[32m0.31984[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31984 - acc: 0.8861 -- iter: 1920/3680
[A[ATraining Step: 6961  | total loss: [1m[32m0.32062[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32062 - acc: 0.8787 -- iter: 1952/3680
[A[ATraining Step: 6962  | total loss: [1m[32m0.34290[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34290 - acc: 0.8690 -- iter: 1984/3680
[A[ATraining Step: 6963  | total loss: [1m[32m0.35022[0m[0m
[2K| Adam | epoch: 061 | loss: 0.35022 - acc: 0.8602 -- iter: 2016/3680
[A[ATraining Step: 6964  | total loss: [1m[32m0.34632[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34632 - acc: 0.8539 -- iter: 2048/3680
[A[ATraining Step: 6965  | total loss: [1m[32m0.36218[0m[0m
[2K| Adam | epoch: 061 | loss: 0.36218 - acc: 0.8539 -- iter: 2080/3680
[A[ATraining Step: 6966  | total loss: [1m[32m0.36218[0m[0m
[2K| Adam | epoch: 061 | loss: 0.36218 - acc: 0.8467 -- iter: 2112/3680
[A[ATraining Step: 6967  | total loss: [1m[32m0.34165[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34165 - acc: 0.8589 -- iter: 2144/3680
[A[ATraining Step: 6968  | total loss: [1m[32m0.33573[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33573 - acc: 0.8574 -- iter: 2176/3680
[A[ATraining Step: 6969  | total loss: [1m[32m0.33352[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33352 - acc: 0.8623 -- iter: 2208/3680
[A[ATraining Step: 6970  | total loss: [1m[32m0.33753[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33753 - acc: 0.8635 -- iter: 2240/3680
[A[ATraining Step: 6971  | total loss: [1m[32m0.34419[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34419 - acc: 0.8616 -- iter: 2272/3680
[A[ATraining Step: 6972  | total loss: [1m[32m0.34587[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34587 - acc: 0.8598 -- iter: 2304/3680
[A[ATraining Step: 6973  | total loss: [1m[32m0.35276[0m[0m
[2K| Adam | epoch: 061 | loss: 0.35276 - acc: 0.8550 -- iter: 2336/3680
[A[ATraining Step: 6974  | total loss: [1m[32m0.34463[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34463 - acc: 0.8570 -- iter: 2368/3680
[A[ATraining Step: 6975  | total loss: [1m[32m0.34226[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34226 - acc: 0.8588 -- iter: 2400/3680
[A[ATraining Step: 6976  | total loss: [1m[32m0.33274[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33274 - acc: 0.8636 -- iter: 2432/3680
[A[ATraining Step: 6977  | total loss: [1m[32m0.32287[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32287 - acc: 0.8710 -- iter: 2464/3680
[A[ATraining Step: 6978  | total loss: [1m[32m0.31785[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31785 - acc: 0.8714 -- iter: 2496/3680
[A[ATraining Step: 6979  | total loss: [1m[32m0.31446[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31446 - acc: 0.8749 -- iter: 2528/3680
[A[ATraining Step: 6980  | total loss: [1m[32m0.32138[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32138 - acc: 0.8717 -- iter: 2560/3680
[A[ATraining Step: 6981  | total loss: [1m[32m0.33182[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33182 - acc: 0.8596 -- iter: 2592/3680
[A[ATraining Step: 6982  | total loss: [1m[32m0.32425[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32425 - acc: 0.8674 -- iter: 2624/3680
[A[ATraining Step: 6983  | total loss: [1m[32m0.32400[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32400 - acc: 0.8713 -- iter: 2656/3680
[A[ATraining Step: 6984  | total loss: [1m[32m0.32811[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32811 - acc: 0.8623 -- iter: 2688/3680
[A[ATraining Step: 6985  | total loss: [1m[32m0.34083[0m[0m
[2K| Adam | epoch: 061 | loss: 0.34083 - acc: 0.8542 -- iter: 2720/3680
[A[ATraining Step: 6986  | total loss: [1m[32m0.33553[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33553 - acc: 0.8562 -- iter: 2752/3680
[A[ATraining Step: 6987  | total loss: [1m[32m0.32116[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32116 - acc: 0.8644 -- iter: 2784/3680
[A[ATraining Step: 6988  | total loss: [1m[32m0.32810[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32810 - acc: 0.8561 -- iter: 2816/3680
[A[ATraining Step: 6989  | total loss: [1m[32m0.32448[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32448 - acc: 0.8579 -- iter: 2848/3680
[A[ATraining Step: 6990  | total loss: [1m[32m0.30988[0m[0m
[2K| Adam | epoch: 061 | loss: 0.30988 - acc: 0.8659 -- iter: 2880/3680
[A[ATraining Step: 6991  | total loss: [1m[32m0.31155[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31155 - acc: 0.8668 -- iter: 2912/3680
[A[ATraining Step: 6992  | total loss: [1m[32m0.32376[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32376 - acc: 0.8676 -- iter: 2944/3680
[A[ATraining Step: 6993  | total loss: [1m[32m0.32322[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32322 - acc: 0.8684 -- iter: 2976/3680
[A[ATraining Step: 6994  | total loss: [1m[32m0.32868[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32868 - acc: 0.8659 -- iter: 3008/3680
[A[ATraining Step: 6995  | total loss: [1m[32m0.32478[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32478 - acc: 0.8668 -- iter: 3040/3680
[A[ATraining Step: 6996  | total loss: [1m[32m0.32749[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32749 - acc: 0.8614 -- iter: 3072/3680
[A[ATraining Step: 6997  | total loss: [1m[32m0.31643[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31643 - acc: 0.8659 -- iter: 3104/3680
[A[ATraining Step: 6998  | total loss: [1m[32m0.30690[0m[0m
[2K| Adam | epoch: 061 | loss: 0.30690 - acc: 0.8730 -- iter: 3136/3680
[A[ATraining Step: 6999  | total loss: [1m[32m0.32752[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32752 - acc: 0.8639 -- iter: 3168/3680
[A[ATraining Step: 7000  | total loss: [1m[32m0.32541[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32541 - acc: 0.8618 | val_loss: 0.30690 - val_acc: 0.8849 -- iter: 3200/3680
[A[ATraining Step: 7000  | total loss: [1m[32m0.32541[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32541 - acc: 0.8618 | val_loss: 0.30690 - val_acc: 0.8849 -- iter: 3200/3680
--
Training Step: 7001  | total loss: [1m[32m0.32651[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32651 - acc: 0.8600 -- iter: 3232/3680
[A[ATraining Step: 7002  | total loss: [1m[32m0.33163[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33163 - acc: 0.8553 -- iter: 3264/3680
[A[ATraining Step: 7003  | total loss: [1m[32m0.32119[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32119 - acc: 0.8604 -- iter: 3296/3680
[A[ATraining Step: 7004  | total loss: [1m[32m0.31763[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31763 - acc: 0.8681 -- iter: 3328/3680
[A[ATraining Step: 7005  | total loss: [1m[32m0.32208[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32208 - acc: 0.8750 -- iter: 3360/3680
[A[ATraining Step: 7006  | total loss: [1m[32m0.33083[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33083 - acc: 0.8688 -- iter: 3392/3680
[A[ATraining Step: 7007  | total loss: [1m[32m0.31806[0m[0m
[2K| Adam | epoch: 061 | loss: 0.31806 - acc: 0.8757 -- iter: 3424/3680
[A[ATraining Step: 7008  | total loss: [1m[32m0.32329[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32329 - acc: 0.8631 -- iter: 3456/3680
[A[ATraining Step: 7009  | total loss: [1m[32m0.32396[0m[0m
[2K| Adam | epoch: 061 | loss: 0.32396 - acc: 0.8643 -- iter: 3488/3680
[A[ATraining Step: 7010  | total loss: [1m[32m0.33201[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33201 - acc: 0.8560 -- iter: 3520/3680
[A[ATraining Step: 7011  | total loss: [1m[32m0.33574[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33574 - acc: 0.8579 -- iter: 3552/3680
[A[ATraining Step: 7012  | total loss: [1m[32m0.33364[0m[0m
[2K| Adam | epoch: 061 | loss: 0.33364 - acc: 0.8596 -- iter: 3584/3680
[A[ATraining Step: 7013  | total loss: [1m[32m0.35014[0m[0m
[2K| Adam | epoch: 061 | loss: 0.35014 - acc: 0.8549 -- iter: 3616/3680
[A[ATraining Step: 7014  | total loss: [1m[32m0.35116[0m[0m
[2K| Adam | epoch: 061 | loss: 0.35116 - acc: 0.8413 -- iter: 3648/3680
[A[ATraining Step: 7015  | total loss: [1m[32m0.36037[0m[0m
[2K| Adam | epoch: 061 | loss: 0.36037 - acc: 0.8384 | val_loss: 0.31127 - val_acc: 0.8860 -- iter: 3680/3680
[A[ATraining Step: 7015  | total loss: [1m[32m0.36037[0m[0m
[2K| Adam | epoch: 061 | loss: 0.36037 - acc: 0.8384 | val_loss: 0.31127 - val_acc: 0.8860 -- iter: 3680/3680
--
Training Step: 7016  | total loss: [1m[32m0.35165[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35165 - acc: 0.8452 -- iter: 0032/3680
[A[ATraining Step: 7017  | total loss: [1m[32m0.34341[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34341 - acc: 0.8513 -- iter: 0064/3680
[A[ATraining Step: 7018  | total loss: [1m[32m0.34104[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34104 - acc: 0.8568 -- iter: 0096/3680
[A[ATraining Step: 7019  | total loss: [1m[32m0.35235[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35235 - acc: 0.8524 -- iter: 0128/3680
[A[ATraining Step: 7020  | total loss: [1m[32m0.34358[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34358 - acc: 0.8577 -- iter: 0160/3680
[A[ATraining Step: 7021  | total loss: [1m[32m0.34483[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34483 - acc: 0.8563 -- iter: 0192/3680
[A[ATraining Step: 7022  | total loss: [1m[32m0.34788[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34788 - acc: 0.8540 -- iter: 0224/3680
[A[ATraining Step: 7023  | total loss: [1m[32m0.34788[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34788 - acc: 0.8540 -- iter: 0256/3680
[A[ATraining Step: 7024  | total loss: [1m[32m0.34401[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34401 - acc: 0.8561 -- iter: 0288/3680
[A[ATraining Step: 7025  | total loss: [1m[32m0.35752[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35752 - acc: 0.8454 -- iter: 0320/3680
[A[ATraining Step: 7026  | total loss: [1m[32m0.36377[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36377 - acc: 0.8453 -- iter: 0352/3680
[A[ATraining Step: 7027  | total loss: [1m[32m0.38177[0m[0m
[2K| Adam | epoch: 062 | loss: 0.38177 - acc: 0.8483 -- iter: 0384/3680
[A[ATraining Step: 7028  | total loss: [1m[32m0.36412[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36412 - acc: 0.8572 -- iter: 0416/3680
[A[ATraining Step: 7029  | total loss: [1m[32m0.37830[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37830 - acc: 0.8558 -- iter: 0448/3680
[A[ATraining Step: 7030  | total loss: [1m[32m0.37074[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37074 - acc: 0.8609 -- iter: 0480/3680
[A[ATraining Step: 7031  | total loss: [1m[32m0.35707[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35707 - acc: 0.8654 -- iter: 0512/3680
[A[ATraining Step: 7032  | total loss: [1m[32m0.41578[0m[0m
[2K| Adam | epoch: 062 | loss: 0.41578 - acc: 0.8382 -- iter: 0544/3680
[A[ATraining Step: 7033  | total loss: [1m[32m0.40515[0m[0m
[2K| Adam | epoch: 062 | loss: 0.40515 - acc: 0.8419 -- iter: 0576/3680
[A[ATraining Step: 7034  | total loss: [1m[32m0.39629[0m[0m
[2K| Adam | epoch: 062 | loss: 0.39629 - acc: 0.8452 -- iter: 0608/3680
[A[ATraining Step: 7035  | total loss: [1m[32m0.38540[0m[0m
[2K| Adam | epoch: 062 | loss: 0.38540 - acc: 0.8513 -- iter: 0640/3680
[A[ATraining Step: 7036  | total loss: [1m[32m0.37593[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37593 - acc: 0.8568 -- iter: 0672/3680
[A[ATraining Step: 7037  | total loss: [1m[32m0.37336[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37336 - acc: 0.8586 -- iter: 0704/3680
[A[ATraining Step: 7038  | total loss: [1m[32m0.38922[0m[0m
[2K| Adam | epoch: 062 | loss: 0.38922 - acc: 0.8478 -- iter: 0736/3680
[A[ATraining Step: 7039  | total loss: [1m[32m0.39180[0m[0m
[2K| Adam | epoch: 062 | loss: 0.39180 - acc: 0.8411 -- iter: 0768/3680
[A[ATraining Step: 7040  | total loss: [1m[32m0.41397[0m[0m
[2K| Adam | epoch: 062 | loss: 0.41397 - acc: 0.8289 -- iter: 0800/3680
[A[ATraining Step: 7041  | total loss: [1m[32m0.39808[0m[0m
[2K| Adam | epoch: 062 | loss: 0.39808 - acc: 0.8335 -- iter: 0832/3680
[A[ATraining Step: 7042  | total loss: [1m[32m0.37810[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37810 - acc: 0.8411 -- iter: 0864/3680
[A[ATraining Step: 7043  | total loss: [1m[32m0.36923[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36923 - acc: 0.8411 -- iter: 0896/3680
[A[ATraining Step: 7044  | total loss: [1m[32m0.37709[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37709 - acc: 0.8351 -- iter: 0928/3680
[A[ATraining Step: 7045  | total loss: [1m[32m0.35692[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35692 - acc: 0.8485 -- iter: 0960/3680
[A[ATraining Step: 7046  | total loss: [1m[32m0.35789[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35789 - acc: 0.8444 -- iter: 0992/3680
[A[ATraining Step: 7047  | total loss: [1m[32m0.35957[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35957 - acc: 0.8444 -- iter: 1024/3680
[A[ATraining Step: 7048  | total loss: [1m[32m0.37463[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37463 - acc: 0.8350 -- iter: 1056/3680
[A[ATraining Step: 7049  | total loss: [1m[32m0.37327[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37327 - acc: 0.8335 -- iter: 1088/3680
[A[ATraining Step: 7050  | total loss: [1m[32m0.37327[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37327 - acc: 0.8335 -- iter: 1120/3680
[A[ATraining Step: 7051  | total loss: [1m[32m0.36282[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36282 - acc: 0.8408 -- iter: 1152/3680
[A[ATraining Step: 7052  | total loss: [1m[32m0.37038[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37038 - acc: 0.8380 -- iter: 1184/3680
[A[ATraining Step: 7053  | total loss: [1m[32m0.35942[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35942 - acc: 0.8448 -- iter: 1216/3680
[A[ATraining Step: 7054  | total loss: [1m[32m0.34861[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34861 - acc: 0.8509 -- iter: 1248/3680
[A[ATraining Step: 7055  | total loss: [1m[32m0.34426[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34426 - acc: 0.8471 -- iter: 1280/3680
[A[ATraining Step: 7056  | total loss: [1m[32m0.34665[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34665 - acc: 0.8436 -- iter: 1312/3680
[A[ATraining Step: 7057  | total loss: [1m[32m0.35023[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35023 - acc: 0.8437 -- iter: 1344/3680
[A[ATraining Step: 7058  | total loss: [1m[32m0.36271[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36271 - acc: 0.8343 -- iter: 1376/3680
[A[ATraining Step: 7059  | total loss: [1m[32m0.36677[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36677 - acc: 0.8352 -- iter: 1408/3680
[A[ATraining Step: 7060  | total loss: [1m[32m0.35163[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35163 - acc: 0.8455 -- iter: 1440/3680
[A[ATraining Step: 7061  | total loss: [1m[32m0.35231[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35231 - acc: 0.8484 -- iter: 1472/3680
[A[ATraining Step: 7062  | total loss: [1m[32m0.37635[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37635 - acc: 0.8417 -- iter: 1504/3680
[A[ATraining Step: 7063  | total loss: [1m[32m0.38264[0m[0m
[2K| Adam | epoch: 062 | loss: 0.38264 - acc: 0.8419 -- iter: 1536/3680
[A[ATraining Step: 7064  | total loss: [1m[32m0.38219[0m[0m
[2K| Adam | epoch: 062 | loss: 0.38219 - acc: 0.8483 -- iter: 1568/3680
[A[ATraining Step: 7065  | total loss: [1m[32m0.37906[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37906 - acc: 0.8510 -- iter: 1600/3680
[A[ATraining Step: 7066  | total loss: [1m[32m0.37315[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37315 - acc: 0.8503 -- iter: 1632/3680
[A[ATraining Step: 7067  | total loss: [1m[32m0.35654[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35654 - acc: 0.8621 -- iter: 1664/3680
[A[ATraining Step: 7068  | total loss: [1m[32m0.34387[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34387 - acc: 0.8728 -- iter: 1696/3680
[A[ATraining Step: 7069  | total loss: [1m[32m0.33504[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33504 - acc: 0.8761 -- iter: 1728/3680
[A[ATraining Step: 7070  | total loss: [1m[32m0.32498[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32498 - acc: 0.8823 -- iter: 1760/3680
[A[ATraining Step: 7071  | total loss: [1m[32m0.32419[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32419 - acc: 0.8815 -- iter: 1792/3680
[A[ATraining Step: 7072  | total loss: [1m[32m0.32201[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32201 - acc: 0.8809 -- iter: 1824/3680
[A[ATraining Step: 7073  | total loss: [1m[32m0.31477[0m[0m
[2K| Adam | epoch: 062 | loss: 0.31477 - acc: 0.8866 -- iter: 1856/3680
[A[ATraining Step: 7074  | total loss: [1m[32m0.31384[0m[0m
[2K| Adam | epoch: 062 | loss: 0.31384 - acc: 0.8854 -- iter: 1888/3680
[A[ATraining Step: 7075  | total loss: [1m[32m0.30846[0m[0m
[2K| Adam | epoch: 062 | loss: 0.30846 - acc: 0.8875 -- iter: 1920/3680
[A[ATraining Step: 7076  | total loss: [1m[32m0.30894[0m[0m
[2K| Adam | epoch: 062 | loss: 0.30894 - acc: 0.8831 -- iter: 1952/3680
[A[ATraining Step: 7077  | total loss: [1m[32m0.32010[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32010 - acc: 0.8823 -- iter: 1984/3680
[A[ATraining Step: 7078  | total loss: [1m[32m0.30697[0m[0m
[2K| Adam | epoch: 062 | loss: 0.30697 - acc: 0.8878 -- iter: 2016/3680
[A[ATraining Step: 7079  | total loss: [1m[32m0.33676[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33676 - acc: 0.8834 -- iter: 2048/3680
[A[ATraining Step: 7080  | total loss: [1m[32m0.34037[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34037 - acc: 0.8826 -- iter: 2080/3680
[A[ATraining Step: 7081  | total loss: [1m[32m0.32416[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32416 - acc: 0.8881 -- iter: 2112/3680
[A[ATraining Step: 7082  | total loss: [1m[32m0.32142[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32142 - acc: 0.8899 -- iter: 2144/3680
[A[ATraining Step: 7083  | total loss: [1m[32m0.32829[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32829 - acc: 0.8790 -- iter: 2176/3680
[A[ATraining Step: 7084  | total loss: [1m[32m0.33824[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33824 - acc: 0.8724 -- iter: 2208/3680
[A[ATraining Step: 7085  | total loss: [1m[32m0.33518[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33518 - acc: 0.8726 -- iter: 2240/3680
[A[ATraining Step: 7086  | total loss: [1m[32m0.35708[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35708 - acc: 0.8572 -- iter: 2272/3680
[A[ATraining Step: 7087  | total loss: [1m[32m0.34316[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34316 - acc: 0.8621 -- iter: 2304/3680
[A[ATraining Step: 7088  | total loss: [1m[32m0.34368[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34368 - acc: 0.8603 -- iter: 2336/3680
[A[ATraining Step: 7089  | total loss: [1m[32m0.33764[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33764 - acc: 0.8680 -- iter: 2368/3680
[A[ATraining Step: 7090  | total loss: [1m[32m0.32115[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32115 - acc: 0.8781 -- iter: 2400/3680
[A[ATraining Step: 7091  | total loss: [1m[32m0.31846[0m[0m
[2K| Adam | epoch: 062 | loss: 0.31846 - acc: 0.8809 -- iter: 2432/3680
[A[ATraining Step: 7092  | total loss: [1m[32m0.32705[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32705 - acc: 0.8772 -- iter: 2464/3680
[A[ATraining Step: 7093  | total loss: [1m[32m0.33042[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33042 - acc: 0.8770 -- iter: 2496/3680
[A[ATraining Step: 7094  | total loss: [1m[32m0.33813[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33813 - acc: 0.8737 -- iter: 2528/3680
[A[ATraining Step: 7095  | total loss: [1m[32m0.33141[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33141 - acc: 0.8769 -- iter: 2560/3680
[A[ATraining Step: 7096  | total loss: [1m[32m0.33474[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33474 - acc: 0.8736 -- iter: 2592/3680
[A[ATraining Step: 7097  | total loss: [1m[32m0.32465[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32465 - acc: 0.8800 -- iter: 2624/3680
[A[ATraining Step: 7098  | total loss: [1m[32m0.31586[0m[0m
[2K| Adam | epoch: 062 | loss: 0.31586 - acc: 0.8764 -- iter: 2656/3680
[A[ATraining Step: 7099  | total loss: [1m[32m0.30444[0m[0m
[2K| Adam | epoch: 062 | loss: 0.30444 - acc: 0.8856 -- iter: 2688/3680
[A[ATraining Step: 7100  | total loss: [1m[32m0.32146[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32146 - acc: 0.8752 | val_loss: 0.29812 - val_acc: 0.8871 -- iter: 2720/3680
[A[ATraining Step: 7100  | total loss: [1m[32m0.32146[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32146 - acc: 0.8752 | val_loss: 0.29812 - val_acc: 0.8871 -- iter: 2720/3680
--
Training Step: 7101  | total loss: [1m[32m0.32344[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32344 - acc: 0.8751 -- iter: 2752/3680
[A[ATraining Step: 7102  | total loss: [1m[32m0.34331[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34331 - acc: 0.8595 -- iter: 2784/3680
[A[ATraining Step: 7103  | total loss: [1m[32m0.34541[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34541 - acc: 0.8579 -- iter: 2816/3680
[A[ATraining Step: 7104  | total loss: [1m[32m0.34313[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34313 - acc: 0.8628 -- iter: 2848/3680
[A[ATraining Step: 7105  | total loss: [1m[32m0.33043[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33043 - acc: 0.8702 -- iter: 2880/3680
[A[ATraining Step: 7106  | total loss: [1m[32m0.34118[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34118 - acc: 0.8613 -- iter: 2912/3680
[A[ATraining Step: 7107  | total loss: [1m[32m0.36160[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36160 - acc: 0.8502 -- iter: 2944/3680
[A[ATraining Step: 7108  | total loss: [1m[32m0.35447[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35447 - acc: 0.8527 -- iter: 2976/3680
[A[ATraining Step: 7109  | total loss: [1m[32m0.33855[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33855 - acc: 0.8643 -- iter: 3008/3680
[A[ATraining Step: 7110  | total loss: [1m[32m0.33786[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33786 - acc: 0.8591 -- iter: 3040/3680
[A[ATraining Step: 7111  | total loss: [1m[32m0.34860[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34860 - acc: 0.8513 -- iter: 3072/3680
[A[ATraining Step: 7112  | total loss: [1m[32m0.35033[0m[0m
[2K| Adam | epoch: 062 | loss: 0.35033 - acc: 0.8568 -- iter: 3104/3680
[A[ATraining Step: 7113  | total loss: [1m[32m0.37901[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37901 - acc: 0.8586 -- iter: 3136/3680
[A[ATraining Step: 7114  | total loss: [1m[32m0.38254[0m[0m
[2K| Adam | epoch: 062 | loss: 0.38254 - acc: 0.8540 -- iter: 3168/3680
[A[ATraining Step: 7115  | total loss: [1m[32m0.37095[0m[0m
[2K| Adam | epoch: 062 | loss: 0.37095 - acc: 0.8561 -- iter: 3200/3680
[A[ATraining Step: 7116  | total loss: [1m[32m0.36930[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36930 - acc: 0.8611 -- iter: 3232/3680
[A[ATraining Step: 7117  | total loss: [1m[32m0.36864[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36864 - acc: 0.8594 -- iter: 3264/3680
[A[ATraining Step: 7118  | total loss: [1m[32m0.36552[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36552 - acc: 0.8672 -- iter: 3296/3680
[A[ATraining Step: 7119  | total loss: [1m[32m0.36732[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36732 - acc: 0.8649 -- iter: 3328/3680
[A[ATraining Step: 7120  | total loss: [1m[32m0.36883[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36883 - acc: 0.8627 -- iter: 3360/3680
[A[ATraining Step: 7121  | total loss: [1m[32m0.36715[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36715 - acc: 0.8608 -- iter: 3392/3680
[A[ATraining Step: 7122  | total loss: [1m[32m0.36370[0m[0m
[2K| Adam | epoch: 062 | loss: 0.36370 - acc: 0.8654 -- iter: 3424/3680
[A[ATraining Step: 7123  | total loss: [1m[32m0.34945[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34945 - acc: 0.8695 -- iter: 3456/3680
[A[ATraining Step: 7124  | total loss: [1m[32m0.34499[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34499 - acc: 0.8700 -- iter: 3488/3680
[A[ATraining Step: 7125  | total loss: [1m[32m0.33504[0m[0m
[2K| Adam | epoch: 062 | loss: 0.33504 - acc: 0.8768 -- iter: 3520/3680
[A[ATraining Step: 7126  | total loss: [1m[32m0.32811[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32811 - acc: 0.8797 -- iter: 3552/3680
[A[ATraining Step: 7127  | total loss: [1m[32m0.34046[0m[0m
[2K| Adam | epoch: 062 | loss: 0.34046 - acc: 0.8636 -- iter: 3584/3680
[A[ATraining Step: 7128  | total loss: [1m[32m0.32715[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32715 - acc: 0.8773 -- iter: 3616/3680
[A[ATraining Step: 7129  | total loss: [1m[32m0.31841[0m[0m
[2K| Adam | epoch: 062 | loss: 0.31841 - acc: 0.8770 -- iter: 3648/3680
[A[ATraining Step: 7130  | total loss: [1m[32m0.32970[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32970 - acc: 0.8675 | val_loss: 0.29905 - val_acc: 0.8936 -- iter: 3680/3680
[A[ATraining Step: 7130  | total loss: [1m[32m0.32970[0m[0m
[2K| Adam | epoch: 062 | loss: 0.32970 - acc: 0.8675 | val_loss: 0.29905 - val_acc: 0.8936 -- iter: 3680/3680
--
Training Step: 7131  | total loss: [1m[32m0.33209[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33209 - acc: 0.8620 -- iter: 0032/3680
[A[ATraining Step: 7132  | total loss: [1m[32m0.31512[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31512 - acc: 0.8695 -- iter: 0064/3680
[A[ATraining Step: 7133  | total loss: [1m[32m0.31041[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31041 - acc: 0.8763 -- iter: 0096/3680
[A[ATraining Step: 7134  | total loss: [1m[32m0.30901[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30901 - acc: 0.8762 -- iter: 0128/3680
[A[ATraining Step: 7135  | total loss: [1m[32m0.30974[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30974 - acc: 0.8729 -- iter: 0160/3680
[A[ATraining Step: 7136  | total loss: [1m[32m0.32680[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32680 - acc: 0.8669 -- iter: 0192/3680
[A[ATraining Step: 7137  | total loss: [1m[32m0.32231[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32231 - acc: 0.8708 -- iter: 0224/3680
[A[ATraining Step: 7138  | total loss: [1m[32m0.31606[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31606 - acc: 0.8744 -- iter: 0256/3680
[A[ATraining Step: 7139  | total loss: [1m[32m0.33269[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33269 - acc: 0.8713 -- iter: 0288/3680
[A[ATraining Step: 7140  | total loss: [1m[32m0.33707[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33707 - acc: 0.8654 -- iter: 0320/3680
[A[ATraining Step: 7141  | total loss: [1m[32m0.32688[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32688 - acc: 0.8676 -- iter: 0352/3680
[A[ATraining Step: 7142  | total loss: [1m[32m0.32688[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32688 - acc: 0.8676 -- iter: 0384/3680
[A[ATraining Step: 7143  | total loss: [1m[32m0.32939[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32939 - acc: 0.8683 -- iter: 0416/3680
[A[ATraining Step: 7144  | total loss: [1m[32m0.32313[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32313 - acc: 0.8752 -- iter: 0448/3680
[A[ATraining Step: 7145  | total loss: [1m[32m0.32029[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32029 - acc: 0.8752 -- iter: 0480/3680
[A[ATraining Step: 7146  | total loss: [1m[32m0.31148[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31148 - acc: 0.8783 -- iter: 0512/3680
[A[ATraining Step: 7147  | total loss: [1m[32m0.30375[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30375 - acc: 0.8780 -- iter: 0544/3680
[A[ATraining Step: 7148  | total loss: [1m[32m0.32713[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32713 - acc: 0.8683 -- iter: 0576/3680
[A[ATraining Step: 7149  | total loss: [1m[32m0.32808[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32808 - acc: 0.8690 -- iter: 0608/3680
[A[ATraining Step: 7150  | total loss: [1m[32m0.33112[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33112 - acc: 0.8602 -- iter: 0640/3680
[A[ATraining Step: 7151  | total loss: [1m[32m0.36213[0m[0m
[2K| Adam | epoch: 063 | loss: 0.36213 - acc: 0.8554 -- iter: 0672/3680
[A[ATraining Step: 7152  | total loss: [1m[32m0.35165[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35165 - acc: 0.8574 -- iter: 0704/3680
[A[ATraining Step: 7153  | total loss: [1m[32m0.33987[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33987 - acc: 0.8654 -- iter: 0736/3680
[A[ATraining Step: 7154  | total loss: [1m[32m0.34344[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34344 - acc: 0.8601 -- iter: 0768/3680
[A[ATraining Step: 7155  | total loss: [1m[32m0.33420[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33420 - acc: 0.8616 -- iter: 0800/3680
[A[ATraining Step: 7156  | total loss: [1m[32m0.33509[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33509 - acc: 0.8629 -- iter: 0832/3680
[A[ATraining Step: 7157  | total loss: [1m[32m0.33694[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33694 - acc: 0.8610 -- iter: 0864/3680
[A[ATraining Step: 7158  | total loss: [1m[32m0.32826[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32826 - acc: 0.8655 -- iter: 0896/3680
[A[ATraining Step: 7159  | total loss: [1m[32m0.33333[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33333 - acc: 0.8634 -- iter: 0928/3680
[A[ATraining Step: 7160  | total loss: [1m[32m0.34474[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34474 - acc: 0.8614 -- iter: 0960/3680
[A[ATraining Step: 7161  | total loss: [1m[32m0.36409[0m[0m
[2K| Adam | epoch: 063 | loss: 0.36409 - acc: 0.8565 -- iter: 0992/3680
[A[ATraining Step: 7162  | total loss: [1m[32m0.36887[0m[0m
[2K| Adam | epoch: 063 | loss: 0.36887 - acc: 0.8584 -- iter: 1024/3680
[A[ATraining Step: 7163  | total loss: [1m[32m0.35789[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35789 - acc: 0.8631 -- iter: 1056/3680
[A[ATraining Step: 7164  | total loss: [1m[32m0.37237[0m[0m
[2K| Adam | epoch: 063 | loss: 0.37237 - acc: 0.8518 -- iter: 1088/3680
[A[ATraining Step: 7165  | total loss: [1m[32m0.37011[0m[0m
[2K| Adam | epoch: 063 | loss: 0.37011 - acc: 0.8542 -- iter: 1120/3680
[A[ATraining Step: 7166  | total loss: [1m[32m0.37247[0m[0m
[2K| Adam | epoch: 063 | loss: 0.37247 - acc: 0.8500 -- iter: 1152/3680
[A[ATraining Step: 7167  | total loss: [1m[32m0.35719[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35719 - acc: 0.8587 -- iter: 1184/3680
[A[ATraining Step: 7168  | total loss: [1m[32m0.35172[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35172 - acc: 0.8572 -- iter: 1216/3680
[A[ATraining Step: 7169  | total loss: [1m[32m0.33915[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33915 - acc: 0.8653 -- iter: 1248/3680
[A[ATraining Step: 7170  | total loss: [1m[32m0.35540[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35540 - acc: 0.8631 -- iter: 1280/3680
[A[ATraining Step: 7171  | total loss: [1m[32m0.39896[0m[0m
[2K| Adam | epoch: 063 | loss: 0.39896 - acc: 0.8612 -- iter: 1312/3680
[A[ATraining Step: 7172  | total loss: [1m[32m0.39203[0m[0m
[2K| Adam | epoch: 063 | loss: 0.39203 - acc: 0.8594 -- iter: 1344/3680
[A[ATraining Step: 7173  | total loss: [1m[32m0.39512[0m[0m
[2K| Adam | epoch: 063 | loss: 0.39512 - acc: 0.8579 -- iter: 1376/3680
[A[ATraining Step: 7174  | total loss: [1m[32m0.37077[0m[0m
[2K| Adam | epoch: 063 | loss: 0.37077 - acc: 0.8690 -- iter: 1408/3680
[A[ATraining Step: 7175  | total loss: [1m[32m0.35957[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35957 - acc: 0.8696 -- iter: 1440/3680
[A[ATraining Step: 7176  | total loss: [1m[32m0.36324[0m[0m
[2K| Adam | epoch: 063 | loss: 0.36324 - acc: 0.8639 -- iter: 1472/3680
[A[ATraining Step: 7177  | total loss: [1m[32m0.35201[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35201 - acc: 0.8712 -- iter: 1504/3680
[A[ATraining Step: 7178  | total loss: [1m[32m0.33621[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33621 - acc: 0.8810 -- iter: 1536/3680
[A[ATraining Step: 7179  | total loss: [1m[32m0.33882[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33882 - acc: 0.8804 -- iter: 1568/3680
[A[ATraining Step: 7180  | total loss: [1m[32m0.33246[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33246 - acc: 0.8830 -- iter: 1600/3680
[A[ATraining Step: 7181  | total loss: [1m[32m0.34552[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34552 - acc: 0.8759 -- iter: 1632/3680
[A[ATraining Step: 7182  | total loss: [1m[32m0.33115[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33115 - acc: 0.8789 -- iter: 1664/3680
[A[ATraining Step: 7183  | total loss: [1m[32m0.32623[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32623 - acc: 0.8786 -- iter: 1696/3680
[A[ATraining Step: 7184  | total loss: [1m[32m0.31698[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31698 - acc: 0.8844 -- iter: 1728/3680
[A[ATraining Step: 7185  | total loss: [1m[32m0.32780[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32780 - acc: 0.8804 -- iter: 1760/3680
[A[ATraining Step: 7186  | total loss: [1m[32m0.33455[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33455 - acc: 0.8705 -- iter: 1792/3680
[A[ATraining Step: 7187  | total loss: [1m[32m0.33010[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33010 - acc: 0.8772 -- iter: 1824/3680
[A[ATraining Step: 7188  | total loss: [1m[32m0.32573[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32573 - acc: 0.8801 -- iter: 1856/3680
[A[ATraining Step: 7189  | total loss: [1m[32m0.32945[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32945 - acc: 0.8764 -- iter: 1888/3680
[A[ATraining Step: 7190  | total loss: [1m[32m0.32839[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32839 - acc: 0.8763 -- iter: 1920/3680
[A[ATraining Step: 7191  | total loss: [1m[32m0.35126[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35126 - acc: 0.8668 -- iter: 1952/3680
[A[ATraining Step: 7192  | total loss: [1m[32m0.34790[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34790 - acc: 0.8676 -- iter: 1984/3680
[A[ATraining Step: 7193  | total loss: [1m[32m0.35341[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35341 - acc: 0.8715 -- iter: 2016/3680
[A[ATraining Step: 7194  | total loss: [1m[32m0.35443[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35443 - acc: 0.8656 -- iter: 2048/3680
[A[ATraining Step: 7195  | total loss: [1m[32m0.34839[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34839 - acc: 0.8728 -- iter: 2080/3680
[A[ATraining Step: 7196  | total loss: [1m[32m0.34471[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34471 - acc: 0.8792 -- iter: 2112/3680
[A[ATraining Step: 7197  | total loss: [1m[32m0.33298[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33298 - acc: 0.8851 -- iter: 2144/3680
[A[ATraining Step: 7198  | total loss: [1m[32m0.33108[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33108 - acc: 0.8841 -- iter: 2176/3680
[A[ATraining Step: 7199  | total loss: [1m[32m0.35409[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35409 - acc: 0.8707 -- iter: 2208/3680
[A[ATraining Step: 7200  | total loss: [1m[32m0.34860[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34860 - acc: 0.8773 | val_loss: 0.30762 - val_acc: 0.8893 -- iter: 2240/3680
[A[ATraining Step: 7200  | total loss: [1m[32m0.34860[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34860 - acc: 0.8773 | val_loss: 0.30762 - val_acc: 0.8893 -- iter: 2240/3680
--
Training Step: 7201  | total loss: [1m[32m0.33596[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33596 - acc: 0.8834 -- iter: 2272/3680
[A[ATraining Step: 7202  | total loss: [1m[32m0.34240[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34240 - acc: 0.8794 -- iter: 2304/3680
[A[ATraining Step: 7203  | total loss: [1m[32m0.33351[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33351 - acc: 0.8790 -- iter: 2336/3680
[A[ATraining Step: 7204  | total loss: [1m[32m0.33917[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33917 - acc: 0.8723 -- iter: 2368/3680
[A[ATraining Step: 7205  | total loss: [1m[32m0.34567[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34567 - acc: 0.8632 -- iter: 2400/3680
[A[ATraining Step: 7206  | total loss: [1m[32m0.34439[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34439 - acc: 0.8550 -- iter: 2432/3680
[A[ATraining Step: 7207  | total loss: [1m[32m0.33693[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33693 - acc: 0.8601 -- iter: 2464/3680
[A[ATraining Step: 7208  | total loss: [1m[32m0.32583[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32583 - acc: 0.8710 -- iter: 2496/3680
[A[ATraining Step: 7209  | total loss: [1m[32m0.32100[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32100 - acc: 0.8714 -- iter: 2528/3680
[A[ATraining Step: 7210  | total loss: [1m[32m0.31268[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31268 - acc: 0.8780 -- iter: 2560/3680
[A[ATraining Step: 7211  | total loss: [1m[32m0.30784[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30784 - acc: 0.8777 -- iter: 2592/3680
[A[ATraining Step: 7212  | total loss: [1m[32m0.30416[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30416 - acc: 0.8806 -- iter: 2624/3680
[A[ATraining Step: 7213  | total loss: [1m[32m0.29484[0m[0m
[2K| Adam | epoch: 063 | loss: 0.29484 - acc: 0.8854 -- iter: 2656/3680
[A[ATraining Step: 7214  | total loss: [1m[32m0.29484[0m[0m
[2K| Adam | epoch: 063 | loss: 0.29484 - acc: 0.8854 -- iter: 2688/3680
[A[ATraining Step: 7215  | total loss: [1m[32m0.28942[0m[0m
[2K| Adam | epoch: 063 | loss: 0.28942 - acc: 0.8906 -- iter: 2720/3680
[A[ATraining Step: 7216  | total loss: [1m[32m0.29919[0m[0m
[2K| Adam | epoch: 063 | loss: 0.29919 - acc: 0.8828 -- iter: 2752/3680
[A[ATraining Step: 7217  | total loss: [1m[32m0.31568[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31568 - acc: 0.8633 -- iter: 2784/3680
[A[ATraining Step: 7218  | total loss: [1m[32m0.31628[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31628 - acc: 0.8582 -- iter: 2816/3680
[A[ATraining Step: 7219  | total loss: [1m[32m0.32972[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32972 - acc: 0.8536 -- iter: 2848/3680
[A[ATraining Step: 7220  | total loss: [1m[32m0.34995[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34995 - acc: 0.8464 -- iter: 2880/3680
[A[ATraining Step: 7221  | total loss: [1m[32m0.33843[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33843 - acc: 0.8524 -- iter: 2912/3680
[A[ATraining Step: 7222  | total loss: [1m[32m0.32838[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32838 - acc: 0.8547 -- iter: 2944/3680
[A[ATraining Step: 7223  | total loss: [1m[32m0.33153[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33153 - acc: 0.8567 -- iter: 2976/3680
[A[ATraining Step: 7224  | total loss: [1m[32m0.32006[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32006 - acc: 0.8539 -- iter: 3008/3680
[A[ATraining Step: 7225  | total loss: [1m[32m0.32290[0m[0m
[2K| Adam | epoch: 063 | loss: 0.32290 - acc: 0.8539 -- iter: 3040/3680
[A[ATraining Step: 7226  | total loss: [1m[32m0.30833[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30833 - acc: 0.8623 -- iter: 3072/3680
[A[ATraining Step: 7227  | total loss: [1m[32m0.29851[0m[0m
[2K| Adam | epoch: 063 | loss: 0.29851 - acc: 0.8667 -- iter: 3104/3680
[A[ATraining Step: 7228  | total loss: [1m[32m0.28870[0m[0m
[2K| Adam | epoch: 063 | loss: 0.28870 - acc: 0.8614 -- iter: 3136/3680
[A[ATraining Step: 7229  | total loss: [1m[32m0.30804[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30804 - acc: 0.8614 -- iter: 3168/3680
[A[ATraining Step: 7230  | total loss: [1m[32m0.31753[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31753 - acc: 0.8596 -- iter: 3200/3680
[A[ATraining Step: 7231  | total loss: [1m[32m0.30896[0m[0m
[2K| Adam | epoch: 063 | loss: 0.30896 - acc: 0.8674 -- iter: 3232/3680
[A[ATraining Step: 7232  | total loss: [1m[32m0.31534[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31534 - acc: 0.8650 -- iter: 3264/3680
[A[ATraining Step: 7233  | total loss: [1m[32m0.31975[0m[0m
[2K| Adam | epoch: 063 | loss: 0.31975 - acc: 0.8629 -- iter: 3296/3680
[A[ATraining Step: 7234  | total loss: [1m[32m0.36142[0m[0m
[2K| Adam | epoch: 063 | loss: 0.36142 - acc: 0.8485 -- iter: 3328/3680
[A[ATraining Step: 7235  | total loss: [1m[32m0.34045[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34045 - acc: 0.8636 -- iter: 3360/3680
[A[ATraining Step: 7236  | total loss: [1m[32m0.33587[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33587 - acc: 0.8658 -- iter: 3392/3680
[A[ATraining Step: 7237  | total loss: [1m[32m0.33587[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33587 - acc: 0.8658 -- iter: 3424/3680
[A[ATraining Step: 7238  | total loss: [1m[32m0.33708[0m[0m
[2K| Adam | epoch: 063 | loss: 0.33708 - acc: 0.8636 -- iter: 3456/3680
[A[ATraining Step: 7239  | total loss: [1m[32m0.34169[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34169 - acc: 0.8616 -- iter: 3488/3680
[A[ATraining Step: 7240  | total loss: [1m[32m0.35147[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35147 - acc: 0.8567 -- iter: 3520/3680
[A[ATraining Step: 7241  | total loss: [1m[32m0.34165[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34165 - acc: 0.8617 -- iter: 3552/3680
[A[ATraining Step: 7242  | total loss: [1m[32m0.34520[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34520 - acc: 0.8599 -- iter: 3584/3680
[A[ATraining Step: 7243  | total loss: [1m[32m0.34479[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34479 - acc: 0.8583 -- iter: 3616/3680
[A[ATraining Step: 7244  | total loss: [1m[32m0.34154[0m[0m
[2K| Adam | epoch: 063 | loss: 0.34154 - acc: 0.8599 -- iter: 3648/3680
[A[ATraining Step: 7245  | total loss: [1m[32m0.35147[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35147 - acc: 0.8521 | val_loss: 0.30250 - val_acc: 0.8871 -- iter: 3680/3680
[A[ATraining Step: 7245  | total loss: [1m[32m0.35147[0m[0m
[2K| Adam | epoch: 063 | loss: 0.35147 - acc: 0.8521 | val_loss: 0.30250 - val_acc: 0.8871 -- iter: 3680/3680
--
Training Step: 7246  | total loss: [1m[32m0.36336[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36336 - acc: 0.8450 -- iter: 0032/3680
[A[ATraining Step: 7247  | total loss: [1m[32m0.35778[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35778 - acc: 0.8480 -- iter: 0064/3680
[A[ATraining Step: 7248  | total loss: [1m[32m0.36389[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36389 - acc: 0.8444 -- iter: 0096/3680
[A[ATraining Step: 7249  | total loss: [1m[32m0.37306[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37306 - acc: 0.8412 -- iter: 0128/3680
[A[ATraining Step: 7250  | total loss: [1m[32m0.38393[0m[0m
[2K| Adam | epoch: 064 | loss: 0.38393 - acc: 0.8352 -- iter: 0160/3680
[A[ATraining Step: 7251  | total loss: [1m[32m0.37689[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37689 - acc: 0.8423 -- iter: 0192/3680
[A[ATraining Step: 7252  | total loss: [1m[32m0.36428[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36428 - acc: 0.8487 -- iter: 0224/3680
[A[ATraining Step: 7253  | total loss: [1m[32m0.36078[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36078 - acc: 0.8482 -- iter: 0256/3680
[A[ATraining Step: 7254  | total loss: [1m[32m0.35659[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35659 - acc: 0.8509 -- iter: 0288/3680
[A[ATraining Step: 7255  | total loss: [1m[32m0.35206[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35206 - acc: 0.8533 -- iter: 0320/3680
[A[ATraining Step: 7256  | total loss: [1m[32m0.36646[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36646 - acc: 0.8524 -- iter: 0352/3680
[A[ATraining Step: 7257  | total loss: [1m[32m0.35876[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35876 - acc: 0.8546 -- iter: 0384/3680
[A[ATraining Step: 7258  | total loss: [1m[32m0.35458[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35458 - acc: 0.8567 -- iter: 0416/3680
[A[ATraining Step: 7259  | total loss: [1m[32m0.38041[0m[0m
[2K| Adam | epoch: 064 | loss: 0.38041 - acc: 0.8429 -- iter: 0448/3680
[A[ATraining Step: 7260  | total loss: [1m[32m0.38924[0m[0m
[2K| Adam | epoch: 064 | loss: 0.38924 - acc: 0.8367 -- iter: 0480/3680
[A[ATraining Step: 7261  | total loss: [1m[32m0.37813[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37813 - acc: 0.8380 -- iter: 0512/3680
[A[ATraining Step: 7262  | total loss: [1m[32m0.37813[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37813 - acc: 0.8380 -- iter: 0544/3680
[A[ATraining Step: 7263  | total loss: [1m[32m0.36600[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36600 - acc: 0.8449 -- iter: 0576/3680
[A[ATraining Step: 7264  | total loss: [1m[32m0.36626[0m[0m
[2K| Adam | epoch: 064 | loss: 0.36626 - acc: 0.8416 -- iter: 0608/3680
[A[ATraining Step: 7265  | total loss: [1m[32m0.34938[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34938 - acc: 0.8512 -- iter: 0640/3680
[A[ATraining Step: 7266  | total loss: [1m[32m0.34394[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34394 - acc: 0.8598 -- iter: 0672/3680
[A[ATraining Step: 7267  | total loss: [1m[32m0.35288[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35288 - acc: 0.8582 -- iter: 0704/3680
[A[ATraining Step: 7268  | total loss: [1m[32m0.33854[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33854 - acc: 0.8705 -- iter: 0736/3680
[A[ATraining Step: 7269  | total loss: [1m[32m0.32746[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32746 - acc: 0.8705 -- iter: 0768/3680
[A[ATraining Step: 7270  | total loss: [1m[32m0.32559[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32559 - acc: 0.8741 -- iter: 0800/3680
[A[ATraining Step: 7271  | total loss: [1m[32m0.31778[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31778 - acc: 0.8773 -- iter: 0832/3680
[A[ATraining Step: 7272  | total loss: [1m[32m0.31274[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31274 - acc: 0.8802 -- iter: 0864/3680
[A[ATraining Step: 7273  | total loss: [1m[32m0.31379[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31379 - acc: 0.8765 -- iter: 0896/3680
[A[ATraining Step: 7274  | total loss: [1m[32m0.32126[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32126 - acc: 0.8764 -- iter: 0928/3680
[A[ATraining Step: 7275  | total loss: [1m[32m0.32817[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32817 - acc: 0.8669 -- iter: 0960/3680
[A[ATraining Step: 7276  | total loss: [1m[32m0.32129[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32129 - acc: 0.8708 -- iter: 0992/3680
[A[ATraining Step: 7277  | total loss: [1m[32m0.31619[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31619 - acc: 0.8744 -- iter: 1024/3680
[A[ATraining Step: 7278  | total loss: [1m[32m0.32709[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32709 - acc: 0.8650 -- iter: 1056/3680
[A[ATraining Step: 7279  | total loss: [1m[32m0.31181[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31181 - acc: 0.8754 -- iter: 1088/3680
[A[ATraining Step: 7280  | total loss: [1m[32m0.31727[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31727 - acc: 0.8785 -- iter: 1120/3680
[A[ATraining Step: 7281  | total loss: [1m[32m0.31778[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31778 - acc: 0.8781 -- iter: 1152/3680
[A[ATraining Step: 7282  | total loss: [1m[32m0.34038[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34038 - acc: 0.8747 -- iter: 1184/3680
[A[ATraining Step: 7283  | total loss: [1m[32m0.37116[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37116 - acc: 0.8560 -- iter: 1216/3680
[A[ATraining Step: 7284  | total loss: [1m[32m0.35712[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35712 - acc: 0.8641 -- iter: 1248/3680
[A[ATraining Step: 7285  | total loss: [1m[32m0.35233[0m[0m
[2K| Adam | epoch: 064 | loss: 0.35233 - acc: 0.8683 -- iter: 1280/3680
[A[ATraining Step: 7286  | total loss: [1m[32m0.34423[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34423 - acc: 0.8690 -- iter: 1312/3680
[A[ATraining Step: 7287  | total loss: [1m[32m0.33490[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33490 - acc: 0.8696 -- iter: 1344/3680
[A[ATraining Step: 7288  | total loss: [1m[32m0.32432[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32432 - acc: 0.8764 -- iter: 1376/3680
[A[ATraining Step: 7289  | total loss: [1m[32m0.31952[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31952 - acc: 0.8821 -- iter: 1408/3680
[A[ATraining Step: 7290  | total loss: [1m[32m0.31770[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31770 - acc: 0.8821 -- iter: 1440/3680
[A[ATraining Step: 7291  | total loss: [1m[32m0.32932[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32932 - acc: 0.8845 -- iter: 1472/3680
[A[ATraining Step: 7292  | total loss: [1m[32m0.32433[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32433 - acc: 0.8867 -- iter: 1504/3680
[A[ATraining Step: 7293  | total loss: [1m[32m0.32334[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32334 - acc: 0.8824 -- iter: 1536/3680
[A[ATraining Step: 7294  | total loss: [1m[32m0.32975[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32975 - acc: 0.8816 -- iter: 1568/3680
[A[ATraining Step: 7295  | total loss: [1m[32m0.32256[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32256 - acc: 0.8841 -- iter: 1600/3680
[A[ATraining Step: 7296  | total loss: [1m[32m0.32998[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32998 - acc: 0.8769 -- iter: 1632/3680
[A[ATraining Step: 7297  | total loss: [1m[32m0.33108[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33108 - acc: 0.8767 -- iter: 1664/3680
[A[ATraining Step: 7298  | total loss: [1m[32m0.32656[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32656 - acc: 0.8828 -- iter: 1696/3680
[A[ATraining Step: 7299  | total loss: [1m[32m0.32221[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32221 - acc: 0.8852 -- iter: 1728/3680
[A[ATraining Step: 7300  | total loss: [1m[32m0.30759[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30759 - acc: 0.8917 | val_loss: 0.29187 - val_acc: 0.8893 -- iter: 1760/3680
[A[ATraining Step: 7300  | total loss: [1m[32m0.30759[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30759 - acc: 0.8917 | val_loss: 0.29187 - val_acc: 0.8893 -- iter: 1760/3680
--
Training Step: 7301  | total loss: [1m[32m0.30870[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30870 - acc: 0.8917 -- iter: 1792/3680
[A[ATraining Step: 7302  | total loss: [1m[32m0.31478[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31478 - acc: 0.8869 -- iter: 1824/3680
[A[ATraining Step: 7303  | total loss: [1m[32m0.31207[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31207 - acc: 0.8888 -- iter: 1856/3680
[A[ATraining Step: 7304  | total loss: [1m[32m0.31051[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31051 - acc: 0.8843 -- iter: 1888/3680
[A[ATraining Step: 7305  | total loss: [1m[32m0.30697[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30697 - acc: 0.8865 -- iter: 1920/3680
[A[ATraining Step: 7306  | total loss: [1m[32m0.30375[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30375 - acc: 0.8916 -- iter: 1952/3680
[A[ATraining Step: 7307  | total loss: [1m[32m0.29711[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29711 - acc: 0.8931 -- iter: 1984/3680
[A[ATraining Step: 7308  | total loss: [1m[32m0.29953[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29953 - acc: 0.8944 -- iter: 2016/3680
[A[ATraining Step: 7309  | total loss: [1m[32m0.29441[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29441 - acc: 0.8956 -- iter: 2048/3680
[A[ATraining Step: 7310  | total loss: [1m[32m0.29806[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29806 - acc: 0.8904 -- iter: 2080/3680
[A[ATraining Step: 7311  | total loss: [1m[32m0.29168[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29168 - acc: 0.8903 -- iter: 2112/3680
[A[ATraining Step: 7312  | total loss: [1m[32m0.30418[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30418 - acc: 0.8903 -- iter: 2144/3680
[A[ATraining Step: 7313  | total loss: [1m[32m0.29747[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29747 - acc: 0.8950 -- iter: 2176/3680
[A[ATraining Step: 7314  | total loss: [1m[32m0.30702[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30702 - acc: 0.8836 -- iter: 2208/3680
[A[ATraining Step: 7315  | total loss: [1m[32m0.29780[0m[0m
[2K| Adam | epoch: 064 | loss: 0.29780 - acc: 0.8859 -- iter: 2240/3680
[A[ATraining Step: 7316  | total loss: [1m[32m0.30974[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30974 - acc: 0.8785 -- iter: 2272/3680
[A[ATraining Step: 7317  | total loss: [1m[32m0.32256[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32256 - acc: 0.8719 -- iter: 2304/3680
[A[ATraining Step: 7318  | total loss: [1m[32m0.32388[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32388 - acc: 0.8722 -- iter: 2336/3680
[A[ATraining Step: 7319  | total loss: [1m[32m0.31437[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31437 - acc: 0.8788 -- iter: 2368/3680
[A[ATraining Step: 7320  | total loss: [1m[32m0.30594[0m[0m
[2K| Adam | epoch: 064 | loss: 0.30594 - acc: 0.8878 -- iter: 2400/3680
[A[ATraining Step: 7321  | total loss: [1m[32m0.31062[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31062 - acc: 0.8834 -- iter: 2432/3680
[A[ATraining Step: 7322  | total loss: [1m[32m0.31491[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31491 - acc: 0.8825 -- iter: 2464/3680
[A[ATraining Step: 7323  | total loss: [1m[32m0.32758[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32758 - acc: 0.8755 -- iter: 2496/3680
[A[ATraining Step: 7324  | total loss: [1m[32m0.31054[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31054 - acc: 0.8817 -- iter: 2528/3680
[A[ATraining Step: 7325  | total loss: [1m[32m0.31054[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31054 - acc: 0.8817 -- iter: 2560/3680
[A[ATraining Step: 7326  | total loss: [1m[32m0.31612[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31612 - acc: 0.8810 -- iter: 2592/3680
[A[ATraining Step: 7327  | total loss: [1m[32m0.33035[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33035 - acc: 0.8742 -- iter: 2624/3680
[A[ATraining Step: 7328  | total loss: [1m[32m0.34173[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34173 - acc: 0.8680 -- iter: 2656/3680
[A[ATraining Step: 7329  | total loss: [1m[32m0.33475[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33475 - acc: 0.8718 -- iter: 2688/3680
[A[ATraining Step: 7330  | total loss: [1m[32m0.33238[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33238 - acc: 0.8690 -- iter: 2720/3680
[A[ATraining Step: 7331  | total loss: [1m[32m0.33585[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33585 - acc: 0.8634 -- iter: 2752/3680
[A[ATraining Step: 7332  | total loss: [1m[32m0.32266[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32266 - acc: 0.8708 -- iter: 2784/3680
[A[ATraining Step: 7333  | total loss: [1m[32m0.31216[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31216 - acc: 0.8774 -- iter: 2816/3680
[A[ATraining Step: 7334  | total loss: [1m[32m0.32578[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32578 - acc: 0.8678 -- iter: 2848/3680
[A[ATraining Step: 7335  | total loss: [1m[32m0.33463[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33463 - acc: 0.8623 -- iter: 2880/3680
[A[ATraining Step: 7336  | total loss: [1m[32m0.33404[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33404 - acc: 0.8604 -- iter: 2912/3680
[A[ATraining Step: 7337  | total loss: [1m[32m0.32527[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32527 - acc: 0.8650 -- iter: 2944/3680
[A[ATraining Step: 7338  | total loss: [1m[32m0.32474[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32474 - acc: 0.8598 -- iter: 2976/3680
[A[ATraining Step: 7339  | total loss: [1m[32m0.32610[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32610 - acc: 0.8550 -- iter: 3008/3680
[A[ATraining Step: 7340  | total loss: [1m[32m0.34140[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34140 - acc: 0.8539 -- iter: 3040/3680
[A[ATraining Step: 7341  | total loss: [1m[32m0.33041[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33041 - acc: 0.8591 -- iter: 3072/3680
[A[ATraining Step: 7342  | total loss: [1m[32m0.32403[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32403 - acc: 0.8670 -- iter: 3104/3680
[A[ATraining Step: 7343  | total loss: [1m[32m0.31224[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31224 - acc: 0.8709 -- iter: 3136/3680
[A[ATraining Step: 7344  | total loss: [1m[32m0.31663[0m[0m
[2K| Adam | epoch: 064 | loss: 0.31663 - acc: 0.8651 -- iter: 3168/3680
[A[ATraining Step: 7345  | total loss: [1m[32m0.33031[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33031 - acc: 0.8598 -- iter: 3200/3680
[A[ATraining Step: 7346  | total loss: [1m[32m0.32704[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32704 - acc: 0.8645 -- iter: 3232/3680
[A[ATraining Step: 7347  | total loss: [1m[32m0.34091[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34091 - acc: 0.8593 -- iter: 3264/3680
[A[ATraining Step: 7348  | total loss: [1m[32m0.34142[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34142 - acc: 0.8608 -- iter: 3296/3680
[A[ATraining Step: 7349  | total loss: [1m[32m0.32815[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32815 - acc: 0.8623 -- iter: 3328/3680
[A[ATraining Step: 7350  | total loss: [1m[32m0.32169[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32169 - acc: 0.8698 -- iter: 3360/3680
[A[ATraining Step: 7351  | total loss: [1m[32m0.33409[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33409 - acc: 0.8640 -- iter: 3392/3680
[A[ATraining Step: 7352  | total loss: [1m[32m0.32990[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32990 - acc: 0.8651 -- iter: 3424/3680
[A[ATraining Step: 7353  | total loss: [1m[32m0.32951[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32951 - acc: 0.8630 -- iter: 3456/3680
[A[ATraining Step: 7354  | total loss: [1m[32m0.32833[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32833 - acc: 0.8656 -- iter: 3488/3680
[A[ATraining Step: 7355  | total loss: [1m[32m0.32833[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32833 - acc: 0.8656 -- iter: 3520/3680
[A[ATraining Step: 7356  | total loss: [1m[32m0.32847[0m[0m
[2K| Adam | epoch: 064 | loss: 0.32847 - acc: 0.8634 -- iter: 3552/3680
[A[ATraining Step: 7357  | total loss: [1m[32m0.33438[0m[0m
[2K| Adam | epoch: 064 | loss: 0.33438 - acc: 0.8614 -- iter: 3584/3680
[A[ATraining Step: 7358  | total loss: [1m[32m0.34188[0m[0m
[2K| Adam | epoch: 064 | loss: 0.34188 - acc: 0.8597 -- iter: 3616/3680
[A[ATraining Step: 7359  | total loss: [1m[32m0.37393[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37393 - acc: 0.8550 -- iter: 3648/3680
[A[ATraining Step: 7360  | total loss: [1m[32m0.37765[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37765 - acc: 0.8538 | val_loss: 0.32609 - val_acc: 0.8751 -- iter: 3680/3680
[A[ATraining Step: 7360  | total loss: [1m[32m0.37765[0m[0m
[2K| Adam | epoch: 064 | loss: 0.37765 - acc: 0.8538 | val_loss: 0.32609 - val_acc: 0.8751 -- iter: 3680/3680
--
Training Step: 7361  | total loss: [1m[32m0.38135[0m[0m
[2K| Adam | epoch: 065 | loss: 0.38135 - acc: 0.8435 -- iter: 0032/3680
[A[ATraining Step: 7362  | total loss: [1m[32m0.36609[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36609 - acc: 0.8497 -- iter: 0064/3680
[A[ATraining Step: 7363  | total loss: [1m[32m0.35961[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35961 - acc: 0.8460 -- iter: 0096/3680
[A[ATraining Step: 7364  | total loss: [1m[32m0.35503[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35503 - acc: 0.8520 -- iter: 0128/3680
[A[ATraining Step: 7365  | total loss: [1m[32m0.35896[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35896 - acc: 0.8512 -- iter: 0160/3680
[A[ATraining Step: 7366  | total loss: [1m[32m0.37989[0m[0m
[2K| Adam | epoch: 065 | loss: 0.37989 - acc: 0.8411 -- iter: 0192/3680
[A[ATraining Step: 7367  | total loss: [1m[32m0.38082[0m[0m
[2K| Adam | epoch: 065 | loss: 0.38082 - acc: 0.8414 -- iter: 0224/3680
[A[ATraining Step: 7368  | total loss: [1m[32m0.37931[0m[0m
[2K| Adam | epoch: 065 | loss: 0.37931 - acc: 0.8447 -- iter: 0256/3680
[A[ATraining Step: 7369  | total loss: [1m[32m0.36990[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36990 - acc: 0.8509 -- iter: 0288/3680
[A[ATraining Step: 7370  | total loss: [1m[32m0.35245[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35245 - acc: 0.8564 -- iter: 0320/3680
[A[ATraining Step: 7371  | total loss: [1m[32m0.33893[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33893 - acc: 0.8645 -- iter: 0352/3680
[A[ATraining Step: 7372  | total loss: [1m[32m0.35539[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35539 - acc: 0.8624 -- iter: 0384/3680
[A[ATraining Step: 7373  | total loss: [1m[32m0.35915[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35915 - acc: 0.8606 -- iter: 0416/3680
[A[ATraining Step: 7374  | total loss: [1m[32m0.34366[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34366 - acc: 0.8683 -- iter: 0448/3680
[A[ATraining Step: 7375  | total loss: [1m[32m0.33208[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33208 - acc: 0.8721 -- iter: 0480/3680
[A[ATraining Step: 7376  | total loss: [1m[32m0.33200[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33200 - acc: 0.8755 -- iter: 0512/3680
[A[ATraining Step: 7377  | total loss: [1m[32m0.35054[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35054 - acc: 0.8723 -- iter: 0544/3680
[A[ATraining Step: 7378  | total loss: [1m[32m0.34686[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34686 - acc: 0.8757 -- iter: 0576/3680
[A[ATraining Step: 7379  | total loss: [1m[32m0.34639[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34639 - acc: 0.8788 -- iter: 0608/3680
[A[ATraining Step: 7380  | total loss: [1m[32m0.35029[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35029 - acc: 0.8753 -- iter: 0640/3680
[A[ATraining Step: 7381  | total loss: [1m[32m0.34292[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34292 - acc: 0.8752 -- iter: 0672/3680
[A[ATraining Step: 7382  | total loss: [1m[32m0.34276[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34276 - acc: 0.8811 -- iter: 0704/3680
[A[ATraining Step: 7383  | total loss: [1m[32m0.32925[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32925 - acc: 0.8811 -- iter: 0736/3680
[A[ATraining Step: 7384  | total loss: [1m[32m0.32430[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32430 - acc: 0.8836 -- iter: 0768/3680
[A[ATraining Step: 7385  | total loss: [1m[32m0.32652[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32652 - acc: 0.8828 -- iter: 0800/3680
[A[ATraining Step: 7386  | total loss: [1m[32m0.30511[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30511 - acc: 0.8945 -- iter: 0832/3680
[A[ATraining Step: 7387  | total loss: [1m[32m0.30707[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30707 - acc: 0.8925 -- iter: 0864/3680
[A[ATraining Step: 7388  | total loss: [1m[32m0.30874[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30874 - acc: 0.8877 -- iter: 0896/3680
[A[ATraining Step: 7389  | total loss: [1m[32m0.30590[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30590 - acc: 0.8895 -- iter: 0928/3680
[A[ATraining Step: 7390  | total loss: [1m[32m0.30798[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30798 - acc: 0.8849 -- iter: 0960/3680
[A[ATraining Step: 7391  | total loss: [1m[32m0.30984[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30984 - acc: 0.8840 -- iter: 0992/3680
[A[ATraining Step: 7392  | total loss: [1m[32m0.41940[0m[0m
[2K| Adam | epoch: 065 | loss: 0.41940 - acc: 0.8541 -- iter: 1024/3680
[A[ATraining Step: 7393  | total loss: [1m[32m0.40249[0m[0m
[2K| Adam | epoch: 065 | loss: 0.40249 - acc: 0.8541 -- iter: 1056/3680
[A[ATraining Step: 7394  | total loss: [1m[32m0.38583[0m[0m
[2K| Adam | epoch: 065 | loss: 0.38583 - acc: 0.8593 -- iter: 1088/3680
[A[ATraining Step: 7395  | total loss: [1m[32m0.39072[0m[0m
[2K| Adam | epoch: 065 | loss: 0.39072 - acc: 0.8578 -- iter: 1120/3680
[A[ATraining Step: 7396  | total loss: [1m[32m0.37913[0m[0m
[2K| Adam | epoch: 065 | loss: 0.37913 - acc: 0.8564 -- iter: 1152/3680
[A[ATraining Step: 7397  | total loss: [1m[32m0.36855[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36855 - acc: 0.8582 -- iter: 1184/3680
[A[ATraining Step: 7398  | total loss: [1m[32m0.36916[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36916 - acc: 0.8505 -- iter: 1216/3680
[A[ATraining Step: 7399  | total loss: [1m[32m0.36499[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36499 - acc: 0.8530 -- iter: 1248/3680
[A[ATraining Step: 7400  | total loss: [1m[32m0.36284[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36284 - acc: 0.8489 | val_loss: 0.34164 - val_acc: 0.8708 -- iter: 1280/3680
[A[ATraining Step: 7400  | total loss: [1m[32m0.36284[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36284 - acc: 0.8489 | val_loss: 0.34164 - val_acc: 0.8708 -- iter: 1280/3680
--
Training Step: 7401  | total loss: [1m[32m0.36253[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36253 - acc: 0.8484 -- iter: 1312/3680
[A[ATraining Step: 7402  | total loss: [1m[32m0.34579[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34579 - acc: 0.8542 -- iter: 1344/3680
[A[ATraining Step: 7403  | total loss: [1m[32m0.33363[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33363 - acc: 0.8594 -- iter: 1376/3680
[A[ATraining Step: 7404  | total loss: [1m[32m0.32074[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32074 - acc: 0.8641 -- iter: 1408/3680
[A[ATraining Step: 7405  | total loss: [1m[32m0.30757[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30757 - acc: 0.8714 -- iter: 1440/3680
[A[ATraining Step: 7406  | total loss: [1m[32m0.30437[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30437 - acc: 0.8749 -- iter: 1472/3680
[A[ATraining Step: 7407  | total loss: [1m[32m0.29793[0m[0m
[2K| Adam | epoch: 065 | loss: 0.29793 - acc: 0.8780 -- iter: 1504/3680
[A[ATraining Step: 7408  | total loss: [1m[32m0.31351[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31351 - acc: 0.8715 -- iter: 1536/3680
[A[ATraining Step: 7409  | total loss: [1m[32m0.31572[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31572 - acc: 0.8656 -- iter: 1568/3680
[A[ATraining Step: 7410  | total loss: [1m[32m0.31293[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31293 - acc: 0.8572 -- iter: 1600/3680
[A[ATraining Step: 7411  | total loss: [1m[32m0.30608[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30608 - acc: 0.8589 -- iter: 1632/3680
[A[ATraining Step: 7412  | total loss: [1m[32m0.30504[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30504 - acc: 0.8605 -- iter: 1664/3680
[A[ATraining Step: 7413  | total loss: [1m[32m0.32100[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32100 - acc: 0.8630 -- iter: 1696/3680
[A[ATraining Step: 7414  | total loss: [1m[32m0.32100[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32100 - acc: 0.8630 -- iter: 1728/3680
[A[ATraining Step: 7415  | total loss: [1m[32m0.31742[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31742 - acc: 0.8642 -- iter: 1760/3680
[A[ATraining Step: 7416  | total loss: [1m[32m0.32802[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32802 - acc: 0.8590 -- iter: 1792/3680
[A[ATraining Step: 7417  | total loss: [1m[32m0.32336[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32336 - acc: 0.8742 -- iter: 1824/3680
[A[ATraining Step: 7418  | total loss: [1m[32m0.31169[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31169 - acc: 0.8742 -- iter: 1856/3680
[A[ATraining Step: 7419  | total loss: [1m[32m0.30782[0m[0m
[2K| Adam | epoch: 065 | loss: 0.30782 - acc: 0.8743 -- iter: 1888/3680
[A[ATraining Step: 7420  | total loss: [1m[32m0.32742[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32742 - acc: 0.8619 -- iter: 1920/3680
[A[ATraining Step: 7421  | total loss: [1m[32m0.33192[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33192 - acc: 0.8569 -- iter: 1952/3680
[A[ATraining Step: 7422  | total loss: [1m[32m0.31919[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31919 - acc: 0.8619 -- iter: 1984/3680
[A[ATraining Step: 7423  | total loss: [1m[32m0.32003[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32003 - acc: 0.8694 -- iter: 2016/3680
[A[ATraining Step: 7424  | total loss: [1m[32m0.31751[0m[0m
[2K| Adam | epoch: 065 | loss: 0.31751 - acc: 0.8731 -- iter: 2048/3680
[A[ATraining Step: 7425  | total loss: [1m[32m0.32258[0m[0m
[2K| Adam | epoch: 065 | loss: 0.32258 - acc: 0.8733 -- iter: 2080/3680
[A[ATraining Step: 7426  | total loss: [1m[32m0.33839[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33839 - acc: 0.8579 -- iter: 2112/3680
[A[ATraining Step: 7427  | total loss: [1m[32m0.33530[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33530 - acc: 0.8658 -- iter: 2144/3680
[A[ATraining Step: 7428  | total loss: [1m[32m0.34468[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34468 - acc: 0.8574 -- iter: 2176/3680
[A[ATraining Step: 7429  | total loss: [1m[32m0.34523[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34523 - acc: 0.8560 -- iter: 2208/3680
[A[ATraining Step: 7430  | total loss: [1m[32m0.34774[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34774 - acc: 0.8548 -- iter: 2240/3680
[A[ATraining Step: 7431  | total loss: [1m[32m0.35284[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35284 - acc: 0.8505 -- iter: 2272/3680
[A[ATraining Step: 7432  | total loss: [1m[32m0.36414[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36414 - acc: 0.8467 -- iter: 2304/3680
[A[ATraining Step: 7433  | total loss: [1m[32m0.36413[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36413 - acc: 0.8433 -- iter: 2336/3680
[A[ATraining Step: 7434  | total loss: [1m[32m0.36189[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36189 - acc: 0.8402 -- iter: 2368/3680
[A[ATraining Step: 7435  | total loss: [1m[32m0.35564[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35564 - acc: 0.8437 -- iter: 2400/3680
[A[ATraining Step: 7436  | total loss: [1m[32m0.34728[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34728 - acc: 0.8437 -- iter: 2432/3680
[A[ATraining Step: 7437  | total loss: [1m[32m0.34987[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34987 - acc: 0.8375 -- iter: 2464/3680
[A[ATraining Step: 7438  | total loss: [1m[32m0.35091[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35091 - acc: 0.8412 -- iter: 2496/3680
[A[ATraining Step: 7439  | total loss: [1m[32m0.34264[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34264 - acc: 0.8446 -- iter: 2528/3680
[A[ATraining Step: 7440  | total loss: [1m[32m0.34090[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34090 - acc: 0.8383 -- iter: 2560/3680
[A[ATraining Step: 7441  | total loss: [1m[32m0.34494[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34494 - acc: 0.8388 -- iter: 2592/3680
[A[ATraining Step: 7442  | total loss: [1m[32m0.34766[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34766 - acc: 0.8393 -- iter: 2624/3680
[A[ATraining Step: 7443  | total loss: [1m[32m0.34850[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34850 - acc: 0.8460 -- iter: 2656/3680
[A[ATraining Step: 7444  | total loss: [1m[32m0.33408[0m[0m
[2K| Adam | epoch: 065 | loss: 0.33408 - acc: 0.8552 -- iter: 2688/3680
[A[ATraining Step: 7445  | total loss: [1m[32m0.34082[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34082 - acc: 0.8478 -- iter: 2720/3680
[A[ATraining Step: 7446  | total loss: [1m[32m0.35253[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35253 - acc: 0.8536 -- iter: 2752/3680
[A[ATraining Step: 7447  | total loss: [1m[32m0.35520[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35520 - acc: 0.8495 -- iter: 2784/3680
[A[ATraining Step: 7448  | total loss: [1m[32m0.35383[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35383 - acc: 0.8520 -- iter: 2816/3680
[A[ATraining Step: 7449  | total loss: [1m[32m0.36777[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36777 - acc: 0.8450 -- iter: 2848/3680
[A[ATraining Step: 7450  | total loss: [1m[32m0.38258[0m[0m
[2K| Adam | epoch: 065 | loss: 0.38258 - acc: 0.8417 -- iter: 2880/3680
[A[ATraining Step: 7451  | total loss: [1m[32m0.36744[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36744 - acc: 0.8544 -- iter: 2912/3680
[A[ATraining Step: 7452  | total loss: [1m[32m0.43690[0m[0m
[2K| Adam | epoch: 065 | loss: 0.43690 - acc: 0.8502 -- iter: 2944/3680
[A[ATraining Step: 7453  | total loss: [1m[32m0.42997[0m[0m
[2K| Adam | epoch: 065 | loss: 0.42997 - acc: 0.8558 -- iter: 2976/3680
[A[ATraining Step: 7454  | total loss: [1m[32m0.41099[0m[0m
[2K| Adam | epoch: 065 | loss: 0.41099 - acc: 0.8640 -- iter: 3008/3680
[A[ATraining Step: 7455  | total loss: [1m[32m0.39840[0m[0m
[2K| Adam | epoch: 065 | loss: 0.39840 - acc: 0.8557 -- iter: 3040/3680
[A[ATraining Step: 7456  | total loss: [1m[32m0.41058[0m[0m
[2K| Adam | epoch: 065 | loss: 0.41058 - acc: 0.8452 -- iter: 3072/3680
[A[ATraining Step: 7457  | total loss: [1m[32m0.41046[0m[0m
[2K| Adam | epoch: 065 | loss: 0.41046 - acc: 0.8481 -- iter: 3104/3680
[A[ATraining Step: 7458  | total loss: [1m[32m0.39580[0m[0m
[2K| Adam | epoch: 065 | loss: 0.39580 - acc: 0.8508 -- iter: 3136/3680
[A[ATraining Step: 7459  | total loss: [1m[32m0.39047[0m[0m
[2K| Adam | epoch: 065 | loss: 0.39047 - acc: 0.8532 -- iter: 3168/3680
[A[ATraining Step: 7460  | total loss: [1m[32m0.40041[0m[0m
[2K| Adam | epoch: 065 | loss: 0.40041 - acc: 0.8460 -- iter: 3200/3680
[A[ATraining Step: 7461  | total loss: [1m[32m0.39135[0m[0m
[2K| Adam | epoch: 065 | loss: 0.39135 - acc: 0.8489 -- iter: 3232/3680
[A[ATraining Step: 7462  | total loss: [1m[32m0.40814[0m[0m
[2K| Adam | epoch: 065 | loss: 0.40814 - acc: 0.8328 -- iter: 3264/3680
[A[ATraining Step: 7463  | total loss: [1m[32m0.39292[0m[0m
[2K| Adam | epoch: 065 | loss: 0.39292 - acc: 0.8370 -- iter: 3296/3680
[A[ATraining Step: 7464  | total loss: [1m[32m0.37518[0m[0m
[2K| Adam | epoch: 065 | loss: 0.37518 - acc: 0.8439 -- iter: 3328/3680
[A[ATraining Step: 7465  | total loss: [1m[32m0.37015[0m[0m
[2K| Adam | epoch: 065 | loss: 0.37015 - acc: 0.8439 -- iter: 3360/3680
[A[ATraining Step: 7466  | total loss: [1m[32m0.35514[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35514 - acc: 0.8533 -- iter: 3392/3680
[A[ATraining Step: 7467  | total loss: [1m[32m0.36418[0m[0m
[2K| Adam | epoch: 065 | loss: 0.36418 - acc: 0.8492 -- iter: 3424/3680
[A[ATraining Step: 7468  | total loss: [1m[32m0.37142[0m[0m
[2K| Adam | epoch: 065 | loss: 0.37142 - acc: 0.8518 -- iter: 3456/3680
[A[ATraining Step: 7469  | total loss: [1m[32m0.35648[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35648 - acc: 0.8604 -- iter: 3488/3680
[A[ATraining Step: 7470  | total loss: [1m[32m0.35168[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35168 - acc: 0.8649 -- iter: 3520/3680
[A[ATraining Step: 7471  | total loss: [1m[32m0.35915[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35915 - acc: 0.8628 -- iter: 3552/3680
[A[ATraining Step: 7472  | total loss: [1m[32m0.35559[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35559 - acc: 0.8640 -- iter: 3584/3680
[A[ATraining Step: 7473  | total loss: [1m[32m0.35749[0m[0m
[2K| Adam | epoch: 065 | loss: 0.35749 - acc: 0.8683 -- iter: 3616/3680
[A[ATraining Step: 7474  | total loss: [1m[32m0.34774[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34774 - acc: 0.8721 -- iter: 3648/3680
[A[ATraining Step: 7475  | total loss: [1m[32m0.34757[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34757 - acc: 0.8755 | val_loss: 0.33887 - val_acc: 0.8664 -- iter: 3680/3680
[A[ATraining Step: 7475  | total loss: [1m[32m0.34757[0m[0m
[2K| Adam | epoch: 065 | loss: 0.34757 - acc: 0.8755 | val_loss: 0.33887 - val_acc: 0.8664 -- iter: 3680/3680
--
Training Step: 7476  | total loss: [1m[32m0.33556[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33556 - acc: 0.8817 -- iter: 0032/3680
[A[ATraining Step: 7477  | total loss: [1m[32m0.31631[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31631 - acc: 0.8904 -- iter: 0064/3680
[A[ATraining Step: 7478  | total loss: [1m[32m0.31817[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31817 - acc: 0.8888 -- iter: 0096/3680
[A[ATraining Step: 7479  | total loss: [1m[32m0.32253[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32253 - acc: 0.8875 -- iter: 0128/3680
[A[ATraining Step: 7480  | total loss: [1m[32m0.31872[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31872 - acc: 0.8862 -- iter: 0160/3680
[A[ATraining Step: 7481  | total loss: [1m[32m0.32978[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32978 - acc: 0.8788 -- iter: 0192/3680
[A[ATraining Step: 7482  | total loss: [1m[32m0.33419[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33419 - acc: 0.8753 -- iter: 0224/3680
[A[ATraining Step: 7483  | total loss: [1m[32m0.32821[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32821 - acc: 0.8722 -- iter: 0256/3680
[A[ATraining Step: 7484  | total loss: [1m[32m0.31477[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31477 - acc: 0.8787 -- iter: 0288/3680
[A[ATraining Step: 7485  | total loss: [1m[32m0.33163[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33163 - acc: 0.8690 -- iter: 0320/3680
[A[ATraining Step: 7486  | total loss: [1m[32m0.32758[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32758 - acc: 0.8727 -- iter: 0352/3680
[A[ATraining Step: 7487  | total loss: [1m[32m0.32099[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32099 - acc: 0.8698 -- iter: 0384/3680
[A[ATraining Step: 7488  | total loss: [1m[32m0.34101[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34101 - acc: 0.8641 -- iter: 0416/3680
[A[ATraining Step: 7489  | total loss: [1m[32m0.34733[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34733 - acc: 0.8589 -- iter: 0448/3680
[A[ATraining Step: 7490  | total loss: [1m[32m0.35939[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35939 - acc: 0.8511 -- iter: 0480/3680
[A[ATraining Step: 7491  | total loss: [1m[32m0.33734[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33734 - acc: 0.8607 -- iter: 0512/3680
[A[ATraining Step: 7492  | total loss: [1m[32m0.33920[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33920 - acc: 0.8607 -- iter: 0544/3680
[A[ATraining Step: 7493  | total loss: [1m[32m0.34044[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34044 - acc: 0.8590 -- iter: 0576/3680
[A[ATraining Step: 7494  | total loss: [1m[32m0.34445[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34445 - acc: 0.8543 -- iter: 0608/3680
[A[ATraining Step: 7495  | total loss: [1m[32m0.32573[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32573 - acc: 0.8658 -- iter: 0640/3680
[A[ATraining Step: 7496  | total loss: [1m[32m0.31994[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31994 - acc: 0.8667 -- iter: 0672/3680
[A[ATraining Step: 7497  | total loss: [1m[32m0.32111[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32111 - acc: 0.8707 -- iter: 0704/3680
[A[ATraining Step: 7498  | total loss: [1m[32m0.31220[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31220 - acc: 0.8805 -- iter: 0736/3680
[A[ATraining Step: 7499  | total loss: [1m[32m0.31454[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31454 - acc: 0.8737 -- iter: 0768/3680
[A[ATraining Step: 7500  | total loss: [1m[32m0.29886[0m[0m
[2K| Adam | epoch: 066 | loss: 0.29886 - acc: 0.8832 | val_loss: 0.29478 - val_acc: 0.8979 -- iter: 0800/3680
[A[ATraining Step: 7500  | total loss: [1m[32m0.29886[0m[0m
[2K| Adam | epoch: 066 | loss: 0.29886 - acc: 0.8832 | val_loss: 0.29478 - val_acc: 0.8979 -- iter: 0800/3680
--
Training Step: 7501  | total loss: [1m[32m0.29669[0m[0m
[2K| Adam | epoch: 066 | loss: 0.29669 - acc: 0.8855 -- iter: 0832/3680
[A[ATraining Step: 7502  | total loss: [1m[32m0.29872[0m[0m
[2K| Adam | epoch: 066 | loss: 0.29872 - acc: 0.8876 -- iter: 0864/3680
[A[ATraining Step: 7503  | total loss: [1m[32m0.29949[0m[0m
[2K| Adam | epoch: 066 | loss: 0.29949 - acc: 0.8863 -- iter: 0896/3680
[A[ATraining Step: 7504  | total loss: [1m[32m0.31730[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31730 - acc: 0.8758 -- iter: 0928/3680
[A[ATraining Step: 7505  | total loss: [1m[32m0.31865[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31865 - acc: 0.8757 -- iter: 0960/3680
[A[ATraining Step: 7506  | total loss: [1m[32m0.31979[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31979 - acc: 0.8725 -- iter: 0992/3680
[A[ATraining Step: 7507  | total loss: [1m[32m0.32220[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32220 - acc: 0.8759 -- iter: 1024/3680
[A[ATraining Step: 7508  | total loss: [1m[32m0.39288[0m[0m
[2K| Adam | epoch: 066 | loss: 0.39288 - acc: 0.8383 -- iter: 1056/3680
[A[ATraining Step: 7509  | total loss: [1m[32m0.39442[0m[0m
[2K| Adam | epoch: 066 | loss: 0.39442 - acc: 0.8482 -- iter: 1088/3680
[A[ATraining Step: 7510  | total loss: [1m[32m0.37591[0m[0m
[2K| Adam | epoch: 066 | loss: 0.37591 - acc: 0.8603 -- iter: 1120/3680
[A[ATraining Step: 7511  | total loss: [1m[32m0.37374[0m[0m
[2K| Adam | epoch: 066 | loss: 0.37374 - acc: 0.8649 -- iter: 1152/3680
[A[ATraining Step: 7512  | total loss: [1m[32m0.36379[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36379 - acc: 0.8690 -- iter: 1184/3680
[A[ATraining Step: 7513  | total loss: [1m[32m0.36346[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36346 - acc: 0.8665 -- iter: 1216/3680
[A[ATraining Step: 7514  | total loss: [1m[32m0.36269[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36269 - acc: 0.8642 -- iter: 1248/3680
[A[ATraining Step: 7515  | total loss: [1m[32m0.35888[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35888 - acc: 0.8622 -- iter: 1280/3680
[A[ATraining Step: 7516  | total loss: [1m[32m0.36092[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36092 - acc: 0.8634 -- iter: 1312/3680
[A[ATraining Step: 7517  | total loss: [1m[32m0.35168[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35168 - acc: 0.8677 -- iter: 1344/3680
[A[ATraining Step: 7518  | total loss: [1m[32m0.34205[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34205 - acc: 0.8747 -- iter: 1376/3680
[A[ATraining Step: 7519  | total loss: [1m[32m0.33531[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33531 - acc: 0.8810 -- iter: 1408/3680
[A[ATraining Step: 7520  | total loss: [1m[32m0.35501[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35501 - acc: 0.8648 -- iter: 1440/3680
[A[ATraining Step: 7521  | total loss: [1m[32m0.34488[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34488 - acc: 0.8658 -- iter: 1472/3680
[A[ATraining Step: 7522  | total loss: [1m[32m0.34062[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34062 - acc: 0.8636 -- iter: 1504/3680
[A[ATraining Step: 7523  | total loss: [1m[32m0.34173[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34173 - acc: 0.8553 -- iter: 1536/3680
[A[ATraining Step: 7524  | total loss: [1m[32m0.35219[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35219 - acc: 0.8511 -- iter: 1568/3680
[A[ATraining Step: 7525  | total loss: [1m[32m0.33502[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33502 - acc: 0.8628 -- iter: 1600/3680
[A[ATraining Step: 7526  | total loss: [1m[32m0.33865[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33865 - acc: 0.8578 -- iter: 1632/3680
[A[ATraining Step: 7527  | total loss: [1m[32m0.34291[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34291 - acc: 0.8564 -- iter: 1664/3680
[A[ATraining Step: 7528  | total loss: [1m[32m0.33026[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33026 - acc: 0.8645 -- iter: 1696/3680
[A[ATraining Step: 7529  | total loss: [1m[32m0.34206[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34206 - acc: 0.8562 -- iter: 1728/3680
[A[ATraining Step: 7530  | total loss: [1m[32m0.36619[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36619 - acc: 0.8456 -- iter: 1760/3680
[A[ATraining Step: 7531  | total loss: [1m[32m0.37486[0m[0m
[2K| Adam | epoch: 066 | loss: 0.37486 - acc: 0.8423 -- iter: 1792/3680
[A[ATraining Step: 7532  | total loss: [1m[32m0.38142[0m[0m
[2K| Adam | epoch: 066 | loss: 0.38142 - acc: 0.8393 -- iter: 1824/3680
[A[ATraining Step: 7533  | total loss: [1m[32m0.36539[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36539 - acc: 0.8522 -- iter: 1856/3680
[A[ATraining Step: 7534  | total loss: [1m[32m0.38450[0m[0m
[2K| Adam | epoch: 066 | loss: 0.38450 - acc: 0.8545 -- iter: 1888/3680
[A[ATraining Step: 7535  | total loss: [1m[32m0.37447[0m[0m
[2K| Adam | epoch: 066 | loss: 0.37447 - acc: 0.8597 -- iter: 1920/3680
[A[ATraining Step: 7536  | total loss: [1m[32m0.36749[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36749 - acc: 0.8612 -- iter: 1952/3680
[A[ATraining Step: 7537  | total loss: [1m[32m0.36017[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36017 - acc: 0.8626 -- iter: 1984/3680
[A[ATraining Step: 7538  | total loss: [1m[32m0.35119[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35119 - acc: 0.8701 -- iter: 2016/3680
[A[ATraining Step: 7539  | total loss: [1m[32m0.33865[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33865 - acc: 0.8768 -- iter: 2048/3680
[A[ATraining Step: 7540  | total loss: [1m[32m0.34997[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34997 - acc: 0.8798 -- iter: 2080/3680
[A[ATraining Step: 7541  | total loss: [1m[32m0.35303[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35303 - acc: 0.8762 -- iter: 2112/3680
[A[ATraining Step: 7542  | total loss: [1m[32m0.34501[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34501 - acc: 0.8823 -- iter: 2144/3680
[A[ATraining Step: 7543  | total loss: [1m[32m0.34748[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34748 - acc: 0.8753 -- iter: 2176/3680
[A[ATraining Step: 7544  | total loss: [1m[32m0.33272[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33272 - acc: 0.8815 -- iter: 2208/3680
[A[ATraining Step: 7545  | total loss: [1m[32m0.33071[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33071 - acc: 0.8809 -- iter: 2240/3680
[A[ATraining Step: 7546  | total loss: [1m[32m0.33612[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33612 - acc: 0.8772 -- iter: 2272/3680
[A[ATraining Step: 7547  | total loss: [1m[32m0.35625[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35625 - acc: 0.8613 -- iter: 2304/3680
[A[ATraining Step: 7548  | total loss: [1m[32m0.35748[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35748 - acc: 0.8627 -- iter: 2336/3680
[A[ATraining Step: 7549  | total loss: [1m[32m0.35806[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35806 - acc: 0.8546 -- iter: 2368/3680
[A[ATraining Step: 7550  | total loss: [1m[32m0.35181[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35181 - acc: 0.8535 -- iter: 2400/3680
[A[ATraining Step: 7551  | total loss: [1m[32m0.36124[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36124 - acc: 0.8494 -- iter: 2432/3680
[A[ATraining Step: 7552  | total loss: [1m[32m0.34629[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34629 - acc: 0.8582 -- iter: 2464/3680
[A[ATraining Step: 7553  | total loss: [1m[32m0.34897[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34897 - acc: 0.8505 -- iter: 2496/3680
[A[ATraining Step: 7554  | total loss: [1m[32m0.34331[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34331 - acc: 0.8561 -- iter: 2528/3680
[A[ATraining Step: 7555  | total loss: [1m[32m0.32839[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32839 - acc: 0.8642 -- iter: 2560/3680
[A[ATraining Step: 7556  | total loss: [1m[32m0.32029[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32029 - acc: 0.8653 -- iter: 2592/3680
[A[ATraining Step: 7557  | total loss: [1m[32m0.30867[0m[0m
[2K| Adam | epoch: 066 | loss: 0.30867 - acc: 0.8725 -- iter: 2624/3680
[A[ATraining Step: 7558  | total loss: [1m[32m0.30460[0m[0m
[2K| Adam | epoch: 066 | loss: 0.30460 - acc: 0.8759 -- iter: 2656/3680
[A[ATraining Step: 7559  | total loss: [1m[32m0.31537[0m[0m
[2K| Adam | epoch: 066 | loss: 0.31537 - acc: 0.8633 -- iter: 2688/3680
[A[ATraining Step: 7560  | total loss: [1m[32m0.32066[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32066 - acc: 0.8645 -- iter: 2720/3680
[A[ATraining Step: 7561  | total loss: [1m[32m0.33962[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33962 - acc: 0.8561 -- iter: 2752/3680
[A[ATraining Step: 7562  | total loss: [1m[32m0.34513[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34513 - acc: 0.8612 -- iter: 2784/3680
[A[ATraining Step: 7563  | total loss: [1m[32m0.35640[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35640 - acc: 0.8594 -- iter: 2816/3680
[A[ATraining Step: 7564  | total loss: [1m[32m0.34658[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34658 - acc: 0.8610 -- iter: 2848/3680
[A[ATraining Step: 7565  | total loss: [1m[32m0.35697[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35697 - acc: 0.8605 -- iter: 2880/3680
[A[ATraining Step: 7566  | total loss: [1m[32m0.34780[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34780 - acc: 0.8620 -- iter: 2912/3680
[A[ATraining Step: 7567  | total loss: [1m[32m0.34780[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34780 - acc: 0.8620 -- iter: 2944/3680
[A[ATraining Step: 7568  | total loss: [1m[32m0.34390[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34390 - acc: 0.8633 -- iter: 2976/3680
[A[ATraining Step: 7569  | total loss: [1m[32m0.35234[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35234 - acc: 0.8582 -- iter: 3008/3680
[A[ATraining Step: 7570  | total loss: [1m[32m0.35670[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35670 - acc: 0.8505 -- iter: 3040/3680
[A[ATraining Step: 7571  | total loss: [1m[32m0.36092[0m[0m
[2K| Adam | epoch: 066 | loss: 0.36092 - acc: 0.8467 -- iter: 3072/3680
[A[ATraining Step: 7572  | total loss: [1m[32m0.35216[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35216 - acc: 0.8527 -- iter: 3104/3680
[A[ATraining Step: 7573  | total loss: [1m[32m0.34425[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34425 - acc: 0.8518 -- iter: 3136/3680
[A[ATraining Step: 7574  | total loss: [1m[32m0.34919[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34919 - acc: 0.8510 -- iter: 3168/3680
[A[ATraining Step: 7575  | total loss: [1m[32m0.35905[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35905 - acc: 0.8462 -- iter: 3200/3680
[A[ATraining Step: 7576  | total loss: [1m[32m0.35905[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35905 - acc: 0.8462 -- iter: 3232/3680
[A[ATraining Step: 7577  | total loss: [1m[32m0.34409[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34409 - acc: 0.8553 -- iter: 3264/3680
[A[ATraining Step: 7578  | total loss: [1m[32m0.35566[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35566 - acc: 0.8541 -- iter: 3296/3680
[A[ATraining Step: 7579  | total loss: [1m[32m0.34767[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34767 - acc: 0.8562 -- iter: 3328/3680
[A[ATraining Step: 7580  | total loss: [1m[32m0.34422[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34422 - acc: 0.8581 -- iter: 3360/3680
[A[ATraining Step: 7581  | total loss: [1m[32m0.35163[0m[0m
[2K| Adam | epoch: 066 | loss: 0.35163 - acc: 0.8567 -- iter: 3392/3680
[A[ATraining Step: 7582  | total loss: [1m[32m0.34072[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34072 - acc: 0.8616 -- iter: 3424/3680
[A[ATraining Step: 7583  | total loss: [1m[32m0.33241[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33241 - acc: 0.8692 -- iter: 3456/3680
[A[ATraining Step: 7584  | total loss: [1m[32m0.34144[0m[0m
[2K| Adam | epoch: 066 | loss: 0.34144 - acc: 0.8635 -- iter: 3488/3680
[A[ATraining Step: 7585  | total loss: [1m[32m0.33197[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33197 - acc: 0.8647 -- iter: 3520/3680
[A[ATraining Step: 7586  | total loss: [1m[32m0.33535[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33535 - acc: 0.8657 -- iter: 3552/3680
[A[ATraining Step: 7587  | total loss: [1m[32m0.33178[0m[0m
[2K| Adam | epoch: 066 | loss: 0.33178 - acc: 0.8729 -- iter: 3584/3680
[A[ATraining Step: 7588  | total loss: [1m[32m0.32500[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32500 - acc: 0.8825 -- iter: 3616/3680
[A[ATraining Step: 7589  | total loss: [1m[32m0.32477[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32477 - acc: 0.8817 -- iter: 3648/3680
[A[ATraining Step: 7590  | total loss: [1m[32m0.32576[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32576 - acc: 0.8811 | val_loss: 0.29735 - val_acc: 0.8914 -- iter: 3680/3680
[A[ATraining Step: 7590  | total loss: [1m[32m0.32576[0m[0m
[2K| Adam | epoch: 066 | loss: 0.32576 - acc: 0.8811 | val_loss: 0.29735 - val_acc: 0.8914 -- iter: 3680/3680
--
Training Step: 7591  | total loss: [1m[32m0.32647[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32647 - acc: 0.8805 -- iter: 0032/3680
[A[ATraining Step: 7592  | total loss: [1m[32m0.33105[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33105 - acc: 0.8768 -- iter: 0064/3680
[A[ATraining Step: 7593  | total loss: [1m[32m0.32159[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32159 - acc: 0.8797 -- iter: 0096/3680
[A[ATraining Step: 7594  | total loss: [1m[32m0.32765[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32765 - acc: 0.8730 -- iter: 0128/3680
[A[ATraining Step: 7595  | total loss: [1m[32m0.31867[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31867 - acc: 0.8795 -- iter: 0160/3680
[A[ATraining Step: 7596  | total loss: [1m[32m0.33278[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33278 - acc: 0.8696 -- iter: 0192/3680
[A[ATraining Step: 7597  | total loss: [1m[32m0.33187[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33187 - acc: 0.8670 -- iter: 0224/3680
[A[ATraining Step: 7598  | total loss: [1m[32m0.35238[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35238 - acc: 0.8585 -- iter: 0256/3680
[A[ATraining Step: 7599  | total loss: [1m[32m0.35319[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35319 - acc: 0.8570 -- iter: 0288/3680
[A[ATraining Step: 7600  | total loss: [1m[32m0.36252[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36252 - acc: 0.8588 | val_loss: 0.29716 - val_acc: 0.8903 -- iter: 0320/3680
[A[ATraining Step: 7600  | total loss: [1m[32m0.36252[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36252 - acc: 0.8588 | val_loss: 0.29716 - val_acc: 0.8903 -- iter: 0320/3680
--
Training Step: 7601  | total loss: [1m[32m0.36041[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36041 - acc: 0.8604 -- iter: 0352/3680
[A[ATraining Step: 7602  | total loss: [1m[32m0.35407[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35407 - acc: 0.8619 -- iter: 0384/3680
[A[ATraining Step: 7603  | total loss: [1m[32m0.36637[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36637 - acc: 0.8569 -- iter: 0416/3680
[A[ATraining Step: 7604  | total loss: [1m[32m0.35342[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35342 - acc: 0.8619 -- iter: 0448/3680
[A[ATraining Step: 7605  | total loss: [1m[32m0.36039[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36039 - acc: 0.8663 -- iter: 0480/3680
[A[ATraining Step: 7606  | total loss: [1m[32m0.36399[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36399 - acc: 0.8672 -- iter: 0512/3680
[A[ATraining Step: 7607  | total loss: [1m[32m0.35134[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35134 - acc: 0.8711 -- iter: 0544/3680
[A[ATraining Step: 7608  | total loss: [1m[32m0.33884[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33884 - acc: 0.8559 -- iter: 0576/3680
[A[ATraining Step: 7609  | total loss: [1m[32m0.35047[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35047 - acc: 0.8559 -- iter: 0608/3680
[A[ATraining Step: 7610  | total loss: [1m[32m0.35814[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35814 - acc: 0.8484 -- iter: 0640/3680
[A[ATraining Step: 7611  | total loss: [1m[32m0.33671[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33671 - acc: 0.8636 -- iter: 0672/3680
[A[ATraining Step: 7612  | total loss: [1m[32m0.34288[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34288 - acc: 0.8508 -- iter: 0704/3680
[A[ATraining Step: 7613  | total loss: [1m[32m0.35260[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35260 - acc: 0.8501 -- iter: 0736/3680
[A[ATraining Step: 7614  | total loss: [1m[32m0.35260[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35260 - acc: 0.8501 -- iter: 0768/3680
[A[ATraining Step: 7615  | total loss: [1m[32m0.35178[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35178 - acc: 0.8494 -- iter: 0800/3680
[A[ATraining Step: 7616  | total loss: [1m[32m0.35361[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35361 - acc: 0.8426 -- iter: 0832/3680
[A[ATraining Step: 7617  | total loss: [1m[32m0.34073[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34073 - acc: 0.8490 -- iter: 0864/3680
[A[ATraining Step: 7618  | total loss: [1m[32m0.33186[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33186 - acc: 0.8547 -- iter: 0896/3680
[A[ATraining Step: 7619  | total loss: [1m[32m0.32268[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32268 - acc: 0.8661 -- iter: 0928/3680
[A[ATraining Step: 7620  | total loss: [1m[32m0.31134[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31134 - acc: 0.8732 -- iter: 0960/3680
[A[ATraining Step: 7621  | total loss: [1m[32m0.30757[0m[0m
[2K| Adam | epoch: 067 | loss: 0.30757 - acc: 0.8765 -- iter: 0992/3680
[A[ATraining Step: 7622  | total loss: [1m[32m0.29456[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29456 - acc: 0.8858 -- iter: 1024/3680
[A[ATraining Step: 7623  | total loss: [1m[32m0.29143[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29143 - acc: 0.8878 -- iter: 1056/3680
[A[ATraining Step: 7624  | total loss: [1m[32m0.39340[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39340 - acc: 0.8647 -- iter: 1088/3680
[A[ATraining Step: 7625  | total loss: [1m[32m0.37780[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37780 - acc: 0.8657 -- iter: 1120/3680
[A[ATraining Step: 7626  | total loss: [1m[32m0.38175[0m[0m
[2K| Adam | epoch: 067 | loss: 0.38175 - acc: 0.8572 -- iter: 1152/3680
[A[ATraining Step: 7627  | total loss: [1m[32m0.38390[0m[0m
[2K| Adam | epoch: 067 | loss: 0.38390 - acc: 0.8559 -- iter: 1184/3680
[A[ATraining Step: 7628  | total loss: [1m[32m0.39074[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39074 - acc: 0.8547 -- iter: 1216/3680
[A[ATraining Step: 7629  | total loss: [1m[32m0.39367[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39367 - acc: 0.8473 -- iter: 1248/3680
[A[ATraining Step: 7630  | total loss: [1m[32m0.39543[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39543 - acc: 0.8407 -- iter: 1280/3680
[A[ATraining Step: 7631  | total loss: [1m[32m0.39717[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39717 - acc: 0.8442 -- iter: 1312/3680
[A[ATraining Step: 7632  | total loss: [1m[32m0.39457[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39457 - acc: 0.8379 -- iter: 1344/3680
[A[ATraining Step: 7633  | total loss: [1m[32m0.39170[0m[0m
[2K| Adam | epoch: 067 | loss: 0.39170 - acc: 0.8385 -- iter: 1376/3680
[A[ATraining Step: 7634  | total loss: [1m[32m0.40112[0m[0m
[2K| Adam | epoch: 067 | loss: 0.40112 - acc: 0.8296 -- iter: 1408/3680
[A[ATraining Step: 7635  | total loss: [1m[32m0.38461[0m[0m
[2K| Adam | epoch: 067 | loss: 0.38461 - acc: 0.8341 -- iter: 1440/3680
[A[ATraining Step: 7636  | total loss: [1m[32m0.37287[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37287 - acc: 0.8414 -- iter: 1472/3680
[A[ATraining Step: 7637  | total loss: [1m[32m0.35562[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35562 - acc: 0.8510 -- iter: 1504/3680
[A[ATraining Step: 7638  | total loss: [1m[32m0.35624[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35624 - acc: 0.8471 -- iter: 1536/3680
[A[ATraining Step: 7639  | total loss: [1m[32m0.35950[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35950 - acc: 0.8374 -- iter: 1568/3680
[A[ATraining Step: 7640  | total loss: [1m[32m0.34657[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34657 - acc: 0.8474 -- iter: 1600/3680
[A[ATraining Step: 7641  | total loss: [1m[32m0.33985[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33985 - acc: 0.8564 -- iter: 1632/3680
[A[ATraining Step: 7642  | total loss: [1m[32m0.33336[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33336 - acc: 0.8645 -- iter: 1664/3680
[A[ATraining Step: 7643  | total loss: [1m[32m0.32038[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32038 - acc: 0.8750 -- iter: 1696/3680
[A[ATraining Step: 7644  | total loss: [1m[32m0.33500[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33500 - acc: 0.8687 -- iter: 1728/3680
[A[ATraining Step: 7645  | total loss: [1m[32m0.32994[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32994 - acc: 0.8725 -- iter: 1760/3680
[A[ATraining Step: 7646  | total loss: [1m[32m0.32140[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32140 - acc: 0.8820 -- iter: 1792/3680
[A[ATraining Step: 7647  | total loss: [1m[32m0.31451[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31451 - acc: 0.8820 -- iter: 1824/3680
[A[ATraining Step: 7648  | total loss: [1m[32m0.31198[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31198 - acc: 0.8844 -- iter: 1856/3680
[A[ATraining Step: 7649  | total loss: [1m[32m0.31673[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31673 - acc: 0.8772 -- iter: 1888/3680
[A[ATraining Step: 7650  | total loss: [1m[32m0.31996[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31996 - acc: 0.8770 -- iter: 1920/3680
[A[ATraining Step: 7651  | total loss: [1m[32m0.30588[0m[0m
[2K| Adam | epoch: 067 | loss: 0.30588 - acc: 0.8831 -- iter: 1952/3680
[A[ATraining Step: 7652  | total loss: [1m[32m0.31698[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31698 - acc: 0.8760 -- iter: 1984/3680
[A[ATraining Step: 7653  | total loss: [1m[32m0.32294[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32294 - acc: 0.8728 -- iter: 2016/3680
[A[ATraining Step: 7654  | total loss: [1m[32m0.33009[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33009 - acc: 0.8668 -- iter: 2048/3680
[A[ATraining Step: 7655  | total loss: [1m[32m0.36002[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36002 - acc: 0.8551 -- iter: 2080/3680
[A[ATraining Step: 7656  | total loss: [1m[32m0.36454[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36454 - acc: 0.8571 -- iter: 2112/3680
[A[ATraining Step: 7657  | total loss: [1m[32m0.37409[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37409 - acc: 0.8642 -- iter: 2144/3680
[A[ATraining Step: 7658  | total loss: [1m[32m0.35733[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35733 - acc: 0.8642 -- iter: 2176/3680
[A[ATraining Step: 7659  | total loss: [1m[32m0.35396[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35396 - acc: 0.8622 -- iter: 2208/3680
[A[ATraining Step: 7660  | total loss: [1m[32m0.34616[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34616 - acc: 0.8666 -- iter: 2240/3680
[A[ATraining Step: 7661  | total loss: [1m[32m0.34275[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34275 - acc: 0.8674 -- iter: 2272/3680
[A[ATraining Step: 7662  | total loss: [1m[32m0.33522[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33522 - acc: 0.8744 -- iter: 2304/3680
[A[ATraining Step: 7663  | total loss: [1m[32m0.31876[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31876 - acc: 0.8870 -- iter: 2336/3680
[A[ATraining Step: 7664  | total loss: [1m[32m0.31221[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31221 - acc: 0.8858 -- iter: 2368/3680
[A[ATraining Step: 7665  | total loss: [1m[32m0.29854[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29854 - acc: 0.8941 -- iter: 2400/3680
[A[ATraining Step: 7666  | total loss: [1m[32m0.29473[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29473 - acc: 0.8953 -- iter: 2432/3680
[A[ATraining Step: 7667  | total loss: [1m[32m0.28713[0m[0m
[2K| Adam | epoch: 067 | loss: 0.28713 - acc: 0.8964 -- iter: 2464/3680
[A[ATraining Step: 7668  | total loss: [1m[32m0.30168[0m[0m
[2K| Adam | epoch: 067 | loss: 0.30168 - acc: 0.8880 -- iter: 2496/3680
[A[ATraining Step: 7669  | total loss: [1m[32m0.29659[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29659 - acc: 0.8912 -- iter: 2528/3680
[A[ATraining Step: 7670  | total loss: [1m[32m0.29873[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29873 - acc: 0.8912 -- iter: 2560/3680
[A[ATraining Step: 7671  | total loss: [1m[32m0.29880[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29880 - acc: 0.8895 -- iter: 2592/3680
[A[ATraining Step: 7672  | total loss: [1m[32m0.29539[0m[0m
[2K| Adam | epoch: 067 | loss: 0.29539 - acc: 0.8818 -- iter: 2624/3680
[A[ATraining Step: 7673  | total loss: [1m[32m0.33612[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33612 - acc: 0.8718 -- iter: 2656/3680
[A[ATraining Step: 7674  | total loss: [1m[32m0.32488[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32488 - acc: 0.8784 -- iter: 2688/3680
[A[ATraining Step: 7675  | total loss: [1m[32m0.33905[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33905 - acc: 0.8749 -- iter: 2720/3680
[A[ATraining Step: 7676  | total loss: [1m[32m0.36370[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36370 - acc: 0.8655 -- iter: 2752/3680
[A[ATraining Step: 7677  | total loss: [1m[32m0.35282[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35282 - acc: 0.8727 -- iter: 2784/3680
[A[ATraining Step: 7678  | total loss: [1m[32m0.33479[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33479 - acc: 0.8761 -- iter: 2816/3680
[A[ATraining Step: 7679  | total loss: [1m[32m0.31776[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31776 - acc: 0.8853 -- iter: 2848/3680
[A[ATraining Step: 7680  | total loss: [1m[32m0.33581[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33581 - acc: 0.8781 -- iter: 2880/3680
[A[ATraining Step: 7681  | total loss: [1m[32m0.32354[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32354 - acc: 0.8809 -- iter: 2912/3680
[A[ATraining Step: 7682  | total loss: [1m[32m0.33682[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33682 - acc: 0.8740 -- iter: 2944/3680
[A[ATraining Step: 7683  | total loss: [1m[32m0.34042[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34042 - acc: 0.8679 -- iter: 2976/3680
[A[ATraining Step: 7684  | total loss: [1m[32m0.34068[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34068 - acc: 0.8686 -- iter: 3008/3680
[A[ATraining Step: 7685  | total loss: [1m[32m0.36005[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36005 - acc: 0.8599 -- iter: 3040/3680
[A[ATraining Step: 7686  | total loss: [1m[32m0.34771[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34771 - acc: 0.8614 -- iter: 3072/3680
[A[ATraining Step: 7687  | total loss: [1m[32m0.34657[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34657 - acc: 0.8596 -- iter: 3104/3680
[A[ATraining Step: 7688  | total loss: [1m[32m0.33389[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33389 - acc: 0.8674 -- iter: 3136/3680
[A[ATraining Step: 7689  | total loss: [1m[32m0.34289[0m[0m
[2K| Adam | epoch: 067 | loss: 0.34289 - acc: 0.8682 -- iter: 3168/3680
[A[ATraining Step: 7690  | total loss: [1m[32m0.32355[0m[0m
[2K| Adam | epoch: 067 | loss: 0.32355 - acc: 0.8782 -- iter: 3200/3680
[A[ATraining Step: 7691  | total loss: [1m[32m0.33354[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33354 - acc: 0.8748 -- iter: 3232/3680
[A[ATraining Step: 7692  | total loss: [1m[32m0.36429[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36429 - acc: 0.8654 -- iter: 3264/3680
[A[ATraining Step: 7693  | total loss: [1m[32m0.37433[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37433 - acc: 0.8539 -- iter: 3296/3680
[A[ATraining Step: 7694  | total loss: [1m[32m0.37200[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37200 - acc: 0.8560 -- iter: 3328/3680
[A[ATraining Step: 7695  | total loss: [1m[32m0.37964[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37964 - acc: 0.8485 -- iter: 3360/3680
[A[ATraining Step: 7696  | total loss: [1m[32m0.37914[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37914 - acc: 0.8449 -- iter: 3392/3680
[A[ATraining Step: 7697  | total loss: [1m[32m0.36859[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36859 - acc: 0.8542 -- iter: 3424/3680
[A[ATraining Step: 7698  | total loss: [1m[32m0.36542[0m[0m
[2K| Adam | epoch: 067 | loss: 0.36542 - acc: 0.8563 -- iter: 3456/3680
[A[ATraining Step: 7699  | total loss: [1m[32m0.38732[0m[0m
[2K| Adam | epoch: 067 | loss: 0.38732 - acc: 0.8519 -- iter: 3488/3680
[A[ATraining Step: 7700  | total loss: [1m[32m0.37527[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37527 - acc: 0.8573 | val_loss: 0.31756 - val_acc: 0.8806 -- iter: 3520/3680
[A[ATraining Step: 7700  | total loss: [1m[32m0.37527[0m[0m
[2K| Adam | epoch: 067 | loss: 0.37527 - acc: 0.8573 | val_loss: 0.31756 - val_acc: 0.8806 -- iter: 3520/3680
--
Training Step: 7701  | total loss: [1m[32m0.35599[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35599 - acc: 0.8672 -- iter: 3552/3680
[A[ATraining Step: 7702  | total loss: [1m[32m0.35599[0m[0m
[2K| Adam | epoch: 067 | loss: 0.35599 - acc: 0.8672 -- iter: 3584/3680
[A[ATraining Step: 7703  | total loss: [1m[32m0.33349[0m[0m
[2K| Adam | epoch: 067 | loss: 0.33349 - acc: 0.8774 -- iter: 3616/3680
[A[ATraining Step: 7704  | total loss: [1m[32m0.31824[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31824 - acc: 0.8865 -- iter: 3648/3680
[A[ATraining Step: 7705  | total loss: [1m[32m0.31320[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31320 - acc: 0.8822 | val_loss: 0.32109 - val_acc: 0.8751 -- iter: 3680/3680
[A[ATraining Step: 7705  | total loss: [1m[32m0.31320[0m[0m
[2K| Adam | epoch: 067 | loss: 0.31320 - acc: 0.8822 | val_loss: 0.32109 - val_acc: 0.8751 -- iter: 3680/3680
--
Training Step: 7706  | total loss: [1m[32m0.30860[0m[0m
[2K| Adam | epoch: 068 | loss: 0.30860 - acc: 0.8753 -- iter: 0032/3680
[A[ATraining Step: 7707  | total loss: [1m[32m0.33160[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33160 - acc: 0.8596 -- iter: 0064/3680
[A[ATraining Step: 7708  | total loss: [1m[32m0.33095[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33095 - acc: 0.8643 -- iter: 0096/3680
[A[ATraining Step: 7709  | total loss: [1m[32m0.33179[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33179 - acc: 0.8591 -- iter: 0128/3680
[A[ATraining Step: 7710  | total loss: [1m[32m0.33893[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33893 - acc: 0.8513 -- iter: 0160/3680
[A[ATraining Step: 7711  | total loss: [1m[32m0.33944[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33944 - acc: 0.8506 -- iter: 0192/3680
[A[ATraining Step: 7712  | total loss: [1m[32m0.35009[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35009 - acc: 0.8468 -- iter: 0224/3680
[A[ATraining Step: 7713  | total loss: [1m[32m0.35009[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35009 - acc: 0.8468 -- iter: 0256/3680
[A[ATraining Step: 7714  | total loss: [1m[32m0.33872[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33872 - acc: 0.8546 -- iter: 0288/3680
[A[ATraining Step: 7715  | total loss: [1m[32m0.34892[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34892 - acc: 0.8546 -- iter: 0320/3680
[A[ATraining Step: 7716  | total loss: [1m[32m0.34550[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34550 - acc: 0.8567 -- iter: 0352/3680
[A[ATraining Step: 7717  | total loss: [1m[32m0.34786[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34786 - acc: 0.8554 -- iter: 0384/3680
[A[ATraining Step: 7718  | total loss: [1m[32m0.34523[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34523 - acc: 0.8573 -- iter: 0416/3680
[A[ATraining Step: 7719  | total loss: [1m[32m0.34300[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34300 - acc: 0.8622 -- iter: 0448/3680
[A[ATraining Step: 7720  | total loss: [1m[32m0.33539[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33539 - acc: 0.8698 -- iter: 0480/3680
[A[ATraining Step: 7721  | total loss: [1m[32m0.33001[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33001 - acc: 0.8765 -- iter: 0512/3680
[A[ATraining Step: 7722  | total loss: [1m[32m0.35504[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35504 - acc: 0.8762 -- iter: 0544/3680
[A[ATraining Step: 7723  | total loss: [1m[32m0.35504[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35504 - acc: 0.8762 -- iter: 0576/3680
[A[ATraining Step: 7724  | total loss: [1m[32m0.35686[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35686 - acc: 0.8730 -- iter: 0608/3680
[A[ATraining Step: 7725  | total loss: [1m[32m0.35590[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35590 - acc: 0.8701 -- iter: 0640/3680
[A[ATraining Step: 7726  | total loss: [1m[32m0.35634[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35634 - acc: 0.8706 -- iter: 0672/3680
[A[ATraining Step: 7727  | total loss: [1m[32m0.34841[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34841 - acc: 0.8804 -- iter: 0704/3680
[A[ATraining Step: 7728  | total loss: [1m[32m0.33688[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33688 - acc: 0.8861 -- iter: 0736/3680
[A[ATraining Step: 7729  | total loss: [1m[32m0.34625[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34625 - acc: 0.8787 -- iter: 0768/3680
[A[ATraining Step: 7730  | total loss: [1m[32m0.34263[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34263 - acc: 0.8752 -- iter: 0800/3680
[A[ATraining Step: 7731  | total loss: [1m[32m0.33646[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33646 - acc: 0.8780 -- iter: 0832/3680
[A[ATraining Step: 7732  | total loss: [1m[32m0.33646[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33646 - acc: 0.8780 -- iter: 0864/3680
[A[ATraining Step: 7733  | total loss: [1m[32m0.34465[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34465 - acc: 0.8683 -- iter: 0896/3680
[A[ATraining Step: 7734  | total loss: [1m[32m0.33125[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33125 - acc: 0.8690 -- iter: 0928/3680
[A[ATraining Step: 7735  | total loss: [1m[32m0.33108[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33108 - acc: 0.8665 -- iter: 0960/3680
[A[ATraining Step: 7736  | total loss: [1m[32m0.32855[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32855 - acc: 0.8611 -- iter: 0992/3680
[A[ATraining Step: 7737  | total loss: [1m[32m0.32105[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32105 - acc: 0.8656 -- iter: 1024/3680
[A[ATraining Step: 7738  | total loss: [1m[32m0.32322[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32322 - acc: 0.8665 -- iter: 1056/3680
[A[ATraining Step: 7739  | total loss: [1m[32m0.32040[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32040 - acc: 0.8705 -- iter: 1088/3680
[A[ATraining Step: 7740  | total loss: [1m[32m0.39412[0m[0m
[2K| Adam | epoch: 068 | loss: 0.39412 - acc: 0.8460 -- iter: 1120/3680
[A[ATraining Step: 7741  | total loss: [1m[32m0.38035[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38035 - acc: 0.8551 -- iter: 1152/3680
[A[ATraining Step: 7742  | total loss: [1m[32m0.36686[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36686 - acc: 0.8602 -- iter: 1184/3680
[A[ATraining Step: 7743  | total loss: [1m[32m0.37358[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37358 - acc: 0.8586 -- iter: 1216/3680
[A[ATraining Step: 7744  | total loss: [1m[32m0.36049[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36049 - acc: 0.8602 -- iter: 1248/3680
[A[ATraining Step: 7745  | total loss: [1m[32m0.36241[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36241 - acc: 0.8523 -- iter: 1280/3680
[A[ATraining Step: 7746  | total loss: [1m[32m0.37139[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37139 - acc: 0.8452 -- iter: 1312/3680
[A[ATraining Step: 7747  | total loss: [1m[32m0.36191[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36191 - acc: 0.8482 -- iter: 1344/3680
[A[ATraining Step: 7748  | total loss: [1m[32m0.36370[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36370 - acc: 0.8446 -- iter: 1376/3680
[A[ATraining Step: 7749  | total loss: [1m[32m0.35720[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35720 - acc: 0.8539 -- iter: 1408/3680
[A[ATraining Step: 7750  | total loss: [1m[32m0.34623[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34623 - acc: 0.8591 -- iter: 1440/3680
[A[ATraining Step: 7751  | total loss: [1m[32m0.34279[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34279 - acc: 0.8607 -- iter: 1472/3680
[A[ATraining Step: 7752  | total loss: [1m[32m0.34723[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34723 - acc: 0.8465 -- iter: 1504/3680
[A[ATraining Step: 7753  | total loss: [1m[32m0.34107[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34107 - acc: 0.8494 -- iter: 1536/3680
[A[ATraining Step: 7754  | total loss: [1m[32m0.34766[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34766 - acc: 0.8426 -- iter: 1568/3680
[A[ATraining Step: 7755  | total loss: [1m[32m0.35090[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35090 - acc: 0.8427 -- iter: 1600/3680
[A[ATraining Step: 7756  | total loss: [1m[32m0.35426[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35426 - acc: 0.8397 -- iter: 1632/3680
[A[ATraining Step: 7757  | total loss: [1m[32m0.35446[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35446 - acc: 0.8463 -- iter: 1664/3680
[A[ATraining Step: 7758  | total loss: [1m[32m0.35978[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35978 - acc: 0.8429 -- iter: 1696/3680
[A[ATraining Step: 7759  | total loss: [1m[32m0.34340[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34340 - acc: 0.8555 -- iter: 1728/3680
[A[ATraining Step: 7760  | total loss: [1m[32m0.35270[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35270 - acc: 0.8575 -- iter: 1760/3680
[A[ATraining Step: 7761  | total loss: [1m[32m0.34238[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34238 - acc: 0.8655 -- iter: 1792/3680
[A[ATraining Step: 7762  | total loss: [1m[32m0.34808[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34808 - acc: 0.8571 -- iter: 1824/3680
[A[ATraining Step: 7763  | total loss: [1m[32m0.35163[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35163 - acc: 0.8588 -- iter: 1856/3680
[A[ATraining Step: 7764  | total loss: [1m[32m0.34629[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34629 - acc: 0.8542 -- iter: 1888/3680
[A[ATraining Step: 7765  | total loss: [1m[32m0.35862[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35862 - acc: 0.8469 -- iter: 1920/3680
[A[ATraining Step: 7766  | total loss: [1m[32m0.35451[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35451 - acc: 0.8560 -- iter: 1952/3680
[A[ATraining Step: 7767  | total loss: [1m[32m0.35672[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35672 - acc: 0.8579 -- iter: 1984/3680
[A[ATraining Step: 7768  | total loss: [1m[32m0.35495[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35495 - acc: 0.8596 -- iter: 2016/3680
[A[ATraining Step: 7769  | total loss: [1m[32m0.34527[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34527 - acc: 0.8611 -- iter: 2048/3680
[A[ATraining Step: 7770  | total loss: [1m[32m0.36530[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36530 - acc: 0.8500 -- iter: 2080/3680
[A[ATraining Step: 7771  | total loss: [1m[32m0.35435[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35435 - acc: 0.8588 -- iter: 2112/3680
[A[ATraining Step: 7772  | total loss: [1m[32m0.35452[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35452 - acc: 0.8541 -- iter: 2144/3680
[A[ATraining Step: 7773  | total loss: [1m[32m0.36019[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36019 - acc: 0.8468 -- iter: 2176/3680
[A[ATraining Step: 7774  | total loss: [1m[32m0.35842[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35842 - acc: 0.8497 -- iter: 2208/3680
[A[ATraining Step: 7775  | total loss: [1m[32m0.34321[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34321 - acc: 0.8616 -- iter: 2240/3680
[A[ATraining Step: 7776  | total loss: [1m[32m0.34171[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34171 - acc: 0.8629 -- iter: 2272/3680
[A[ATraining Step: 7777  | total loss: [1m[32m0.34622[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34622 - acc: 0.8579 -- iter: 2304/3680
[A[ATraining Step: 7778  | total loss: [1m[32m0.40030[0m[0m
[2K| Adam | epoch: 068 | loss: 0.40030 - acc: 0.8440 -- iter: 2336/3680
[A[ATraining Step: 7779  | total loss: [1m[32m0.40195[0m[0m
[2K| Adam | epoch: 068 | loss: 0.40195 - acc: 0.8408 -- iter: 2368/3680
[A[ATraining Step: 7780  | total loss: [1m[32m0.39560[0m[0m
[2K| Adam | epoch: 068 | loss: 0.39560 - acc: 0.8474 -- iter: 2400/3680
[A[ATraining Step: 7781  | total loss: [1m[32m0.38144[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38144 - acc: 0.8532 -- iter: 2432/3680
[A[ATraining Step: 7782  | total loss: [1m[32m0.38492[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38492 - acc: 0.8523 -- iter: 2464/3680
[A[ATraining Step: 7783  | total loss: [1m[32m0.38135[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38135 - acc: 0.8514 -- iter: 2496/3680
[A[ATraining Step: 7784  | total loss: [1m[32m0.38668[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38668 - acc: 0.8444 -- iter: 2528/3680
[A[ATraining Step: 7785  | total loss: [1m[32m0.37808[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37808 - acc: 0.8506 -- iter: 2560/3680
[A[ATraining Step: 7786  | total loss: [1m[32m0.37478[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37478 - acc: 0.8468 -- iter: 2592/3680
[A[ATraining Step: 7787  | total loss: [1m[32m0.36419[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36419 - acc: 0.8465 -- iter: 2624/3680
[A[ATraining Step: 7788  | total loss: [1m[32m0.35027[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35027 - acc: 0.8556 -- iter: 2656/3680
[A[ATraining Step: 7789  | total loss: [1m[32m0.37481[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37481 - acc: 0.8450 -- iter: 2688/3680
[A[ATraining Step: 7790  | total loss: [1m[32m0.37593[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37593 - acc: 0.8418 -- iter: 2720/3680
[A[ATraining Step: 7791  | total loss: [1m[32m0.36800[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36800 - acc: 0.8451 -- iter: 2752/3680
[A[ATraining Step: 7792  | total loss: [1m[32m0.36414[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36414 - acc: 0.8481 -- iter: 2784/3680
[A[ATraining Step: 7793  | total loss: [1m[32m0.35872[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35872 - acc: 0.8570 -- iter: 2816/3680
[A[ATraining Step: 7794  | total loss: [1m[32m0.34575[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34575 - acc: 0.8620 -- iter: 2848/3680
[A[ATraining Step: 7795  | total loss: [1m[32m0.35335[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35335 - acc: 0.8539 -- iter: 2880/3680
[A[ATraining Step: 7796  | total loss: [1m[32m0.34796[0m[0m
[2K| Adam | epoch: 068 | loss: 0.34796 - acc: 0.8529 -- iter: 2912/3680
[A[ATraining Step: 7797  | total loss: [1m[32m0.32884[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32884 - acc: 0.8645 -- iter: 2944/3680
[A[ATraining Step: 7798  | total loss: [1m[32m0.32293[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32293 - acc: 0.8686 -- iter: 2976/3680
[A[ATraining Step: 7799  | total loss: [1m[32m0.32356[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32356 - acc: 0.8661 -- iter: 3008/3680
[A[ATraining Step: 7800  | total loss: [1m[32m0.30675[0m[0m
[2K| Adam | epoch: 068 | loss: 0.30675 - acc: 0.8795 | val_loss: 0.35115 - val_acc: 0.8686 -- iter: 3040/3680
[A[ATraining Step: 7800  | total loss: [1m[32m0.30675[0m[0m
[2K| Adam | epoch: 068 | loss: 0.30675 - acc: 0.8795 | val_loss: 0.35115 - val_acc: 0.8686 -- iter: 3040/3680
--
Training Step: 7801  | total loss: [1m[32m0.30612[0m[0m
[2K| Adam | epoch: 068 | loss: 0.30612 - acc: 0.8697 -- iter: 3072/3680
[A[ATraining Step: 7802  | total loss: [1m[32m0.30105[0m[0m
[2K| Adam | epoch: 068 | loss: 0.30105 - acc: 0.8765 -- iter: 3104/3680
[A[ATraining Step: 7803  | total loss: [1m[32m0.31296[0m[0m
[2K| Adam | epoch: 068 | loss: 0.31296 - acc: 0.8670 -- iter: 3136/3680
[A[ATraining Step: 7804  | total loss: [1m[32m0.31330[0m[0m
[2K| Adam | epoch: 068 | loss: 0.31330 - acc: 0.8526 -- iter: 3168/3680
[A[ATraining Step: 7805  | total loss: [1m[32m0.33366[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33366 - acc: 0.8526 -- iter: 3200/3680
[A[ATraining Step: 7806  | total loss: [1m[32m0.32707[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32707 - acc: 0.8610 -- iter: 3232/3680
[A[ATraining Step: 7807  | total loss: [1m[32m0.33518[0m[0m
[2K| Adam | epoch: 068 | loss: 0.33518 - acc: 0.8562 -- iter: 3264/3680
[A[ATraining Step: 7808  | total loss: [1m[32m0.32466[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32466 - acc: 0.8657 -- iter: 3296/3680
[A[ATraining Step: 7809  | total loss: [1m[32m0.32717[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32717 - acc: 0.8657 -- iter: 3328/3680
[A[ATraining Step: 7810  | total loss: [1m[32m0.32504[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32504 - acc: 0.8635 -- iter: 3360/3680
[A[ATraining Step: 7811  | total loss: [1m[32m0.32013[0m[0m
[2K| Adam | epoch: 068 | loss: 0.32013 - acc: 0.8678 -- iter: 3392/3680
[A[ATraining Step: 7812  | total loss: [1m[32m0.38762[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38762 - acc: 0.8654 -- iter: 3424/3680
[A[ATraining Step: 7813  | total loss: [1m[32m0.38201[0m[0m
[2K| Adam | epoch: 068 | loss: 0.38201 - acc: 0.8632 -- iter: 3456/3680
[A[ATraining Step: 7814  | total loss: [1m[32m0.37933[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37933 - acc: 0.8613 -- iter: 3488/3680
[A[ATraining Step: 7815  | total loss: [1m[32m0.37816[0m[0m
[2K| Adam | epoch: 068 | loss: 0.37816 - acc: 0.8564 -- iter: 3520/3680
[A[ATraining Step: 7816  | total loss: [1m[32m0.36353[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36353 - acc: 0.8614 -- iter: 3552/3680
[A[ATraining Step: 7817  | total loss: [1m[32m0.36342[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36342 - acc: 0.8565 -- iter: 3584/3680
[A[ATraining Step: 7818  | total loss: [1m[32m0.35972[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35972 - acc: 0.8552 -- iter: 3616/3680
[A[ATraining Step: 7819  | total loss: [1m[32m0.35026[0m[0m
[2K| Adam | epoch: 068 | loss: 0.35026 - acc: 0.8666 -- iter: 3648/3680
[A[ATraining Step: 7820  | total loss: [1m[32m0.36225[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36225 - acc: 0.8549 | val_loss: 0.31348 - val_acc: 0.8762 -- iter: 3680/3680
[A[ATraining Step: 7820  | total loss: [1m[32m0.36225[0m[0m
[2K| Adam | epoch: 068 | loss: 0.36225 - acc: 0.8549 | val_loss: 0.31348 - val_acc: 0.8762 -- iter: 3680/3680
--
Training Step: 7821  | total loss: [1m[32m0.34876[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34876 - acc: 0.8734 -- iter: 0032/3680
[A[ATraining Step: 7822  | total loss: [1m[32m0.33588[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33588 - acc: 0.8734 -- iter: 0064/3680
[A[ATraining Step: 7823  | total loss: [1m[32m0.33334[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33334 - acc: 0.8705 -- iter: 0096/3680
[A[ATraining Step: 7824  | total loss: [1m[32m0.33606[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33606 - acc: 0.8678 -- iter: 0128/3680
[A[ATraining Step: 7825  | total loss: [1m[32m0.35099[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35099 - acc: 0.8654 -- iter: 0160/3680
[A[ATraining Step: 7826  | total loss: [1m[32m0.35710[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35710 - acc: 0.8632 -- iter: 0192/3680
[A[ATraining Step: 7827  | total loss: [1m[32m0.34868[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34868 - acc: 0.8714 -- iter: 0224/3680
[A[ATraining Step: 7828  | total loss: [1m[32m0.34529[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34529 - acc: 0.8593 -- iter: 0256/3680
[A[ATraining Step: 7829  | total loss: [1m[32m0.35028[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35028 - acc: 0.8593 -- iter: 0288/3680
[A[ATraining Step: 7830  | total loss: [1m[32m0.34972[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34972 - acc: 0.8608 -- iter: 0320/3680
[A[ATraining Step: 7831  | total loss: [1m[32m0.35594[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35594 - acc: 0.8560 -- iter: 0352/3680
[A[ATraining Step: 7832  | total loss: [1m[32m0.34656[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34656 - acc: 0.8579 -- iter: 0384/3680
[A[ATraining Step: 7833  | total loss: [1m[32m0.34433[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34433 - acc: 0.8596 -- iter: 0416/3680
[A[ATraining Step: 7834  | total loss: [1m[32m0.34083[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34083 - acc: 0.8563 -- iter: 0448/3680
[A[ATraining Step: 7835  | total loss: [1m[32m0.34282[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34282 - acc: 0.8563 -- iter: 0480/3680
[A[ATraining Step: 7836  | total loss: [1m[32m0.38199[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38199 - acc: 0.8394 -- iter: 0512/3680
[A[ATraining Step: 7837  | total loss: [1m[32m0.36885[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36885 - acc: 0.8492 -- iter: 0544/3680
[A[ATraining Step: 7838  | total loss: [1m[32m0.36014[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36014 - acc: 0.8549 -- iter: 0576/3680
[A[ATraining Step: 7839  | total loss: [1m[32m0.36121[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36121 - acc: 0.8569 -- iter: 0608/3680
[A[ATraining Step: 7840  | total loss: [1m[32m0.35524[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35524 - acc: 0.8572 -- iter: 0640/3680
[A[ATraining Step: 7841  | total loss: [1m[32m0.36563[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36563 - acc: 0.8572 -- iter: 0672/3680
[A[ATraining Step: 7842  | total loss: [1m[32m0.38215[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38215 - acc: 0.8434 -- iter: 0704/3680
[A[ATraining Step: 7843  | total loss: [1m[32m0.36856[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36856 - acc: 0.8528 -- iter: 0736/3680
[A[ATraining Step: 7844  | total loss: [1m[32m0.38949[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38949 - acc: 0.8456 -- iter: 0768/3680
[A[ATraining Step: 7845  | total loss: [1m[32m0.39793[0m[0m
[2K| Adam | epoch: 069 | loss: 0.39793 - acc: 0.8423 -- iter: 0800/3680
[A[ATraining Step: 7846  | total loss: [1m[32m0.40480[0m[0m
[2K| Adam | epoch: 069 | loss: 0.40480 - acc: 0.8300 -- iter: 0832/3680
[A[ATraining Step: 7847  | total loss: [1m[32m0.40235[0m[0m
[2K| Adam | epoch: 069 | loss: 0.40235 - acc: 0.8313 -- iter: 0864/3680
[A[ATraining Step: 7848  | total loss: [1m[32m0.39492[0m[0m
[2K| Adam | epoch: 069 | loss: 0.39492 - acc: 0.8420 -- iter: 0896/3680
[A[ATraining Step: 7849  | total loss: [1m[32m0.37429[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37429 - acc: 0.8578 -- iter: 0928/3680
[A[ATraining Step: 7850  | total loss: [1m[32m0.36654[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36654 - acc: 0.8595 -- iter: 0960/3680
[A[ATraining Step: 7851  | total loss: [1m[32m0.36678[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36678 - acc: 0.8579 -- iter: 0992/3680
[A[ATraining Step: 7852  | total loss: [1m[32m0.38776[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38776 - acc: 0.8565 -- iter: 1024/3680
[A[ATraining Step: 7853  | total loss: [1m[32m0.37225[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37225 - acc: 0.8552 -- iter: 1056/3680
[A[ATraining Step: 7854  | total loss: [1m[32m0.37085[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37085 - acc: 0.8572 -- iter: 1088/3680
[A[ATraining Step: 7855  | total loss: [1m[32m0.36158[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36158 - acc: 0.8590 -- iter: 1120/3680
[A[ATraining Step: 7856  | total loss: [1m[32m0.48299[0m[0m
[2K| Adam | epoch: 069 | loss: 0.48299 - acc: 0.8293 -- iter: 1152/3680
[A[ATraining Step: 7857  | total loss: [1m[32m0.46520[0m[0m
[2K| Adam | epoch: 069 | loss: 0.46520 - acc: 0.8370 -- iter: 1184/3680
[A[ATraining Step: 7858  | total loss: [1m[32m0.44193[0m[0m
[2K| Adam | epoch: 069 | loss: 0.44193 - acc: 0.8439 -- iter: 1216/3680
[A[ATraining Step: 7859  | total loss: [1m[32m0.43218[0m[0m
[2K| Adam | epoch: 069 | loss: 0.43218 - acc: 0.8408 -- iter: 1248/3680
[A[ATraining Step: 7860  | total loss: [1m[32m0.45353[0m[0m
[2K| Adam | epoch: 069 | loss: 0.45353 - acc: 0.8223 -- iter: 1280/3680
[A[ATraining Step: 7861  | total loss: [1m[32m0.43870[0m[0m
[2K| Adam | epoch: 069 | loss: 0.43870 - acc: 0.8307 -- iter: 1312/3680
[A[ATraining Step: 7862  | total loss: [1m[32m0.42546[0m[0m
[2K| Adam | epoch: 069 | loss: 0.42546 - acc: 0.8352 -- iter: 1344/3680
[A[ATraining Step: 7863  | total loss: [1m[32m0.40765[0m[0m
[2K| Adam | epoch: 069 | loss: 0.40765 - acc: 0.8480 -- iter: 1376/3680
[A[ATraining Step: 7864  | total loss: [1m[32m0.40765[0m[0m
[2K| Adam | epoch: 069 | loss: 0.40765 - acc: 0.8480 -- iter: 1408/3680
[A[ATraining Step: 7865  | total loss: [1m[32m0.40002[0m[0m
[2K| Adam | epoch: 069 | loss: 0.40002 - acc: 0.8507 -- iter: 1440/3680
[A[ATraining Step: 7866  | total loss: [1m[32m0.37857[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37857 - acc: 0.8625 -- iter: 1472/3680
[A[ATraining Step: 7867  | total loss: [1m[32m0.35911[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35911 - acc: 0.8700 -- iter: 1504/3680
[A[ATraining Step: 7868  | total loss: [1m[32m0.36102[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36102 - acc: 0.8643 -- iter: 1536/3680
[A[ATraining Step: 7869  | total loss: [1m[32m0.35034[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35034 - acc: 0.8716 -- iter: 1568/3680
[A[ATraining Step: 7870  | total loss: [1m[32m0.33984[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33984 - acc: 0.8813 -- iter: 1600/3680
[A[ATraining Step: 7871  | total loss: [1m[32m0.32896[0m[0m
[2K| Adam | epoch: 069 | loss: 0.32896 - acc: 0.8838 -- iter: 1632/3680
[A[ATraining Step: 7872  | total loss: [1m[32m0.34842[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34842 - acc: 0.8767 -- iter: 1664/3680
[A[ATraining Step: 7873  | total loss: [1m[32m0.34561[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34561 - acc: 0.8671 -- iter: 1696/3680
[A[ATraining Step: 7874  | total loss: [1m[32m0.34501[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34501 - acc: 0.8679 -- iter: 1728/3680
[A[ATraining Step: 7875  | total loss: [1m[32m0.34035[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34035 - acc: 0.8718 -- iter: 1760/3680
[A[ATraining Step: 7876  | total loss: [1m[32m0.33235[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33235 - acc: 0.8749 -- iter: 1792/3680
[A[ATraining Step: 7877  | total loss: [1m[32m0.33702[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33702 - acc: 0.8749 -- iter: 1824/3680
[A[ATraining Step: 7878  | total loss: [1m[32m0.32617[0m[0m
[2K| Adam | epoch: 069 | loss: 0.32617 - acc: 0.8811 -- iter: 1856/3680
[A[ATraining Step: 7879  | total loss: [1m[32m0.32472[0m[0m
[2K| Adam | epoch: 069 | loss: 0.32472 - acc: 0.8805 -- iter: 1888/3680
[A[ATraining Step: 7880  | total loss: [1m[32m0.32286[0m[0m
[2K| Adam | epoch: 069 | loss: 0.32286 - acc: 0.8768 -- iter: 1920/3680
[A[ATraining Step: 7881  | total loss: [1m[32m0.31056[0m[0m
[2K| Adam | epoch: 069 | loss: 0.31056 - acc: 0.8829 -- iter: 1952/3680
[A[ATraining Step: 7882  | total loss: [1m[32m0.30014[0m[0m
[2K| Adam | epoch: 069 | loss: 0.30014 - acc: 0.8884 -- iter: 1984/3680
[A[ATraining Step: 7883  | total loss: [1m[32m0.30912[0m[0m
[2K| Adam | epoch: 069 | loss: 0.30912 - acc: 0.8839 -- iter: 2016/3680
[A[ATraining Step: 7884  | total loss: [1m[32m0.30259[0m[0m
[2K| Adam | epoch: 069 | loss: 0.30259 - acc: 0.8893 -- iter: 2048/3680
[A[ATraining Step: 7885  | total loss: [1m[32m0.29252[0m[0m
[2K| Adam | epoch: 069 | loss: 0.29252 - acc: 0.8972 -- iter: 2080/3680
[A[ATraining Step: 7886  | total loss: [1m[32m0.30134[0m[0m
[2K| Adam | epoch: 069 | loss: 0.30134 - acc: 0.8927 -- iter: 2112/3680
[A[ATraining Step: 7887  | total loss: [1m[32m0.30693[0m[0m
[2K| Adam | epoch: 069 | loss: 0.30693 - acc: 0.8927 -- iter: 2144/3680
[A[ATraining Step: 7888  | total loss: [1m[32m0.31927[0m[0m
[2K| Adam | epoch: 069 | loss: 0.31927 - acc: 0.8784 -- iter: 2176/3680
[A[ATraining Step: 7889  | total loss: [1m[32m0.37453[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37453 - acc: 0.8656 -- iter: 2208/3680
[A[ATraining Step: 7890  | total loss: [1m[32m0.37940[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37940 - acc: 0.8603 -- iter: 2240/3680
[A[ATraining Step: 7891  | total loss: [1m[32m0.36345[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36345 - acc: 0.8680 -- iter: 2272/3680
[A[ATraining Step: 7892  | total loss: [1m[32m0.36986[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36986 - acc: 0.8656 -- iter: 2304/3680
[A[ATraining Step: 7893  | total loss: [1m[32m0.36266[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36266 - acc: 0.8665 -- iter: 2336/3680
[A[ATraining Step: 7894  | total loss: [1m[32m0.34668[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34668 - acc: 0.8736 -- iter: 2368/3680
[A[ATraining Step: 7895  | total loss: [1m[32m0.34357[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34357 - acc: 0.8737 -- iter: 2400/3680
[A[ATraining Step: 7896  | total loss: [1m[32m0.33947[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33947 - acc: 0.8707 -- iter: 2432/3680
[A[ATraining Step: 7897  | total loss: [1m[32m0.33815[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33815 - acc: 0.8680 -- iter: 2464/3680
[A[ATraining Step: 7898  | total loss: [1m[32m0.36319[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36319 - acc: 0.8625 -- iter: 2496/3680
[A[ATraining Step: 7899  | total loss: [1m[32m0.36510[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36510 - acc: 0.8606 -- iter: 2528/3680
[A[ATraining Step: 7900  | total loss: [1m[32m0.36080[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36080 - acc: 0.8558 | val_loss: 0.29766 - val_acc: 0.8914 -- iter: 2560/3680
[A[ATraining Step: 7900  | total loss: [1m[32m0.36080[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36080 - acc: 0.8558 | val_loss: 0.29766 - val_acc: 0.8914 -- iter: 2560/3680
--
Training Step: 7901  | total loss: [1m[32m0.38755[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38755 - acc: 0.8484 -- iter: 2592/3680
[A[ATraining Step: 7902  | total loss: [1m[32m0.39296[0m[0m
[2K| Adam | epoch: 069 | loss: 0.39296 - acc: 0.8465 -- iter: 2624/3680
[A[ATraining Step: 7903  | total loss: [1m[32m0.39296[0m[0m
[2K| Adam | epoch: 069 | loss: 0.39296 - acc: 0.8465 -- iter: 2656/3680
[A[ATraining Step: 7904  | total loss: [1m[32m0.38505[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38505 - acc: 0.8431 -- iter: 2688/3680
[A[ATraining Step: 7905  | total loss: [1m[32m0.38750[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38750 - acc: 0.8432 -- iter: 2720/3680
[A[ATraining Step: 7906  | total loss: [1m[32m0.37704[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37704 - acc: 0.8464 -- iter: 2752/3680
[A[ATraining Step: 7907  | total loss: [1m[32m0.36798[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36798 - acc: 0.8524 -- iter: 2784/3680
[A[ATraining Step: 7908  | total loss: [1m[32m0.36644[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36644 - acc: 0.8546 -- iter: 2816/3680
[A[ATraining Step: 7909  | total loss: [1m[32m0.36636[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36636 - acc: 0.8588 -- iter: 2848/3680
[A[ATraining Step: 7910  | total loss: [1m[32m0.35112[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35112 - acc: 0.8588 -- iter: 2880/3680
[A[ATraining Step: 7911  | total loss: [1m[32m0.34069[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34069 - acc: 0.8636 -- iter: 2912/3680
[A[ATraining Step: 7912  | total loss: [1m[32m0.33180[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33180 - acc: 0.8741 -- iter: 2944/3680
[A[ATraining Step: 7913  | total loss: [1m[32m0.40194[0m[0m
[2K| Adam | epoch: 069 | loss: 0.40194 - acc: 0.8742 -- iter: 2976/3680
[A[ATraining Step: 7914  | total loss: [1m[32m0.38182[0m[0m
[2K| Adam | epoch: 069 | loss: 0.38182 - acc: 0.8805 -- iter: 3008/3680
[A[ATraining Step: 7915  | total loss: [1m[32m0.37011[0m[0m
[2K| Adam | epoch: 069 | loss: 0.37011 - acc: 0.8862 -- iter: 3040/3680
[A[ATraining Step: 7916  | total loss: [1m[32m0.36981[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36981 - acc: 0.8851 -- iter: 3072/3680
[A[ATraining Step: 7917  | total loss: [1m[32m0.36530[0m[0m
[2K| Adam | epoch: 069 | loss: 0.36530 - acc: 0.8841 -- iter: 3104/3680
[A[ATraining Step: 7918  | total loss: [1m[32m0.34557[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34557 - acc: 0.8894 -- iter: 3136/3680
[A[ATraining Step: 7919  | total loss: [1m[32m0.35860[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35860 - acc: 0.8755 -- iter: 3168/3680
[A[ATraining Step: 7920  | total loss: [1m[32m0.35716[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35716 - acc: 0.8723 -- iter: 3200/3680
[A[ATraining Step: 7921  | total loss: [1m[32m0.34833[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34833 - acc: 0.8728 -- iter: 3232/3680
[A[ATraining Step: 7922  | total loss: [1m[32m0.33924[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33924 - acc: 0.8793 -- iter: 3264/3680
[A[ATraining Step: 7923  | total loss: [1m[32m0.33924[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33924 - acc: 0.8793 -- iter: 3296/3680
[A[ATraining Step: 7924  | total loss: [1m[32m0.33505[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33505 - acc: 0.8851 -- iter: 3328/3680
[A[ATraining Step: 7925  | total loss: [1m[32m0.35462[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35462 - acc: 0.8653 -- iter: 3360/3680
[A[ATraining Step: 7926  | total loss: [1m[32m0.35163[0m[0m
[2K| Adam | epoch: 069 | loss: 0.35163 - acc: 0.8694 -- iter: 3392/3680
[A[ATraining Step: 7927  | total loss: [1m[32m0.34650[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34650 - acc: 0.8762 -- iter: 3424/3680
[A[ATraining Step: 7928  | total loss: [1m[32m0.33430[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33430 - acc: 0.8844 -- iter: 3456/3680
[A[ATraining Step: 7929  | total loss: [1m[32m0.32926[0m[0m
[2K| Adam | epoch: 069 | loss: 0.32926 - acc: 0.8844 -- iter: 3488/3680
[A[ATraining Step: 7930  | total loss: [1m[32m0.32595[0m[0m
[2K| Adam | epoch: 069 | loss: 0.32595 - acc: 0.8835 -- iter: 3520/3680
[A[ATraining Step: 7931  | total loss: [1m[32m0.33272[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33272 - acc: 0.8728 -- iter: 3552/3680
[A[ATraining Step: 7932  | total loss: [1m[32m0.34011[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34011 - acc: 0.8728 -- iter: 3584/3680
[A[ATraining Step: 7933  | total loss: [1m[32m0.33488[0m[0m
[2K| Adam | epoch: 069 | loss: 0.33488 - acc: 0.8762 -- iter: 3616/3680
[A[ATraining Step: 7934  | total loss: [1m[32m0.34032[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34032 - acc: 0.8792 -- iter: 3648/3680
[A[ATraining Step: 7935  | total loss: [1m[32m0.34098[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34098 - acc: 0.8721 | val_loss: 0.28725 - val_acc: 0.8969 -- iter: 3680/3680
[A[ATraining Step: 7935  | total loss: [1m[32m0.34098[0m[0m
[2K| Adam | epoch: 069 | loss: 0.34098 - acc: 0.8721 | val_loss: 0.28725 - val_acc: 0.8969 -- iter: 3680/3680
--
Training Step: 7936  | total loss: [1m[32m0.34098[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34098 - acc: 0.8721 -- iter: 0032/3680
[A[ATraining Step: 7937  | total loss: [1m[32m0.35297[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35297 - acc: 0.8724 -- iter: 0064/3680
[A[ATraining Step: 7938  | total loss: [1m[32m0.35626[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35626 - acc: 0.8633 -- iter: 0096/3680
[A[ATraining Step: 7939  | total loss: [1m[32m0.34372[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34372 - acc: 0.8655 -- iter: 0128/3680
[A[ATraining Step: 7940  | total loss: [1m[32m0.34372[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34372 - acc: 0.8655 -- iter: 0160/3680
[A[ATraining Step: 7941  | total loss: [1m[32m0.33913[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33913 - acc: 0.8633 -- iter: 0192/3680
[A[ATraining Step: 7942  | total loss: [1m[32m0.34686[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34686 - acc: 0.8676 -- iter: 0224/3680
[A[ATraining Step: 7943  | total loss: [1m[32m0.33968[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33968 - acc: 0.8715 -- iter: 0256/3680
[A[ATraining Step: 7944  | total loss: [1m[32m0.35509[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35509 - acc: 0.8625 -- iter: 0288/3680
[A[ATraining Step: 7945  | total loss: [1m[32m0.36573[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36573 - acc: 0.8606 -- iter: 0320/3680
[A[ATraining Step: 7946  | total loss: [1m[32m0.35649[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35649 - acc: 0.8683 -- iter: 0352/3680
[A[ATraining Step: 7947  | total loss: [1m[32m0.36187[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36187 - acc: 0.8752 -- iter: 0384/3680
[A[ATraining Step: 7948  | total loss: [1m[32m0.37220[0m[0m
[2K| Adam | epoch: 070 | loss: 0.37220 - acc: 0.8596 -- iter: 0416/3680
[A[ATraining Step: 7949  | total loss: [1m[32m0.37019[0m[0m
[2K| Adam | epoch: 070 | loss: 0.37019 - acc: 0.8580 -- iter: 0448/3680
[A[ATraining Step: 7950  | total loss: [1m[32m0.36969[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36969 - acc: 0.8597 -- iter: 0480/3680
[A[ATraining Step: 7951  | total loss: [1m[32m0.35955[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35955 - acc: 0.8643 -- iter: 0512/3680
[A[ATraining Step: 7952  | total loss: [1m[32m0.35876[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35876 - acc: 0.8654 -- iter: 0544/3680
[A[ATraining Step: 7953  | total loss: [1m[32m0.34787[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34787 - acc: 0.8695 -- iter: 0576/3680
[A[ATraining Step: 7954  | total loss: [1m[32m0.35559[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35559 - acc: 0.8638 -- iter: 0608/3680
[A[ATraining Step: 7955  | total loss: [1m[32m0.35806[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35806 - acc: 0.8587 -- iter: 0640/3680
[A[ATraining Step: 7956  | total loss: [1m[32m0.35436[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35436 - acc: 0.8572 -- iter: 0672/3680
[A[ATraining Step: 7957  | total loss: [1m[32m0.35079[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35079 - acc: 0.8590 -- iter: 0704/3680
[A[ATraining Step: 7958  | total loss: [1m[32m0.35396[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35396 - acc: 0.8637 -- iter: 0736/3680
[A[ATraining Step: 7959  | total loss: [1m[32m0.35801[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35801 - acc: 0.8617 -- iter: 0768/3680
[A[ATraining Step: 7960  | total loss: [1m[32m0.34966[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34966 - acc: 0.8693 -- iter: 0800/3680
[A[ATraining Step: 7961  | total loss: [1m[32m0.33372[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33372 - acc: 0.8761 -- iter: 0832/3680
[A[ATraining Step: 7962  | total loss: [1m[32m0.32008[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32008 - acc: 0.8854 -- iter: 0864/3680
[A[ATraining Step: 7963  | total loss: [1m[32m0.35405[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35405 - acc: 0.8725 -- iter: 0896/3680
[A[ATraining Step: 7964  | total loss: [1m[32m0.33792[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33792 - acc: 0.8725 -- iter: 0928/3680
[A[ATraining Step: 7965  | total loss: [1m[32m0.32627[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32627 - acc: 0.8758 -- iter: 0960/3680
[A[ATraining Step: 7966  | total loss: [1m[32m0.32651[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32651 - acc: 0.8726 -- iter: 0992/3680
[A[ATraining Step: 7967  | total loss: [1m[32m0.32925[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32925 - acc: 0.8700 -- iter: 1024/3680
[A[ATraining Step: 7968  | total loss: [1m[32m0.32519[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32519 - acc: 0.8700 -- iter: 1056/3680
[A[ATraining Step: 7969  | total loss: [1m[32m0.31039[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31039 - acc: 0.8767 -- iter: 1088/3680
[A[ATraining Step: 7970  | total loss: [1m[32m0.32027[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32027 - acc: 0.8703 -- iter: 1120/3680
[A[ATraining Step: 7971  | total loss: [1m[32m0.34198[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34198 - acc: 0.8676 -- iter: 1152/3680
[A[ATraining Step: 7972  | total loss: [1m[32m0.33442[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33442 - acc: 0.8715 -- iter: 1184/3680
[A[ATraining Step: 7973  | total loss: [1m[32m0.31805[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31805 - acc: 0.8812 -- iter: 1216/3680
[A[ATraining Step: 7974  | total loss: [1m[32m0.31757[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31757 - acc: 0.8775 -- iter: 1248/3680
[A[ATraining Step: 7975  | total loss: [1m[32m0.31300[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31300 - acc: 0.8772 -- iter: 1280/3680
[A[ATraining Step: 7976  | total loss: [1m[32m0.30116[0m[0m
[2K| Adam | epoch: 070 | loss: 0.30116 - acc: 0.8833 -- iter: 1312/3680
[A[ATraining Step: 7977  | total loss: [1m[32m0.31148[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31148 - acc: 0.8820 -- iter: 1344/3680
[A[ATraining Step: 7978  | total loss: [1m[32m0.31708[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31708 - acc: 0.8820 -- iter: 1376/3680
[A[ATraining Step: 7979  | total loss: [1m[32m0.33101[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33101 - acc: 0.8782 -- iter: 1408/3680
[A[ATraining Step: 7980  | total loss: [1m[32m0.31297[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31297 - acc: 0.8872 -- iter: 1440/3680
[A[ATraining Step: 7981  | total loss: [1m[32m0.29954[0m[0m
[2K| Adam | epoch: 070 | loss: 0.29954 - acc: 0.8923 -- iter: 1472/3680
[A[ATraining Step: 7982  | total loss: [1m[32m0.29914[0m[0m
[2K| Adam | epoch: 070 | loss: 0.29914 - acc: 0.8905 -- iter: 1504/3680
[A[ATraining Step: 7983  | total loss: [1m[32m0.29247[0m[0m
[2K| Adam | epoch: 070 | loss: 0.29247 - acc: 0.8921 -- iter: 1536/3680
[A[ATraining Step: 7984  | total loss: [1m[32m0.29433[0m[0m
[2K| Adam | epoch: 070 | loss: 0.29433 - acc: 0.8810 -- iter: 1568/3680
[A[ATraining Step: 7985  | total loss: [1m[32m0.28820[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28820 - acc: 0.8867 -- iter: 1600/3680
[A[ATraining Step: 7986  | total loss: [1m[32m0.28247[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28247 - acc: 0.8886 -- iter: 1632/3680
[A[ATraining Step: 7987  | total loss: [1m[32m0.29053[0m[0m
[2K| Adam | epoch: 070 | loss: 0.29053 - acc: 0.8841 -- iter: 1664/3680
[A[ATraining Step: 7988  | total loss: [1m[32m0.28180[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28180 - acc: 0.8926 -- iter: 1696/3680
[A[ATraining Step: 7989  | total loss: [1m[32m0.28721[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28721 - acc: 0.8877 -- iter: 1728/3680
[A[ATraining Step: 7990  | total loss: [1m[32m0.28466[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28466 - acc: 0.8896 -- iter: 1760/3680
[A[ATraining Step: 7991  | total loss: [1m[32m0.28492[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28492 - acc: 0.8912 -- iter: 1792/3680
[A[ATraining Step: 7992  | total loss: [1m[32m0.28283[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28283 - acc: 0.8865 -- iter: 1824/3680
[A[ATraining Step: 7993  | total loss: [1m[32m0.28006[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28006 - acc: 0.8947 -- iter: 1856/3680
[A[ATraining Step: 7994  | total loss: [1m[32m0.27853[0m[0m
[2K| Adam | epoch: 070 | loss: 0.27853 - acc: 0.8927 -- iter: 1888/3680
[A[ATraining Step: 7995  | total loss: [1m[32m0.31856[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31856 - acc: 0.8653 -- iter: 1920/3680
[A[ATraining Step: 7996  | total loss: [1m[32m0.31856[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31856 - acc: 0.8653 -- iter: 1952/3680
[A[ATraining Step: 7997  | total loss: [1m[32m0.32534[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32534 - acc: 0.8694 -- iter: 1984/3680
[A[ATraining Step: 7998  | total loss: [1m[32m0.31477[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31477 - acc: 0.8731 -- iter: 2016/3680
[A[ATraining Step: 7999  | total loss: [1m[32m0.30659[0m[0m
[2K| Adam | epoch: 070 | loss: 0.30659 - acc: 0.8795 -- iter: 2048/3680
[A[ATraining Step: 8000  | total loss: [1m[32m0.28793[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28793 - acc: 0.8916 | val_loss: 0.33515 - val_acc: 0.8686 -- iter: 2080/3680
[A[ATraining Step: 8000  | total loss: [1m[32m0.28793[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28793 - acc: 0.8916 | val_loss: 0.33515 - val_acc: 0.8686 -- iter: 2080/3680
--
Training Step: 8001  | total loss: [1m[32m0.28915[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28915 - acc: 0.8941 -- iter: 2112/3680
[A[ATraining Step: 8002  | total loss: [1m[32m0.29397[0m[0m
[2K| Adam | epoch: 070 | loss: 0.29397 - acc: 0.8941 -- iter: 2144/3680
[A[ATraining Step: 8003  | total loss: [1m[32m0.28773[0m[0m
[2K| Adam | epoch: 070 | loss: 0.28773 - acc: 0.8953 -- iter: 2176/3680
[A[ATraining Step: 8004  | total loss: [1m[32m0.30203[0m[0m
[2K| Adam | epoch: 070 | loss: 0.30203 - acc: 0.8901 -- iter: 2208/3680
[A[ATraining Step: 8005  | total loss: [1m[32m0.30825[0m[0m
[2K| Adam | epoch: 070 | loss: 0.30825 - acc: 0.8824 -- iter: 2240/3680
[A[ATraining Step: 8006  | total loss: [1m[32m0.31499[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31499 - acc: 0.8754 -- iter: 2272/3680
[A[ATraining Step: 8007  | total loss: [1m[32m0.31180[0m[0m
[2K| Adam | epoch: 070 | loss: 0.31180 - acc: 0.8753 -- iter: 2304/3680
[A[ATraining Step: 8008  | total loss: [1m[32m0.34311[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34311 - acc: 0.8659 -- iter: 2336/3680
[A[ATraining Step: 8009  | total loss: [1m[32m0.34145[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34145 - acc: 0.8668 -- iter: 2368/3680
[A[ATraining Step: 8010  | total loss: [1m[32m0.34586[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34586 - acc: 0.8677 -- iter: 2400/3680
[A[ATraining Step: 8011  | total loss: [1m[32m0.33705[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33705 - acc: 0.8715 -- iter: 2432/3680
[A[ATraining Step: 8012  | total loss: [1m[32m0.32897[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32897 - acc: 0.8628 -- iter: 2464/3680
[A[ATraining Step: 8013  | total loss: [1m[32m0.35254[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35254 - acc: 0.8628 -- iter: 2496/3680
[A[ATraining Step: 8014  | total loss: [1m[32m0.34130[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34130 - acc: 0.8645 -- iter: 2528/3680
[A[ATraining Step: 8015  | total loss: [1m[32m0.33861[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33861 - acc: 0.8645 -- iter: 2560/3680
[A[ATraining Step: 8016  | total loss: [1m[32m0.34114[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34114 - acc: 0.8624 -- iter: 2592/3680
[A[ATraining Step: 8017  | total loss: [1m[32m0.33970[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33970 - acc: 0.8668 -- iter: 2624/3680
[A[ATraining Step: 8018  | total loss: [1m[32m0.35134[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35134 - acc: 0.8645 -- iter: 2656/3680
[A[ATraining Step: 8019  | total loss: [1m[32m0.34432[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34432 - acc: 0.8687 -- iter: 2688/3680
[A[ATraining Step: 8020  | total loss: [1m[32m0.33710[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33710 - acc: 0.8693 -- iter: 2720/3680
[A[ATraining Step: 8021  | total loss: [1m[32m0.35215[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35215 - acc: 0.8636 -- iter: 2752/3680
[A[ATraining Step: 8022  | total loss: [1m[32m0.35416[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35416 - acc: 0.8616 -- iter: 2784/3680
[A[ATraining Step: 8023  | total loss: [1m[32m0.33604[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33604 - acc: 0.8723 -- iter: 2816/3680
[A[ATraining Step: 8024  | total loss: [1m[32m0.33171[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33171 - acc: 0.8757 -- iter: 2848/3680
[A[ATraining Step: 8025  | total loss: [1m[32m0.32934[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32934 - acc: 0.8819 -- iter: 2880/3680
[A[ATraining Step: 8026  | total loss: [1m[32m0.32453[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32453 - acc: 0.8875 -- iter: 2912/3680
[A[ATraining Step: 8027  | total loss: [1m[32m0.33191[0m[0m
[2K| Adam | epoch: 070 | loss: 0.33191 - acc: 0.8800 -- iter: 2944/3680
[A[ATraining Step: 8028  | total loss: [1m[32m0.34076[0m[0m
[2K| Adam | epoch: 070 | loss: 0.34076 - acc: 0.8764 -- iter: 2976/3680
[A[ATraining Step: 8029  | total loss: [1m[32m0.32974[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32974 - acc: 0.8820 -- iter: 3008/3680
[A[ATraining Step: 8030  | total loss: [1m[32m0.32974[0m[0m
[2K| Adam | epoch: 070 | loss: 0.32974 - acc: 0.8820 -- iter: 3040/3680
[A[ATraining Step: 8031  | total loss: [1m[32m0.35577[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35577 - acc: 0.8626 -- iter: 3072/3680
[A[ATraining Step: 8032  | total loss: [1m[32m0.35665[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35665 - acc: 0.8607 -- iter: 3104/3680
[A[ATraining Step: 8033  | total loss: [1m[32m0.36871[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36871 - acc: 0.8465 -- iter: 3136/3680
[A[ATraining Step: 8034  | total loss: [1m[32m0.38857[0m[0m
[2K| Adam | epoch: 070 | loss: 0.38857 - acc: 0.8337 -- iter: 3168/3680
[A[ATraining Step: 8035  | total loss: [1m[32m0.38286[0m[0m
[2K| Adam | epoch: 070 | loss: 0.38286 - acc: 0.8379 -- iter: 3200/3680
[A[ATraining Step: 8036  | total loss: [1m[32m0.37761[0m[0m
[2K| Adam | epoch: 070 | loss: 0.37761 - acc: 0.8416 -- iter: 3232/3680
[A[ATraining Step: 8037  | total loss: [1m[32m0.37299[0m[0m
[2K| Adam | epoch: 070 | loss: 0.37299 - acc: 0.8449 -- iter: 3264/3680
[A[ATraining Step: 8038  | total loss: [1m[32m0.36738[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36738 - acc: 0.8510 -- iter: 3296/3680
[A[ATraining Step: 8039  | total loss: [1m[32m0.38190[0m[0m
[2K| Adam | epoch: 070 | loss: 0.38190 - acc: 0.8472 -- iter: 3328/3680
[A[ATraining Step: 8040  | total loss: [1m[32m0.38758[0m[0m
[2K| Adam | epoch: 070 | loss: 0.38758 - acc: 0.8437 -- iter: 3360/3680
[A[ATraining Step: 8041  | total loss: [1m[32m0.37661[0m[0m
[2K| Adam | epoch: 070 | loss: 0.37661 - acc: 0.8468 -- iter: 3392/3680
[A[ATraining Step: 8042  | total loss: [1m[32m0.36830[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36830 - acc: 0.8528 -- iter: 3424/3680
[A[ATraining Step: 8043  | total loss: [1m[32m0.36959[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36959 - acc: 0.8488 -- iter: 3456/3680
[A[ATraining Step: 8044  | total loss: [1m[32m0.36399[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36399 - acc: 0.8545 -- iter: 3488/3680
[A[ATraining Step: 8045  | total loss: [1m[32m0.36758[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36758 - acc: 0.8534 -- iter: 3520/3680
[A[ATraining Step: 8046  | total loss: [1m[32m0.35854[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35854 - acc: 0.8556 -- iter: 3552/3680
[A[ATraining Step: 8047  | total loss: [1m[32m0.35948[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35948 - acc: 0.8544 -- iter: 3584/3680
[A[ATraining Step: 8048  | total loss: [1m[32m0.35386[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35386 - acc: 0.8502 -- iter: 3616/3680
[A[ATraining Step: 8049  | total loss: [1m[32m0.35666[0m[0m
[2K| Adam | epoch: 070 | loss: 0.35666 - acc: 0.8464 -- iter: 3648/3680
[A[ATraining Step: 8050  | total loss: [1m[32m0.36577[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36577 - acc: 0.8399 | val_loss: 0.30055 - val_acc: 0.8990 -- iter: 3680/3680
[A[ATraining Step: 8050  | total loss: [1m[32m0.36577[0m[0m
[2K| Adam | epoch: 070 | loss: 0.36577 - acc: 0.8399 | val_loss: 0.30055 - val_acc: 0.8990 -- iter: 3680/3680
--
Training Step: 8051  | total loss: [1m[32m0.35293[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35293 - acc: 0.8434 -- iter: 0032/3680
[A[ATraining Step: 8052  | total loss: [1m[32m0.34998[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34998 - acc: 0.8466 -- iter: 0064/3680
[A[ATraining Step: 8053  | total loss: [1m[32m0.36080[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36080 - acc: 0.8494 -- iter: 0096/3680
[A[ATraining Step: 8054  | total loss: [1m[32m0.35471[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35471 - acc: 0.8582 -- iter: 0128/3680
[A[ATraining Step: 8055  | total loss: [1m[32m0.33824[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33824 - acc: 0.8662 -- iter: 0160/3680
[A[ATraining Step: 8056  | total loss: [1m[32m0.33095[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33095 - acc: 0.8702 -- iter: 0192/3680
[A[ATraining Step: 8057  | total loss: [1m[32m0.32825[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32825 - acc: 0.8644 -- iter: 0224/3680
[A[ATraining Step: 8058  | total loss: [1m[32m0.32900[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32900 - acc: 0.8623 -- iter: 0256/3680
[A[ATraining Step: 8059  | total loss: [1m[32m0.34293[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34293 - acc: 0.8644 -- iter: 0288/3680
[A[ATraining Step: 8060  | total loss: [1m[32m0.34293[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34293 - acc: 0.8644 -- iter: 0320/3680
[A[ATraining Step: 8061  | total loss: [1m[32m0.33647[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33647 - acc: 0.8686 -- iter: 0352/3680
[A[ATraining Step: 8062  | total loss: [1m[32m0.35176[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35176 - acc: 0.8599 -- iter: 0384/3680
[A[ATraining Step: 8063  | total loss: [1m[32m0.35544[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35544 - acc: 0.8551 -- iter: 0416/3680
[A[ATraining Step: 8064  | total loss: [1m[32m0.34772[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34772 - acc: 0.8634 -- iter: 0448/3680
[A[ATraining Step: 8065  | total loss: [1m[32m0.34690[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34690 - acc: 0.8583 -- iter: 0480/3680
[A[ATraining Step: 8066  | total loss: [1m[32m0.33541[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33541 - acc: 0.8649 -- iter: 0512/3680
[A[ATraining Step: 8067  | total loss: [1m[32m0.33541[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33541 - acc: 0.8649 -- iter: 0544/3680
[A[ATraining Step: 8068  | total loss: [1m[32m0.32783[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32783 - acc: 0.8690 -- iter: 0576/3680
[A[ATraining Step: 8069  | total loss: [1m[32m0.32725[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32725 - acc: 0.8728 -- iter: 0608/3680
[A[ATraining Step: 8070  | total loss: [1m[32m0.32946[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32946 - acc: 0.8792 -- iter: 0640/3680
[A[ATraining Step: 8071  | total loss: [1m[32m0.32798[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32798 - acc: 0.8544 -- iter: 0672/3680
[A[ATraining Step: 8072  | total loss: [1m[32m0.34953[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34953 - acc: 0.8533 -- iter: 0704/3680
[A[ATraining Step: 8073  | total loss: [1m[32m0.34716[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34716 - acc: 0.8533 -- iter: 0736/3680
[A[ATraining Step: 8074  | total loss: [1m[32m0.34770[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34770 - acc: 0.8523 -- iter: 0768/3680
[A[ATraining Step: 8075  | total loss: [1m[32m0.34172[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34172 - acc: 0.8546 -- iter: 0800/3680
[A[ATraining Step: 8076  | total loss: [1m[32m0.34896[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34896 - acc: 0.8567 -- iter: 0832/3680
[A[ATraining Step: 8077  | total loss: [1m[32m0.33377[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33377 - acc: 0.8647 -- iter: 0864/3680
[A[ATraining Step: 8078  | total loss: [1m[32m0.34086[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34086 - acc: 0.8626 -- iter: 0896/3680
[A[ATraining Step: 8079  | total loss: [1m[32m0.32734[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32734 - acc: 0.8764 -- iter: 0928/3680
[A[ATraining Step: 8080  | total loss: [1m[32m0.33172[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33172 - acc: 0.8731 -- iter: 0960/3680
[A[ATraining Step: 8081  | total loss: [1m[32m0.32605[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32605 - acc: 0.8764 -- iter: 0992/3680
[A[ATraining Step: 8082  | total loss: [1m[32m0.33392[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33392 - acc: 0.8700 -- iter: 1024/3680
[A[ATraining Step: 8083  | total loss: [1m[32m0.33569[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33569 - acc: 0.8674 -- iter: 1056/3680
[A[ATraining Step: 8084  | total loss: [1m[32m0.35181[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35181 - acc: 0.8619 -- iter: 1088/3680
[A[ATraining Step: 8085  | total loss: [1m[32m0.37198[0m[0m
[2K| Adam | epoch: 071 | loss: 0.37198 - acc: 0.8476 -- iter: 1120/3680
[A[ATraining Step: 8086  | total loss: [1m[32m0.37097[0m[0m
[2K| Adam | epoch: 071 | loss: 0.37097 - acc: 0.8503 -- iter: 1152/3680
[A[ATraining Step: 8087  | total loss: [1m[32m0.36375[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36375 - acc: 0.8460 -- iter: 1184/3680
[A[ATraining Step: 8088  | total loss: [1m[32m0.36270[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36270 - acc: 0.8460 -- iter: 1216/3680
[A[ATraining Step: 8089  | total loss: [1m[32m0.36703[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36703 - acc: 0.8426 -- iter: 1248/3680
[A[ATraining Step: 8090  | total loss: [1m[32m0.35824[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35824 - acc: 0.8490 -- iter: 1280/3680
[A[ATraining Step: 8091  | total loss: [1m[32m0.35339[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35339 - acc: 0.8516 -- iter: 1312/3680
[A[ATraining Step: 8092  | total loss: [1m[32m0.33977[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33977 - acc: 0.8570 -- iter: 1344/3680
[A[ATraining Step: 8093  | total loss: [1m[32m0.33490[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33490 - acc: 0.8588 -- iter: 1376/3680
[A[ATraining Step: 8094  | total loss: [1m[32m0.35036[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35036 - acc: 0.8573 -- iter: 1408/3680
[A[ATraining Step: 8095  | total loss: [1m[32m0.32552[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32552 - acc: 0.8757 -- iter: 1440/3680
[A[ATraining Step: 8096  | total loss: [1m[32m0.32552[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32552 - acc: 0.8757 -- iter: 1472/3680
[A[ATraining Step: 8097  | total loss: [1m[32m0.32840[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32840 - acc: 0.8756 -- iter: 1504/3680
[A[ATraining Step: 8098  | total loss: [1m[32m0.33526[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33526 - acc: 0.8756 -- iter: 1536/3680
[A[ATraining Step: 8099  | total loss: [1m[32m0.33574[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33574 - acc: 0.8755 -- iter: 1568/3680
[A[ATraining Step: 8100  | total loss: [1m[32m0.34071[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34071 - acc: 0.8726 | val_loss: 0.30226 - val_acc: 0.8903 -- iter: 1600/3680
[A[ATraining Step: 8100  | total loss: [1m[32m0.34071[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34071 - acc: 0.8726 | val_loss: 0.30226 - val_acc: 0.8903 -- iter: 1600/3680
--
Training Step: 8101  | total loss: [1m[32m0.34404[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34404 - acc: 0.8726 -- iter: 1632/3680
[A[ATraining Step: 8102  | total loss: [1m[32m0.33826[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33826 - acc: 0.8728 -- iter: 1664/3680
[A[ATraining Step: 8103  | total loss: [1m[32m0.34836[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34836 - acc: 0.8699 -- iter: 1696/3680
[A[ATraining Step: 8104  | total loss: [1m[32m0.34499[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34499 - acc: 0.8704 -- iter: 1728/3680
[A[ATraining Step: 8105  | total loss: [1m[32m0.32949[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32949 - acc: 0.8771 -- iter: 1760/3680
[A[ATraining Step: 8106  | total loss: [1m[32m0.31767[0m[0m
[2K| Adam | epoch: 071 | loss: 0.31767 - acc: 0.8801 -- iter: 1792/3680
[A[ATraining Step: 8107  | total loss: [1m[32m0.30998[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30998 - acc: 0.8795 -- iter: 1824/3680
[A[ATraining Step: 8108  | total loss: [1m[32m0.30699[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30699 - acc: 0.8791 -- iter: 1856/3680
[A[ATraining Step: 8109  | total loss: [1m[32m0.31074[0m[0m
[2K| Adam | epoch: 071 | loss: 0.31074 - acc: 0.8756 -- iter: 1888/3680
[A[ATraining Step: 8110  | total loss: [1m[32m0.30787[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30787 - acc: 0.8786 -- iter: 1920/3680
[A[ATraining Step: 8111  | total loss: [1m[32m0.31257[0m[0m
[2K| Adam | epoch: 071 | loss: 0.31257 - acc: 0.8783 -- iter: 1952/3680
[A[ATraining Step: 8112  | total loss: [1m[32m0.31050[0m[0m
[2K| Adam | epoch: 071 | loss: 0.31050 - acc: 0.8748 -- iter: 1984/3680
[A[ATraining Step: 8113  | total loss: [1m[32m0.29477[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29477 - acc: 0.8842 -- iter: 2016/3680
[A[ATraining Step: 8114  | total loss: [1m[32m0.29635[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29635 - acc: 0.8833 -- iter: 2048/3680
[A[ATraining Step: 8115  | total loss: [1m[32m0.30883[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30883 - acc: 0.8731 -- iter: 2080/3680
[A[ATraining Step: 8116  | total loss: [1m[32m0.32145[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32145 - acc: 0.8670 -- iter: 2112/3680
[A[ATraining Step: 8117  | total loss: [1m[32m0.34057[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34057 - acc: 0.8584 -- iter: 2144/3680
[A[ATraining Step: 8118  | total loss: [1m[32m0.32473[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32473 - acc: 0.8695 -- iter: 2176/3680
[A[ATraining Step: 8119  | total loss: [1m[32m0.32966[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32966 - acc: 0.8607 -- iter: 2208/3680
[A[ATraining Step: 8120  | total loss: [1m[32m0.32499[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32499 - acc: 0.8590 -- iter: 2240/3680
[A[ATraining Step: 8121  | total loss: [1m[32m0.30846[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30846 - acc: 0.8731 -- iter: 2272/3680
[A[ATraining Step: 8122  | total loss: [1m[32m0.30848[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30848 - acc: 0.8733 -- iter: 2304/3680
[A[ATraining Step: 8123  | total loss: [1m[32m0.31465[0m[0m
[2K| Adam | epoch: 071 | loss: 0.31465 - acc: 0.8766 -- iter: 2336/3680
[A[ATraining Step: 8124  | total loss: [1m[32m0.30739[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30739 - acc: 0.8795 -- iter: 2368/3680
[A[ATraining Step: 8125  | total loss: [1m[32m0.30690[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30690 - acc: 0.8760 -- iter: 2400/3680
[A[ATraining Step: 8126  | total loss: [1m[32m0.32438[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32438 - acc: 0.8602 -- iter: 2432/3680
[A[ATraining Step: 8127  | total loss: [1m[32m0.33157[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33157 - acc: 0.8577 -- iter: 2464/3680
[A[ATraining Step: 8128  | total loss: [1m[32m0.32241[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32241 - acc: 0.8577 -- iter: 2496/3680
[A[ATraining Step: 8129  | total loss: [1m[32m0.32955[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32955 - acc: 0.8563 -- iter: 2528/3680
[A[ATraining Step: 8130  | total loss: [1m[32m0.32874[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32874 - acc: 0.8551 -- iter: 2560/3680
[A[ATraining Step: 8131  | total loss: [1m[32m0.32132[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32132 - acc: 0.8633 -- iter: 2592/3680
[A[ATraining Step: 8132  | total loss: [1m[32m0.30187[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30187 - acc: 0.8687 -- iter: 2624/3680
[A[ATraining Step: 8133  | total loss: [1m[32m0.30187[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30187 - acc: 0.8687 -- iter: 2656/3680
[A[ATraining Step: 8134  | total loss: [1m[32m0.30893[0m[0m
[2K| Adam | epoch: 071 | loss: 0.30893 - acc: 0.8662 -- iter: 2688/3680
[A[ATraining Step: 8135  | total loss: [1m[32m0.32878[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32878 - acc: 0.8672 -- iter: 2720/3680
[A[ATraining Step: 8136  | total loss: [1m[32m0.32878[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32878 - acc: 0.8672 -- iter: 2752/3680
[A[ATraining Step: 8137  | total loss: [1m[32m0.33505[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33505 - acc: 0.8649 -- iter: 2784/3680
[A[ATraining Step: 8138  | total loss: [1m[32m0.33465[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33465 - acc: 0.8596 -- iter: 2816/3680
[A[ATraining Step: 8139  | total loss: [1m[32m0.33808[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33808 - acc: 0.8580 -- iter: 2848/3680
[A[ATraining Step: 8140  | total loss: [1m[32m0.34734[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34734 - acc: 0.8566 -- iter: 2880/3680
[A[ATraining Step: 8141  | total loss: [1m[32m0.36326[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36326 - acc: 0.8460 -- iter: 2912/3680
[A[ATraining Step: 8142  | total loss: [1m[32m0.34800[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34800 - acc: 0.8480 -- iter: 2944/3680
[A[ATraining Step: 8143  | total loss: [1m[32m0.34969[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34969 - acc: 0.8480 -- iter: 2976/3680
[A[ATraining Step: 8144  | total loss: [1m[32m0.34484[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34484 - acc: 0.8539 -- iter: 3008/3680
[A[ATraining Step: 8145  | total loss: [1m[32m0.35114[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35114 - acc: 0.8528 -- iter: 3040/3680
[A[ATraining Step: 8146  | total loss: [1m[32m0.35385[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35385 - acc: 0.8519 -- iter: 3072/3680
[A[ATraining Step: 8147  | total loss: [1m[32m0.34101[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34101 - acc: 0.8605 -- iter: 3104/3680
[A[ATraining Step: 8148  | total loss: [1m[32m0.33193[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33193 - acc: 0.8651 -- iter: 3136/3680
[A[ATraining Step: 8149  | total loss: [1m[32m0.34628[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34628 - acc: 0.8598 -- iter: 3168/3680
[A[ATraining Step: 8150  | total loss: [1m[32m0.35222[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35222 - acc: 0.8582 -- iter: 3200/3680
[A[ATraining Step: 8151  | total loss: [1m[32m0.35014[0m[0m
[2K| Adam | epoch: 071 | loss: 0.35014 - acc: 0.8568 -- iter: 3232/3680
[A[ATraining Step: 8152  | total loss: [1m[32m0.36353[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36353 - acc: 0.8492 -- iter: 3264/3680
[A[ATraining Step: 8153  | total loss: [1m[32m0.37482[0m[0m
[2K| Adam | epoch: 071 | loss: 0.37482 - acc: 0.8393 -- iter: 3296/3680
[A[ATraining Step: 8154  | total loss: [1m[32m0.36516[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36516 - acc: 0.8429 -- iter: 3328/3680
[A[ATraining Step: 8155  | total loss: [1m[32m0.36453[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36453 - acc: 0.8396 -- iter: 3360/3680
[A[ATraining Step: 8156  | total loss: [1m[32m0.36453[0m[0m
[2K| Adam | epoch: 071 | loss: 0.36453 - acc: 0.8396 -- iter: 3392/3680
[A[ATraining Step: 8157  | total loss: [1m[32m0.34993[0m[0m
[2K| Adam | epoch: 071 | loss: 0.34993 - acc: 0.8463 -- iter: 3424/3680
[A[ATraining Step: 8158  | total loss: [1m[32m0.33375[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33375 - acc: 0.8523 -- iter: 3456/3680
[A[ATraining Step: 8159  | total loss: [1m[32m0.33303[0m[0m
[2K| Adam | epoch: 071 | loss: 0.33303 - acc: 0.8514 -- iter: 3488/3680
[A[ATraining Step: 8160  | total loss: [1m[32m0.31878[0m[0m
[2K| Adam | epoch: 071 | loss: 0.31878 - acc: 0.8600 -- iter: 3520/3680
[A[ATraining Step: 8161  | total loss: [1m[32m0.32071[0m[0m
[2K| Adam | epoch: 071 | loss: 0.32071 - acc: 0.8521 -- iter: 3552/3680
[A[ATraining Step: 8162  | total loss: [1m[32m0.29978[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29978 - acc: 0.8544 -- iter: 3584/3680
[A[ATraining Step: 8163  | total loss: [1m[32m0.29978[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29978 - acc: 0.8659 -- iter: 3616/3680
[A[ATraining Step: 8164  | total loss: [1m[32m0.29608[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29608 - acc: 0.8730 -- iter: 3648/3680
[A[ATraining Step: 8165  | total loss: [1m[32m0.29514[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29514 - acc: 0.8763 | val_loss: 0.35216 - val_acc: 0.8588 -- iter: 3680/3680
[A[ATraining Step: 8165  | total loss: [1m[32m0.29514[0m[0m
[2K| Adam | epoch: 071 | loss: 0.29514 - acc: 0.8763 | val_loss: 0.35216 - val_acc: 0.8588 -- iter: 3680/3680
--
Training Step: 8166  | total loss: [1m[32m0.30387[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30387 - acc: 0.8705 -- iter: 0032/3680
[A[ATraining Step: 8167  | total loss: [1m[32m0.29716[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29716 - acc: 0.8705 -- iter: 0064/3680
[A[ATraining Step: 8168  | total loss: [1m[32m0.29547[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29547 - acc: 0.8678 -- iter: 0096/3680
[A[ATraining Step: 8169  | total loss: [1m[32m0.33229[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33229 - acc: 0.8542 -- iter: 0128/3680
[A[ATraining Step: 8170  | total loss: [1m[32m0.33229[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33229 - acc: 0.8542 -- iter: 0160/3680
[A[ATraining Step: 8171  | total loss: [1m[32m0.33437[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33437 - acc: 0.8594 -- iter: 0192/3680
[A[ATraining Step: 8172  | total loss: [1m[32m0.33568[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33568 - acc: 0.8609 -- iter: 0224/3680
[A[ATraining Step: 8173  | total loss: [1m[32m0.33912[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33912 - acc: 0.8623 -- iter: 0256/3680
[A[ATraining Step: 8174  | total loss: [1m[32m0.32772[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32772 - acc: 0.8699 -- iter: 0288/3680
[A[ATraining Step: 8175  | total loss: [1m[32m0.34243[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34243 - acc: 0.8652 -- iter: 0320/3680
[A[ATraining Step: 8176  | total loss: [1m[32m0.34243[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34243 - acc: 0.8652 -- iter: 0352/3680
[A[ATraining Step: 8177  | total loss: [1m[32m0.33021[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33021 - acc: 0.8724 -- iter: 0384/3680
[A[ATraining Step: 8178  | total loss: [1m[32m0.33481[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33481 - acc: 0.8696 -- iter: 0416/3680
[A[ATraining Step: 8179  | total loss: [1m[32m0.33127[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33127 - acc: 0.8584 -- iter: 0448/3680
[A[ATraining Step: 8180  | total loss: [1m[32m0.35163[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35163 - acc: 0.8584 -- iter: 0480/3680
[A[ATraining Step: 8181  | total loss: [1m[32m0.35346[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35346 - acc: 0.8632 -- iter: 0512/3680
[A[ATraining Step: 8182  | total loss: [1m[32m0.33846[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33846 - acc: 0.8706 -- iter: 0544/3680
[A[ATraining Step: 8183  | total loss: [1m[32m0.33254[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33254 - acc: 0.8679 -- iter: 0576/3680
[A[ATraining Step: 8184  | total loss: [1m[32m0.35778[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35778 - acc: 0.8655 -- iter: 0608/3680
[A[ATraining Step: 8185  | total loss: [1m[32m0.35304[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35304 - acc: 0.8665 -- iter: 0640/3680
[A[ATraining Step: 8186  | total loss: [1m[32m0.33425[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33425 - acc: 0.8737 -- iter: 0672/3680
[A[ATraining Step: 8187  | total loss: [1m[32m0.33616[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33616 - acc: 0.8737 -- iter: 0704/3680
[A[ATraining Step: 8188  | total loss: [1m[32m0.32293[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32293 - acc: 0.8770 -- iter: 0736/3680
[A[ATraining Step: 8189  | total loss: [1m[32m0.31121[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31121 - acc: 0.8830 -- iter: 0768/3680
[A[ATraining Step: 8190  | total loss: [1m[32m0.31484[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31484 - acc: 0.8791 -- iter: 0800/3680
[A[ATraining Step: 8191  | total loss: [1m[32m0.32681[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32681 - acc: 0.8756 -- iter: 0832/3680
[A[ATraining Step: 8192  | total loss: [1m[32m0.33439[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33439 - acc: 0.8695 -- iter: 0864/3680
[A[ATraining Step: 8193  | total loss: [1m[32m0.33595[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33595 - acc: 0.8669 -- iter: 0896/3680
[A[ATraining Step: 8194  | total loss: [1m[32m0.31891[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31891 - acc: 0.8709 -- iter: 0928/3680
[A[ATraining Step: 8195  | total loss: [1m[32m0.31891[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31891 - acc: 0.8709 -- iter: 0960/3680
[A[ATraining Step: 8196  | total loss: [1m[32m0.31105[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31105 - acc: 0.8713 -- iter: 0992/3680
[A[ATraining Step: 8197  | total loss: [1m[32m0.31285[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31285 - acc: 0.8748 -- iter: 1024/3680
[A[ATraining Step: 8198  | total loss: [1m[32m0.31992[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31992 - acc: 0.8686 -- iter: 1056/3680
[A[ATraining Step: 8199  | total loss: [1m[32m0.31668[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31668 - acc: 0.8629 -- iter: 1088/3680
[A[ATraining Step: 8200  | total loss: [1m[32m0.31668[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31668 - acc: 0.8642 | val_loss: 0.29329 - val_acc: 0.8914 -- iter: 1120/3680
[A[ATraining Step: 8200  | total loss: [1m[32m0.31668[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31668 - acc: 0.8642 | val_loss: 0.29329 - val_acc: 0.8914 -- iter: 1120/3680
--
Training Step: 8201  | total loss: [1m[32m0.31589[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31589 - acc: 0.8621 -- iter: 1152/3680
[A[ATraining Step: 8202  | total loss: [1m[32m0.31064[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31064 - acc: 0.8634 -- iter: 1184/3680
[A[ATraining Step: 8203  | total loss: [1m[32m0.31555[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31555 - acc: 0.8646 -- iter: 1216/3680
[A[ATraining Step: 8204  | total loss: [1m[32m0.35327[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35327 - acc: 0.8437 -- iter: 1248/3680
[A[ATraining Step: 8205  | total loss: [1m[32m0.35114[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35114 - acc: 0.8469 -- iter: 1280/3680
[A[ATraining Step: 8206  | total loss: [1m[32m0.34981[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34981 - acc: 0.8528 -- iter: 1312/3680
[A[ATraining Step: 8207  | total loss: [1m[32m0.34135[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34135 - acc: 0.8644 -- iter: 1344/3680
[A[ATraining Step: 8208  | total loss: [1m[32m0.33545[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33545 - acc: 0.8623 -- iter: 1376/3680
[A[ATraining Step: 8209  | total loss: [1m[32m0.33335[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33335 - acc: 0.8667 -- iter: 1408/3680
[A[ATraining Step: 8210  | total loss: [1m[32m0.33615[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33615 - acc: 0.8644 -- iter: 1440/3680
[A[ATraining Step: 8211  | total loss: [1m[32m0.33131[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33131 - acc: 0.8686 -- iter: 1472/3680
[A[ATraining Step: 8212  | total loss: [1m[32m0.32387[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32387 - acc: 0.8755 -- iter: 1504/3680
[A[ATraining Step: 8213  | total loss: [1m[32m0.32281[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32281 - acc: 0.8723 -- iter: 1536/3680
[A[ATraining Step: 8214  | total loss: [1m[32m0.33540[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33540 - acc: 0.8632 -- iter: 1568/3680
[A[ATraining Step: 8215  | total loss: [1m[32m0.35064[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35064 - acc: 0.8488 -- iter: 1600/3680
[A[ATraining Step: 8216  | total loss: [1m[32m0.34138[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34138 - acc: 0.8538 -- iter: 1632/3680
[A[ATraining Step: 8217  | total loss: [1m[32m0.34138[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34138 - acc: 0.8538 -- iter: 1664/3680
[A[ATraining Step: 8218  | total loss: [1m[32m0.33211[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33211 - acc: 0.8590 -- iter: 1696/3680
[A[ATraining Step: 8219  | total loss: [1m[32m0.31366[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31366 - acc: 0.8731 -- iter: 1728/3680
[A[ATraining Step: 8220  | total loss: [1m[32m0.34111[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34111 - acc: 0.8577 -- iter: 1760/3680
[A[ATraining Step: 8221  | total loss: [1m[32m0.34821[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34821 - acc: 0.8594 -- iter: 1792/3680
[A[ATraining Step: 8222  | total loss: [1m[32m0.35660[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35660 - acc: 0.8610 -- iter: 1824/3680
[A[ATraining Step: 8223  | total loss: [1m[32m0.35541[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35541 - acc: 0.8592 -- iter: 1856/3680
[A[ATraining Step: 8224  | total loss: [1m[32m0.34816[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34816 - acc: 0.8608 -- iter: 1888/3680
[A[ATraining Step: 8225  | total loss: [1m[32m0.35094[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35094 - acc: 0.8622 -- iter: 1920/3680
[A[ATraining Step: 8226  | total loss: [1m[32m0.33850[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33850 - acc: 0.8797 -- iter: 1952/3680
[A[ATraining Step: 8227  | total loss: [1m[32m0.32248[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32248 - acc: 0.8797 -- iter: 1984/3680
[A[ATraining Step: 8228  | total loss: [1m[32m0.32345[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32345 - acc: 0.8761 -- iter: 2016/3680
[A[ATraining Step: 8229  | total loss: [1m[32m0.32352[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32352 - acc: 0.8728 -- iter: 2048/3680
[A[ATraining Step: 8230  | total loss: [1m[32m0.31615[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31615 - acc: 0.8762 -- iter: 2080/3680
[A[ATraining Step: 8231  | total loss: [1m[32m0.31341[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31341 - acc: 0.8761 -- iter: 2112/3680
[A[ATraining Step: 8232  | total loss: [1m[32m0.34145[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34145 - acc: 0.8634 -- iter: 2144/3680
[A[ATraining Step: 8233  | total loss: [1m[32m0.34145[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34145 - acc: 0.8634 -- iter: 2176/3680
[A[ATraining Step: 8234  | total loss: [1m[32m0.34721[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34721 - acc: 0.8708 -- iter: 2208/3680
[A[ATraining Step: 8235  | total loss: [1m[32m0.35797[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35797 - acc: 0.8681 -- iter: 2240/3680
[A[ATraining Step: 8236  | total loss: [1m[32m0.35075[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35075 - acc: 0.8756 -- iter: 2272/3680
[A[ATraining Step: 8237  | total loss: [1m[32m0.33984[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33984 - acc: 0.8756 -- iter: 2304/3680
[A[ATraining Step: 8238  | total loss: [1m[32m0.32700[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32700 - acc: 0.8818 -- iter: 2336/3680
[A[ATraining Step: 8239  | total loss: [1m[32m0.33394[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33394 - acc: 0.8718 -- iter: 2368/3680
[A[ATraining Step: 8240  | total loss: [1m[32m0.32935[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32935 - acc: 0.8752 -- iter: 2400/3680
[A[ATraining Step: 8241  | total loss: [1m[32m0.32849[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32849 - acc: 0.8752 -- iter: 2432/3680
[A[ATraining Step: 8242  | total loss: [1m[32m0.33741[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33741 - acc: 0.8667 -- iter: 2464/3680
[A[ATraining Step: 8243  | total loss: [1m[32m0.35272[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35272 - acc: 0.8644 -- iter: 2496/3680
[A[ATraining Step: 8244  | total loss: [1m[32m0.35272[0m[0m
[2K| Adam | epoch: 072 | loss: 0.35272 - acc: 0.8644 -- iter: 2528/3680
[A[ATraining Step: 8245  | total loss: [1m[32m0.33666[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33666 - acc: 0.8686 -- iter: 2560/3680
[A[ATraining Step: 8246  | total loss: [1m[32m0.34717[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34717 - acc: 0.8599 -- iter: 2592/3680
[A[ATraining Step: 8247  | total loss: [1m[32m0.34809[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34809 - acc: 0.8583 -- iter: 2624/3680
[A[ATraining Step: 8248  | total loss: [1m[32m0.33554[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33554 - acc: 0.8662 -- iter: 2656/3680
[A[ATraining Step: 8249  | total loss: [1m[32m0.32050[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32050 - acc: 0.8671 -- iter: 2688/3680
[A[ATraining Step: 8250  | total loss: [1m[32m0.32050[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32050 - acc: 0.8710 -- iter: 2720/3680
[A[ATraining Step: 8251  | total loss: [1m[32m0.32532[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32532 - acc: 0.8683 -- iter: 2752/3680
[A[ATraining Step: 8252  | total loss: [1m[32m0.31577[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31577 - acc: 0.8783 -- iter: 2784/3680
[A[ATraining Step: 8253  | total loss: [1m[32m0.31115[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31115 - acc: 0.8811 -- iter: 2816/3680
[A[ATraining Step: 8254  | total loss: [1m[32m0.31139[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31139 - acc: 0.8805 -- iter: 2848/3680
[A[ATraining Step: 8255  | total loss: [1m[32m0.30739[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30739 - acc: 0.8831 -- iter: 2880/3680
[A[ATraining Step: 8256  | total loss: [1m[32m0.29709[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29709 - acc: 0.8843 -- iter: 2912/3680
[A[ATraining Step: 8257  | total loss: [1m[32m0.29947[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29947 - acc: 0.8843 -- iter: 2944/3680
[A[ATraining Step: 8258  | total loss: [1m[32m0.30375[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30375 - acc: 0.8834 -- iter: 2976/3680
[A[ATraining Step: 8259  | total loss: [1m[32m0.30731[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30731 - acc: 0.8794 -- iter: 3008/3680
[A[ATraining Step: 8260  | total loss: [1m[32m0.29699[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29699 - acc: 0.8853 -- iter: 3040/3680
[A[ATraining Step: 8261  | total loss: [1m[32m0.32159[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32159 - acc: 0.8780 -- iter: 3072/3680
[A[ATraining Step: 8262  | total loss: [1m[32m0.30945[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30945 - acc: 0.8839 -- iter: 3104/3680
[A[ATraining Step: 8263  | total loss: [1m[32m0.33657[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33657 - acc: 0.8674 -- iter: 3136/3680
[A[ATraining Step: 8264  | total loss: [1m[32m0.33261[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33261 - acc: 0.8650 -- iter: 3168/3680
[A[ATraining Step: 8265  | total loss: [1m[32m0.33015[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33015 - acc: 0.8692 -- iter: 3200/3680
[A[ATraining Step: 8266  | total loss: [1m[32m0.34728[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34728 - acc: 0.8604 -- iter: 3232/3680
[A[ATraining Step: 8267  | total loss: [1m[32m0.33574[0m[0m
[2K| Adam | epoch: 072 | loss: 0.33574 - acc: 0.8618 -- iter: 3264/3680
[A[ATraining Step: 8268  | total loss: [1m[32m0.31688[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31688 - acc: 0.8731 -- iter: 3296/3680
[A[ATraining Step: 8269  | total loss: [1m[32m0.31688[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31688 - acc: 0.8731 -- iter: 3328/3680
[A[ATraining Step: 8270  | total loss: [1m[32m0.32169[0m[0m
[2K| Adam | epoch: 072 | loss: 0.32169 - acc: 0.8702 -- iter: 3360/3680
[A[ATraining Step: 8271  | total loss: [1m[32m0.31315[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31315 - acc: 0.8769 -- iter: 3392/3680
[A[ATraining Step: 8272  | total loss: [1m[32m0.31472[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31472 - acc: 0.8767 -- iter: 3424/3680
[A[ATraining Step: 8273  | total loss: [1m[32m0.30378[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30378 - acc: 0.8828 -- iter: 3456/3680
[A[ATraining Step: 8274  | total loss: [1m[32m0.30082[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30082 - acc: 0.8851 -- iter: 3488/3680
[A[ATraining Step: 8275  | total loss: [1m[32m0.29450[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29450 - acc: 0.8872 -- iter: 3520/3680
[A[ATraining Step: 8276  | total loss: [1m[32m0.30179[0m[0m
[2K| Adam | epoch: 072 | loss: 0.30179 - acc: 0.8860 -- iter: 3552/3680
[A[ATraining Step: 8277  | total loss: [1m[32m0.29742[0m[0m
[2K| Adam | epoch: 072 | loss: 0.29742 - acc: 0.8912 -- iter: 3584/3680
[A[ATraining Step: 8278  | total loss: [1m[32m0.31750[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31750 - acc: 0.8802 -- iter: 3616/3680
[A[ATraining Step: 8279  | total loss: [1m[32m0.31366[0m[0m
[2K| Adam | epoch: 072 | loss: 0.31366 - acc: 0.8797 -- iter: 3648/3680
[A[ATraining Step: 8280  | total loss: [1m[32m0.34291[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34291 - acc: 0.8550 | val_loss: 0.30631 - val_acc: 0.8903 -- iter: 3680/3680
[A[ATraining Step: 8280  | total loss: [1m[32m0.34291[0m[0m
[2K| Adam | epoch: 072 | loss: 0.34291 - acc: 0.8550 | val_loss: 0.30631 - val_acc: 0.8903 -- iter: 3680/3680
--
Training Step: 8281  | total loss: [1m[32m0.35683[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35683 - acc: 0.8550 -- iter: 0032/3680
[A[ATraining Step: 8282  | total loss: [1m[32m0.33816[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33816 - acc: 0.8664 -- iter: 0064/3680
[A[ATraining Step: 8283  | total loss: [1m[32m0.32944[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32944 - acc: 0.8735 -- iter: 0096/3680
[A[ATraining Step: 8284  | total loss: [1m[32m0.33046[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33046 - acc: 0.8674 -- iter: 0128/3680
[A[ATraining Step: 8285  | total loss: [1m[32m0.32194[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32194 - acc: 0.8713 -- iter: 0160/3680
[A[ATraining Step: 8286  | total loss: [1m[32m0.31964[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31964 - acc: 0.8685 -- iter: 0192/3680
[A[ATraining Step: 8287  | total loss: [1m[32m0.31953[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31953 - acc: 0.8692 -- iter: 0224/3680
[A[ATraining Step: 8288  | total loss: [1m[32m0.31855[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31855 - acc: 0.8666 -- iter: 0256/3680
[A[ATraining Step: 8289  | total loss: [1m[32m0.32377[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32377 - acc: 0.8612 -- iter: 0288/3680
[A[ATraining Step: 8290  | total loss: [1m[32m0.31470[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31470 - acc: 0.8657 -- iter: 0320/3680
[A[ATraining Step: 8291  | total loss: [1m[32m0.33590[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33590 - acc: 0.8667 -- iter: 0352/3680
[A[ATraining Step: 8292  | total loss: [1m[32m0.32100[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32100 - acc: 0.8737 -- iter: 0384/3680
[A[ATraining Step: 8293  | total loss: [1m[32m0.32557[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32557 - acc: 0.8739 -- iter: 0416/3680
[A[ATraining Step: 8294  | total loss: [1m[32m0.32642[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32642 - acc: 0.8709 -- iter: 0448/3680
[A[ATraining Step: 8295  | total loss: [1m[32m0.31706[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31706 - acc: 0.8775 -- iter: 0480/3680
[A[ATraining Step: 8296  | total loss: [1m[32m0.31107[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31107 - acc: 0.8774 -- iter: 0512/3680
[A[ATraining Step: 8297  | total loss: [1m[32m0.31107[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31107 - acc: 0.8774 -- iter: 0544/3680
[A[ATraining Step: 8298  | total loss: [1m[32m0.32987[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32987 - acc: 0.8677 -- iter: 0576/3680
[A[ATraining Step: 8299  | total loss: [1m[32m0.32711[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32711 - acc: 0.8685 -- iter: 0608/3680
[A[ATraining Step: 8300  | total loss: [1m[32m0.31569[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31569 - acc: 0.8785 | val_loss: 0.29832 - val_acc: 0.8947 -- iter: 0640/3680
[A[ATraining Step: 8300  | total loss: [1m[32m0.31569[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31569 - acc: 0.8785 | val_loss: 0.29832 - val_acc: 0.8947 -- iter: 0640/3680
--
Training Step: 8301  | total loss: [1m[32m0.32888[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32888 - acc: 0.8685 -- iter: 0672/3680
[A[ATraining Step: 8302  | total loss: [1m[32m0.33164[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33164 - acc: 0.8685 -- iter: 0704/3680
[A[ATraining Step: 8303  | total loss: [1m[32m0.34171[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34171 - acc: 0.8629 -- iter: 0736/3680
[A[ATraining Step: 8304  | total loss: [1m[32m0.35679[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35679 - acc: 0.8516 -- iter: 0768/3680
[A[ATraining Step: 8305  | total loss: [1m[32m0.36662[0m[0m
[2K| Adam | epoch: 073 | loss: 0.36662 - acc: 0.8414 -- iter: 0800/3680
[A[ATraining Step: 8306  | total loss: [1m[32m0.37201[0m[0m
[2K| Adam | epoch: 073 | loss: 0.37201 - acc: 0.8385 -- iter: 0832/3680
[A[ATraining Step: 8307  | total loss: [1m[32m0.38629[0m[0m
[2K| Adam | epoch: 073 | loss: 0.38629 - acc: 0.8390 -- iter: 0864/3680
[A[ATraining Step: 8308  | total loss: [1m[32m0.37325[0m[0m
[2K| Adam | epoch: 073 | loss: 0.37325 - acc: 0.8489 -- iter: 0896/3680
[A[ATraining Step: 8309  | total loss: [1m[32m0.36541[0m[0m
[2K| Adam | epoch: 073 | loss: 0.36541 - acc: 0.8484 -- iter: 0928/3680
[A[ATraining Step: 8310  | total loss: [1m[32m0.36053[0m[0m
[2K| Adam | epoch: 073 | loss: 0.36053 - acc: 0.8510 -- iter: 0960/3680
[A[ATraining Step: 8311  | total loss: [1m[32m0.34841[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34841 - acc: 0.8597 -- iter: 0992/3680
[A[ATraining Step: 8312  | total loss: [1m[32m0.34498[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34498 - acc: 0.8550 -- iter: 1024/3680
[A[ATraining Step: 8313  | total loss: [1m[32m0.35916[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35916 - acc: 0.8476 -- iter: 1056/3680
[A[ATraining Step: 8314  | total loss: [1m[32m0.35498[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35498 - acc: 0.8503 -- iter: 1088/3680
[A[ATraining Step: 8315  | total loss: [1m[32m0.34066[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34066 - acc: 0.8559 -- iter: 1120/3680
[A[ATraining Step: 8316  | total loss: [1m[32m0.33262[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33262 - acc: 0.8578 -- iter: 1152/3680
[A[ATraining Step: 8317  | total loss: [1m[32m0.33966[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33966 - acc: 0.8533 -- iter: 1184/3680
[A[ATraining Step: 8318  | total loss: [1m[32m0.37620[0m[0m
[2K| Adam | epoch: 073 | loss: 0.37620 - acc: 0.8367 -- iter: 1216/3680
[A[ATraining Step: 8319  | total loss: [1m[32m0.36026[0m[0m
[2K| Adam | epoch: 073 | loss: 0.36026 - acc: 0.8468 -- iter: 1248/3680
[A[ATraining Step: 8320  | total loss: [1m[32m0.35479[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35479 - acc: 0.8527 -- iter: 1280/3680
[A[ATraining Step: 8321  | total loss: [1m[32m0.36345[0m[0m
[2K| Adam | epoch: 073 | loss: 0.36345 - acc: 0.8456 -- iter: 1312/3680
[A[ATraining Step: 8322  | total loss: [1m[32m0.35753[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35753 - acc: 0.8548 -- iter: 1344/3680
[A[ATraining Step: 8323  | total loss: [1m[32m0.34728[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34728 - acc: 0.8599 -- iter: 1376/3680
[A[ATraining Step: 8324  | total loss: [1m[32m0.34728[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34728 - acc: 0.8646 -- iter: 1408/3680
[A[ATraining Step: 8325  | total loss: [1m[32m0.33556[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33556 - acc: 0.8672 -- iter: 1440/3680
[A[ATraining Step: 8326  | total loss: [1m[32m0.33556[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33556 - acc: 0.8672 -- iter: 1472/3680
[A[ATraining Step: 8327  | total loss: [1m[32m0.33869[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33869 - acc: 0.8617 -- iter: 1504/3680
[A[ATraining Step: 8328  | total loss: [1m[32m0.35021[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35021 - acc: 0.8599 -- iter: 1536/3680
[A[ATraining Step: 8329  | total loss: [1m[32m0.34121[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34121 - acc: 0.8778 -- iter: 1568/3680
[A[ATraining Step: 8330  | total loss: [1m[32m0.32705[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32705 - acc: 0.8778 -- iter: 1600/3680
[A[ATraining Step: 8331  | total loss: [1m[32m0.32498[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32498 - acc: 0.8775 -- iter: 1632/3680
[A[ATraining Step: 8332  | total loss: [1m[32m0.31612[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31612 - acc: 0.8804 -- iter: 1664/3680
[A[ATraining Step: 8333  | total loss: [1m[32m0.30847[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30847 - acc: 0.8830 -- iter: 1696/3680
[A[ATraining Step: 8334  | total loss: [1m[32m0.29861[0m[0m
[2K| Adam | epoch: 073 | loss: 0.29861 - acc: 0.8915 -- iter: 1728/3680
[A[ATraining Step: 8335  | total loss: [1m[32m0.30944[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30944 - acc: 0.8899 -- iter: 1760/3680
[A[ATraining Step: 8336  | total loss: [1m[32m0.33006[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33006 - acc: 0.8849 -- iter: 1792/3680
[A[ATraining Step: 8337  | total loss: [1m[32m0.32483[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32483 - acc: 0.8849 -- iter: 1824/3680
[A[ATraining Step: 8338  | total loss: [1m[32m0.32302[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32302 - acc: 0.8870 -- iter: 1856/3680
[A[ATraining Step: 8339  | total loss: [1m[32m0.31854[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31854 - acc: 0.8858 -- iter: 1888/3680
[A[ATraining Step: 8340  | total loss: [1m[32m0.32269[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32269 - acc: 0.8847 -- iter: 1920/3680
[A[ATraining Step: 8341  | total loss: [1m[32m0.30407[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30407 - acc: 0.8963 -- iter: 1952/3680
[A[ATraining Step: 8342  | total loss: [1m[32m0.30981[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30981 - acc: 0.8910 -- iter: 1984/3680
[A[ATraining Step: 8343  | total loss: [1m[32m0.32464[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32464 - acc: 0.8832 -- iter: 2016/3680
[A[ATraining Step: 8344  | total loss: [1m[32m0.32626[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32626 - acc: 0.8792 -- iter: 2048/3680
[A[ATraining Step: 8345  | total loss: [1m[32m0.32970[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32970 - acc: 0.8788 -- iter: 2080/3680
[A[ATraining Step: 8346  | total loss: [1m[32m0.32030[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32030 - acc: 0.8815 -- iter: 2112/3680
[A[ATraining Step: 8347  | total loss: [1m[32m0.30287[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30287 - acc: 0.8903 -- iter: 2144/3680
[A[ATraining Step: 8348  | total loss: [1m[32m0.28309[0m[0m
[2K| Adam | epoch: 073 | loss: 0.28309 - acc: 0.8981 -- iter: 2176/3680
[A[ATraining Step: 8349  | total loss: [1m[32m0.28778[0m[0m
[2K| Adam | epoch: 073 | loss: 0.28778 - acc: 0.8927 -- iter: 2208/3680
[A[ATraining Step: 8350  | total loss: [1m[32m0.29895[0m[0m
[2K| Adam | epoch: 073 | loss: 0.29895 - acc: 0.8878 -- iter: 2240/3680
[A[ATraining Step: 8351  | total loss: [1m[32m0.28972[0m[0m
[2K| Adam | epoch: 073 | loss: 0.28972 - acc: 0.8896 -- iter: 2272/3680
[A[ATraining Step: 8352  | total loss: [1m[32m0.29487[0m[0m
[2K| Adam | epoch: 073 | loss: 0.29487 - acc: 0.8882 -- iter: 2304/3680
[A[ATraining Step: 8353  | total loss: [1m[32m0.30861[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30861 - acc: 0.8806 -- iter: 2336/3680
[A[ATraining Step: 8354  | total loss: [1m[32m0.30452[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30452 - acc: 0.8800 -- iter: 2368/3680
[A[ATraining Step: 8355  | total loss: [1m[32m0.30717[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30717 - acc: 0.8764 -- iter: 2400/3680
[A[ATraining Step: 8356  | total loss: [1m[32m0.31977[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31977 - acc: 0.8763 -- iter: 2432/3680
[A[ATraining Step: 8357  | total loss: [1m[32m0.32125[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32125 - acc: 0.8761 -- iter: 2464/3680
[A[ATraining Step: 8358  | total loss: [1m[32m0.33517[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33517 - acc: 0.8729 -- iter: 2496/3680
[A[ATraining Step: 8359  | total loss: [1m[32m0.33127[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33127 - acc: 0.8700 -- iter: 2528/3680
[A[ATraining Step: 8360  | total loss: [1m[32m0.35450[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35450 - acc: 0.8549 -- iter: 2560/3680
[A[ATraining Step: 8361  | total loss: [1m[32m0.34948[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34948 - acc: 0.8569 -- iter: 2592/3680
[A[ATraining Step: 8362  | total loss: [1m[32m0.35320[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35320 - acc: 0.8556 -- iter: 2624/3680
[A[ATraining Step: 8363  | total loss: [1m[32m0.35361[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35361 - acc: 0.8606 -- iter: 2656/3680
[A[ATraining Step: 8364  | total loss: [1m[32m0.36123[0m[0m
[2K| Adam | epoch: 073 | loss: 0.36123 - acc: 0.8527 -- iter: 2688/3680
[A[ATraining Step: 8365  | total loss: [1m[32m0.34987[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34987 - acc: 0.8612 -- iter: 2720/3680
[A[ATraining Step: 8366  | total loss: [1m[32m0.34105[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34105 - acc: 0.8594 -- iter: 2752/3680
[A[ATraining Step: 8367  | total loss: [1m[32m0.33239[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33239 - acc: 0.8610 -- iter: 2784/3680
[A[ATraining Step: 8368  | total loss: [1m[32m0.34411[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34411 - acc: 0.8561 -- iter: 2816/3680
[A[ATraining Step: 8369  | total loss: [1m[32m0.34451[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34451 - acc: 0.8612 -- iter: 2848/3680
[A[ATraining Step: 8370  | total loss: [1m[32m0.33739[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33739 - acc: 0.8657 -- iter: 2880/3680
[A[ATraining Step: 8371  | total loss: [1m[32m0.32191[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32191 - acc: 0.8760 -- iter: 2912/3680
[A[ATraining Step: 8372  | total loss: [1m[32m0.30649[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30649 - acc: 0.8852 -- iter: 2944/3680
[A[ATraining Step: 8373  | total loss: [1m[32m0.29888[0m[0m
[2K| Adam | epoch: 073 | loss: 0.29888 - acc: 0.8905 -- iter: 2976/3680
[A[ATraining Step: 8374  | total loss: [1m[32m0.29485[0m[0m
[2K| Adam | epoch: 073 | loss: 0.29485 - acc: 0.8921 -- iter: 3008/3680
[A[ATraining Step: 8375  | total loss: [1m[32m0.29123[0m[0m
[2K| Adam | epoch: 073 | loss: 0.29123 - acc: 0.8826 -- iter: 3040/3680
[A[ATraining Step: 8376  | total loss: [1m[32m0.30841[0m[0m
[2K| Adam | epoch: 073 | loss: 0.30841 - acc: 0.8826 -- iter: 3072/3680
[A[ATraining Step: 8377  | total loss: [1m[32m0.33318[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33318 - acc: 0.8724 -- iter: 3104/3680
[A[ATraining Step: 8378  | total loss: [1m[32m0.34338[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34338 - acc: 0.8633 -- iter: 3136/3680
[A[ATraining Step: 8379  | total loss: [1m[32m0.34629[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34629 - acc: 0.8582 -- iter: 3168/3680
[A[ATraining Step: 8380  | total loss: [1m[32m0.35712[0m[0m
[2K| Adam | epoch: 073 | loss: 0.35712 - acc: 0.8630 -- iter: 3200/3680
[A[ATraining Step: 8381  | total loss: [1m[32m0.34082[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34082 - acc: 0.8653 -- iter: 3232/3680
[A[ATraining Step: 8382  | total loss: [1m[32m0.34082[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34082 - acc: 0.8653 -- iter: 3264/3680
[A[ATraining Step: 8383  | total loss: [1m[32m0.32992[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32992 - acc: 0.8731 -- iter: 3296/3680
[A[ATraining Step: 8384  | total loss: [1m[32m0.31872[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31872 - acc: 0.8731 -- iter: 3328/3680
[A[ATraining Step: 8385  | total loss: [1m[32m0.31150[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31150 - acc: 0.8722 -- iter: 3360/3680
[A[ATraining Step: 8386  | total loss: [1m[32m0.31150[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31150 - acc: 0.8722 -- iter: 3392/3680
[A[ATraining Step: 8387  | total loss: [1m[32m0.31362[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31362 - acc: 0.8725 -- iter: 3424/3680
[A[ATraining Step: 8388  | total loss: [1m[32m0.31340[0m[0m
[2K| Adam | epoch: 073 | loss: 0.31340 - acc: 0.8727 -- iter: 3456/3680
[A[ATraining Step: 8389  | total loss: [1m[32m0.32393[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32393 - acc: 0.8667 -- iter: 3488/3680
[A[ATraining Step: 8390  | total loss: [1m[32m0.32655[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32655 - acc: 0.8582 -- iter: 3520/3680
[A[ATraining Step: 8391  | total loss: [1m[32m0.34212[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34212 - acc: 0.8505 -- iter: 3552/3680
[A[ATraining Step: 8392  | total loss: [1m[32m0.33254[0m[0m
[2K| Adam | epoch: 073 | loss: 0.33254 - acc: 0.8560 -- iter: 3584/3680
[A[ATraining Step: 8393  | total loss: [1m[32m0.32458[0m[0m
[2K| Adam | epoch: 073 | loss: 0.32458 - acc: 0.8611 -- iter: 3616/3680
[A[ATraining Step: 8394  | total loss: [1m[32m0.34277[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34277 - acc: 0.8490 -- iter: 3648/3680
[A[ATraining Step: 8395  | total loss: [1m[32m0.34277[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34277 - acc: 0.8490 | val_loss: 0.28705 - val_acc: 0.9023 -- iter: 3680/3680
[A[ATraining Step: 8395  | total loss: [1m[32m0.34277[0m[0m
[2K| Adam | epoch: 073 | loss: 0.34277 - acc: 0.8490 | val_loss: 0.28705 - val_acc: 0.9023 -- iter: 3680/3680
--
Training Step: 8396  | total loss: [1m[32m0.33358[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33358 - acc: 0.8579 -- iter: 0032/3680
[A[ATraining Step: 8397  | total loss: [1m[32m0.33006[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33006 - acc: 0.8596 -- iter: 0064/3680
[A[ATraining Step: 8398  | total loss: [1m[32m0.34794[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34794 - acc: 0.8455 -- iter: 0096/3680
[A[ATraining Step: 8399  | total loss: [1m[32m0.34061[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34061 - acc: 0.8516 -- iter: 0128/3680
[A[ATraining Step: 8400  | total loss: [1m[32m0.33696[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33696 - acc: 0.8539 | val_loss: 0.30270 - val_acc: 0.8958 -- iter: 0160/3680
[A[ATraining Step: 8400  | total loss: [1m[32m0.33696[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33696 - acc: 0.8539 | val_loss: 0.30270 - val_acc: 0.8958 -- iter: 0160/3680
--
Training Step: 8401  | total loss: [1m[32m0.32341[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32341 - acc: 0.8623 -- iter: 0192/3680
[A[ATraining Step: 8402  | total loss: [1m[32m0.31590[0m[0m
[2K| Adam | epoch: 074 | loss: 0.31590 - acc: 0.8698 -- iter: 0224/3680
[A[ATraining Step: 8403  | total loss: [1m[32m0.34265[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34265 - acc: 0.8516 -- iter: 0256/3680
[A[ATraining Step: 8404  | total loss: [1m[32m0.33418[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33418 - acc: 0.8570 -- iter: 0288/3680
[A[ATraining Step: 8405  | total loss: [1m[32m0.32202[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32202 - acc: 0.8651 -- iter: 0320/3680
[A[ATraining Step: 8406  | total loss: [1m[32m0.32798[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32798 - acc: 0.8661 -- iter: 0352/3680
[A[ATraining Step: 8407  | total loss: [1m[32m0.32659[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32659 - acc: 0.8638 -- iter: 0384/3680
[A[ATraining Step: 8408  | total loss: [1m[32m0.33182[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33182 - acc: 0.8650 -- iter: 0416/3680
[A[ATraining Step: 8409  | total loss: [1m[32m0.34735[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34735 - acc: 0.8522 -- iter: 0448/3680
[A[ATraining Step: 8410  | total loss: [1m[32m0.36510[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36510 - acc: 0.8522 -- iter: 0480/3680
[A[ATraining Step: 8411  | total loss: [1m[32m0.37290[0m[0m
[2K| Adam | epoch: 074 | loss: 0.37290 - acc: 0.8451 -- iter: 0512/3680
[A[ATraining Step: 8412  | total loss: [1m[32m0.36516[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36516 - acc: 0.8476 -- iter: 0544/3680
[A[ATraining Step: 8413  | total loss: [1m[32m0.35473[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35473 - acc: 0.8476 -- iter: 0576/3680
[A[ATraining Step: 8414  | total loss: [1m[32m0.33365[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33365 - acc: 0.8598 -- iter: 0608/3680
[A[ATraining Step: 8415  | total loss: [1m[32m0.32260[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32260 - acc: 0.8644 -- iter: 0640/3680
[A[ATraining Step: 8416  | total loss: [1m[32m0.30723[0m[0m
[2K| Adam | epoch: 074 | loss: 0.30723 - acc: 0.8717 -- iter: 0672/3680
[A[ATraining Step: 8417  | total loss: [1m[32m0.30424[0m[0m
[2K| Adam | epoch: 074 | loss: 0.30424 - acc: 0.8783 -- iter: 0704/3680
[A[ATraining Step: 8418  | total loss: [1m[32m0.31782[0m[0m
[2K| Adam | epoch: 074 | loss: 0.31782 - acc: 0.8780 -- iter: 0736/3680
[A[ATraining Step: 8419  | total loss: [1m[32m0.30844[0m[0m
[2K| Adam | epoch: 074 | loss: 0.30844 - acc: 0.8777 -- iter: 0768/3680
[A[ATraining Step: 8420  | total loss: [1m[32m0.30037[0m[0m
[2K| Adam | epoch: 074 | loss: 0.30037 - acc: 0.8805 -- iter: 0800/3680
[A[ATraining Step: 8421  | total loss: [1m[32m0.28145[0m[0m
[2K| Adam | epoch: 074 | loss: 0.28145 - acc: 0.8893 -- iter: 0832/3680
[A[ATraining Step: 8422  | total loss: [1m[32m0.29662[0m[0m
[2K| Adam | epoch: 074 | loss: 0.29662 - acc: 0.8716 -- iter: 0864/3680
[A[ATraining Step: 8423  | total loss: [1m[32m0.30444[0m[0m
[2K| Adam | epoch: 074 | loss: 0.30444 - acc: 0.8716 -- iter: 0896/3680
[A[ATraining Step: 8424  | total loss: [1m[32m0.28954[0m[0m
[2K| Adam | epoch: 074 | loss: 0.28954 - acc: 0.8782 -- iter: 0928/3680
[A[ATraining Step: 8425  | total loss: [1m[32m0.28875[0m[0m
[2K| Adam | epoch: 074 | loss: 0.28875 - acc: 0.8841 -- iter: 0960/3680
[A[ATraining Step: 8426  | total loss: [1m[32m0.30992[0m[0m
[2K| Adam | epoch: 074 | loss: 0.30992 - acc: 0.8707 -- iter: 0992/3680
[A[ATraining Step: 8427  | total loss: [1m[32m0.31857[0m[0m
[2K| Adam | epoch: 074 | loss: 0.31857 - acc: 0.8649 -- iter: 1024/3680
[A[ATraining Step: 8428  | total loss: [1m[32m0.32870[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32870 - acc: 0.8565 -- iter: 1056/3680
[A[ATraining Step: 8429  | total loss: [1m[32m0.33985[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33985 - acc: 0.8521 -- iter: 1088/3680
[A[ATraining Step: 8430  | total loss: [1m[32m0.35146[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35146 - acc: 0.8482 -- iter: 1120/3680
[A[ATraining Step: 8431  | total loss: [1m[32m0.35279[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35279 - acc: 0.8509 -- iter: 1152/3680
[A[ATraining Step: 8432  | total loss: [1m[32m0.34650[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34650 - acc: 0.8564 -- iter: 1184/3680
[A[ATraining Step: 8433  | total loss: [1m[32m0.35146[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35146 - acc: 0.8458 -- iter: 1216/3680
[A[ATraining Step: 8434  | total loss: [1m[32m0.35171[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35171 - acc: 0.8424 -- iter: 1248/3680
[A[ATraining Step: 8435  | total loss: [1m[32m0.37242[0m[0m
[2K| Adam | epoch: 074 | loss: 0.37242 - acc: 0.8332 -- iter: 1280/3680
[A[ATraining Step: 8436  | total loss: [1m[32m0.37767[0m[0m
[2K| Adam | epoch: 074 | loss: 0.37767 - acc: 0.8280 -- iter: 1312/3680
[A[ATraining Step: 8437  | total loss: [1m[32m0.37152[0m[0m
[2K| Adam | epoch: 074 | loss: 0.37152 - acc: 0.8327 -- iter: 1344/3680
[A[ATraining Step: 8438  | total loss: [1m[32m0.38165[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38165 - acc: 0.8307 -- iter: 1376/3680
[A[ATraining Step: 8439  | total loss: [1m[32m0.42155[0m[0m
[2K| Adam | epoch: 074 | loss: 0.42155 - acc: 0.8195 -- iter: 1408/3680
[A[ATraining Step: 8440  | total loss: [1m[32m0.42954[0m[0m
[2K| Adam | epoch: 074 | loss: 0.42954 - acc: 0.8094 -- iter: 1440/3680
[A[ATraining Step: 8441  | total loss: [1m[32m0.41380[0m[0m
[2K| Adam | epoch: 074 | loss: 0.41380 - acc: 0.8128 -- iter: 1472/3680
[A[ATraining Step: 8442  | total loss: [1m[32m0.40732[0m[0m
[2K| Adam | epoch: 074 | loss: 0.40732 - acc: 0.8159 -- iter: 1504/3680
[A[ATraining Step: 8443  | total loss: [1m[32m0.38584[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38584 - acc: 0.8250 -- iter: 1536/3680
[A[ATraining Step: 8444  | total loss: [1m[32m0.36964[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36964 - acc: 0.8362 -- iter: 1568/3680
[A[ATraining Step: 8445  | total loss: [1m[32m0.37778[0m[0m
[2K| Adam | epoch: 074 | loss: 0.37778 - acc: 0.8276 -- iter: 1600/3680
[A[ATraining Step: 8446  | total loss: [1m[32m0.36034[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36034 - acc: 0.8386 -- iter: 1632/3680
[A[ATraining Step: 8447  | total loss: [1m[32m0.35876[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35876 - acc: 0.8454 -- iter: 1664/3680
[A[ATraining Step: 8448  | total loss: [1m[32m0.34861[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34861 - acc: 0.8483 -- iter: 1696/3680
[A[ATraining Step: 8449  | total loss: [1m[32m0.34139[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34139 - acc: 0.8510 -- iter: 1728/3680
[A[ATraining Step: 8450  | total loss: [1m[32m0.34593[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34593 - acc: 0.8471 -- iter: 1760/3680
[A[ATraining Step: 8451  | total loss: [1m[32m0.33632[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33632 - acc: 0.8499 -- iter: 1792/3680
[A[ATraining Step: 8452  | total loss: [1m[32m0.34332[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34332 - acc: 0.8493 -- iter: 1824/3680
[A[ATraining Step: 8453  | total loss: [1m[32m0.34032[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34032 - acc: 0.8517 -- iter: 1856/3680
[A[ATraining Step: 8454  | total loss: [1m[32m0.33894[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33894 - acc: 0.8517 -- iter: 1888/3680
[A[ATraining Step: 8455  | total loss: [1m[32m0.33496[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33496 - acc: 0.8603 -- iter: 1920/3680
[A[ATraining Step: 8456  | total loss: [1m[32m0.34719[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34719 - acc: 0.8617 -- iter: 1952/3680
[A[ATraining Step: 8457  | total loss: [1m[32m0.33256[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33256 - acc: 0.8662 -- iter: 1984/3680
[A[ATraining Step: 8458  | total loss: [1m[32m0.32683[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32683 - acc: 0.8639 -- iter: 2016/3680
[A[ATraining Step: 8459  | total loss: [1m[32m0.32900[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32900 - acc: 0.8619 -- iter: 2048/3680
[A[ATraining Step: 8460  | total loss: [1m[32m0.33676[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33676 - acc: 0.8601 -- iter: 2080/3680
[A[ATraining Step: 8461  | total loss: [1m[32m0.34169[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34169 - acc: 0.8553 -- iter: 2112/3680
[A[ATraining Step: 8462  | total loss: [1m[32m0.36235[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36235 - acc: 0.8448 -- iter: 2144/3680
[A[ATraining Step: 8463  | total loss: [1m[32m0.35871[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35871 - acc: 0.8478 -- iter: 2176/3680
[A[ATraining Step: 8464  | total loss: [1m[32m0.35489[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35489 - acc: 0.8474 -- iter: 2208/3680
[A[ATraining Step: 8465  | total loss: [1m[32m0.38061[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38061 - acc: 0.8439 -- iter: 2240/3680
[A[ATraining Step: 8466  | total loss: [1m[32m0.38107[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38107 - acc: 0.8439 -- iter: 2272/3680
[A[ATraining Step: 8467  | total loss: [1m[32m0.37641[0m[0m
[2K| Adam | epoch: 074 | loss: 0.37641 - acc: 0.8470 -- iter: 2304/3680
[A[ATraining Step: 8468  | total loss: [1m[32m0.38474[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38474 - acc: 0.8373 -- iter: 2336/3680
[A[ATraining Step: 8469  | total loss: [1m[32m0.38722[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38722 - acc: 0.8348 -- iter: 2368/3680
[A[ATraining Step: 8470  | total loss: [1m[32m0.39685[0m[0m
[2K| Adam | epoch: 074 | loss: 0.39685 - acc: 0.8357 -- iter: 2400/3680
[A[ATraining Step: 8471  | total loss: [1m[32m0.39845[0m[0m
[2K| Adam | epoch: 074 | loss: 0.39845 - acc: 0.8344 -- iter: 2432/3680
[A[ATraining Step: 8472  | total loss: [1m[32m0.39845[0m[0m
[2K| Adam | epoch: 074 | loss: 0.39845 - acc: 0.8344 -- iter: 2464/3680
[A[ATraining Step: 8473  | total loss: [1m[32m0.39185[0m[0m
[2K| Adam | epoch: 074 | loss: 0.39185 - acc: 0.8385 -- iter: 2496/3680
[A[ATraining Step: 8474  | total loss: [1m[32m0.38430[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38430 - acc: 0.8476 -- iter: 2528/3680
[A[ATraining Step: 8475  | total loss: [1m[32m0.38430[0m[0m
[2K| Adam | epoch: 074 | loss: 0.38430 - acc: 0.8476 -- iter: 2560/3680
[A[ATraining Step: 8476  | total loss: [1m[32m0.36864[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36864 - acc: 0.8647 -- iter: 2592/3680
[A[ATraining Step: 8477  | total loss: [1m[32m0.35331[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35331 - acc: 0.8689 -- iter: 2624/3680
[A[ATraining Step: 8478  | total loss: [1m[32m0.35331[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35331 - acc: 0.8689 -- iter: 2656/3680
[A[ATraining Step: 8479  | total loss: [1m[32m0.35099[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35099 - acc: 0.8695 -- iter: 2688/3680
[A[ATraining Step: 8480  | total loss: [1m[32m0.33424[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33424 - acc: 0.8763 -- iter: 2720/3680
[A[ATraining Step: 8481  | total loss: [1m[32m0.33370[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33370 - acc: 0.8761 -- iter: 2752/3680
[A[ATraining Step: 8482  | total loss: [1m[32m0.34018[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34018 - acc: 0.8700 -- iter: 2784/3680
[A[ATraining Step: 8483  | total loss: [1m[32m0.33842[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33842 - acc: 0.8700 -- iter: 2816/3680
[A[ATraining Step: 8484  | total loss: [1m[32m0.32946[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32946 - acc: 0.8767 -- iter: 2848/3680
[A[ATraining Step: 8485  | total loss: [1m[32m0.32737[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32737 - acc: 0.8797 -- iter: 2880/3680
[A[ATraining Step: 8486  | total loss: [1m[32m0.34365[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34365 - acc: 0.8761 -- iter: 2912/3680
[A[ATraining Step: 8487  | total loss: [1m[32m0.33093[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33093 - acc: 0.8843 -- iter: 2944/3680
[A[ATraining Step: 8488  | total loss: [1m[32m0.32464[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32464 - acc: 0.8843 -- iter: 2976/3680
[A[ATraining Step: 8489  | total loss: [1m[32m0.31844[0m[0m
[2K| Adam | epoch: 074 | loss: 0.31844 - acc: 0.8896 -- iter: 3008/3680
[A[ATraining Step: 8490  | total loss: [1m[32m0.32041[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32041 - acc: 0.8851 -- iter: 3040/3680
[A[ATraining Step: 8491  | total loss: [1m[32m0.32820[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32820 - acc: 0.8778 -- iter: 3072/3680
[A[ATraining Step: 8492  | total loss: [1m[32m0.33038[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33038 - acc: 0.8775 -- iter: 3104/3680
[A[ATraining Step: 8493  | total loss: [1m[32m0.33079[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33079 - acc: 0.8741 -- iter: 3136/3680
[A[ATraining Step: 8494  | total loss: [1m[32m0.34406[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34406 - acc: 0.8646 -- iter: 3168/3680
[A[ATraining Step: 8495  | total loss: [1m[32m0.34406[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34406 - acc: 0.8646 -- iter: 3200/3680
[A[ATraining Step: 8496  | total loss: [1m[32m0.34128[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34128 - acc: 0.8594 -- iter: 3232/3680
[A[ATraining Step: 8497  | total loss: [1m[32m0.33775[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33775 - acc: 0.8672 -- iter: 3264/3680
[A[ATraining Step: 8498  | total loss: [1m[32m0.33412[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33412 - acc: 0.8649 -- iter: 3296/3680
[A[ATraining Step: 8499  | total loss: [1m[32m0.35191[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35191 - acc: 0.8628 -- iter: 3328/3680
[A[ATraining Step: 8500  | total loss: [1m[32m0.35191[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35191 - acc: 0.8609 | val_loss: 0.30620 - val_acc: 0.8914 -- iter: 3360/3680
[A[ATraining Step: 8500  | total loss: [1m[32m0.35191[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35191 - acc: 0.8609 | val_loss: 0.30620 - val_acc: 0.8914 -- iter: 3360/3680
--
Training Step: 8501  | total loss: [1m[32m0.36660[0m[0m
[2K| Adam | epoch: 074 | loss: 0.36660 - acc: 0.8560 -- iter: 3392/3680
[A[ATraining Step: 8502  | total loss: [1m[32m0.34754[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34754 - acc: 0.8610 -- iter: 3424/3680
[A[ATraining Step: 8503  | total loss: [1m[32m0.35989[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35989 - acc: 0.8531 -- iter: 3456/3680
[A[ATraining Step: 8504  | total loss: [1m[32m0.35717[0m[0m
[2K| Adam | epoch: 074 | loss: 0.35717 - acc: 0.8584 -- iter: 3488/3680
[A[ATraining Step: 8505  | total loss: [1m[32m0.34750[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34750 - acc: 0.8663 -- iter: 3520/3680
[A[ATraining Step: 8506  | total loss: [1m[32m0.34018[0m[0m
[2K| Adam | epoch: 074 | loss: 0.34018 - acc: 0.8734 -- iter: 3552/3680
[A[ATraining Step: 8507  | total loss: [1m[32m0.32968[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32968 - acc: 0.8767 -- iter: 3584/3680
[A[ATraining Step: 8508  | total loss: [1m[32m0.32714[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32714 - acc: 0.8797 -- iter: 3616/3680
[A[ATraining Step: 8509  | total loss: [1m[32m0.33923[0m[0m
[2K| Adam | epoch: 074 | loss: 0.33923 - acc: 0.8667 -- iter: 3648/3680
[A[ATraining Step: 8510  | total loss: [1m[32m0.32085[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32085 - acc: 0.8769 | val_loss: 0.31910 - val_acc: 0.8860 -- iter: 3680/3680
[A[ATraining Step: 8510  | total loss: [1m[32m0.32085[0m[0m
[2K| Adam | epoch: 074 | loss: 0.32085 - acc: 0.8769 | val_loss: 0.31910 - val_acc: 0.8860 -- iter: 3680/3680
--
Training Step: 8511  | total loss: [1m[32m0.30949[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30949 - acc: 0.8830 -- iter: 0032/3680
[A[ATraining Step: 8512  | total loss: [1m[32m0.31232[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31232 - acc: 0.8728 -- iter: 0064/3680
[A[ATraining Step: 8513  | total loss: [1m[32m0.32070[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32070 - acc: 0.8636 -- iter: 0096/3680
[A[ATraining Step: 8514  | total loss: [1m[32m0.31373[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31373 - acc: 0.8648 -- iter: 0128/3680
[A[ATraining Step: 8515  | total loss: [1m[32m0.31296[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31296 - acc: 0.8689 -- iter: 0160/3680
[A[ATraining Step: 8516  | total loss: [1m[32m0.31766[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31766 - acc: 0.8704 -- iter: 0192/3680
[A[ATraining Step: 8517  | total loss: [1m[32m0.30874[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30874 - acc: 0.8704 -- iter: 0224/3680
[A[ATraining Step: 8518  | total loss: [1m[32m0.30928[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30928 - acc: 0.8744 -- iter: 0256/3680
[A[ATraining Step: 8519  | total loss: [1m[32m0.30928[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30928 - acc: 0.8744 -- iter: 0288/3680
[A[ATraining Step: 8520  | total loss: [1m[32m0.30362[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30362 - acc: 0.8804 -- iter: 0320/3680
[A[ATraining Step: 8521  | total loss: [1m[32m0.30362[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30362 - acc: 0.8804 -- iter: 0352/3680
[A[ATraining Step: 8522  | total loss: [1m[32m0.32050[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32050 - acc: 0.8736 -- iter: 0384/3680
[A[ATraining Step: 8523  | total loss: [1m[32m0.32449[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32449 - acc: 0.8738 -- iter: 0416/3680
[A[ATraining Step: 8524  | total loss: [1m[32m0.34599[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34599 - acc: 0.8614 -- iter: 0448/3680
[A[ATraining Step: 8525  | total loss: [1m[32m0.33163[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33163 - acc: 0.8690 -- iter: 0480/3680
[A[ATraining Step: 8526  | total loss: [1m[32m0.32281[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32281 - acc: 0.8759 -- iter: 0512/3680
[A[ATraining Step: 8527  | total loss: [1m[32m0.34565[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34565 - acc: 0.8676 -- iter: 0544/3680
[A[ATraining Step: 8528  | total loss: [1m[32m0.34059[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34059 - acc: 0.8676 -- iter: 0576/3680
[A[ATraining Step: 8529  | total loss: [1m[32m0.34561[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34561 - acc: 0.8558 -- iter: 0608/3680
[A[ATraining Step: 8530  | total loss: [1m[32m0.34736[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34736 - acc: 0.8546 -- iter: 0640/3680
[A[ATraining Step: 8531  | total loss: [1m[32m0.35347[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35347 - acc: 0.8535 -- iter: 0672/3680
[A[ATraining Step: 8532  | total loss: [1m[32m0.35625[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35625 - acc: 0.8557 -- iter: 0704/3680
[A[ATraining Step: 8533  | total loss: [1m[32m0.34250[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34250 - acc: 0.8587 -- iter: 0736/3680
[A[ATraining Step: 8534  | total loss: [1m[32m0.34426[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34426 - acc: 0.8587 -- iter: 0768/3680
[A[ATraining Step: 8535  | total loss: [1m[32m0.34307[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34307 - acc: 0.8510 -- iter: 0800/3680
[A[ATraining Step: 8536  | total loss: [1m[32m0.32977[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32977 - acc: 0.8627 -- iter: 0832/3680
[A[ATraining Step: 8537  | total loss: [1m[32m0.33216[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33216 - acc: 0.8608 -- iter: 0864/3680
[A[ATraining Step: 8538  | total loss: [1m[32m0.32968[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32968 - acc: 0.8623 -- iter: 0896/3680
[A[ATraining Step: 8539  | total loss: [1m[32m0.31959[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31959 - acc: 0.8635 -- iter: 0928/3680
[A[ATraining Step: 8540  | total loss: [1m[32m0.30689[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30689 - acc: 0.8741 -- iter: 0960/3680
[A[ATraining Step: 8541  | total loss: [1m[32m0.30586[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30586 - acc: 0.8773 -- iter: 0992/3680
[A[ATraining Step: 8542  | total loss: [1m[32m0.31641[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31641 - acc: 0.8739 -- iter: 1024/3680
[A[ATraining Step: 8543  | total loss: [1m[32m0.31419[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31419 - acc: 0.8740 -- iter: 1056/3680
[A[ATraining Step: 8544  | total loss: [1m[32m0.33963[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33963 - acc: 0.8741 -- iter: 1088/3680
[A[ATraining Step: 8545  | total loss: [1m[32m0.33502[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33502 - acc: 0.8893 -- iter: 1120/3680
[A[ATraining Step: 8546  | total loss: [1m[32m0.32693[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32693 - acc: 0.8893 -- iter: 1152/3680
[A[ATraining Step: 8547  | total loss: [1m[32m0.33195[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33195 - acc: 0.8847 -- iter: 1184/3680
[A[ATraining Step: 8548  | total loss: [1m[32m0.32337[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32337 - acc: 0.8838 -- iter: 1216/3680
[A[ATraining Step: 8549  | total loss: [1m[32m0.31410[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31410 - acc: 0.8860 -- iter: 1248/3680
[A[ATraining Step: 8550  | total loss: [1m[32m0.31277[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31277 - acc: 0.8880 -- iter: 1280/3680
[A[ATraining Step: 8551  | total loss: [1m[32m0.30819[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30819 - acc: 0.8899 -- iter: 1312/3680
[A[ATraining Step: 8552  | total loss: [1m[32m0.32450[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32450 - acc: 0.8790 -- iter: 1344/3680
[A[ATraining Step: 8553  | total loss: [1m[32m0.32961[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32961 - acc: 0.8664 -- iter: 1376/3680
[A[ATraining Step: 8554  | total loss: [1m[32m0.33185[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33185 - acc: 0.8664 -- iter: 1408/3680
[A[ATraining Step: 8555  | total loss: [1m[32m0.32650[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32650 - acc: 0.8704 -- iter: 1440/3680
[A[ATraining Step: 8556  | total loss: [1m[32m0.32373[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32373 - acc: 0.8677 -- iter: 1472/3680
[A[ATraining Step: 8557  | total loss: [1m[32m0.30931[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30931 - acc: 0.8747 -- iter: 1504/3680
[A[ATraining Step: 8558  | total loss: [1m[32m0.30384[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30384 - acc: 0.8778 -- iter: 1536/3680
[A[ATraining Step: 8559  | total loss: [1m[32m0.29271[0m[0m
[2K| Adam | epoch: 075 | loss: 0.29271 - acc: 0.8838 -- iter: 1568/3680
[A[ATraining Step: 8560  | total loss: [1m[32m0.30111[0m[0m
[2K| Adam | epoch: 075 | loss: 0.30111 - acc: 0.8767 -- iter: 1600/3680
[A[ATraining Step: 8561  | total loss: [1m[32m0.28767[0m[0m
[2K| Adam | epoch: 075 | loss: 0.28767 - acc: 0.8859 -- iter: 1632/3680
[A[ATraining Step: 8562  | total loss: [1m[32m0.28000[0m[0m
[2K| Adam | epoch: 075 | loss: 0.28000 - acc: 0.8866 -- iter: 1664/3680
[A[ATraining Step: 8563  | total loss: [1m[32m0.28664[0m[0m
[2K| Adam | epoch: 075 | loss: 0.28664 - acc: 0.8866 -- iter: 1696/3680
[A[ATraining Step: 8564  | total loss: [1m[32m0.27878[0m[0m
[2K| Adam | epoch: 075 | loss: 0.27878 - acc: 0.8886 -- iter: 1728/3680
[A[ATraining Step: 8565  | total loss: [1m[32m0.29165[0m[0m
[2K| Adam | epoch: 075 | loss: 0.29165 - acc: 0.8872 -- iter: 1760/3680
[A[ATraining Step: 8566  | total loss: [1m[32m0.28811[0m[0m
[2K| Adam | epoch: 075 | loss: 0.28811 - acc: 0.8891 -- iter: 1792/3680
[A[ATraining Step: 8567  | total loss: [1m[32m0.32358[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32358 - acc: 0.8680 -- iter: 1824/3680
[A[ATraining Step: 8568  | total loss: [1m[32m0.32358[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32358 - acc: 0.8680 -- iter: 1856/3680
[A[ATraining Step: 8569  | total loss: [1m[32m0.32479[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32479 - acc: 0.8656 -- iter: 1888/3680
[A[ATraining Step: 8570  | total loss: [1m[32m0.31590[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31590 - acc: 0.8696 -- iter: 1920/3680
[A[ATraining Step: 8571  | total loss: [1m[32m0.31310[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31310 - acc: 0.8733 -- iter: 1952/3680
[A[ATraining Step: 8572  | total loss: [1m[32m0.32007[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32007 - acc: 0.8735 -- iter: 1984/3680
[A[ATraining Step: 8573  | total loss: [1m[32m0.31895[0m[0m
[2K| Adam | epoch: 075 | loss: 0.31895 - acc: 0.8736 -- iter: 2016/3680
[A[ATraining Step: 8574  | total loss: [1m[32m0.34639[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34639 - acc: 0.8644 -- iter: 2048/3680
[A[ATraining Step: 8575  | total loss: [1m[32m0.34355[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34355 - acc: 0.8623 -- iter: 2080/3680
[A[ATraining Step: 8576  | total loss: [1m[32m0.34521[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34521 - acc: 0.8573 -- iter: 2112/3680
[A[ATraining Step: 8577  | total loss: [1m[32m0.35219[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35219 - acc: 0.8529 -- iter: 2144/3680
[A[ATraining Step: 8578  | total loss: [1m[32m0.34753[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34753 - acc: 0.8551 -- iter: 2176/3680
[A[ATraining Step: 8579  | total loss: [1m[32m0.33743[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33743 - acc: 0.8664 -- iter: 2208/3680
[A[ATraining Step: 8580  | total loss: [1m[32m0.33743[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33743 - acc: 0.8673 -- iter: 2240/3680
[A[ATraining Step: 8581  | total loss: [1m[32m0.32807[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32807 - acc: 0.8743 -- iter: 2272/3680
[A[ATraining Step: 8582  | total loss: [1m[32m0.32492[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32492 - acc: 0.8713 -- iter: 2304/3680
[A[ATraining Step: 8583  | total loss: [1m[32m0.32271[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32271 - acc: 0.8748 -- iter: 2336/3680
[A[ATraining Step: 8584  | total loss: [1m[32m0.32557[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32557 - acc: 0.8810 -- iter: 2368/3680
[A[ATraining Step: 8585  | total loss: [1m[32m0.33839[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33839 - acc: 0.8804 -- iter: 2400/3680
[A[ATraining Step: 8586  | total loss: [1m[32m0.35164[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35164 - acc: 0.8736 -- iter: 2432/3680
[A[ATraining Step: 8587  | total loss: [1m[32m0.34872[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34872 - acc: 0.8589 -- iter: 2464/3680
[A[ATraining Step: 8588  | total loss: [1m[32m0.36308[0m[0m
[2K| Adam | epoch: 075 | loss: 0.36308 - acc: 0.8589 -- iter: 2496/3680
[A[ATraining Step: 8589  | total loss: [1m[32m0.34349[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34349 - acc: 0.8699 -- iter: 2528/3680
[A[ATraining Step: 8590  | total loss: [1m[32m0.32996[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32996 - acc: 0.8735 -- iter: 2560/3680
[A[ATraining Step: 8591  | total loss: [1m[32m0.32976[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32976 - acc: 0.8737 -- iter: 2592/3680
[A[ATraining Step: 8592  | total loss: [1m[32m0.34235[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34235 - acc: 0.8707 -- iter: 2624/3680
[A[ATraining Step: 8593  | total loss: [1m[32m0.34395[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34395 - acc: 0.8711 -- iter: 2656/3680
[A[ATraining Step: 8594  | total loss: [1m[32m0.35184[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35184 - acc: 0.8621 -- iter: 2688/3680
[A[ATraining Step: 8595  | total loss: [1m[32m0.35140[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35140 - acc: 0.8603 -- iter: 2720/3680
[A[ATraining Step: 8596  | total loss: [1m[32m0.37885[0m[0m
[2K| Adam | epoch: 075 | loss: 0.37885 - acc: 0.8399 -- iter: 2752/3680
[A[ATraining Step: 8597  | total loss: [1m[32m0.36494[0m[0m
[2K| Adam | epoch: 075 | loss: 0.36494 - acc: 0.8496 -- iter: 2784/3680
[A[ATraining Step: 8598  | total loss: [1m[32m0.36061[0m[0m
[2K| Adam | epoch: 075 | loss: 0.36061 - acc: 0.8553 -- iter: 2816/3680
[A[ATraining Step: 8599  | total loss: [1m[32m0.34423[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34423 - acc: 0.8604 -- iter: 2848/3680
[A[ATraining Step: 8600  | total loss: [1m[32m0.33843[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33843 - acc: 0.8619 | val_loss: 0.32138 - val_acc: 0.8871 -- iter: 2880/3680
[A[ATraining Step: 8600  | total loss: [1m[32m0.33843[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33843 - acc: 0.8619 | val_loss: 0.32138 - val_acc: 0.8871 -- iter: 2880/3680
--
Training Step: 8601  | total loss: [1m[32m0.34786[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34786 - acc: 0.8538 -- iter: 2912/3680
[A[ATraining Step: 8602  | total loss: [1m[32m0.35707[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35707 - acc: 0.8497 -- iter: 2944/3680
[A[ATraining Step: 8603  | total loss: [1m[32m0.35707[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35707 - acc: 0.8497 -- iter: 2976/3680
[A[ATraining Step: 8604  | total loss: [1m[32m0.38786[0m[0m
[2K| Adam | epoch: 075 | loss: 0.38786 - acc: 0.8397 -- iter: 3008/3680
[A[ATraining Step: 8605  | total loss: [1m[32m0.36856[0m[0m
[2K| Adam | epoch: 075 | loss: 0.36856 - acc: 0.8495 -- iter: 3040/3680
[A[ATraining Step: 8606  | total loss: [1m[32m0.37259[0m[0m
[2K| Adam | epoch: 075 | loss: 0.37259 - acc: 0.8489 -- iter: 3072/3680
[A[ATraining Step: 8607  | total loss: [1m[32m0.36087[0m[0m
[2K| Adam | epoch: 075 | loss: 0.36087 - acc: 0.8578 -- iter: 3104/3680
[A[ATraining Step: 8608  | total loss: [1m[32m0.36962[0m[0m
[2K| Adam | epoch: 075 | loss: 0.36962 - acc: 0.8501 -- iter: 3136/3680
[A[ATraining Step: 8609  | total loss: [1m[32m0.35220[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35220 - acc: 0.8608 -- iter: 3168/3680
[A[ATraining Step: 8610  | total loss: [1m[32m0.34625[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34625 - acc: 0.8608 -- iter: 3200/3680
[A[ATraining Step: 8611  | total loss: [1m[32m0.32344[0m[0m
[2K| Adam | epoch: 075 | loss: 0.32344 - acc: 0.8716 -- iter: 3232/3680
[A[ATraining Step: 8612  | total loss: [1m[32m0.33093[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33093 - acc: 0.8688 -- iter: 3264/3680
[A[ATraining Step: 8613  | total loss: [1m[32m0.33474[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33474 - acc: 0.8694 -- iter: 3296/3680
[A[ATraining Step: 8614  | total loss: [1m[32m0.33390[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33390 - acc: 0.8669 -- iter: 3328/3680
[A[ATraining Step: 8615  | total loss: [1m[32m0.34471[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34471 - acc: 0.8583 -- iter: 3360/3680
[A[ATraining Step: 8616  | total loss: [1m[32m0.33427[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33427 - acc: 0.8631 -- iter: 3392/3680
[A[ATraining Step: 8617  | total loss: [1m[32m0.35393[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35393 - acc: 0.8487 -- iter: 3424/3680
[A[ATraining Step: 8618  | total loss: [1m[32m0.34754[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34754 - acc: 0.8450 -- iter: 3456/3680
[A[ATraining Step: 8619  | total loss: [1m[32m0.33921[0m[0m
[2K| Adam | epoch: 075 | loss: 0.33921 - acc: 0.8480 -- iter: 3488/3680
[A[ATraining Step: 8620  | total loss: [1m[32m0.34394[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34394 - acc: 0.8539 -- iter: 3520/3680
[A[ATraining Step: 8621  | total loss: [1m[32m0.34037[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34037 - acc: 0.8528 -- iter: 3552/3680
[A[ATraining Step: 8622  | total loss: [1m[32m0.34310[0m[0m
[2K| Adam | epoch: 075 | loss: 0.34310 - acc: 0.8519 -- iter: 3584/3680
[A[ATraining Step: 8623  | total loss: [1m[32m0.35345[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35345 - acc: 0.8423 -- iter: 3616/3680
[A[ATraining Step: 8624  | total loss: [1m[32m0.35550[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35550 - acc: 0.8423 -- iter: 3648/3680
[A[ATraining Step: 8625  | total loss: [1m[32m0.35003[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35003 - acc: 0.8455 | val_loss: 0.30800 - val_acc: 0.8903 -- iter: 3680/3680
[A[ATraining Step: 8625  | total loss: [1m[32m0.35003[0m[0m
[2K| Adam | epoch: 075 | loss: 0.35003 - acc: 0.8455 | val_loss: 0.30800 - val_acc: 0.8903 -- iter: 3680/3680
--
Training Step: 8626  | total loss: [1m[32m0.35841[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35841 - acc: 0.8474 -- iter: 0032/3680
[A[ATraining Step: 8627  | total loss: [1m[32m0.35841[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35841 - acc: 0.8474 -- iter: 0064/3680
[A[ATraining Step: 8628  | total loss: [1m[32m0.34859[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34859 - acc: 0.8470 -- iter: 0096/3680
[A[ATraining Step: 8629  | total loss: [1m[32m0.35595[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35595 - acc: 0.8467 -- iter: 0128/3680
[A[ATraining Step: 8630  | total loss: [1m[32m0.34659[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34659 - acc: 0.8558 -- iter: 0160/3680
[A[ATraining Step: 8631  | total loss: [1m[32m0.36332[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36332 - acc: 0.8452 -- iter: 0192/3680
[A[ATraining Step: 8632  | total loss: [1m[32m0.36039[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36039 - acc: 0.8388 -- iter: 0224/3680
[A[ATraining Step: 8633  | total loss: [1m[32m0.35786[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35786 - acc: 0.8362 -- iter: 0256/3680
[A[ATraining Step: 8634  | total loss: [1m[32m0.39233[0m[0m
[2K| Adam | epoch: 076 | loss: 0.39233 - acc: 0.8244 -- iter: 0288/3680
[A[ATraining Step: 8635  | total loss: [1m[32m0.38537[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38537 - acc: 0.8232 -- iter: 0320/3680
[A[ATraining Step: 8636  | total loss: [1m[32m0.38128[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38128 - acc: 0.8222 -- iter: 0352/3680
[A[ATraining Step: 8637  | total loss: [1m[32m0.36683[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36683 - acc: 0.8306 -- iter: 0384/3680
[A[ATraining Step: 8638  | total loss: [1m[32m0.35410[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35410 - acc: 0.8350 -- iter: 0416/3680
[A[ATraining Step: 8639  | total loss: [1m[32m0.35039[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35039 - acc: 0.8390 -- iter: 0448/3680
[A[ATraining Step: 8640  | total loss: [1m[32m0.34963[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34963 - acc: 0.8364 -- iter: 0480/3680
[A[ATraining Step: 8641  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34347 - acc: 0.8402 -- iter: 0512/3680
[A[ATraining Step: 8642  | total loss: [1m[32m0.32738[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32738 - acc: 0.8500 -- iter: 0544/3680
[A[ATraining Step: 8643  | total loss: [1m[32m0.35316[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35316 - acc: 0.8462 -- iter: 0576/3680
[A[ATraining Step: 8644  | total loss: [1m[32m0.35384[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35384 - acc: 0.8460 -- iter: 0608/3680
[A[ATraining Step: 8645  | total loss: [1m[32m0.36848[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36848 - acc: 0.8426 -- iter: 0640/3680
[A[ATraining Step: 8646  | total loss: [1m[32m0.36331[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36331 - acc: 0.8459 -- iter: 0672/3680
[A[ATraining Step: 8647  | total loss: [1m[32m0.36475[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36475 - acc: 0.8456 -- iter: 0704/3680
[A[ATraining Step: 8648  | total loss: [1m[32m0.35718[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35718 - acc: 0.8517 -- iter: 0736/3680
[A[ATraining Step: 8649  | total loss: [1m[32m0.36207[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36207 - acc: 0.8478 -- iter: 0768/3680
[A[ATraining Step: 8650  | total loss: [1m[32m0.37781[0m[0m
[2K| Adam | epoch: 076 | loss: 0.37781 - acc: 0.8349 -- iter: 0800/3680
[A[ATraining Step: 8651  | total loss: [1m[32m0.39525[0m[0m
[2K| Adam | epoch: 076 | loss: 0.39525 - acc: 0.8326 -- iter: 0832/3680
[A[ATraining Step: 8652  | total loss: [1m[32m0.38106[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38106 - acc: 0.8338 -- iter: 0864/3680
[A[ATraining Step: 8653  | total loss: [1m[32m0.39215[0m[0m
[2K| Adam | epoch: 076 | loss: 0.39215 - acc: 0.8316 -- iter: 0896/3680
[A[ATraining Step: 8654  | total loss: [1m[32m0.38806[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38806 - acc: 0.8328 -- iter: 0928/3680
[A[ATraining Step: 8655  | total loss: [1m[32m0.38398[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38398 - acc: 0.8339 -- iter: 0960/3680
[A[ATraining Step: 8656  | total loss: [1m[32m0.39263[0m[0m
[2K| Adam | epoch: 076 | loss: 0.39263 - acc: 0.8349 -- iter: 0992/3680
[A[ATraining Step: 8657  | total loss: [1m[32m0.37287[0m[0m
[2K| Adam | epoch: 076 | loss: 0.37287 - acc: 0.8452 -- iter: 1024/3680
[A[ATraining Step: 8658  | total loss: [1m[32m0.36125[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36125 - acc: 0.8482 -- iter: 1056/3680
[A[ATraining Step: 8659  | total loss: [1m[32m0.35015[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35015 - acc: 0.8508 -- iter: 1088/3680
[A[ATraining Step: 8660  | total loss: [1m[32m0.34570[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34570 - acc: 0.8557 -- iter: 1120/3680
[A[ATraining Step: 8661  | total loss: [1m[32m0.34035[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34035 - acc: 0.8577 -- iter: 1152/3680
[A[ATraining Step: 8662  | total loss: [1m[32m0.33048[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33048 - acc: 0.8625 -- iter: 1184/3680
[A[ATraining Step: 8663  | total loss: [1m[32m0.33048[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33048 - acc: 0.8625 -- iter: 1216/3680
[A[ATraining Step: 8664  | total loss: [1m[32m0.32323[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32323 - acc: 0.8638 -- iter: 1248/3680
[A[ATraining Step: 8665  | total loss: [1m[32m0.31644[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31644 - acc: 0.8743 -- iter: 1280/3680
[A[ATraining Step: 8666  | total loss: [1m[32m0.31423[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31423 - acc: 0.8775 -- iter: 1312/3680
[A[ATraining Step: 8667  | total loss: [1m[32m0.30254[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30254 - acc: 0.8835 -- iter: 1344/3680
[A[ATraining Step: 8668  | total loss: [1m[32m0.38629[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38629 - acc: 0.8451 -- iter: 1376/3680
[A[ATraining Step: 8669  | total loss: [1m[32m0.37796[0m[0m
[2K| Adam | epoch: 076 | loss: 0.37796 - acc: 0.8544 -- iter: 1408/3680
[A[ATraining Step: 8670  | total loss: [1m[32m0.37908[0m[0m
[2K| Adam | epoch: 076 | loss: 0.37908 - acc: 0.8471 -- iter: 1440/3680
[A[ATraining Step: 8671  | total loss: [1m[32m0.37746[0m[0m
[2K| Adam | epoch: 076 | loss: 0.37746 - acc: 0.8498 -- iter: 1472/3680
[A[ATraining Step: 8672  | total loss: [1m[32m0.38789[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38789 - acc: 0.8461 -- iter: 1504/3680
[A[ATraining Step: 8673  | total loss: [1m[32m0.38143[0m[0m
[2K| Adam | epoch: 076 | loss: 0.38143 - acc: 0.8521 -- iter: 1536/3680
[A[ATraining Step: 8674  | total loss: [1m[32m0.36764[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36764 - acc: 0.8607 -- iter: 1568/3680
[A[ATraining Step: 8675  | total loss: [1m[32m0.36103[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36103 - acc: 0.8621 -- iter: 1600/3680
[A[ATraining Step: 8676  | total loss: [1m[32m0.35100[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35100 - acc: 0.8634 -- iter: 1632/3680
[A[ATraining Step: 8677  | total loss: [1m[32m0.34499[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34499 - acc: 0.8583 -- iter: 1664/3680
[A[ATraining Step: 8678  | total loss: [1m[32m0.34020[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34020 - acc: 0.8568 -- iter: 1696/3680
[A[ATraining Step: 8679  | total loss: [1m[32m0.33459[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33459 - acc: 0.8618 -- iter: 1728/3680
[A[ATraining Step: 8680  | total loss: [1m[32m0.33715[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33715 - acc: 0.8631 -- iter: 1760/3680
[A[ATraining Step: 8681  | total loss: [1m[32m0.33499[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33499 - acc: 0.8612 -- iter: 1792/3680
[A[ATraining Step: 8682  | total loss: [1m[32m0.32589[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32589 - acc: 0.8657 -- iter: 1824/3680
[A[ATraining Step: 8683  | total loss: [1m[32m0.32977[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32977 - acc: 0.8666 -- iter: 1856/3680
[A[ATraining Step: 8684  | total loss: [1m[32m0.32659[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32659 - acc: 0.8674 -- iter: 1888/3680
[A[ATraining Step: 8685  | total loss: [1m[32m0.32029[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32029 - acc: 0.8745 -- iter: 1920/3680
[A[ATraining Step: 8686  | total loss: [1m[32m0.32256[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32256 - acc: 0.8745 -- iter: 1952/3680
[A[ATraining Step: 8687  | total loss: [1m[32m0.32818[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32818 - acc: 0.8714 -- iter: 1984/3680
[A[ATraining Step: 8688  | total loss: [1m[32m0.32993[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32993 - acc: 0.8687 -- iter: 2016/3680
[A[ATraining Step: 8689  | total loss: [1m[32m0.32220[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32220 - acc: 0.8755 -- iter: 2048/3680
[A[ATraining Step: 8690  | total loss: [1m[32m0.31198[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31198 - acc: 0.8817 -- iter: 2080/3680
[A[ATraining Step: 8691  | total loss: [1m[32m0.31267[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31267 - acc: 0.8836 -- iter: 2112/3680
[A[ATraining Step: 8692  | total loss: [1m[32m0.30122[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30122 - acc: 0.8836 -- iter: 2144/3680
[A[ATraining Step: 8693  | total loss: [1m[32m0.30122[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30122 - acc: 0.8859 -- iter: 2176/3680
[A[ATraining Step: 8694  | total loss: [1m[32m0.30505[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30505 - acc: 0.8879 -- iter: 2208/3680
[A[ATraining Step: 8695  | total loss: [1m[32m0.32122[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32122 - acc: 0.8741 -- iter: 2240/3680
[A[ATraining Step: 8696  | total loss: [1m[32m0.30853[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30853 - acc: 0.8836 -- iter: 2272/3680
[A[ATraining Step: 8697  | total loss: [1m[32m0.32302[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32302 - acc: 0.8765 -- iter: 2304/3680
[A[ATraining Step: 8698  | total loss: [1m[32m0.31648[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31648 - acc: 0.8763 -- iter: 2336/3680
[A[ATraining Step: 8699  | total loss: [1m[32m0.30944[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30944 - acc: 0.8824 -- iter: 2368/3680
[A[ATraining Step: 8700  | total loss: [1m[32m0.31004[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31004 - acc: 0.8786 | val_loss: 0.32227 - val_acc: 0.8795 -- iter: 2400/3680
[A[ATraining Step: 8700  | total loss: [1m[32m0.31004[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31004 - acc: 0.8786 | val_loss: 0.32227 - val_acc: 0.8795 -- iter: 2400/3680
--
Training Step: 8701  | total loss: [1m[32m0.34142[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34142 - acc: 0.8657 -- iter: 2432/3680
[A[ATraining Step: 8702  | total loss: [1m[32m0.33386[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33386 - acc: 0.8698 -- iter: 2464/3680
[A[ATraining Step: 8703  | total loss: [1m[32m0.34509[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34509 - acc: 0.8672 -- iter: 2496/3680
[A[ATraining Step: 8704  | total loss: [1m[32m0.33269[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33269 - acc: 0.8742 -- iter: 2528/3680
[A[ATraining Step: 8705  | total loss: [1m[32m0.32497[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32497 - acc: 0.8743 -- iter: 2560/3680
[A[ATraining Step: 8706  | total loss: [1m[32m0.31952[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31952 - acc: 0.8775 -- iter: 2592/3680
[A[ATraining Step: 8707  | total loss: [1m[32m0.33377[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33377 - acc: 0.8647 -- iter: 2624/3680
[A[ATraining Step: 8708  | total loss: [1m[32m0.35302[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35302 - acc: 0.8533 -- iter: 2656/3680
[A[ATraining Step: 8709  | total loss: [1m[32m0.32154[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32154 - acc: 0.8783 -- iter: 2688/3680
[A[ATraining Step: 8710  | total loss: [1m[32m0.32154[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32154 - acc: 0.8686 -- iter: 2720/3680
[A[ATraining Step: 8711  | total loss: [1m[32m0.33241[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33241 - acc: 0.8661 -- iter: 2752/3680
[A[ATraining Step: 8712  | total loss: [1m[32m0.33391[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33391 - acc: 0.8661 -- iter: 2784/3680
[A[ATraining Step: 8713  | total loss: [1m[32m0.34407[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34407 - acc: 0.8608 -- iter: 2816/3680
[A[ATraining Step: 8714  | total loss: [1m[32m0.33384[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33384 - acc: 0.8653 -- iter: 2848/3680
[A[ATraining Step: 8715  | total loss: [1m[32m0.35919[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35919 - acc: 0.8507 -- iter: 2880/3680
[A[ATraining Step: 8716  | total loss: [1m[32m0.35470[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35470 - acc: 0.8531 -- iter: 2912/3680
[A[ATraining Step: 8717  | total loss: [1m[32m0.36484[0m[0m
[2K| Adam | epoch: 076 | loss: 0.36484 - acc: 0.8459 -- iter: 2944/3680
[A[ATraining Step: 8718  | total loss: [1m[32m0.35614[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35614 - acc: 0.8519 -- iter: 2976/3680
[A[ATraining Step: 8719  | total loss: [1m[32m0.35596[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35596 - acc: 0.8542 -- iter: 3008/3680
[A[ATraining Step: 8720  | total loss: [1m[32m0.35254[0m[0m
[2K| Adam | epoch: 076 | loss: 0.35254 - acc: 0.8563 -- iter: 3040/3680
[A[ATraining Step: 8721  | total loss: [1m[32m0.34481[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34481 - acc: 0.8661 -- iter: 3072/3680
[A[ATraining Step: 8722  | total loss: [1m[32m0.32954[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32954 - acc: 0.8661 -- iter: 3104/3680
[A[ATraining Step: 8723  | total loss: [1m[32m0.33351[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33351 - acc: 0.8678 -- iter: 3136/3680
[A[ATraining Step: 8724  | total loss: [1m[32m0.33344[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33344 - acc: 0.8678 -- iter: 3168/3680
[A[ATraining Step: 8725  | total loss: [1m[32m0.32721[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32721 - acc: 0.8748 -- iter: 3200/3680
[A[ATraining Step: 8726  | total loss: [1m[32m0.32887[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32887 - acc: 0.8686 -- iter: 3232/3680
[A[ATraining Step: 8727  | total loss: [1m[32m0.32371[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32371 - acc: 0.8723 -- iter: 3264/3680
[A[ATraining Step: 8728  | total loss: [1m[32m0.31800[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31800 - acc: 0.8726 -- iter: 3296/3680
[A[ATraining Step: 8729  | total loss: [1m[32m0.34297[0m[0m
[2K| Adam | epoch: 076 | loss: 0.34297 - acc: 0.8635 -- iter: 3328/3680
[A[ATraining Step: 8730  | total loss: [1m[32m0.33108[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33108 - acc: 0.8656 -- iter: 3360/3680
[A[ATraining Step: 8731  | total loss: [1m[32m0.33108[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33108 - acc: 0.8656 -- iter: 3392/3680
[A[ATraining Step: 8732  | total loss: [1m[32m0.32176[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32176 - acc: 0.8728 -- iter: 3424/3680
[A[ATraining Step: 8733  | total loss: [1m[32m0.30678[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30678 - acc: 0.8824 -- iter: 3456/3680
[A[ATraining Step: 8734  | total loss: [1m[32m0.29805[0m[0m
[2K| Adam | epoch: 076 | loss: 0.29805 - acc: 0.8879 -- iter: 3488/3680
[A[ATraining Step: 8735  | total loss: [1m[32m0.30600[0m[0m
[2K| Adam | epoch: 076 | loss: 0.30600 - acc: 0.8866 -- iter: 3520/3680
[A[ATraining Step: 8736  | total loss: [1m[32m0.31721[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31721 - acc: 0.8729 -- iter: 3552/3680
[A[ATraining Step: 8737  | total loss: [1m[32m0.31721[0m[0m
[2K| Adam | epoch: 076 | loss: 0.31721 - acc: 0.8729 -- iter: 3584/3680
[A[ATraining Step: 8738  | total loss: [1m[32m0.33141[0m[0m
[2K| Adam | epoch: 076 | loss: 0.33141 - acc: 0.8793 -- iter: 3616/3680
[A[ATraining Step: 8739  | total loss: [1m[32m0.32408[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32408 - acc: 0.8782 -- iter: 3648/3680
[A[ATraining Step: 8740  | total loss: [1m[32m0.32916[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32916 - acc: 0.8782 | val_loss: 0.30867 - val_acc: 0.8871 -- iter: 3680/3680
[A[ATraining Step: 8740  | total loss: [1m[32m0.32916[0m[0m
[2K| Adam | epoch: 076 | loss: 0.32916 - acc: 0.8782 | val_loss: 0.30867 - val_acc: 0.8871 -- iter: 3680/3680
--
Training Step: 8741  | total loss: [1m[32m0.32929[0m[0m
[2K| Adam | epoch: 077 | loss: 0.32929 - acc: 0.8747 -- iter: 0032/3680
[A[ATraining Step: 8742  | total loss: [1m[32m0.33555[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33555 - acc: 0.8654 -- iter: 0064/3680
[A[ATraining Step: 8743  | total loss: [1m[32m0.32923[0m[0m
[2K| Adam | epoch: 077 | loss: 0.32923 - acc: 0.8726 -- iter: 0096/3680
[A[ATraining Step: 8744  | total loss: [1m[32m0.31723[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31723 - acc: 0.8822 -- iter: 0128/3680
[A[ATraining Step: 8745  | total loss: [1m[32m0.31514[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31514 - acc: 0.8815 -- iter: 0160/3680
[A[ATraining Step: 8746  | total loss: [1m[32m0.32388[0m[0m
[2K| Adam | epoch: 077 | loss: 0.32388 - acc: 0.8746 -- iter: 0192/3680
[A[ATraining Step: 8747  | total loss: [1m[32m0.34124[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34124 - acc: 0.8684 -- iter: 0224/3680
[A[ATraining Step: 8748  | total loss: [1m[32m0.35656[0m[0m
[2K| Adam | epoch: 077 | loss: 0.35656 - acc: 0.8628 -- iter: 0256/3680
[A[ATraining Step: 8749  | total loss: [1m[32m0.36905[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36905 - acc: 0.8515 -- iter: 0288/3680
[A[ATraining Step: 8750  | total loss: [1m[32m0.37833[0m[0m
[2K| Adam | epoch: 077 | loss: 0.37833 - acc: 0.8500 -- iter: 0320/3680
[A[ATraining Step: 8751  | total loss: [1m[32m0.38108[0m[0m
[2K| Adam | epoch: 077 | loss: 0.38108 - acc: 0.8500 -- iter: 0352/3680
[A[ATraining Step: 8752  | total loss: [1m[32m0.37023[0m[0m
[2K| Adam | epoch: 077 | loss: 0.37023 - acc: 0.8494 -- iter: 0384/3680
[A[ATraining Step: 8753  | total loss: [1m[32m0.37424[0m[0m
[2K| Adam | epoch: 077 | loss: 0.37424 - acc: 0.8488 -- iter: 0416/3680
[A[ATraining Step: 8754  | total loss: [1m[32m0.36989[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36989 - acc: 0.8515 -- iter: 0448/3680
[A[ATraining Step: 8755  | total loss: [1m[32m0.39024[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39024 - acc: 0.8437 -- iter: 0480/3680
[A[ATraining Step: 8756  | total loss: [1m[32m0.39024[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39024 - acc: 0.8437 -- iter: 0512/3680
[A[ATraining Step: 8757  | total loss: [1m[32m0.38525[0m[0m
[2K| Adam | epoch: 077 | loss: 0.38525 - acc: 0.8559 -- iter: 0544/3680
[A[ATraining Step: 8758  | total loss: [1m[32m0.36896[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36896 - acc: 0.8559 -- iter: 0576/3680
[A[ATraining Step: 8759  | total loss: [1m[32m0.40106[0m[0m
[2K| Adam | epoch: 077 | loss: 0.40106 - acc: 0.8422 -- iter: 0608/3680
[A[ATraining Step: 8760  | total loss: [1m[32m0.42024[0m[0m
[2K| Adam | epoch: 077 | loss: 0.42024 - acc: 0.8330 -- iter: 0640/3680
[A[ATraining Step: 8761  | total loss: [1m[32m0.42145[0m[0m
[2K| Adam | epoch: 077 | loss: 0.42145 - acc: 0.8309 -- iter: 0672/3680
[A[ATraining Step: 8762  | total loss: [1m[32m0.40623[0m[0m
[2K| Adam | epoch: 077 | loss: 0.40623 - acc: 0.8385 -- iter: 0704/3680
[A[ATraining Step: 8763  | total loss: [1m[32m0.40941[0m[0m
[2K| Adam | epoch: 077 | loss: 0.40941 - acc: 0.8453 -- iter: 0736/3680
[A[ATraining Step: 8764  | total loss: [1m[32m0.39699[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39699 - acc: 0.8503 -- iter: 0768/3680
[A[ATraining Step: 8765  | total loss: [1m[32m0.39699[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39699 - acc: 0.8503 -- iter: 0800/3680
[A[ATraining Step: 8766  | total loss: [1m[32m0.39644[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39644 - acc: 0.8465 -- iter: 0832/3680
[A[ATraining Step: 8767  | total loss: [1m[32m0.39510[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39510 - acc: 0.8494 -- iter: 0864/3680
[A[ATraining Step: 8768  | total loss: [1m[32m0.39279[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39279 - acc: 0.8488 -- iter: 0896/3680
[A[ATraining Step: 8769  | total loss: [1m[32m0.37087[0m[0m
[2K| Adam | epoch: 077 | loss: 0.37087 - acc: 0.8608 -- iter: 0928/3680
[A[ATraining Step: 8770  | total loss: [1m[32m0.36176[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36176 - acc: 0.8653 -- iter: 0960/3680
[A[ATraining Step: 8771  | total loss: [1m[32m0.36712[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36712 - acc: 0.8632 -- iter: 0992/3680
[A[ATraining Step: 8772  | total loss: [1m[32m0.35846[0m[0m
[2K| Adam | epoch: 077 | loss: 0.35846 - acc: 0.8706 -- iter: 1024/3680
[A[ATraining Step: 8773  | total loss: [1m[32m0.34325[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34325 - acc: 0.8773 -- iter: 1056/3680
[A[ATraining Step: 8774  | total loss: [1m[32m0.31923[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31923 - acc: 0.8864 -- iter: 1088/3680
[A[ATraining Step: 8775  | total loss: [1m[32m0.31923[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31923 - acc: 0.8978 -- iter: 1120/3680
[A[ATraining Step: 8776  | total loss: [1m[32m0.30086[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30086 - acc: 0.9050 -- iter: 1152/3680
[A[ATraining Step: 8777  | total loss: [1m[32m0.30086[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30086 - acc: 0.9050 -- iter: 1184/3680
[A[ATraining Step: 8778  | total loss: [1m[32m0.28540[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28540 - acc: 0.9145 -- iter: 1216/3680
[A[ATraining Step: 8779  | total loss: [1m[32m0.29254[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29254 - acc: 0.9106 -- iter: 1248/3680
[A[ATraining Step: 8780  | total loss: [1m[32m0.29254[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29254 - acc: 0.9070 -- iter: 1280/3680
[A[ATraining Step: 8781  | total loss: [1m[32m0.28867[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28867 - acc: 0.9037 -- iter: 1312/3680
[A[ATraining Step: 8782  | total loss: [1m[32m0.29263[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29263 - acc: 0.9037 -- iter: 1344/3680
[A[ATraining Step: 8783  | total loss: [1m[32m0.28738[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28738 - acc: 0.9040 -- iter: 1376/3680
[A[ATraining Step: 8784  | total loss: [1m[32m0.29040[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29040 - acc: 0.9011 -- iter: 1408/3680
[A[ATraining Step: 8785  | total loss: [1m[32m0.28379[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28379 - acc: 0.9047 -- iter: 1440/3680
[A[ATraining Step: 8786  | total loss: [1m[32m0.28383[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28383 - acc: 0.9080 -- iter: 1472/3680
[A[ATraining Step: 8787  | total loss: [1m[32m0.28904[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28904 - acc: 0.8952 -- iter: 1504/3680
[A[ATraining Step: 8788  | total loss: [1m[32m0.28904[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28904 - acc: 0.8952 -- iter: 1536/3680
[A[ATraining Step: 8789  | total loss: [1m[32m0.31630[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31630 - acc: 0.8838 -- iter: 1568/3680
[A[ATraining Step: 8790  | total loss: [1m[32m0.31191[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31191 - acc: 0.8829 -- iter: 1600/3680
[A[ATraining Step: 8791  | total loss: [1m[32m0.30599[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30599 - acc: 0.8852 -- iter: 1632/3680
[A[ATraining Step: 8792  | total loss: [1m[32m0.29622[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29622 - acc: 0.8936 -- iter: 1664/3680
[A[ATraining Step: 8793  | total loss: [1m[32m0.31017[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31017 - acc: 0.8917 -- iter: 1696/3680
[A[ATraining Step: 8794  | total loss: [1m[32m0.30995[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30995 - acc: 0.8869 -- iter: 1728/3680
[A[ATraining Step: 8795  | total loss: [1m[32m0.30822[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30822 - acc: 0.8920 -- iter: 1760/3680
[A[ATraining Step: 8796  | total loss: [1m[32m0.31833[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31833 - acc: 0.8872 -- iter: 1792/3680
[A[ATraining Step: 8797  | total loss: [1m[32m0.33441[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33441 - acc: 0.8922 -- iter: 1824/3680
[A[ATraining Step: 8798  | total loss: [1m[32m0.33119[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33119 - acc: 0.8905 -- iter: 1856/3680
[A[ATraining Step: 8799  | total loss: [1m[32m0.34052[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34052 - acc: 0.8827 -- iter: 1888/3680
[A[ATraining Step: 8800  | total loss: [1m[32m0.34713[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34713 - acc: 0.8757 | val_loss: 0.30880 - val_acc: 0.8849 -- iter: 1920/3680
[A[ATraining Step: 8800  | total loss: [1m[32m0.34713[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34713 - acc: 0.8757 | val_loss: 0.30880 - val_acc: 0.8849 -- iter: 1920/3680
--
Training Step: 8801  | total loss: [1m[32m0.34530[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34530 - acc: 0.8725 -- iter: 1952/3680
[A[ATraining Step: 8802  | total loss: [1m[32m0.34449[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34449 - acc: 0.8665 -- iter: 1984/3680
[A[ATraining Step: 8803  | total loss: [1m[32m0.32669[0m[0m
[2K| Adam | epoch: 077 | loss: 0.32669 - acc: 0.8736 -- iter: 2016/3680
[A[ATraining Step: 8804  | total loss: [1m[32m0.31873[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31873 - acc: 0.8768 -- iter: 2048/3680
[A[ATraining Step: 8805  | total loss: [1m[32m0.30950[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30950 - acc: 0.8829 -- iter: 2080/3680
[A[ATraining Step: 8806  | total loss: [1m[32m0.31430[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31430 - acc: 0.8821 -- iter: 2112/3680
[A[ATraining Step: 8807  | total loss: [1m[32m0.30914[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30914 - acc: 0.8908 -- iter: 2144/3680
[A[ATraining Step: 8808  | total loss: [1m[32m0.29556[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29556 - acc: 0.8955 -- iter: 2176/3680
[A[ATraining Step: 8809  | total loss: [1m[32m0.30691[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30691 - acc: 0.8903 -- iter: 2208/3680
[A[ATraining Step: 8810  | total loss: [1m[32m0.30866[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30866 - acc: 0.8919 -- iter: 2240/3680
[A[ATraining Step: 8811  | total loss: [1m[32m0.32038[0m[0m
[2K| Adam | epoch: 077 | loss: 0.32038 - acc: 0.8839 -- iter: 2272/3680
[A[ATraining Step: 8812  | total loss: [1m[32m0.33193[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33193 - acc: 0.8768 -- iter: 2304/3680
[A[ATraining Step: 8813  | total loss: [1m[32m0.31449[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31449 - acc: 0.8891 -- iter: 2336/3680
[A[ATraining Step: 8814  | total loss: [1m[32m0.29449[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29449 - acc: 0.9002 -- iter: 2368/3680
[A[ATraining Step: 8815  | total loss: [1m[32m0.28206[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28206 - acc: 0.9071 -- iter: 2400/3680
[A[ATraining Step: 8816  | total loss: [1m[32m0.28859[0m[0m
[2K| Adam | epoch: 077 | loss: 0.28859 - acc: 0.9039 -- iter: 2432/3680
[A[ATraining Step: 8817  | total loss: [1m[32m0.29770[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29770 - acc: 0.8947 -- iter: 2464/3680
[A[ATraining Step: 8818  | total loss: [1m[32m0.30137[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30137 - acc: 0.8853 -- iter: 2496/3680
[A[ATraining Step: 8819  | total loss: [1m[32m0.30860[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30860 - acc: 0.8853 -- iter: 2528/3680
[A[ATraining Step: 8820  | total loss: [1m[32m0.29845[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29845 - acc: 0.8906 -- iter: 2560/3680
[A[ATraining Step: 8821  | total loss: [1m[32m0.30253[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30253 - acc: 0.8921 -- iter: 2592/3680
[A[ATraining Step: 8822  | total loss: [1m[32m0.29519[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29519 - acc: 0.8967 -- iter: 2624/3680
[A[ATraining Step: 8823  | total loss: [1m[32m0.30160[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30160 - acc: 0.8894 -- iter: 2656/3680
[A[ATraining Step: 8824  | total loss: [1m[32m0.31788[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31788 - acc: 0.8894 -- iter: 2688/3680
[A[ATraining Step: 8825  | total loss: [1m[32m0.30996[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30996 - acc: 0.8942 -- iter: 2720/3680
[A[ATraining Step: 8826  | total loss: [1m[32m0.31152[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31152 - acc: 0.8923 -- iter: 2752/3680
[A[ATraining Step: 8827  | total loss: [1m[32m0.30384[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30384 - acc: 0.8968 -- iter: 2784/3680
[A[ATraining Step: 8828  | total loss: [1m[32m0.30717[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30717 - acc: 0.8946 -- iter: 2816/3680
[A[ATraining Step: 8829  | total loss: [1m[32m0.29519[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29519 - acc: 0.8989 -- iter: 2848/3680
[A[ATraining Step: 8830  | total loss: [1m[32m0.29726[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29726 - acc: 0.8965 -- iter: 2880/3680
[A[ATraining Step: 8831  | total loss: [1m[32m0.29729[0m[0m
[2K| Adam | epoch: 077 | loss: 0.29729 - acc: 0.8944 -- iter: 2912/3680
[A[ATraining Step: 8832  | total loss: [1m[32m0.31305[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31305 - acc: 0.8862 -- iter: 2944/3680
[A[ATraining Step: 8833  | total loss: [1m[32m0.30247[0m[0m
[2K| Adam | epoch: 077 | loss: 0.30247 - acc: 0.8882 -- iter: 2976/3680
[A[ATraining Step: 8834  | total loss: [1m[32m0.31420[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31420 - acc: 0.8775 -- iter: 3008/3680
[A[ATraining Step: 8835  | total loss: [1m[32m0.31419[0m[0m
[2K| Adam | epoch: 077 | loss: 0.31419 - acc: 0.8773 -- iter: 3040/3680
[A[ATraining Step: 8836  | total loss: [1m[32m0.32770[0m[0m
[2K| Adam | epoch: 077 | loss: 0.32770 - acc: 0.8743 -- iter: 3072/3680
[A[ATraining Step: 8837  | total loss: [1m[32m0.33256[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33256 - acc: 0.8743 -- iter: 3104/3680
[A[ATraining Step: 8838  | total loss: [1m[32m0.33883[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33883 - acc: 0.8681 -- iter: 3136/3680
[A[ATraining Step: 8839  | total loss: [1m[32m0.35074[0m[0m
[2K| Adam | epoch: 077 | loss: 0.35074 - acc: 0.8688 -- iter: 3168/3680
[A[ATraining Step: 8840  | total loss: [1m[32m0.34442[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34442 - acc: 0.8726 -- iter: 3200/3680
[A[ATraining Step: 8841  | total loss: [1m[32m0.36033[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36033 - acc: 0.8634 -- iter: 3232/3680
[A[ATraining Step: 8842  | total loss: [1m[32m0.35347[0m[0m
[2K| Adam | epoch: 077 | loss: 0.35347 - acc: 0.8677 -- iter: 3264/3680
[A[ATraining Step: 8843  | total loss: [1m[32m0.35462[0m[0m
[2K| Adam | epoch: 077 | loss: 0.35462 - acc: 0.8653 -- iter: 3296/3680
[A[ATraining Step: 8844  | total loss: [1m[32m0.36746[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36746 - acc: 0.8600 -- iter: 3328/3680
[A[ATraining Step: 8845  | total loss: [1m[32m0.36171[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36171 - acc: 0.8647 -- iter: 3360/3680
[A[ATraining Step: 8846  | total loss: [1m[32m0.36567[0m[0m
[2K| Adam | epoch: 077 | loss: 0.36567 - acc: 0.8594 -- iter: 3392/3680
[A[ATraining Step: 8847  | total loss: [1m[32m0.38138[0m[0m
[2K| Adam | epoch: 077 | loss: 0.38138 - acc: 0.8548 -- iter: 3424/3680
[A[ATraining Step: 8848  | total loss: [1m[32m0.39965[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39965 - acc: 0.8505 -- iter: 3456/3680
[A[ATraining Step: 8849  | total loss: [1m[32m0.39293[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39293 - acc: 0.8498 -- iter: 3488/3680
[A[ATraining Step: 8850  | total loss: [1m[32m0.39160[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39160 - acc: 0.8430 -- iter: 3520/3680
[A[ATraining Step: 8851  | total loss: [1m[32m0.39732[0m[0m
[2K| Adam | epoch: 077 | loss: 0.39732 - acc: 0.8462 -- iter: 3552/3680
[A[ATraining Step: 8852  | total loss: [1m[32m0.38147[0m[0m
[2K| Adam | epoch: 077 | loss: 0.38147 - acc: 0.8522 -- iter: 3584/3680
[A[ATraining Step: 8853  | total loss: [1m[32m0.37164[0m[0m
[2K| Adam | epoch: 077 | loss: 0.37164 - acc: 0.8576 -- iter: 3616/3680
[A[ATraining Step: 8854  | total loss: [1m[32m0.34926[0m[0m
[2K| Adam | epoch: 077 | loss: 0.34926 - acc: 0.8784 -- iter: 3648/3680
[A[ATraining Step: 8855  | total loss: [1m[32m0.33821[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33821 - acc: 0.8784 | val_loss: 0.30256 - val_acc: 0.8914 -- iter: 3680/3680
[A[ATraining Step: 8855  | total loss: [1m[32m0.33821[0m[0m
[2K| Adam | epoch: 077 | loss: 0.33821 - acc: 0.8784 | val_loss: 0.30256 - val_acc: 0.8914 -- iter: 3680/3680
--
Training Step: 8856  | total loss: [1m[32m0.32527[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32527 - acc: 0.8843 -- iter: 0032/3680
[A[ATraining Step: 8857  | total loss: [1m[32m0.31675[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31675 - acc: 0.8896 -- iter: 0064/3680
[A[ATraining Step: 8858  | total loss: [1m[32m0.32608[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32608 - acc: 0.8819 -- iter: 0096/3680
[A[ATraining Step: 8859  | total loss: [1m[32m0.33353[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33353 - acc: 0.8747 -- iter: 0128/3680
[A[ATraining Step: 8860  | total loss: [1m[32m0.33515[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33515 - acc: 0.8747 -- iter: 0160/3680
[A[ATraining Step: 8861  | total loss: [1m[32m0.34265[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34265 - acc: 0.8653 -- iter: 0192/3680
[A[ATraining Step: 8862  | total loss: [1m[32m0.35425[0m[0m
[2K| Adam | epoch: 078 | loss: 0.35425 - acc: 0.8569 -- iter: 0224/3680
[A[ATraining Step: 8863  | total loss: [1m[32m0.36108[0m[0m
[2K| Adam | epoch: 078 | loss: 0.36108 - acc: 0.8516 -- iter: 0256/3680
[A[ATraining Step: 8864  | total loss: [1m[32m0.36108[0m[0m
[2K| Adam | epoch: 078 | loss: 0.36108 - acc: 0.8516 -- iter: 0288/3680
[A[ATraining Step: 8865  | total loss: [1m[32m0.34788[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34788 - acc: 0.8595 -- iter: 0320/3680
[A[ATraining Step: 8866  | total loss: [1m[32m0.34788[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34788 - acc: 0.8595 -- iter: 0352/3680
[A[ATraining Step: 8867  | total loss: [1m[32m0.33583[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33583 - acc: 0.8673 -- iter: 0384/3680
[A[ATraining Step: 8868  | total loss: [1m[32m0.34186[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34186 - acc: 0.8618 -- iter: 0416/3680
[A[ATraining Step: 8869  | total loss: [1m[32m0.33475[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33475 - acc: 0.8663 -- iter: 0448/3680
[A[ATraining Step: 8870  | total loss: [1m[32m0.32409[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32409 - acc: 0.8707 -- iter: 0480/3680
[A[ATraining Step: 8871  | total loss: [1m[32m0.32409[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32409 - acc: 0.8707 -- iter: 0512/3680
[A[ATraining Step: 8872  | total loss: [1m[32m0.32451[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32451 - acc: 0.8743 -- iter: 0544/3680
[A[ATraining Step: 8873  | total loss: [1m[32m0.32191[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32191 - acc: 0.8775 -- iter: 0576/3680
[A[ATraining Step: 8874  | total loss: [1m[32m0.31214[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31214 - acc: 0.8835 -- iter: 0608/3680
[A[ATraining Step: 8875  | total loss: [1m[32m0.32327[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32327 - acc: 0.8733 -- iter: 0640/3680
[A[ATraining Step: 8876  | total loss: [1m[32m0.32715[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32715 - acc: 0.8734 -- iter: 0672/3680
[A[ATraining Step: 8877  | total loss: [1m[32m0.33168[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33168 - acc: 0.8709 -- iter: 0704/3680
[A[ATraining Step: 8878  | total loss: [1m[32m0.33168[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33168 - acc: 0.8709 -- iter: 0736/3680
[A[ATraining Step: 8879  | total loss: [1m[32m0.32795[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32795 - acc: 0.8713 -- iter: 0768/3680
[A[ATraining Step: 8880  | total loss: [1m[32m0.32788[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32788 - acc: 0.8717 -- iter: 0800/3680
[A[ATraining Step: 8881  | total loss: [1m[32m0.31906[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31906 - acc: 0.8751 -- iter: 0832/3680
[A[ATraining Step: 8882  | total loss: [1m[32m0.33817[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33817 - acc: 0.8720 -- iter: 0864/3680
[A[ATraining Step: 8883  | total loss: [1m[32m0.34180[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34180 - acc: 0.8786 -- iter: 0896/3680
[A[ATraining Step: 8884  | total loss: [1m[32m0.34180[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34180 - acc: 0.8757 -- iter: 0928/3680
[A[ATraining Step: 8885  | total loss: [1m[32m0.33247[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33247 - acc: 0.8757 -- iter: 0960/3680
[A[ATraining Step: 8886  | total loss: [1m[32m0.34478[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34478 - acc: 0.8781 -- iter: 0992/3680
[A[ATraining Step: 8887  | total loss: [1m[32m0.34478[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34478 - acc: 0.8781 -- iter: 1024/3680
[A[ATraining Step: 8888  | total loss: [1m[32m0.34092[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34092 - acc: 0.8809 -- iter: 1056/3680
[A[ATraining Step: 8889  | total loss: [1m[32m0.34208[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34208 - acc: 0.8772 -- iter: 1088/3680
[A[ATraining Step: 8890  | total loss: [1m[32m0.34296[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34296 - acc: 0.8738 -- iter: 1120/3680
[A[ATraining Step: 8891  | total loss: [1m[32m0.33649[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33649 - acc: 0.8771 -- iter: 1152/3680
[A[ATraining Step: 8892  | total loss: [1m[32m0.32355[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32355 - acc: 0.8862 -- iter: 1184/3680
[A[ATraining Step: 8893  | total loss: [1m[32m0.31590[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31590 - acc: 0.8882 -- iter: 1216/3680
[A[ATraining Step: 8894  | total loss: [1m[32m0.31041[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31041 - acc: 0.8932 -- iter: 1248/3680
[A[ATraining Step: 8895  | total loss: [1m[32m0.33005[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33005 - acc: 0.8788 -- iter: 1280/3680
[A[ATraining Step: 8896  | total loss: [1m[32m0.32498[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32498 - acc: 0.8815 -- iter: 1312/3680
[A[ATraining Step: 8897  | total loss: [1m[32m0.31976[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31976 - acc: 0.8815 -- iter: 1344/3680
[A[ATraining Step: 8898  | total loss: [1m[32m0.32028[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32028 - acc: 0.8840 -- iter: 1376/3680
[A[ATraining Step: 8899  | total loss: [1m[32m0.31492[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31492 - acc: 0.8862 -- iter: 1408/3680
[A[ATraining Step: 8900  | total loss: [1m[32m0.38136[0m[0m
[2K| Adam | epoch: 078 | loss: 0.38136 - acc: 0.8560 | val_loss: 0.30976 - val_acc: 0.8817 -- iter: 1440/3680
[A[ATraining Step: 8900  | total loss: [1m[32m0.38136[0m[0m
[2K| Adam | epoch: 078 | loss: 0.38136 - acc: 0.8560 | val_loss: 0.30976 - val_acc: 0.8817 -- iter: 1440/3680
--
Training Step: 8901  | total loss: [1m[32m0.38136[0m[0m
[2K| Adam | epoch: 078 | loss: 0.38136 - acc: 0.8560 -- iter: 1472/3680
[A[ATraining Step: 8902  | total loss: [1m[32m0.38533[0m[0m
[2K| Adam | epoch: 078 | loss: 0.38533 - acc: 0.8610 -- iter: 1504/3680
[A[ATraining Step: 8903  | total loss: [1m[32m0.38197[0m[0m
[2K| Adam | epoch: 078 | loss: 0.38197 - acc: 0.8593 -- iter: 1536/3680
[A[ATraining Step: 8904  | total loss: [1m[32m0.39919[0m[0m
[2K| Adam | epoch: 078 | loss: 0.39919 - acc: 0.8515 -- iter: 1568/3680
[A[ATraining Step: 8905  | total loss: [1m[32m0.37604[0m[0m
[2K| Adam | epoch: 078 | loss: 0.37604 - acc: 0.8601 -- iter: 1600/3680
[A[ATraining Step: 8906  | total loss: [1m[32m0.35865[0m[0m
[2K| Adam | epoch: 078 | loss: 0.35865 - acc: 0.8647 -- iter: 1632/3680
[A[ATraining Step: 8907  | total loss: [1m[32m0.34630[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34630 - acc: 0.8657 -- iter: 1664/3680
[A[ATraining Step: 8908  | total loss: [1m[32m0.33835[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33835 - acc: 0.8729 -- iter: 1696/3680
[A[ATraining Step: 8909  | total loss: [1m[32m0.33963[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33963 - acc: 0.8733 -- iter: 1728/3680
[A[ATraining Step: 8910  | total loss: [1m[32m0.34094[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34094 - acc: 0.8733 -- iter: 1760/3680
[A[ATraining Step: 8911  | total loss: [1m[32m0.32417[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32417 - acc: 0.8797 -- iter: 1792/3680
[A[ATraining Step: 8912  | total loss: [1m[32m0.32560[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32560 - acc: 0.8730 -- iter: 1824/3680
[A[ATraining Step: 8913  | total loss: [1m[32m0.32823[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32823 - acc: 0.8763 -- iter: 1856/3680
[A[ATraining Step: 8914  | total loss: [1m[32m0.34221[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34221 - acc: 0.8699 -- iter: 1888/3680
[A[ATraining Step: 8915  | total loss: [1m[32m0.37668[0m[0m
[2K| Adam | epoch: 078 | loss: 0.37668 - acc: 0.8611 -- iter: 1920/3680
[A[ATraining Step: 8916  | total loss: [1m[32m0.38051[0m[0m
[2K| Adam | epoch: 078 | loss: 0.38051 - acc: 0.8672 -- iter: 1952/3680
[A[ATraining Step: 8917  | total loss: [1m[32m0.37730[0m[0m
[2K| Adam | epoch: 078 | loss: 0.37730 - acc: 0.8679 -- iter: 1984/3680
[A[ATraining Step: 8918  | total loss: [1m[32m0.37730[0m[0m
[2K| Adam | epoch: 078 | loss: 0.37730 - acc: 0.8679 -- iter: 2016/3680
[A[ATraining Step: 8919  | total loss: [1m[32m0.37780[0m[0m
[2K| Adam | epoch: 078 | loss: 0.37780 - acc: 0.8686 -- iter: 2048/3680
[A[ATraining Step: 8920  | total loss: [1m[32m0.36900[0m[0m
[2K| Adam | epoch: 078 | loss: 0.36900 - acc: 0.8724 -- iter: 2080/3680
[A[ATraining Step: 8921  | total loss: [1m[32m0.35977[0m[0m
[2K| Adam | epoch: 078 | loss: 0.35977 - acc: 0.8757 -- iter: 2112/3680
[A[ATraining Step: 8922  | total loss: [1m[32m0.35977[0m[0m
[2K| Adam | epoch: 078 | loss: 0.35977 - acc: 0.8757 -- iter: 2144/3680
[A[ATraining Step: 8923  | total loss: [1m[32m0.36590[0m[0m
[2K| Adam | epoch: 078 | loss: 0.36590 - acc: 0.8694 -- iter: 2176/3680
[A[ATraining Step: 8924  | total loss: [1m[32m0.35674[0m[0m
[2K| Adam | epoch: 078 | loss: 0.35674 - acc: 0.8762 -- iter: 2208/3680
[A[ATraining Step: 8925  | total loss: [1m[32m0.34398[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34398 - acc: 0.8823 -- iter: 2240/3680
[A[ATraining Step: 8926  | total loss: [1m[32m0.35036[0m[0m
[2K| Adam | epoch: 078 | loss: 0.35036 - acc: 0.8753 -- iter: 2272/3680
[A[ATraining Step: 8927  | total loss: [1m[32m0.33861[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33861 - acc: 0.8847 -- iter: 2304/3680
[A[ATraining Step: 8928  | total loss: [1m[32m0.34704[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34704 - acc: 0.8775 -- iter: 2336/3680
[A[ATraining Step: 8929  | total loss: [1m[32m0.33580[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33580 - acc: 0.8803 -- iter: 2368/3680
[A[ATraining Step: 8930  | total loss: [1m[32m0.33447[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33447 - acc: 0.8767 -- iter: 2400/3680
[A[ATraining Step: 8931  | total loss: [1m[32m0.32659[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32659 - acc: 0.8796 -- iter: 2432/3680
[A[ATraining Step: 8932  | total loss: [1m[32m0.31503[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31503 - acc: 0.8917 -- iter: 2464/3680
[A[ATraining Step: 8933  | total loss: [1m[32m0.30654[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30654 - acc: 0.8963 -- iter: 2496/3680
[A[ATraining Step: 8934  | total loss: [1m[32m0.30515[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30515 - acc: 0.8973 -- iter: 2528/3680
[A[ATraining Step: 8935  | total loss: [1m[32m0.32730[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32730 - acc: 0.8888 -- iter: 2560/3680
[A[ATraining Step: 8936  | total loss: [1m[32m0.32418[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32418 - acc: 0.8812 -- iter: 2592/3680
[A[ATraining Step: 8937  | total loss: [1m[32m0.32611[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32611 - acc: 0.8743 -- iter: 2624/3680
[A[ATraining Step: 8938  | total loss: [1m[32m0.32565[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32565 - acc: 0.8681 -- iter: 2656/3680
[A[ATraining Step: 8939  | total loss: [1m[32m0.30915[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30915 - acc: 0.8782 -- iter: 2688/3680
[A[ATraining Step: 8940  | total loss: [1m[32m0.31172[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31172 - acc: 0.8841 -- iter: 2720/3680
[A[ATraining Step: 8941  | total loss: [1m[32m0.29699[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29699 - acc: 0.8926 -- iter: 2752/3680
[A[ATraining Step: 8942  | total loss: [1m[32m0.29628[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29628 - acc: 0.8939 -- iter: 2784/3680
[A[ATraining Step: 8943  | total loss: [1m[32m0.30421[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30421 - acc: 0.8795 -- iter: 2816/3680
[A[ATraining Step: 8944  | total loss: [1m[32m0.30859[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30859 - acc: 0.8760 -- iter: 2848/3680
[A[ATraining Step: 8945  | total loss: [1m[32m0.31364[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31364 - acc: 0.8696 -- iter: 2880/3680
[A[ATraining Step: 8946  | total loss: [1m[32m0.30491[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30491 - acc: 0.8795 -- iter: 2912/3680
[A[ATraining Step: 8947  | total loss: [1m[32m0.30009[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30009 - acc: 0.8853 -- iter: 2944/3680
[A[ATraining Step: 8948  | total loss: [1m[32m0.29744[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29744 - acc: 0.8843 -- iter: 2976/3680
[A[ATraining Step: 8949  | total loss: [1m[32m0.29206[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29206 - acc: 0.8857 -- iter: 3008/3680
[A[ATraining Step: 8950  | total loss: [1m[32m0.29206[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29206 - acc: 0.8877 -- iter: 3040/3680
[A[ATraining Step: 8951  | total loss: [1m[32m0.28437[0m[0m
[2K| Adam | epoch: 078 | loss: 0.28437 - acc: 0.8877 -- iter: 3072/3680
[A[ATraining Step: 8952  | total loss: [1m[32m0.30168[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30168 - acc: 0.8802 -- iter: 3104/3680
[A[ATraining Step: 8953  | total loss: [1m[32m0.29669[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29669 - acc: 0.8797 -- iter: 3136/3680
[A[ATraining Step: 8954  | total loss: [1m[32m0.29560[0m[0m
[2K| Adam | epoch: 078 | loss: 0.29560 - acc: 0.8792 -- iter: 3168/3680
[A[ATraining Step: 8955  | total loss: [1m[32m0.30699[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30699 - acc: 0.8694 -- iter: 3200/3680
[A[ATraining Step: 8956  | total loss: [1m[32m0.31187[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31187 - acc: 0.8700 -- iter: 3232/3680
[A[ATraining Step: 8957  | total loss: [1m[32m0.30965[0m[0m
[2K| Adam | epoch: 078 | loss: 0.30965 - acc: 0.8736 -- iter: 3264/3680
[A[ATraining Step: 8958  | total loss: [1m[32m0.32491[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32491 - acc: 0.8644 -- iter: 3296/3680
[A[ATraining Step: 8959  | total loss: [1m[32m0.32681[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32681 - acc: 0.8608 -- iter: 3328/3680
[A[ATraining Step: 8960  | total loss: [1m[32m0.32815[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32815 - acc: 0.8608 -- iter: 3360/3680
[A[ATraining Step: 8961  | total loss: [1m[32m0.31242[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31242 - acc: 0.8684 -- iter: 3392/3680
[A[ATraining Step: 8962  | total loss: [1m[32m0.31151[0m[0m
[2K| Adam | epoch: 078 | loss: 0.31151 - acc: 0.8722 -- iter: 3424/3680
[A[ATraining Step: 8963  | total loss: [1m[32m0.33629[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33629 - acc: 0.8537 -- iter: 3456/3680
[A[ATraining Step: 8964  | total loss: [1m[32m0.34687[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34687 - acc: 0.8496 -- iter: 3488/3680
[A[ATraining Step: 8965  | total loss: [1m[32m0.34164[0m[0m
[2K| Adam | epoch: 078 | loss: 0.34164 - acc: 0.8522 -- iter: 3520/3680
[A[ATraining Step: 8966  | total loss: [1m[32m0.33851[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33851 - acc: 0.8576 -- iter: 3552/3680
[A[ATraining Step: 8967  | total loss: [1m[32m0.32483[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32483 - acc: 0.8656 -- iter: 3584/3680
[A[ATraining Step: 8968  | total loss: [1m[32m0.33501[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33501 - acc: 0.8603 -- iter: 3616/3680
[A[ATraining Step: 8969  | total loss: [1m[32m0.32682[0m[0m
[2K| Adam | epoch: 078 | loss: 0.32682 - acc: 0.8711 -- iter: 3648/3680
[A[ATraining Step: 8970  | total loss: [1m[32m0.33702[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33702 - acc: 0.8621 | val_loss: 0.30498 - val_acc: 0.8849 -- iter: 3680/3680
[A[ATraining Step: 8970  | total loss: [1m[32m0.33702[0m[0m
[2K| Adam | epoch: 078 | loss: 0.33702 - acc: 0.8621 | val_loss: 0.30498 - val_acc: 0.8849 -- iter: 3680/3680
--
Training Step: 8971  | total loss: [1m[32m0.33331[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33331 - acc: 0.8634 -- iter: 0032/3680
[A[ATraining Step: 8972  | total loss: [1m[32m0.34454[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34454 - acc: 0.8552 -- iter: 0064/3680
[A[ATraining Step: 8973  | total loss: [1m[32m0.34192[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34192 - acc: 0.8540 -- iter: 0096/3680
[A[ATraining Step: 8974  | total loss: [1m[32m0.35577[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35577 - acc: 0.8374 -- iter: 0128/3680
[A[ATraining Step: 8975  | total loss: [1m[32m0.35660[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35660 - acc: 0.8349 -- iter: 0160/3680
[A[ATraining Step: 8976  | total loss: [1m[32m0.36143[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36143 - acc: 0.8358 -- iter: 0192/3680
[A[ATraining Step: 8977  | total loss: [1m[32m0.34972[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34972 - acc: 0.8397 -- iter: 0224/3680
[A[ATraining Step: 8978  | total loss: [1m[32m0.35716[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35716 - acc: 0.8370 -- iter: 0256/3680
[A[ATraining Step: 8979  | total loss: [1m[32m0.34672[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34672 - acc: 0.8470 -- iter: 0288/3680
[A[ATraining Step: 8980  | total loss: [1m[32m0.35515[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35515 - acc: 0.8436 -- iter: 0320/3680
[A[ATraining Step: 8981  | total loss: [1m[32m0.35759[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35759 - acc: 0.8467 -- iter: 0352/3680
[A[ATraining Step: 8982  | total loss: [1m[32m0.35428[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35428 - acc: 0.8487 -- iter: 0384/3680
[A[ATraining Step: 8983  | total loss: [1m[32m0.35636[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35636 - acc: 0.8487 -- iter: 0416/3680
[A[ATraining Step: 8984  | total loss: [1m[32m0.35417[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35417 - acc: 0.8482 -- iter: 0448/3680
[A[ATraining Step: 8985  | total loss: [1m[32m0.34569[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34569 - acc: 0.8602 -- iter: 0480/3680
[A[ATraining Step: 8986  | total loss: [1m[32m0.34172[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34172 - acc: 0.8617 -- iter: 0512/3680
[A[ATraining Step: 8987  | total loss: [1m[32m0.33540[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33540 - acc: 0.8630 -- iter: 0544/3680
[A[ATraining Step: 8988  | total loss: [1m[32m0.33050[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33050 - acc: 0.8705 -- iter: 0576/3680
[A[ATraining Step: 8989  | total loss: [1m[32m0.31894[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31894 - acc: 0.8772 -- iter: 0608/3680
[A[ATraining Step: 8990  | total loss: [1m[32m0.34045[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34045 - acc: 0.8613 -- iter: 0640/3680
[A[ATraining Step: 8991  | total loss: [1m[32m0.34644[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34644 - acc: 0.8565 -- iter: 0672/3680
[A[ATraining Step: 8992  | total loss: [1m[32m0.34369[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34369 - acc: 0.8583 -- iter: 0704/3680
[A[ATraining Step: 8993  | total loss: [1m[32m0.35145[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35145 - acc: 0.8537 -- iter: 0736/3680
[A[ATraining Step: 8994  | total loss: [1m[32m0.36115[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36115 - acc: 0.8496 -- iter: 0768/3680
[A[ATraining Step: 8995  | total loss: [1m[32m0.34239[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34239 - acc: 0.8584 -- iter: 0800/3680
[A[ATraining Step: 8996  | total loss: [1m[32m0.34963[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34963 - acc: 0.8569 -- iter: 0832/3680
[A[ATraining Step: 8997  | total loss: [1m[32m0.34465[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34465 - acc: 0.8619 -- iter: 0864/3680
[A[ATraining Step: 8998  | total loss: [1m[32m0.33811[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33811 - acc: 0.8694 -- iter: 0896/3680
[A[ATraining Step: 8999  | total loss: [1m[32m0.34060[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34060 - acc: 0.8669 -- iter: 0928/3680
[A[ATraining Step: 9000  | total loss: [1m[32m0.32629[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32629 - acc: 0.8708 | val_loss: 0.29927 - val_acc: 0.8914 -- iter: 0960/3680
[A[ATraining Step: 9000  | total loss: [1m[32m0.32629[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32629 - acc: 0.8708 | val_loss: 0.29927 - val_acc: 0.8914 -- iter: 0960/3680
--
Training Step: 9001  | total loss: [1m[32m0.31899[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31899 - acc: 0.8681 -- iter: 0992/3680
[A[ATraining Step: 9002  | total loss: [1m[32m0.31763[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31763 - acc: 0.8657 -- iter: 1024/3680
[A[ATraining Step: 9003  | total loss: [1m[32m0.32121[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32121 - acc: 0.8666 -- iter: 1056/3680
[A[ATraining Step: 9004  | total loss: [1m[32m0.32383[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32383 - acc: 0.8643 -- iter: 1088/3680
[A[ATraining Step: 9005  | total loss: [1m[32m0.32340[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32340 - acc: 0.8685 -- iter: 1120/3680
[A[ATraining Step: 9006  | total loss: [1m[32m0.34016[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34016 - acc: 0.8660 -- iter: 1152/3680
[A[ATraining Step: 9007  | total loss: [1m[32m0.36376[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36376 - acc: 0.8513 -- iter: 1184/3680
[A[ATraining Step: 9008  | total loss: [1m[32m0.35696[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35696 - acc: 0.8537 -- iter: 1216/3680
[A[ATraining Step: 9009  | total loss: [1m[32m0.36229[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36229 - acc: 0.8464 -- iter: 1248/3680
[A[ATraining Step: 9010  | total loss: [1m[32m0.35450[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35450 - acc: 0.8550 -- iter: 1280/3680
[A[ATraining Step: 9011  | total loss: [1m[32m0.34651[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34651 - acc: 0.8550 -- iter: 1312/3680
[A[ATraining Step: 9012  | total loss: [1m[32m0.33720[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33720 - acc: 0.8570 -- iter: 1344/3680
[A[ATraining Step: 9013  | total loss: [1m[32m0.33689[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33689 - acc: 0.8463 -- iter: 1376/3680
[A[ATraining Step: 9014  | total loss: [1m[32m0.33646[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33646 - acc: 0.8460 -- iter: 1408/3680
[A[ATraining Step: 9015  | total loss: [1m[32m0.33257[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33257 - acc: 0.8521 -- iter: 1440/3680
[A[ATraining Step: 9016  | total loss: [1m[32m0.45665[0m[0m
[2K| Adam | epoch: 079 | loss: 0.45665 - acc: 0.8043 -- iter: 1472/3680
[A[ATraining Step: 9017  | total loss: [1m[32m0.45395[0m[0m
[2K| Adam | epoch: 079 | loss: 0.45395 - acc: 0.8083 -- iter: 1504/3680
[A[ATraining Step: 9018  | total loss: [1m[32m0.43404[0m[0m
[2K| Adam | epoch: 079 | loss: 0.43404 - acc: 0.8181 -- iter: 1536/3680
[A[ATraining Step: 9019  | total loss: [1m[32m0.40473[0m[0m
[2K| Adam | epoch: 079 | loss: 0.40473 - acc: 0.8363 -- iter: 1568/3680
[A[ATraining Step: 9020  | total loss: [1m[32m0.40225[0m[0m
[2K| Adam | epoch: 079 | loss: 0.40225 - acc: 0.8370 -- iter: 1600/3680
[A[ATraining Step: 9021  | total loss: [1m[32m0.40089[0m[0m
[2K| Adam | epoch: 079 | loss: 0.40089 - acc: 0.8383 -- iter: 1632/3680
[A[ATraining Step: 9022  | total loss: [1m[32m0.39052[0m[0m
[2K| Adam | epoch: 079 | loss: 0.39052 - acc: 0.8383 -- iter: 1664/3680
[A[ATraining Step: 9023  | total loss: [1m[32m0.37414[0m[0m
[2K| Adam | epoch: 079 | loss: 0.37414 - acc: 0.8482 -- iter: 1696/3680
[A[ATraining Step: 9024  | total loss: [1m[32m0.36201[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36201 - acc: 0.8502 -- iter: 1728/3680
[A[ATraining Step: 9025  | total loss: [1m[32m0.36201[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36201 - acc: 0.8502 -- iter: 1760/3680
[A[ATraining Step: 9026  | total loss: [1m[32m0.36655[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36655 - acc: 0.8527 -- iter: 1792/3680
[A[ATraining Step: 9027  | total loss: [1m[32m0.35583[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35583 - acc: 0.8611 -- iter: 1824/3680
[A[ATraining Step: 9028  | total loss: [1m[32m0.35867[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35867 - acc: 0.8657 -- iter: 1856/3680
[A[ATraining Step: 9029  | total loss: [1m[32m0.35457[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35457 - acc: 0.8666 -- iter: 1888/3680
[A[ATraining Step: 9030  | total loss: [1m[32m0.34673[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34673 - acc: 0.8737 -- iter: 1920/3680
[A[ATraining Step: 9031  | total loss: [1m[32m0.34464[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34464 - acc: 0.8801 -- iter: 1952/3680
[A[ATraining Step: 9032  | total loss: [1m[32m0.33652[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33652 - acc: 0.8827 -- iter: 1984/3680
[A[ATraining Step: 9033  | total loss: [1m[32m0.32620[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32620 - acc: 0.8882 -- iter: 2016/3680
[A[ATraining Step: 9034  | total loss: [1m[32m0.32338[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32338 - acc: 0.8837 -- iter: 2048/3680
[A[ATraining Step: 9035  | total loss: [1m[32m0.32714[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32714 - acc: 0.8735 -- iter: 2080/3680
[A[ATraining Step: 9036  | total loss: [1m[32m0.31357[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31357 - acc: 0.8799 -- iter: 2112/3680
[A[ATraining Step: 9037  | total loss: [1m[32m0.30176[0m[0m
[2K| Adam | epoch: 079 | loss: 0.30176 - acc: 0.8888 -- iter: 2144/3680
[A[ATraining Step: 9038  | total loss: [1m[32m0.29432[0m[0m
[2K| Adam | epoch: 079 | loss: 0.29432 - acc: 0.8936 -- iter: 2176/3680
[A[ATraining Step: 9039  | total loss: [1m[32m0.32555[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32555 - acc: 0.8757 -- iter: 2208/3680
[A[ATraining Step: 9040  | total loss: [1m[32m0.32453[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32453 - acc: 0.8757 -- iter: 2240/3680
[A[ATraining Step: 9041  | total loss: [1m[32m0.33884[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33884 - acc: 0.8725 -- iter: 2272/3680
[A[ATraining Step: 9042  | total loss: [1m[32m0.35501[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35501 - acc: 0.8571 -- iter: 2304/3680
[A[ATraining Step: 9043  | total loss: [1m[32m0.35964[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35964 - acc: 0.8621 -- iter: 2336/3680
[A[ATraining Step: 9044  | total loss: [1m[32m0.34364[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34364 - acc: 0.8696 -- iter: 2368/3680
[A[ATraining Step: 9045  | total loss: [1m[32m0.35206[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35206 - acc: 0.8608 -- iter: 2400/3680
[A[ATraining Step: 9046  | total loss: [1m[32m0.36487[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36487 - acc: 0.8528 -- iter: 2432/3680
[A[ATraining Step: 9047  | total loss: [1m[32m0.36814[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36814 - acc: 0.8550 -- iter: 2464/3680
[A[ATraining Step: 9048  | total loss: [1m[32m0.37765[0m[0m
[2K| Adam | epoch: 079 | loss: 0.37765 - acc: 0.8477 -- iter: 2496/3680
[A[ATraining Step: 9049  | total loss: [1m[32m0.37316[0m[0m
[2K| Adam | epoch: 079 | loss: 0.37316 - acc: 0.8473 -- iter: 2528/3680
[A[ATraining Step: 9050  | total loss: [1m[32m0.37756[0m[0m
[2K| Adam | epoch: 079 | loss: 0.37756 - acc: 0.8469 -- iter: 2560/3680
[A[ATraining Step: 9051  | total loss: [1m[32m0.36953[0m[0m
[2K| Adam | epoch: 079 | loss: 0.36953 - acc: 0.8497 -- iter: 2592/3680
[A[ATraining Step: 9052  | total loss: [1m[32m0.35811[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35811 - acc: 0.8554 -- iter: 2624/3680
[A[ATraining Step: 9053  | total loss: [1m[32m0.33823[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33823 - acc: 0.8667 -- iter: 2656/3680
[A[ATraining Step: 9054  | total loss: [1m[32m0.31911[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31911 - acc: 0.8738 -- iter: 2688/3680
[A[ATraining Step: 9055  | total loss: [1m[32m0.32127[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32127 - acc: 0.8739 -- iter: 2720/3680
[A[ATraining Step: 9056  | total loss: [1m[32m0.32153[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32153 - acc: 0.8709 -- iter: 2752/3680
[A[ATraining Step: 9057  | total loss: [1m[32m0.33115[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33115 - acc: 0.8776 -- iter: 2784/3680
[A[ATraining Step: 9058  | total loss: [1m[32m0.33147[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33147 - acc: 0.8742 -- iter: 2816/3680
[A[ATraining Step: 9059  | total loss: [1m[32m0.33219[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33219 - acc: 0.8774 -- iter: 2848/3680
[A[ATraining Step: 9060  | total loss: [1m[32m0.33307[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33307 - acc: 0.8740 -- iter: 2880/3680
[A[ATraining Step: 9061  | total loss: [1m[32m0.32940[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32940 - acc: 0.8741 -- iter: 2912/3680
[A[ATraining Step: 9062  | total loss: [1m[32m0.31909[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31909 - acc: 0.8865 -- iter: 2944/3680
[A[ATraining Step: 9063  | total loss: [1m[32m0.30535[0m[0m
[2K| Adam | epoch: 079 | loss: 0.30535 - acc: 0.8865 -- iter: 2976/3680
[A[ATraining Step: 9064  | total loss: [1m[32m0.31256[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31256 - acc: 0.8760 -- iter: 3008/3680
[A[ATraining Step: 9065  | total loss: [1m[32m0.31820[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31820 - acc: 0.8727 -- iter: 3040/3680
[A[ATraining Step: 9066  | total loss: [1m[32m0.30938[0m[0m
[2K| Adam | epoch: 079 | loss: 0.30938 - acc: 0.8761 -- iter: 3072/3680
[A[ATraining Step: 9067  | total loss: [1m[32m0.31209[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31209 - acc: 0.8760 -- iter: 3104/3680
[A[ATraining Step: 9068  | total loss: [1m[32m0.30904[0m[0m
[2K| Adam | epoch: 079 | loss: 0.30904 - acc: 0.8759 -- iter: 3136/3680
[A[ATraining Step: 9069  | total loss: [1m[32m0.31690[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31690 - acc: 0.8758 -- iter: 3168/3680
[A[ATraining Step: 9070  | total loss: [1m[32m0.32700[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32700 - acc: 0.8632 -- iter: 3200/3680
[A[ATraining Step: 9071  | total loss: [1m[32m0.32999[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32999 - acc: 0.8613 -- iter: 3232/3680
[A[ATraining Step: 9072  | total loss: [1m[32m0.32270[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32270 - acc: 0.8689 -- iter: 3264/3680
[A[ATraining Step: 9073  | total loss: [1m[32m0.32303[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32303 - acc: 0.8664 -- iter: 3296/3680
[A[ATraining Step: 9074  | total loss: [1m[32m0.31857[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31857 - acc: 0.8641 -- iter: 3328/3680
[A[ATraining Step: 9075  | total loss: [1m[32m0.34171[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34171 - acc: 0.8612 -- iter: 3360/3680
[A[ATraining Step: 9076  | total loss: [1m[32m0.32401[0m[0m
[2K| Adam | epoch: 079 | loss: 0.32401 - acc: 0.8612 -- iter: 3392/3680
[A[ATraining Step: 9077  | total loss: [1m[32m0.31437[0m[0m
[2K| Adam | epoch: 079 | loss: 0.31437 - acc: 0.8626 -- iter: 3424/3680
[A[ATraining Step: 9078  | total loss: [1m[32m0.33506[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33506 - acc: 0.8638 -- iter: 3456/3680
[A[ATraining Step: 9079  | total loss: [1m[32m0.35026[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35026 - acc: 0.8556 -- iter: 3488/3680
[A[ATraining Step: 9080  | total loss: [1m[32m0.33378[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33378 - acc: 0.8592 -- iter: 3520/3680
[A[ATraining Step: 9081  | total loss: [1m[32m0.33378[0m[0m
[2K| Adam | epoch: 079 | loss: 0.33378 - acc: 0.8592 -- iter: 3552/3680
[A[ATraining Step: 9082  | total loss: [1m[32m0.34115[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34115 - acc: 0.8546 -- iter: 3584/3680
[A[ATraining Step: 9083  | total loss: [1m[32m0.34230[0m[0m
[2K| Adam | epoch: 079 | loss: 0.34230 - acc: 0.8535 -- iter: 3616/3680
[A[ATraining Step: 9084  | total loss: [1m[32m0.37858[0m[0m
[2K| Adam | epoch: 079 | loss: 0.37858 - acc: 0.8400 -- iter: 3648/3680
[A[ATraining Step: 9085  | total loss: [1m[32m0.35817[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35817 - acc: 0.8529 | val_loss: 0.30444 - val_acc: 0.8925 -- iter: 3680/3680
[A[ATraining Step: 9085  | total loss: [1m[32m0.35817[0m[0m
[2K| Adam | epoch: 079 | loss: 0.35817 - acc: 0.8529 | val_loss: 0.30444 - val_acc: 0.8925 -- iter: 3680/3680
--
Training Step: 9086  | total loss: [1m[32m0.36341[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36341 - acc: 0.8457 -- iter: 0032/3680
[A[ATraining Step: 9087  | total loss: [1m[32m0.36012[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36012 - acc: 0.8487 -- iter: 0064/3680
[A[ATraining Step: 9088  | total loss: [1m[32m0.34551[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34551 - acc: 0.8575 -- iter: 0096/3680
[A[ATraining Step: 9089  | total loss: [1m[32m0.33551[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33551 - acc: 0.8655 -- iter: 0128/3680
[A[ATraining Step: 9090  | total loss: [1m[32m0.33347[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33347 - acc: 0.8696 -- iter: 0160/3680
[A[ATraining Step: 9091  | total loss: [1m[32m0.34338[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34338 - acc: 0.8639 -- iter: 0192/3680
[A[ATraining Step: 9092  | total loss: [1m[32m0.32909[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32909 - acc: 0.8681 -- iter: 0224/3680
[A[ATraining Step: 9093  | total loss: [1m[32m0.32673[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32673 - acc: 0.8719 -- iter: 0256/3680
[A[ATraining Step: 9094  | total loss: [1m[32m0.32707[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32707 - acc: 0.8725 -- iter: 0288/3680
[A[ATraining Step: 9095  | total loss: [1m[32m0.32707[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32707 - acc: 0.8725 -- iter: 0320/3680
[A[ATraining Step: 9096  | total loss: [1m[32m0.34486[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34486 - acc: 0.8634 -- iter: 0352/3680
[A[ATraining Step: 9097  | total loss: [1m[32m0.34174[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34174 - acc: 0.8646 -- iter: 0384/3680
[A[ATraining Step: 9098  | total loss: [1m[32m0.34770[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34770 - acc: 0.8553 -- iter: 0416/3680
[A[ATraining Step: 9099  | total loss: [1m[32m0.35344[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35344 - acc: 0.8553 -- iter: 0448/3680
[A[ATraining Step: 9100  | total loss: [1m[32m0.33822[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33822 - acc: 0.8635 | val_loss: 0.33310 - val_acc: 0.8708 -- iter: 0480/3680
[A[ATraining Step: 9100  | total loss: [1m[32m0.33822[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33822 - acc: 0.8635 | val_loss: 0.33310 - val_acc: 0.8708 -- iter: 0480/3680
--
Training Step: 9101  | total loss: [1m[32m0.36063[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36063 - acc: 0.8522 -- iter: 0512/3680
[A[ATraining Step: 9102  | total loss: [1m[32m0.36182[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36182 - acc: 0.8544 -- iter: 0544/3680
[A[ATraining Step: 9103  | total loss: [1m[32m0.35725[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35725 - acc: 0.8565 -- iter: 0576/3680
[A[ATraining Step: 9104  | total loss: [1m[32m0.35846[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35846 - acc: 0.8490 -- iter: 0608/3680
[A[ATraining Step: 9105  | total loss: [1m[32m0.37878[0m[0m
[2K| Adam | epoch: 080 | loss: 0.37878 - acc: 0.8360 -- iter: 0640/3680
[A[ATraining Step: 9106  | total loss: [1m[32m0.38149[0m[0m
[2K| Adam | epoch: 080 | loss: 0.38149 - acc: 0.8399 -- iter: 0672/3680
[A[ATraining Step: 9107  | total loss: [1m[32m0.36979[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36979 - acc: 0.8465 -- iter: 0704/3680
[A[ATraining Step: 9108  | total loss: [1m[32m0.35116[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35116 - acc: 0.8618 -- iter: 0736/3680
[A[ATraining Step: 9109  | total loss: [1m[32m0.34372[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34372 - acc: 0.8663 -- iter: 0768/3680
[A[ATraining Step: 9110  | total loss: [1m[32m0.34122[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34122 - acc: 0.8648 -- iter: 0800/3680
[A[ATraining Step: 9111  | total loss: [1m[32m0.33089[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33089 - acc: 0.8752 -- iter: 0832/3680
[A[ATraining Step: 9112  | total loss: [1m[32m0.33089[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33089 - acc: 0.8752 -- iter: 0864/3680
[A[ATraining Step: 9113  | total loss: [1m[32m0.34451[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34451 - acc: 0.8658 -- iter: 0896/3680
[A[ATraining Step: 9114  | total loss: [1m[32m0.35282[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35282 - acc: 0.8542 -- iter: 0928/3680
[A[ATraining Step: 9115  | total loss: [1m[32m0.33908[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33908 - acc: 0.8657 -- iter: 0960/3680
[A[ATraining Step: 9116  | total loss: [1m[32m0.33852[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33852 - acc: 0.8635 -- iter: 0992/3680
[A[ATraining Step: 9117  | total loss: [1m[32m0.34728[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34728 - acc: 0.8615 -- iter: 1024/3680
[A[ATraining Step: 9118  | total loss: [1m[32m0.33879[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33879 - acc: 0.8660 -- iter: 1056/3680
[A[ATraining Step: 9119  | total loss: [1m[32m0.33509[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33509 - acc: 0.8700 -- iter: 1088/3680
[A[ATraining Step: 9120  | total loss: [1m[32m0.33469[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33469 - acc: 0.8705 -- iter: 1120/3680
[A[ATraining Step: 9121  | total loss: [1m[32m0.33066[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33066 - acc: 0.8710 -- iter: 1152/3680
[A[ATraining Step: 9122  | total loss: [1m[32m0.32079[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32079 - acc: 0.8776 -- iter: 1184/3680
[A[ATraining Step: 9123  | total loss: [1m[32m0.30787[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30787 - acc: 0.8836 -- iter: 1216/3680
[A[ATraining Step: 9124  | total loss: [1m[32m0.31684[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31684 - acc: 0.8702 -- iter: 1248/3680
[A[ATraining Step: 9125  | total loss: [1m[32m0.30410[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30410 - acc: 0.8801 -- iter: 1280/3680
[A[ATraining Step: 9126  | total loss: [1m[32m0.32351[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32351 - acc: 0.8702 -- iter: 1312/3680
[A[ATraining Step: 9127  | total loss: [1m[32m0.32438[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32438 - acc: 0.8707 -- iter: 1344/3680
[A[ATraining Step: 9128  | total loss: [1m[32m0.31781[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31781 - acc: 0.8742 -- iter: 1376/3680
[A[ATraining Step: 9129  | total loss: [1m[32m0.31799[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31799 - acc: 0.8743 -- iter: 1408/3680
[A[ATraining Step: 9130  | total loss: [1m[32m0.33413[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33413 - acc: 0.8716 -- iter: 1440/3680
[A[ATraining Step: 9131  | total loss: [1m[32m0.32680[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32680 - acc: 0.8716 -- iter: 1472/3680
[A[ATraining Step: 9132  | total loss: [1m[32m0.33098[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33098 - acc: 0.8720 -- iter: 1504/3680
[A[ATraining Step: 9133  | total loss: [1m[32m0.34558[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34558 - acc: 0.8629 -- iter: 1536/3680
[A[ATraining Step: 9134  | total loss: [1m[32m0.33718[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33718 - acc: 0.8672 -- iter: 1568/3680
[A[ATraining Step: 9135  | total loss: [1m[32m0.34919[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34919 - acc: 0.8568 -- iter: 1600/3680
[A[ATraining Step: 9136  | total loss: [1m[32m0.34919[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34919 - acc: 0.8618 -- iter: 1632/3680
[A[ATraining Step: 9137  | total loss: [1m[32m0.34291[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34291 - acc: 0.8662 -- iter: 1664/3680
[A[ATraining Step: 9138  | total loss: [1m[32m0.33297[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33297 - acc: 0.8662 -- iter: 1696/3680
[A[ATraining Step: 9139  | total loss: [1m[32m0.31880[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31880 - acc: 0.8702 -- iter: 1728/3680
[A[ATraining Step: 9140  | total loss: [1m[32m0.32003[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32003 - acc: 0.8645 -- iter: 1760/3680
[A[ATraining Step: 9141  | total loss: [1m[32m0.30925[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30925 - acc: 0.8693 -- iter: 1792/3680
[A[ATraining Step: 9142  | total loss: [1m[32m0.31421[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31421 - acc: 0.8693 -- iter: 1824/3680
[A[ATraining Step: 9143  | total loss: [1m[32m0.30382[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30382 - acc: 0.8730 -- iter: 1856/3680
[A[ATraining Step: 9144  | total loss: [1m[32m0.30591[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30591 - acc: 0.8700 -- iter: 1888/3680
[A[ATraining Step: 9145  | total loss: [1m[32m0.33496[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33496 - acc: 0.8580 -- iter: 1920/3680
[A[ATraining Step: 9146  | total loss: [1m[32m0.31817[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31817 - acc: 0.8691 -- iter: 1952/3680
[A[ATraining Step: 9147  | total loss: [1m[32m0.34073[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34073 - acc: 0.8541 -- iter: 1984/3680
[A[ATraining Step: 9148  | total loss: [1m[32m0.33561[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33561 - acc: 0.8530 -- iter: 2016/3680
[A[ATraining Step: 9149  | total loss: [1m[32m0.32830[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32830 - acc: 0.8552 -- iter: 2048/3680
[A[ATraining Step: 9150  | total loss: [1m[32m0.32831[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32831 - acc: 0.8603 -- iter: 2080/3680
[A[ATraining Step: 9151  | total loss: [1m[32m0.32392[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32392 - acc: 0.8618 -- iter: 2112/3680
[A[ATraining Step: 9152  | total loss: [1m[32m0.33838[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33838 - acc: 0.8538 -- iter: 2144/3680
[A[ATraining Step: 9153  | total loss: [1m[32m0.34780[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34780 - acc: 0.8496 -- iter: 2176/3680
[A[ATraining Step: 9154  | total loss: [1m[32m0.34320[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34320 - acc: 0.8553 -- iter: 2208/3680
[A[ATraining Step: 9155  | total loss: [1m[32m0.34320[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34320 - acc: 0.8510 -- iter: 2240/3680
[A[ATraining Step: 9156  | total loss: [1m[32m0.35987[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35987 - acc: 0.8534 -- iter: 2272/3680
[A[ATraining Step: 9157  | total loss: [1m[32m0.35610[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35610 - acc: 0.8556 -- iter: 2304/3680
[A[ATraining Step: 9158  | total loss: [1m[32m0.36865[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36865 - acc: 0.8450 -- iter: 2336/3680
[A[ATraining Step: 9159  | total loss: [1m[32m0.36712[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36712 - acc: 0.8418 -- iter: 2368/3680
[A[ATraining Step: 9160  | total loss: [1m[32m0.37867[0m[0m
[2K| Adam | epoch: 080 | loss: 0.37867 - acc: 0.8482 -- iter: 2400/3680
[A[ATraining Step: 9161  | total loss: [1m[32m0.37135[0m[0m
[2K| Adam | epoch: 080 | loss: 0.37135 - acc: 0.8540 -- iter: 2432/3680
[A[ATraining Step: 9162  | total loss: [1m[32m0.38590[0m[0m
[2K| Adam | epoch: 080 | loss: 0.38590 - acc: 0.8499 -- iter: 2464/3680
[A[ATraining Step: 9163  | total loss: [1m[32m0.38001[0m[0m
[2K| Adam | epoch: 080 | loss: 0.38001 - acc: 0.8524 -- iter: 2496/3680
[A[ATraining Step: 9164  | total loss: [1m[32m0.36480[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36480 - acc: 0.8609 -- iter: 2528/3680
[A[ATraining Step: 9165  | total loss: [1m[32m0.34769[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34769 - acc: 0.8717 -- iter: 2560/3680
[A[ATraining Step: 9166  | total loss: [1m[32m0.35156[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35156 - acc: 0.8658 -- iter: 2592/3680
[A[ATraining Step: 9167  | total loss: [1m[32m0.34923[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34923 - acc: 0.8573 -- iter: 2624/3680
[A[ATraining Step: 9168  | total loss: [1m[32m0.37215[0m[0m
[2K| Adam | epoch: 080 | loss: 0.37215 - acc: 0.8560 -- iter: 2656/3680
[A[ATraining Step: 9169  | total loss: [1m[32m0.36856[0m[0m
[2K| Adam | epoch: 080 | loss: 0.36856 - acc: 0.8579 -- iter: 2688/3680
[A[ATraining Step: 9170  | total loss: [1m[32m0.35724[0m[0m
[2K| Adam | epoch: 080 | loss: 0.35724 - acc: 0.8658 -- iter: 2720/3680
[A[ATraining Step: 9171  | total loss: [1m[32m0.34914[0m[0m
[2K| Adam | epoch: 080 | loss: 0.34914 - acc: 0.8605 -- iter: 2752/3680
[A[ATraining Step: 9172  | total loss: [1m[32m0.33585[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33585 - acc: 0.8720 -- iter: 2784/3680
[A[ATraining Step: 9173  | total loss: [1m[32m0.33585[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33585 - acc: 0.8720 -- iter: 2816/3680
[A[ATraining Step: 9174  | total loss: [1m[32m0.32752[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32752 - acc: 0.8723 -- iter: 2848/3680
[A[ATraining Step: 9175  | total loss: [1m[32m0.33301[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33301 - acc: 0.8694 -- iter: 2880/3680
[A[ATraining Step: 9176  | total loss: [1m[32m0.33688[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33688 - acc: 0.8700 -- iter: 2912/3680
[A[ATraining Step: 9177  | total loss: [1m[32m0.33271[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33271 - acc: 0.8736 -- iter: 2944/3680
[A[ATraining Step: 9178  | total loss: [1m[32m0.31046[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31046 - acc: 0.8863 -- iter: 2976/3680
[A[ATraining Step: 9179  | total loss: [1m[32m0.30253[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30253 - acc: 0.8851 -- iter: 3008/3680
[A[ATraining Step: 9180  | total loss: [1m[32m0.29624[0m[0m
[2K| Adam | epoch: 080 | loss: 0.29624 - acc: 0.8872 -- iter: 3040/3680
[A[ATraining Step: 9181  | total loss: [1m[32m0.29247[0m[0m
[2K| Adam | epoch: 080 | loss: 0.29247 - acc: 0.8891 -- iter: 3072/3680
[A[ATraining Step: 9182  | total loss: [1m[32m0.31048[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31048 - acc: 0.8815 -- iter: 3104/3680
[A[ATraining Step: 9183  | total loss: [1m[32m0.30228[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30228 - acc: 0.8871 -- iter: 3136/3680
[A[ATraining Step: 9184  | total loss: [1m[32m0.31021[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31021 - acc: 0.8828 -- iter: 3168/3680
[A[ATraining Step: 9185  | total loss: [1m[32m0.31874[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31874 - acc: 0.8757 -- iter: 3200/3680
[A[ATraining Step: 9186  | total loss: [1m[32m0.31320[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31320 - acc: 0.8788 -- iter: 3232/3680
[A[ATraining Step: 9187  | total loss: [1m[32m0.31969[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31969 - acc: 0.8721 -- iter: 3264/3680
[A[ATraining Step: 9188  | total loss: [1m[32m0.30789[0m[0m
[2K| Adam | epoch: 080 | loss: 0.30789 - acc: 0.8818 -- iter: 3296/3680
[A[ATraining Step: 9189  | total loss: [1m[32m0.31446[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31446 - acc: 0.8777 -- iter: 3328/3680
[A[ATraining Step: 9190  | total loss: [1m[32m0.32065[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32065 - acc: 0.8743 -- iter: 3360/3680
[A[ATraining Step: 9191  | total loss: [1m[32m0.32065[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32065 - acc: 0.8743 -- iter: 3392/3680
[A[ATraining Step: 9192  | total loss: [1m[32m0.32467[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32467 - acc: 0.8744 -- iter: 3424/3680
[A[ATraining Step: 9193  | total loss: [1m[32m0.32515[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32515 - acc: 0.8744 -- iter: 3456/3680
[A[ATraining Step: 9194  | total loss: [1m[32m0.32377[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32377 - acc: 0.8682 -- iter: 3488/3680
[A[ATraining Step: 9195  | total loss: [1m[32m0.33033[0m[0m
[2K| Adam | epoch: 080 | loss: 0.33033 - acc: 0.8658 -- iter: 3520/3680
[A[ATraining Step: 9196  | total loss: [1m[32m0.32787[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32787 - acc: 0.8667 -- iter: 3552/3680
[A[ATraining Step: 9197  | total loss: [1m[32m0.32411[0m[0m
[2K| Adam | epoch: 080 | loss: 0.32411 - acc: 0.8675 -- iter: 3584/3680
[A[ATraining Step: 9198  | total loss: [1m[32m0.31585[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31585 - acc: 0.8714 -- iter: 3616/3680
[A[ATraining Step: 9199  | total loss: [1m[32m0.31389[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31389 - acc: 0.8749 -- iter: 3648/3680
[A[ATraining Step: 9200  | total loss: [1m[32m0.31592[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31592 - acc: 0.8687 | val_loss: 0.28189 - val_acc: 0.9023 -- iter: 3680/3680
[A[ATraining Step: 9200  | total loss: [1m[32m0.31592[0m[0m
[2K| Adam | epoch: 080 | loss: 0.31592 - acc: 0.8687 | val_loss: 0.28189 - val_acc: 0.9023 -- iter: 3680/3680
--
Training Step: 9201  | total loss: [1m[32m0.31207[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31207 - acc: 0.8693 -- iter: 0032/3680
[A[ATraining Step: 9202  | total loss: [1m[32m0.30719[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30719 - acc: 0.8699 -- iter: 0064/3680
[A[ATraining Step: 9203  | total loss: [1m[32m0.30435[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30435 - acc: 0.8766 -- iter: 0096/3680
[A[ATraining Step: 9204  | total loss: [1m[32m0.30199[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30199 - acc: 0.8765 -- iter: 0128/3680
[A[ATraining Step: 9205  | total loss: [1m[32m0.28789[0m[0m
[2K| Adam | epoch: 081 | loss: 0.28789 - acc: 0.8857 -- iter: 0160/3680
[A[ATraining Step: 9206  | total loss: [1m[32m0.30090[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30090 - acc: 0.8815 -- iter: 0192/3680
[A[ATraining Step: 9207  | total loss: [1m[32m0.29979[0m[0m
[2K| Adam | epoch: 081 | loss: 0.29979 - acc: 0.8809 -- iter: 0224/3680
[A[ATraining Step: 9208  | total loss: [1m[32m0.29979[0m[0m
[2K| Adam | epoch: 081 | loss: 0.29979 - acc: 0.8834 -- iter: 0256/3680
[A[ATraining Step: 9209  | total loss: [1m[32m0.30400[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30400 - acc: 0.8834 -- iter: 0288/3680
[A[ATraining Step: 9210  | total loss: [1m[32m0.31350[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31350 - acc: 0.8795 -- iter: 0320/3680
[A[ATraining Step: 9211  | total loss: [1m[32m0.32727[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32727 - acc: 0.8728 -- iter: 0352/3680
[A[ATraining Step: 9212  | total loss: [1m[32m0.31917[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31917 - acc: 0.8730 -- iter: 0384/3680
[A[ATraining Step: 9213  | total loss: [1m[32m0.31275[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31275 - acc: 0.8771 -- iter: 0416/3680
[A[ATraining Step: 9214  | total loss: [1m[32m0.31275[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31275 - acc: 0.8771 -- iter: 0448/3680
[A[ATraining Step: 9215  | total loss: [1m[32m0.32264[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32264 - acc: 0.8707 -- iter: 0480/3680
[A[ATraining Step: 9216  | total loss: [1m[32m0.32934[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32934 - acc: 0.8648 -- iter: 0512/3680
[A[ATraining Step: 9217  | total loss: [1m[32m0.32468[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32468 - acc: 0.8690 -- iter: 0544/3680
[A[ATraining Step: 9218  | total loss: [1m[32m0.35509[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35509 - acc: 0.8589 -- iter: 0576/3680
[A[ATraining Step: 9219  | total loss: [1m[32m0.34845[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34845 - acc: 0.8589 -- iter: 0608/3680
[A[ATraining Step: 9220  | total loss: [1m[32m0.33167[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33167 - acc: 0.8667 -- iter: 0640/3680
[A[ATraining Step: 9221  | total loss: [1m[32m0.34471[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34471 - acc: 0.8644 -- iter: 0672/3680
[A[ATraining Step: 9222  | total loss: [1m[32m0.34506[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34506 - acc: 0.8655 -- iter: 0704/3680
[A[ATraining Step: 9223  | total loss: [1m[32m0.33527[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33527 - acc: 0.8732 -- iter: 0736/3680
[A[ATraining Step: 9224  | total loss: [1m[32m0.32817[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32817 - acc: 0.8765 -- iter: 0768/3680
[A[ATraining Step: 9225  | total loss: [1m[32m0.32065[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32065 - acc: 0.8765 -- iter: 0800/3680
[A[ATraining Step: 9226  | total loss: [1m[32m0.34086[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34086 - acc: 0.8733 -- iter: 0832/3680
[A[ATraining Step: 9227  | total loss: [1m[32m0.33917[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33917 - acc: 0.8766 -- iter: 0864/3680
[A[ATraining Step: 9228  | total loss: [1m[32m0.34368[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34368 - acc: 0.8795 -- iter: 0896/3680
[A[ATraining Step: 9229  | total loss: [1m[32m0.33912[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33912 - acc: 0.8791 -- iter: 0928/3680
[A[ATraining Step: 9230  | total loss: [1m[32m0.33379[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33379 - acc: 0.8902 -- iter: 0960/3680
[A[ATraining Step: 9231  | total loss: [1m[32m0.32252[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32252 - acc: 0.8902 -- iter: 0992/3680
[A[ATraining Step: 9232  | total loss: [1m[32m0.31305[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31305 - acc: 0.8980 -- iter: 1024/3680
[A[ATraining Step: 9233  | total loss: [1m[32m0.31784[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31784 - acc: 0.8926 -- iter: 1056/3680
[A[ATraining Step: 9234  | total loss: [1m[32m0.31387[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31387 - acc: 0.8940 -- iter: 1088/3680
[A[ATraining Step: 9235  | total loss: [1m[32m0.30415[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30415 - acc: 0.8983 -- iter: 1120/3680
[A[ATraining Step: 9236  | total loss: [1m[32m0.30251[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30251 - acc: 0.8929 -- iter: 1152/3680
[A[ATraining Step: 9237  | total loss: [1m[32m0.30600[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30600 - acc: 0.8892 -- iter: 1184/3680
[A[ATraining Step: 9238  | total loss: [1m[32m0.30385[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30385 - acc: 0.8971 -- iter: 1216/3680
[A[ATraining Step: 9239  | total loss: [1m[32m0.30070[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30070 - acc: 0.8971 -- iter: 1248/3680
[A[ATraining Step: 9240  | total loss: [1m[32m0.29680[0m[0m
[2K| Adam | epoch: 081 | loss: 0.29680 - acc: 0.9012 -- iter: 1280/3680
[A[ATraining Step: 9241  | total loss: [1m[32m0.30509[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30509 - acc: 0.9048 -- iter: 1312/3680
[A[ATraining Step: 9242  | total loss: [1m[32m0.30260[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30260 - acc: 0.9049 -- iter: 1344/3680
[A[ATraining Step: 9243  | total loss: [1m[32m0.29538[0m[0m
[2K| Adam | epoch: 081 | loss: 0.29538 - acc: 0.9052 -- iter: 1376/3680
[A[ATraining Step: 9244  | total loss: [1m[32m0.29538[0m[0m
[2K| Adam | epoch: 081 | loss: 0.29538 - acc: 0.9052 -- iter: 1408/3680
[A[ATraining Step: 9245  | total loss: [1m[32m0.29658[0m[0m
[2K| Adam | epoch: 081 | loss: 0.29658 - acc: 0.8959 -- iter: 1440/3680
[A[ATraining Step: 9246  | total loss: [1m[32m0.28761[0m[0m
[2K| Adam | epoch: 081 | loss: 0.28761 - acc: 0.9001 -- iter: 1472/3680
[A[ATraining Step: 9247  | total loss: [1m[32m0.28727[0m[0m
[2K| Adam | epoch: 081 | loss: 0.28727 - acc: 0.8484 -- iter: 1504/3680
[A[ATraining Step: 9248  | total loss: [1m[32m0.40053[0m[0m
[2K| Adam | epoch: 081 | loss: 0.40053 - acc: 0.8484 -- iter: 1536/3680
[A[ATraining Step: 9249  | total loss: [1m[32m0.38995[0m[0m
[2K| Adam | epoch: 081 | loss: 0.38995 - acc: 0.8511 -- iter: 1568/3680
[A[ATraining Step: 9250  | total loss: [1m[32m0.37775[0m[0m
[2K| Adam | epoch: 081 | loss: 0.37775 - acc: 0.8566 -- iter: 1600/3680
[A[ATraining Step: 9251  | total loss: [1m[32m0.36389[0m[0m
[2K| Adam | epoch: 081 | loss: 0.36389 - acc: 0.8647 -- iter: 1632/3680
[A[ATraining Step: 9252  | total loss: [1m[32m0.34767[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34767 - acc: 0.8720 -- iter: 1664/3680
[A[ATraining Step: 9253  | total loss: [1m[32m0.35000[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35000 - acc: 0.8723 -- iter: 1696/3680
[A[ATraining Step: 9254  | total loss: [1m[32m0.34188[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34188 - acc: 0.8669 -- iter: 1728/3680
[A[ATraining Step: 9255  | total loss: [1m[32m0.34188[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34188 - acc: 0.8669 -- iter: 1760/3680
[A[ATraining Step: 9256  | total loss: [1m[32m0.34984[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34984 - acc: 0.8677 -- iter: 1792/3680
[A[ATraining Step: 9257  | total loss: [1m[32m0.33654[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33654 - acc: 0.8747 -- iter: 1824/3680
[A[ATraining Step: 9258  | total loss: [1m[32m0.33064[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33064 - acc: 0.8747 -- iter: 1856/3680
[A[ATraining Step: 9259  | total loss: [1m[32m0.32199[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32199 - acc: 0.8810 -- iter: 1888/3680
[A[ATraining Step: 9260  | total loss: [1m[32m0.32047[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32047 - acc: 0.8835 -- iter: 1920/3680
[A[ATraining Step: 9261  | total loss: [1m[32m0.31864[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31864 - acc: 0.8826 -- iter: 1952/3680
[A[ATraining Step: 9262  | total loss: [1m[32m0.32994[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32994 - acc: 0.8756 -- iter: 1984/3680
[A[ATraining Step: 9263  | total loss: [1m[32m0.33740[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33740 - acc: 0.8724 -- iter: 2016/3680
[A[ATraining Step: 9264  | total loss: [1m[32m0.32262[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32262 - acc: 0.8758 -- iter: 2048/3680
[A[ATraining Step: 9265  | total loss: [1m[32m0.31666[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31666 - acc: 0.8789 -- iter: 2080/3680
[A[ATraining Step: 9266  | total loss: [1m[32m0.31309[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31309 - acc: 0.8816 -- iter: 2112/3680
[A[ATraining Step: 9267  | total loss: [1m[32m0.30680[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30680 - acc: 0.8860 -- iter: 2144/3680
[A[ATraining Step: 9268  | total loss: [1m[32m0.30733[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30733 - acc: 0.8860 -- iter: 2176/3680
[A[ATraining Step: 9269  | total loss: [1m[32m0.30458[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30458 - acc: 0.8880 -- iter: 2208/3680
[A[ATraining Step: 9270  | total loss: [1m[32m0.30006[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30006 - acc: 0.8930 -- iter: 2240/3680
[A[ATraining Step: 9271  | total loss: [1m[32m0.30988[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30988 - acc: 0.8811 -- iter: 2272/3680
[A[ATraining Step: 9272  | total loss: [1m[32m0.31128[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31128 - acc: 0.8680 -- iter: 2304/3680
[A[ATraining Step: 9273  | total loss: [1m[32m0.33258[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33258 - acc: 0.8680 -- iter: 2336/3680
[A[ATraining Step: 9274  | total loss: [1m[32m0.32854[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32854 - acc: 0.8718 -- iter: 2368/3680
[A[ATraining Step: 9275  | total loss: [1m[32m0.32993[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32993 - acc: 0.8690 -- iter: 2400/3680
[A[ATraining Step: 9276  | total loss: [1m[32m0.32188[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32188 - acc: 0.8696 -- iter: 2432/3680
[A[ATraining Step: 9277  | total loss: [1m[32m0.32769[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32769 - acc: 0.8619 -- iter: 2464/3680
[A[ATraining Step: 9278  | total loss: [1m[32m0.32769[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32769 - acc: 0.8619 -- iter: 2496/3680
[A[ATraining Step: 9279  | total loss: [1m[32m0.33295[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33295 - acc: 0.8553 -- iter: 2528/3680
[A[ATraining Step: 9280  | total loss: [1m[32m0.34176[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34176 - acc: 0.8553 -- iter: 2560/3680
[A[ATraining Step: 9281  | total loss: [1m[32m0.35162[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35162 - acc: 0.8542 -- iter: 2592/3680
[A[ATraining Step: 9282  | total loss: [1m[32m0.34758[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34758 - acc: 0.8562 -- iter: 2624/3680
[A[ATraining Step: 9283  | total loss: [1m[32m0.34325[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34325 - acc: 0.8550 -- iter: 2656/3680
[A[ATraining Step: 9284  | total loss: [1m[32m0.34477[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34477 - acc: 0.8507 -- iter: 2688/3680
[A[ATraining Step: 9285  | total loss: [1m[32m0.34567[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34567 - acc: 0.8532 -- iter: 2720/3680
[A[ATraining Step: 9286  | total loss: [1m[32m0.36128[0m[0m
[2K| Adam | epoch: 081 | loss: 0.36128 - acc: 0.8522 -- iter: 2752/3680
[A[ATraining Step: 9287  | total loss: [1m[32m0.35803[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35803 - acc: 0.8514 -- iter: 2784/3680
[A[ATraining Step: 9288  | total loss: [1m[32m0.35656[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35656 - acc: 0.8444 -- iter: 2816/3680
[A[ATraining Step: 9289  | total loss: [1m[32m0.35626[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35626 - acc: 0.8443 -- iter: 2848/3680
[A[ATraining Step: 9290  | total loss: [1m[32m0.35150[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35150 - acc: 0.8505 -- iter: 2880/3680
[A[ATraining Step: 9291  | total loss: [1m[32m0.34874[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34874 - acc: 0.8561 -- iter: 2912/3680
[A[ATraining Step: 9292  | total loss: [1m[32m0.35698[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35698 - acc: 0.8423 -- iter: 2944/3680
[A[ATraining Step: 9293  | total loss: [1m[32m0.35947[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35947 - acc: 0.8394 -- iter: 2976/3680
[A[ATraining Step: 9294  | total loss: [1m[32m0.36059[0m[0m
[2K| Adam | epoch: 081 | loss: 0.36059 - acc: 0.8367 -- iter: 3008/3680
[A[ATraining Step: 9295  | total loss: [1m[32m0.35925[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35925 - acc: 0.8405 -- iter: 3040/3680
[A[ATraining Step: 9296  | total loss: [1m[32m0.35944[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35944 - acc: 0.8408 -- iter: 3072/3680
[A[ATraining Step: 9297  | total loss: [1m[32m0.37258[0m[0m
[2K| Adam | epoch: 081 | loss: 0.37258 - acc: 0.8380 -- iter: 3104/3680
[A[ATraining Step: 9298  | total loss: [1m[32m0.37011[0m[0m
[2K| Adam | epoch: 081 | loss: 0.37011 - acc: 0.8363 -- iter: 3136/3680
[A[ATraining Step: 9299  | total loss: [1m[32m0.36206[0m[0m
[2K| Adam | epoch: 081 | loss: 0.36206 - acc: 0.8363 -- iter: 3168/3680
[A[ATraining Step: 9300  | total loss: [1m[32m0.35849[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35849 - acc: 0.8401 | val_loss: 0.28536 - val_acc: 0.9045 -- iter: 3200/3680
[A[ATraining Step: 9300  | total loss: [1m[32m0.35849[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35849 - acc: 0.8401 | val_loss: 0.28536 - val_acc: 0.9045 -- iter: 3200/3680
--
Training Step: 9301  | total loss: [1m[32m0.35400[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35400 - acc: 0.8436 -- iter: 3232/3680
[A[ATraining Step: 9302  | total loss: [1m[32m0.35444[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35444 - acc: 0.8468 -- iter: 3264/3680
[A[ATraining Step: 9303  | total loss: [1m[32m0.35489[0m[0m
[2K| Adam | epoch: 081 | loss: 0.35489 - acc: 0.8433 -- iter: 3296/3680
[A[ATraining Step: 9304  | total loss: [1m[32m0.34966[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34966 - acc: 0.8434 -- iter: 3328/3680
[A[ATraining Step: 9305  | total loss: [1m[32m0.34235[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34235 - acc: 0.8434 -- iter: 3360/3680
[A[ATraining Step: 9306  | total loss: [1m[32m0.34359[0m[0m
[2K| Adam | epoch: 081 | loss: 0.34359 - acc: 0.8497 -- iter: 3392/3680
[A[ATraining Step: 9307  | total loss: [1m[32m0.33487[0m[0m
[2K| Adam | epoch: 081 | loss: 0.33487 - acc: 0.8554 -- iter: 3424/3680
[A[ATraining Step: 9308  | total loss: [1m[32m0.32850[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32850 - acc: 0.8573 -- iter: 3456/3680
[A[ATraining Step: 9309  | total loss: [1m[32m0.32613[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32613 - acc: 0.8591 -- iter: 3488/3680
[A[ATraining Step: 9310  | total loss: [1m[32m0.32883[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32883 - acc: 0.8513 -- iter: 3520/3680
[A[ATraining Step: 9311  | total loss: [1m[32m0.32246[0m[0m
[2K| Adam | epoch: 081 | loss: 0.32246 - acc: 0.8568 -- iter: 3552/3680
[A[ATraining Step: 9312  | total loss: [1m[32m0.30817[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30817 - acc: 0.8680 -- iter: 3584/3680
[A[ATraining Step: 9313  | total loss: [1m[32m0.30948[0m[0m
[2K| Adam | epoch: 081 | loss: 0.30948 - acc: 0.8687 -- iter: 3616/3680
[A[ATraining Step: 9314  | total loss: [1m[32m0.31087[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31087 - acc: 0.8725 -- iter: 3648/3680
[A[ATraining Step: 9315  | total loss: [1m[32m0.31813[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31813 - acc: 0.8761 | val_loss: 0.28365 - val_acc: 0.9034 -- iter: 3680/3680
[A[ATraining Step: 9315  | total loss: [1m[32m0.31813[0m[0m
[2K| Adam | epoch: 081 | loss: 0.31813 - acc: 0.8761 | val_loss: 0.28365 - val_acc: 0.9034 -- iter: 3680/3680
--
Training Step: 9316  | total loss: [1m[32m0.30779[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30779 - acc: 0.8761 -- iter: 0032/3680
[A[ATraining Step: 9317  | total loss: [1m[32m0.30286[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30286 - acc: 0.8760 -- iter: 0064/3680
[A[ATraining Step: 9318  | total loss: [1m[32m0.30281[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30281 - acc: 0.8759 -- iter: 0096/3680
[A[ATraining Step: 9319  | total loss: [1m[32m0.29855[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29855 - acc: 0.8695 -- iter: 0128/3680
[A[ATraining Step: 9320  | total loss: [1m[32m0.31338[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31338 - acc: 0.8669 -- iter: 0160/3680
[A[ATraining Step: 9321  | total loss: [1m[32m0.31112[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31112 - acc: 0.8740 -- iter: 0192/3680
[A[ATraining Step: 9322  | total loss: [1m[32m0.30426[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30426 - acc: 0.8801 -- iter: 0224/3680
[A[ATraining Step: 9323  | total loss: [1m[32m0.36025[0m[0m
[2K| Adam | epoch: 082 | loss: 0.36025 - acc: 0.8801 -- iter: 0256/3680
[A[ATraining Step: 9324  | total loss: [1m[32m0.34661[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34661 - acc: 0.8796 -- iter: 0288/3680
[A[ATraining Step: 9325  | total loss: [1m[32m0.34838[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34838 - acc: 0.8823 -- iter: 0320/3680
[A[ATraining Step: 9326  | total loss: [1m[32m0.35217[0m[0m
[2K| Adam | epoch: 082 | loss: 0.35217 - acc: 0.8784 -- iter: 0352/3680
[A[ATraining Step: 9327  | total loss: [1m[32m0.34148[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34148 - acc: 0.8812 -- iter: 0384/3680
[A[ATraining Step: 9328  | total loss: [1m[32m0.35307[0m[0m
[2K| Adam | epoch: 082 | loss: 0.35307 - acc: 0.8712 -- iter: 0416/3680
[A[ATraining Step: 9329  | total loss: [1m[32m0.34228[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34228 - acc: 0.8776 -- iter: 0448/3680
[A[ATraining Step: 9330  | total loss: [1m[32m0.34228[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34228 - acc: 0.8776 -- iter: 0480/3680
[A[ATraining Step: 9331  | total loss: [1m[32m0.32785[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32785 - acc: 0.8836 -- iter: 0512/3680
[A[ATraining Step: 9332  | total loss: [1m[32m0.33012[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33012 - acc: 0.8827 -- iter: 0544/3680
[A[ATraining Step: 9333  | total loss: [1m[32m0.32442[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32442 - acc: 0.8819 -- iter: 0576/3680
[A[ATraining Step: 9334  | total loss: [1m[32m0.33551[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33551 - acc: 0.8781 -- iter: 0608/3680
[A[ATraining Step: 9335  | total loss: [1m[32m0.32402[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32402 - acc: 0.8840 -- iter: 0640/3680
[A[ATraining Step: 9336  | total loss: [1m[32m0.32283[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32283 - acc: 0.8705 -- iter: 0672/3680
[A[ATraining Step: 9337  | total loss: [1m[32m0.33026[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33026 - acc: 0.8705 -- iter: 0704/3680
[A[ATraining Step: 9338  | total loss: [1m[32m0.32489[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32489 - acc: 0.8709 -- iter: 0736/3680
[A[ATraining Step: 9339  | total loss: [1m[32m0.32001[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32001 - acc: 0.8751 -- iter: 0768/3680
[A[ATraining Step: 9340  | total loss: [1m[32m0.32734[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32734 - acc: 0.8751 -- iter: 0800/3680
[A[ATraining Step: 9341  | total loss: [1m[32m0.34218[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34218 - acc: 0.8657 -- iter: 0832/3680
[A[ATraining Step: 9342  | total loss: [1m[32m0.32509[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32509 - acc: 0.8734 -- iter: 0864/3680
[A[ATraining Step: 9343  | total loss: [1m[32m0.32509[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32509 - acc: 0.8734 -- iter: 0896/3680
[A[ATraining Step: 9344  | total loss: [1m[32m0.31760[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31760 - acc: 0.8798 -- iter: 0928/3680
[A[ATraining Step: 9345  | total loss: [1m[32m0.31886[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31886 - acc: 0.8762 -- iter: 0960/3680
[A[ATraining Step: 9346  | total loss: [1m[32m0.31575[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31575 - acc: 0.8824 -- iter: 0992/3680
[A[ATraining Step: 9347  | total loss: [1m[32m0.31234[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31234 - acc: 0.8785 -- iter: 1024/3680
[A[ATraining Step: 9348  | total loss: [1m[32m0.32160[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32160 - acc: 0.8750 -- iter: 1056/3680
[A[ATraining Step: 9349  | total loss: [1m[32m0.31575[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31575 - acc: 0.8781 -- iter: 1088/3680
[A[ATraining Step: 9350  | total loss: [1m[32m0.30809[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30809 - acc: 0.8841 -- iter: 1120/3680
[A[ATraining Step: 9351  | total loss: [1m[32m0.29952[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29952 - acc: 0.8832 -- iter: 1152/3680
[A[ATraining Step: 9352  | total loss: [1m[32m0.29015[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29015 - acc: 0.8917 -- iter: 1184/3680
[A[ATraining Step: 9353  | total loss: [1m[32m0.31444[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31444 - acc: 0.8807 -- iter: 1216/3680
[A[ATraining Step: 9354  | total loss: [1m[32m0.29435[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29435 - acc: 0.8880 -- iter: 1248/3680
[A[ATraining Step: 9355  | total loss: [1m[32m0.29435[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29435 - acc: 0.8880 -- iter: 1280/3680
[A[ATraining Step: 9356  | total loss: [1m[32m0.30013[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30013 - acc: 0.8867 -- iter: 1312/3680
[A[ATraining Step: 9357  | total loss: [1m[32m0.30578[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30578 - acc: 0.8824 -- iter: 1344/3680
[A[ATraining Step: 9358  | total loss: [1m[32m0.31401[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31401 - acc: 0.8629 -- iter: 1376/3680
[A[ATraining Step: 9359  | total loss: [1m[32m0.34013[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34013 - acc: 0.8672 -- iter: 1408/3680
[A[ATraining Step: 9360  | total loss: [1m[32m0.33282[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33282 - acc: 0.8672 -- iter: 1440/3680
[A[ATraining Step: 9361  | total loss: [1m[32m0.34902[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34902 - acc: 0.8509 -- iter: 1472/3680
[A[ATraining Step: 9362  | total loss: [1m[32m0.34902[0m[0m
[2K| Adam | epoch: 082 | loss: 0.34902 - acc: 0.8509 -- iter: 1504/3680
[A[ATraining Step: 9363  | total loss: [1m[32m0.35601[0m[0m
[2K| Adam | epoch: 082 | loss: 0.35601 - acc: 0.8502 -- iter: 1536/3680
[A[ATraining Step: 9364  | total loss: [1m[32m0.33968[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33968 - acc: 0.8558 -- iter: 1568/3680
[A[ATraining Step: 9365  | total loss: [1m[32m0.33873[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33873 - acc: 0.8577 -- iter: 1600/3680
[A[ATraining Step: 9366  | total loss: [1m[32m0.33865[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33865 - acc: 0.8563 -- iter: 1632/3680
[A[ATraining Step: 9367  | total loss: [1m[32m0.33994[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33994 - acc: 0.8551 -- iter: 1664/3680
[A[ATraining Step: 9368  | total loss: [1m[32m0.32190[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32190 - acc: 0.8707 -- iter: 1696/3680
[A[ATraining Step: 9369  | total loss: [1m[32m0.32190[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32190 - acc: 0.8707 -- iter: 1728/3680
[A[ATraining Step: 9370  | total loss: [1m[32m0.32216[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32216 - acc: 0.8680 -- iter: 1760/3680
[A[ATraining Step: 9371  | total loss: [1m[32m0.31786[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31786 - acc: 0.8687 -- iter: 1792/3680
[A[ATraining Step: 9372  | total loss: [1m[32m0.32393[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32393 - acc: 0.8662 -- iter: 1824/3680
[A[ATraining Step: 9373  | total loss: [1m[32m0.31317[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31317 - acc: 0.8671 -- iter: 1856/3680
[A[ATraining Step: 9374  | total loss: [1m[32m0.30371[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30371 - acc: 0.8773 -- iter: 1888/3680
[A[ATraining Step: 9375  | total loss: [1m[32m0.29683[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29683 - acc: 0.8802 -- iter: 1920/3680
[A[ATraining Step: 9376  | total loss: [1m[32m0.30116[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30116 - acc: 0.8796 -- iter: 1952/3680
[A[ATraining Step: 9377  | total loss: [1m[32m0.30215[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30215 - acc: 0.8823 -- iter: 1984/3680
[A[ATraining Step: 9378  | total loss: [1m[32m0.28344[0m[0m
[2K| Adam | epoch: 082 | loss: 0.28344 - acc: 0.8910 -- iter: 2016/3680
[A[ATraining Step: 9379  | total loss: [1m[32m0.28609[0m[0m
[2K| Adam | epoch: 082 | loss: 0.28609 - acc: 0.8925 -- iter: 2048/3680
[A[ATraining Step: 9380  | total loss: [1m[32m0.27997[0m[0m
[2K| Adam | epoch: 082 | loss: 0.27997 - acc: 0.8970 -- iter: 2080/3680
[A[ATraining Step: 9381  | total loss: [1m[32m0.31491[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31491 - acc: 0.8885 -- iter: 2112/3680
[A[ATraining Step: 9382  | total loss: [1m[32m0.30352[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30352 - acc: 0.8903 -- iter: 2144/3680
[A[ATraining Step: 9383  | total loss: [1m[32m0.29729[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29729 - acc: 0.8950 -- iter: 2176/3680
[A[ATraining Step: 9384  | total loss: [1m[32m0.32534[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32534 - acc: 0.8805 -- iter: 2208/3680
[A[ATraining Step: 9385  | total loss: [1m[32m0.32105[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32105 - acc: 0.8831 -- iter: 2240/3680
[A[ATraining Step: 9386  | total loss: [1m[32m0.32014[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32014 - acc: 0.8854 -- iter: 2272/3680
[A[ATraining Step: 9387  | total loss: [1m[32m0.33171[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33171 - acc: 0.8812 -- iter: 2304/3680
[A[ATraining Step: 9388  | total loss: [1m[32m0.32018[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32018 - acc: 0.8837 -- iter: 2336/3680
[A[ATraining Step: 9389  | total loss: [1m[32m0.33500[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33500 - acc: 0.8766 -- iter: 2368/3680
[A[ATraining Step: 9390  | total loss: [1m[32m0.32455[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32455 - acc: 0.8735 -- iter: 2400/3680
[A[ATraining Step: 9391  | total loss: [1m[32m0.33403[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33403 - acc: 0.8735 -- iter: 2432/3680
[A[ATraining Step: 9392  | total loss: [1m[32m0.33560[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33560 - acc: 0.8682 -- iter: 2464/3680
[A[ATraining Step: 9393  | total loss: [1m[32m0.32788[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32788 - acc: 0.8682 -- iter: 2496/3680
[A[ATraining Step: 9394  | total loss: [1m[32m0.33501[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33501 - acc: 0.8595 -- iter: 2528/3680
[A[ATraining Step: 9395  | total loss: [1m[32m0.33667[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33667 - acc: 0.8579 -- iter: 2560/3680
[A[ATraining Step: 9396  | total loss: [1m[32m0.32564[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32564 - acc: 0.8690 -- iter: 2592/3680
[A[ATraining Step: 9397  | total loss: [1m[32m0.32196[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32196 - acc: 0.8758 -- iter: 2624/3680
[A[ATraining Step: 9398  | total loss: [1m[32m0.32603[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32603 - acc: 0.8732 -- iter: 2656/3680
[A[ATraining Step: 9399  | total loss: [1m[32m0.32603[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32603 - acc: 0.8732 -- iter: 2688/3680
[A[ATraining Step: 9400  | total loss: [1m[32m0.31892[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31892 - acc: 0.8765 | val_loss: 0.28995 - val_acc: 0.8958 -- iter: 2720/3680
[A[ATraining Step: 9400  | total loss: [1m[32m0.31892[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31892 - acc: 0.8765 | val_loss: 0.28995 - val_acc: 0.8958 -- iter: 2720/3680
--
Training Step: 9401  | total loss: [1m[32m0.30800[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30800 - acc: 0.8763 -- iter: 2752/3680
[A[ATraining Step: 9402  | total loss: [1m[32m0.29799[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29799 - acc: 0.8825 -- iter: 2784/3680
[A[ATraining Step: 9403  | total loss: [1m[32m0.31539[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31539 - acc: 0.8817 -- iter: 2816/3680
[A[ATraining Step: 9404  | total loss: [1m[32m0.31181[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31181 - acc: 0.8810 -- iter: 2848/3680
[A[ATraining Step: 9405  | total loss: [1m[32m0.31502[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31502 - acc: 0.8773 -- iter: 2880/3680
[A[ATraining Step: 9406  | total loss: [1m[32m0.31561[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31561 - acc: 0.8740 -- iter: 2912/3680
[A[ATraining Step: 9407  | total loss: [1m[32m0.33301[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33301 - acc: 0.8584 -- iter: 2944/3680
[A[ATraining Step: 9408  | total loss: [1m[32m0.31193[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31193 - acc: 0.8681 -- iter: 2976/3680
[A[ATraining Step: 9409  | total loss: [1m[32m0.30711[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30711 - acc: 0.8720 -- iter: 3008/3680
[A[ATraining Step: 9410  | total loss: [1m[32m0.30711[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30711 - acc: 0.8720 -- iter: 3040/3680
[A[ATraining Step: 9411  | total loss: [1m[32m0.30148[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30148 - acc: 0.8723 -- iter: 3072/3680
[A[ATraining Step: 9412  | total loss: [1m[32m0.33127[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33127 - acc: 0.8600 -- iter: 3104/3680
[A[ATraining Step: 9413  | total loss: [1m[32m0.33855[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33855 - acc: 0.8516 -- iter: 3136/3680
[A[ATraining Step: 9414  | total loss: [1m[32m0.33855[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33855 - acc: 0.8516 -- iter: 3168/3680
[A[ATraining Step: 9415  | total loss: [1m[32m0.33002[0m[0m
[2K| Adam | epoch: 082 | loss: 0.33002 - acc: 0.8540 -- iter: 3200/3680
[A[ATraining Step: 9416  | total loss: [1m[32m0.31485[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31485 - acc: 0.8623 -- iter: 3232/3680
[A[ATraining Step: 9417  | total loss: [1m[32m0.30289[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30289 - acc: 0.8761 -- iter: 3264/3680
[A[ATraining Step: 9418  | total loss: [1m[32m0.30109[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30109 - acc: 0.8728 -- iter: 3296/3680
[A[ATraining Step: 9419  | total loss: [1m[32m0.30109[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30109 - acc: 0.8728 -- iter: 3328/3680
[A[ATraining Step: 9420  | total loss: [1m[32m0.30165[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30165 - acc: 0.8761 -- iter: 3360/3680
[A[ATraining Step: 9421  | total loss: [1m[32m0.30206[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30206 - acc: 0.8760 -- iter: 3392/3680
[A[ATraining Step: 9422  | total loss: [1m[32m0.30017[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30017 - acc: 0.8821 -- iter: 3424/3680
[A[ATraining Step: 9423  | total loss: [1m[32m0.29402[0m[0m
[2K| Adam | epoch: 082 | loss: 0.29402 - acc: 0.8846 -- iter: 3456/3680
[A[ATraining Step: 9424  | total loss: [1m[32m0.30728[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30728 - acc: 0.8836 -- iter: 3488/3680
[A[ATraining Step: 9425  | total loss: [1m[32m0.30221[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30221 - acc: 0.8890 -- iter: 3520/3680
[A[ATraining Step: 9426  | total loss: [1m[32m0.30144[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30144 - acc: 0.8938 -- iter: 3552/3680
[A[ATraining Step: 9427  | total loss: [1m[32m0.30362[0m[0m
[2K| Adam | epoch: 082 | loss: 0.30362 - acc: 0.8888 -- iter: 3584/3680
[A[ATraining Step: 9428  | total loss: [1m[32m0.32593[0m[0m
[2K| Adam | epoch: 082 | loss: 0.32593 - acc: 0.8812 -- iter: 3616/3680
[A[ATraining Step: 9429  | total loss: [1m[32m0.31891[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31891 - acc: 0.8800 -- iter: 3648/3680
[A[ATraining Step: 9430  | total loss: [1m[32m0.31049[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31049 - acc: 0.8800 | val_loss: 0.29449 - val_acc: 0.8925 -- iter: 3680/3680
[A[ATraining Step: 9430  | total loss: [1m[32m0.31049[0m[0m
[2K| Adam | epoch: 082 | loss: 0.31049 - acc: 0.8800 | val_loss: 0.29449 - val_acc: 0.8925 -- iter: 3680/3680
--
Training Step: 9431  | total loss: [1m[32m0.32347[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32347 - acc: 0.8701 -- iter: 0032/3680
[A[ATraining Step: 9432  | total loss: [1m[32m0.32132[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32132 - acc: 0.8738 -- iter: 0064/3680
[A[ATraining Step: 9433  | total loss: [1m[32m0.32179[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32179 - acc: 0.8708 -- iter: 0096/3680
[A[ATraining Step: 9434  | total loss: [1m[32m0.31923[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31923 - acc: 0.8712 -- iter: 0128/3680
[A[ATraining Step: 9435  | total loss: [1m[32m0.33579[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33579 - acc: 0.8660 -- iter: 0160/3680
[A[ATraining Step: 9436  | total loss: [1m[32m0.33873[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33873 - acc: 0.8660 -- iter: 0192/3680
[A[ATraining Step: 9437  | total loss: [1m[32m0.32474[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32474 - acc: 0.8762 -- iter: 0224/3680
[A[ATraining Step: 9438  | total loss: [1m[32m0.33231[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33231 - acc: 0.8761 -- iter: 0256/3680
[A[ATraining Step: 9439  | total loss: [1m[32m0.33471[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33471 - acc: 0.8762 -- iter: 0288/3680
[A[ATraining Step: 9440  | total loss: [1m[32m0.33471[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33471 - acc: 0.8762 -- iter: 0320/3680
[A[ATraining Step: 9441  | total loss: [1m[32m0.33435[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33435 - acc: 0.8730 -- iter: 0352/3680
[A[ATraining Step: 9442  | total loss: [1m[32m0.31905[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31905 - acc: 0.8826 -- iter: 0384/3680
[A[ATraining Step: 9443  | total loss: [1m[32m0.31573[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31573 - acc: 0.8933 -- iter: 0416/3680
[A[ATraining Step: 9444  | total loss: [1m[32m0.30466[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30466 - acc: 0.8933 -- iter: 0448/3680
[A[ATraining Step: 9445  | total loss: [1m[32m0.30150[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30150 - acc: 0.8915 -- iter: 0480/3680
[A[ATraining Step: 9446  | total loss: [1m[32m0.32725[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32725 - acc: 0.8805 -- iter: 0512/3680
[A[ATraining Step: 9447  | total loss: [1m[32m0.33583[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33583 - acc: 0.8705 -- iter: 0544/3680
[A[ATraining Step: 9448  | total loss: [1m[32m0.32895[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32895 - acc: 0.8741 -- iter: 0576/3680
[A[ATraining Step: 9449  | total loss: [1m[32m0.31475[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31475 - acc: 0.8804 -- iter: 0608/3680
[A[ATraining Step: 9450  | total loss: [1m[32m0.31386[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31386 - acc: 0.8799 -- iter: 0640/3680
[A[ATraining Step: 9451  | total loss: [1m[32m0.30314[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30314 - acc: 0.8857 -- iter: 0672/3680
[A[ATraining Step: 9452  | total loss: [1m[32m0.29677[0m[0m
[2K| Adam | epoch: 083 | loss: 0.29677 - acc: 0.8768 -- iter: 0704/3680
[A[ATraining Step: 9453  | total loss: [1m[32m0.30158[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30158 - acc: 0.8768 -- iter: 0736/3680
[A[ATraining Step: 9454  | total loss: [1m[32m0.30388[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30388 - acc: 0.8735 -- iter: 0768/3680
[A[ATraining Step: 9455  | total loss: [1m[32m0.29961[0m[0m
[2K| Adam | epoch: 083 | loss: 0.29961 - acc: 0.8799 -- iter: 0800/3680
[A[ATraining Step: 9456  | total loss: [1m[32m0.29856[0m[0m
[2K| Adam | epoch: 083 | loss: 0.29856 - acc: 0.8825 -- iter: 0832/3680
[A[ATraining Step: 9457  | total loss: [1m[32m0.29148[0m[0m
[2K| Adam | epoch: 083 | loss: 0.29148 - acc: 0.8849 -- iter: 0864/3680
[A[ATraining Step: 9458  | total loss: [1m[32m0.29131[0m[0m
[2K| Adam | epoch: 083 | loss: 0.29131 - acc: 0.8901 -- iter: 0896/3680
[A[ATraining Step: 9459  | total loss: [1m[32m0.31504[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31504 - acc: 0.8824 -- iter: 0928/3680
[A[ATraining Step: 9460  | total loss: [1m[32m0.34207[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34207 - acc: 0.8628 -- iter: 0960/3680
[A[ATraining Step: 9461  | total loss: [1m[32m0.34207[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34207 - acc: 0.8628 -- iter: 0992/3680
[A[ATraining Step: 9462  | total loss: [1m[32m0.34370[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34370 - acc: 0.8641 -- iter: 1024/3680
[A[ATraining Step: 9463  | total loss: [1m[32m0.33725[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33725 - acc: 0.8652 -- iter: 1056/3680
[A[ATraining Step: 9464  | total loss: [1m[32m0.32958[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32958 - acc: 0.8693 -- iter: 1088/3680
[A[ATraining Step: 9465  | total loss: [1m[32m0.33344[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33344 - acc: 0.8636 -- iter: 1120/3680
[A[ATraining Step: 9466  | total loss: [1m[32m0.33874[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33874 - acc: 0.8585 -- iter: 1152/3680
[A[ATraining Step: 9467  | total loss: [1m[32m0.33156[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33156 - acc: 0.8588 -- iter: 1184/3680
[A[ATraining Step: 9468  | total loss: [1m[32m0.33156[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33156 - acc: 0.8588 -- iter: 1216/3680
[A[ATraining Step: 9469  | total loss: [1m[32m0.32062[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32062 - acc: 0.8667 -- iter: 1248/3680
[A[ATraining Step: 9470  | total loss: [1m[32m0.31558[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31558 - acc: 0.8706 -- iter: 1280/3680
[A[ATraining Step: 9471  | total loss: [1m[32m0.32876[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32876 - acc: 0.8617 -- iter: 1312/3680
[A[ATraining Step: 9472  | total loss: [1m[32m0.34228[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34228 - acc: 0.8662 -- iter: 1344/3680
[A[ATraining Step: 9473  | total loss: [1m[32m0.34712[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34712 - acc: 0.8670 -- iter: 1376/3680
[A[ATraining Step: 9474  | total loss: [1m[32m0.33021[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33021 - acc: 0.8772 -- iter: 1408/3680
[A[ATraining Step: 9475  | total loss: [1m[32m0.34608[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34608 - acc: 0.8770 -- iter: 1440/3680
[A[ATraining Step: 9476  | total loss: [1m[32m0.33753[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33753 - acc: 0.8768 -- iter: 1472/3680
[A[ATraining Step: 9477  | total loss: [1m[32m0.34376[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34376 - acc: 0.8735 -- iter: 1504/3680
[A[ATraining Step: 9478  | total loss: [1m[32m0.35951[0m[0m
[2K| Adam | epoch: 083 | loss: 0.35951 - acc: 0.8643 -- iter: 1536/3680
[A[ATraining Step: 9479  | total loss: [1m[32m0.36743[0m[0m
[2K| Adam | epoch: 083 | loss: 0.36743 - acc: 0.8591 -- iter: 1568/3680
[A[ATraining Step: 9480  | total loss: [1m[32m0.38235[0m[0m
[2K| Adam | epoch: 083 | loss: 0.38235 - acc: 0.8419 -- iter: 1600/3680
[A[ATraining Step: 9481  | total loss: [1m[32m0.36981[0m[0m
[2K| Adam | epoch: 083 | loss: 0.36981 - acc: 0.8484 -- iter: 1632/3680
[A[ATraining Step: 9482  | total loss: [1m[32m0.36395[0m[0m
[2K| Adam | epoch: 083 | loss: 0.36395 - acc: 0.8573 -- iter: 1664/3680
[A[ATraining Step: 9483  | total loss: [1m[32m0.34841[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34841 - acc: 0.8590 -- iter: 1696/3680
[A[ATraining Step: 9484  | total loss: [1m[32m0.34884[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34884 - acc: 0.8575 -- iter: 1728/3680
[A[ATraining Step: 9485  | total loss: [1m[32m0.33248[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33248 - acc: 0.8655 -- iter: 1760/3680
[A[ATraining Step: 9486  | total loss: [1m[32m0.32360[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32360 - acc: 0.8727 -- iter: 1792/3680
[A[ATraining Step: 9487  | total loss: [1m[32m0.32310[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32310 - acc: 0.8761 -- iter: 1824/3680
[A[ATraining Step: 9488  | total loss: [1m[32m0.34348[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34348 - acc: 0.8635 -- iter: 1856/3680
[A[ATraining Step: 9489  | total loss: [1m[32m0.31752[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31752 - acc: 0.8771 -- iter: 1888/3680
[A[ATraining Step: 9490  | total loss: [1m[32m0.30687[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30687 - acc: 0.8769 -- iter: 1920/3680
[A[ATraining Step: 9491  | total loss: [1m[32m0.31595[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31595 - acc: 0.8736 -- iter: 1952/3680
[A[ATraining Step: 9492  | total loss: [1m[32m0.33545[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33545 - acc: 0.8612 -- iter: 1984/3680
[A[ATraining Step: 9493  | total loss: [1m[32m0.31837[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31837 - acc: 0.8720 -- iter: 2016/3680
[A[ATraining Step: 9494  | total loss: [1m[32m0.30714[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30714 - acc: 0.8754 -- iter: 2048/3680
[A[ATraining Step: 9495  | total loss: [1m[32m0.30714[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30714 - acc: 0.8816 -- iter: 2080/3680
[A[ATraining Step: 9496  | total loss: [1m[32m0.30139[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30139 - acc: 0.8810 -- iter: 2112/3680
[A[ATraining Step: 9497  | total loss: [1m[32m0.31526[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31526 - acc: 0.8772 -- iter: 2144/3680
[A[ATraining Step: 9498  | total loss: [1m[32m0.31795[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31795 - acc: 0.8739 -- iter: 2176/3680
[A[ATraining Step: 9499  | total loss: [1m[32m0.33044[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33044 - acc: 0.8709 -- iter: 2208/3680
[A[ATraining Step: 9500  | total loss: [1m[32m0.31866[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31866 - acc: 0.8713 | val_loss: 0.29415 - val_acc: 0.8882 -- iter: 2240/3680
[A[ATraining Step: 9500  | total loss: [1m[32m0.31866[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31866 - acc: 0.8713 | val_loss: 0.29415 - val_acc: 0.8882 -- iter: 2240/3680
--
Training Step: 9501  | total loss: [1m[32m0.32283[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32283 - acc: 0.8685 -- iter: 2272/3680
[A[ATraining Step: 9502  | total loss: [1m[32m0.31342[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31342 - acc: 0.8723 -- iter: 2304/3680
[A[ATraining Step: 9503  | total loss: [1m[32m0.30549[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30549 - acc: 0.8757 -- iter: 2336/3680
[A[ATraining Step: 9504  | total loss: [1m[32m0.30241[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30241 - acc: 0.8725 -- iter: 2368/3680
[A[ATraining Step: 9505  | total loss: [1m[32m0.31196[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31196 - acc: 0.8634 -- iter: 2400/3680
[A[ATraining Step: 9506  | total loss: [1m[32m0.32571[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32571 - acc: 0.8552 -- iter: 2432/3680
[A[ATraining Step: 9507  | total loss: [1m[32m0.32792[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32792 - acc: 0.8571 -- iter: 2464/3680
[A[ATraining Step: 9508  | total loss: [1m[32m0.31430[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31430 - acc: 0.8699 -- iter: 2496/3680
[A[ATraining Step: 9509  | total loss: [1m[32m0.32097[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32097 - acc: 0.8704 -- iter: 2528/3680
[A[ATraining Step: 9510  | total loss: [1m[32m0.32097[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32097 - acc: 0.8704 -- iter: 2560/3680
[A[ATraining Step: 9511  | total loss: [1m[32m0.33005[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33005 - acc: 0.8678 -- iter: 2592/3680
[A[ATraining Step: 9512  | total loss: [1m[32m0.32422[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32422 - acc: 0.8716 -- iter: 2624/3680
[A[ATraining Step: 9513  | total loss: [1m[32m0.32880[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32880 - acc: 0.8719 -- iter: 2656/3680
[A[ATraining Step: 9514  | total loss: [1m[32m0.32310[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32310 - acc: 0.8691 -- iter: 2688/3680
[A[ATraining Step: 9515  | total loss: [1m[32m0.32711[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32711 - acc: 0.8637 -- iter: 2720/3680
[A[ATraining Step: 9516  | total loss: [1m[32m0.32711[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32711 - acc: 0.8637 -- iter: 2752/3680
[A[ATraining Step: 9517  | total loss: [1m[32m0.32808[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32808 - acc: 0.8617 -- iter: 2784/3680
[A[ATraining Step: 9518  | total loss: [1m[32m0.32456[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32456 - acc: 0.8661 -- iter: 2816/3680
[A[ATraining Step: 9519  | total loss: [1m[32m0.31907[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31907 - acc: 0.8670 -- iter: 2848/3680
[A[ATraining Step: 9520  | total loss: [1m[32m0.30313[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30313 - acc: 0.8772 -- iter: 2880/3680
[A[ATraining Step: 9521  | total loss: [1m[32m0.31356[0m[0m
[2K| Adam | epoch: 083 | loss: 0.31356 - acc: 0.8707 -- iter: 2912/3680
[A[ATraining Step: 9522  | total loss: [1m[32m0.32259[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32259 - acc: 0.8618 -- iter: 2944/3680
[A[ATraining Step: 9523  | total loss: [1m[32m0.32003[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32003 - acc: 0.8577 -- iter: 2976/3680
[A[ATraining Step: 9524  | total loss: [1m[32m0.32003[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32003 - acc: 0.8688 -- iter: 3008/3680
[A[ATraining Step: 9525  | total loss: [1m[32m0.30232[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30232 - acc: 0.8688 -- iter: 3040/3680
[A[ATraining Step: 9526  | total loss: [1m[32m0.30715[0m[0m
[2K| Adam | epoch: 083 | loss: 0.30715 - acc: 0.8632 -- iter: 3072/3680
[A[ATraining Step: 9527  | total loss: [1m[32m0.34242[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34242 - acc: 0.8488 -- iter: 3104/3680
[A[ATraining Step: 9528  | total loss: [1m[32m0.33008[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33008 - acc: 0.8608 -- iter: 3136/3680
[A[ATraining Step: 9529  | total loss: [1m[32m0.33590[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33590 - acc: 0.8559 -- iter: 3168/3680
[A[ATraining Step: 9530  | total loss: [1m[32m0.33615[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33615 - acc: 0.8453 -- iter: 3200/3680
[A[ATraining Step: 9531  | total loss: [1m[32m0.34379[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34379 - acc: 0.8452 -- iter: 3232/3680
[A[ATraining Step: 9532  | total loss: [1m[32m0.33957[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33957 - acc: 0.8513 -- iter: 3264/3680
[A[ATraining Step: 9533  | total loss: [1m[32m0.34372[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34372 - acc: 0.8474 -- iter: 3296/3680
[A[ATraining Step: 9534  | total loss: [1m[32m0.35398[0m[0m
[2K| Adam | epoch: 083 | loss: 0.35398 - acc: 0.8470 -- iter: 3328/3680
[A[ATraining Step: 9535  | total loss: [1m[32m0.34514[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34514 - acc: 0.8561 -- iter: 3360/3680
[A[ATraining Step: 9536  | total loss: [1m[32m0.34701[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34701 - acc: 0.8549 -- iter: 3392/3680
[A[ATraining Step: 9537  | total loss: [1m[32m0.34376[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34376 - acc: 0.8631 -- iter: 3424/3680
[A[ATraining Step: 9538  | total loss: [1m[32m0.32907[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32907 - acc: 0.8706 -- iter: 3456/3680
[A[ATraining Step: 9539  | total loss: [1m[32m0.32029[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32029 - acc: 0.8773 -- iter: 3488/3680
[A[ATraining Step: 9540  | total loss: [1m[32m0.34754[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34754 - acc: 0.8645 -- iter: 3520/3680
[A[ATraining Step: 9541  | total loss: [1m[32m0.34145[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34145 - acc: 0.8718 -- iter: 3552/3680
[A[ATraining Step: 9542  | total loss: [1m[32m0.34740[0m[0m
[2K| Adam | epoch: 083 | loss: 0.34740 - acc: 0.8756 -- iter: 3584/3680
[A[ATraining Step: 9543  | total loss: [1m[32m0.33031[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33031 - acc: 0.8817 -- iter: 3616/3680
[A[ATraining Step: 9544  | total loss: [1m[32m0.33031[0m[0m
[2K| Adam | epoch: 083 | loss: 0.33031 - acc: 0.8817 -- iter: 3648/3680
[A[ATraining Step: 9545  | total loss: [1m[32m0.32020[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32020 - acc: 0.8873 | val_loss: 0.30714 - val_acc: 0.8882 -- iter: 3680/3680
[A[ATraining Step: 9545  | total loss: [1m[32m0.32020[0m[0m
[2K| Adam | epoch: 083 | loss: 0.32020 - acc: 0.8873 | val_loss: 0.30714 - val_acc: 0.8882 -- iter: 3680/3680
--
Training Step: 9546  | total loss: [1m[32m0.31167[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31167 - acc: 0.8923 -- iter: 0032/3680
[A[ATraining Step: 9547  | total loss: [1m[32m0.33051[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33051 - acc: 0.8844 -- iter: 0064/3680
[A[ATraining Step: 9548  | total loss: [1m[32m0.34442[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34442 - acc: 0.8740 -- iter: 0096/3680
[A[ATraining Step: 9549  | total loss: [1m[32m0.35312[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35312 - acc: 0.8679 -- iter: 0128/3680
[A[ATraining Step: 9550  | total loss: [1m[32m0.37047[0m[0m
[2K| Adam | epoch: 084 | loss: 0.37047 - acc: 0.8592 -- iter: 0160/3680
[A[ATraining Step: 9551  | total loss: [1m[32m0.35821[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35821 - acc: 0.8608 -- iter: 0192/3680
[A[ATraining Step: 9552  | total loss: [1m[32m0.35661[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35661 - acc: 0.8653 -- iter: 0224/3680
[A[ATraining Step: 9553  | total loss: [1m[32m0.35146[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35146 - acc: 0.8632 -- iter: 0256/3680
[A[ATraining Step: 9554  | total loss: [1m[32m0.33985[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33985 - acc: 0.8675 -- iter: 0288/3680
[A[ATraining Step: 9555  | total loss: [1m[32m0.33647[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33647 - acc: 0.8651 -- iter: 0320/3680
[A[ATraining Step: 9556  | total loss: [1m[32m0.34964[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34964 - acc: 0.8704 -- iter: 0352/3680
[A[ATraining Step: 9557  | total loss: [1m[32m0.34185[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34185 - acc: 0.8709 -- iter: 0384/3680
[A[ATraining Step: 9558  | total loss: [1m[32m0.34185[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34185 - acc: 0.8709 -- iter: 0416/3680
[A[ATraining Step: 9559  | total loss: [1m[32m0.32846[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32846 - acc: 0.8776 -- iter: 0448/3680
[A[ATraining Step: 9560  | total loss: [1m[32m0.31891[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31891 - acc: 0.8835 -- iter: 0480/3680
[A[ATraining Step: 9561  | total loss: [1m[32m0.32840[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32840 - acc: 0.8764 -- iter: 0512/3680
[A[ATraining Step: 9562  | total loss: [1m[32m0.32385[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32385 - acc: 0.8763 -- iter: 0544/3680
[A[ATraining Step: 9563  | total loss: [1m[32m0.31309[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31309 - acc: 0.8855 -- iter: 0576/3680
[A[ATraining Step: 9564  | total loss: [1m[32m0.32538[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32538 - acc: 0.8814 -- iter: 0608/3680
[A[ATraining Step: 9565  | total loss: [1m[32m0.32843[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32843 - acc: 0.8745 -- iter: 0640/3680
[A[ATraining Step: 9566  | total loss: [1m[32m0.37091[0m[0m
[2K| Adam | epoch: 084 | loss: 0.37091 - acc: 0.8652 -- iter: 0672/3680
[A[ATraining Step: 9567  | total loss: [1m[32m0.36638[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36638 - acc: 0.8661 -- iter: 0704/3680
[A[ATraining Step: 9568  | total loss: [1m[32m0.35873[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35873 - acc: 0.8639 -- iter: 0736/3680
[A[ATraining Step: 9569  | total loss: [1m[32m0.36139[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36139 - acc: 0.8598 -- iter: 0768/3680
[A[ATraining Step: 9570  | total loss: [1m[32m0.36133[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36133 - acc: 0.8598 -- iter: 0800/3680
[A[ATraining Step: 9571  | total loss: [1m[32m0.37431[0m[0m
[2K| Adam | epoch: 084 | loss: 0.37431 - acc: 0.8488 -- iter: 0832/3680
[A[ATraining Step: 9572  | total loss: [1m[32m0.38639[0m[0m
[2K| Adam | epoch: 084 | loss: 0.38639 - acc: 0.8483 -- iter: 0864/3680
[A[ATraining Step: 9573  | total loss: [1m[32m0.38013[0m[0m
[2K| Adam | epoch: 084 | loss: 0.38013 - acc: 0.8510 -- iter: 0896/3680
[A[ATraining Step: 9574  | total loss: [1m[32m0.38583[0m[0m
[2K| Adam | epoch: 084 | loss: 0.38583 - acc: 0.8471 -- iter: 0928/3680
[A[ATraining Step: 9575  | total loss: [1m[32m0.38583[0m[0m
[2K| Adam | epoch: 084 | loss: 0.38583 - acc: 0.8471 -- iter: 0960/3680
[A[ATraining Step: 9576  | total loss: [1m[32m0.36822[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36822 - acc: 0.8561 -- iter: 0992/3680
[A[ATraining Step: 9577  | total loss: [1m[32m0.36487[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36487 - acc: 0.8549 -- iter: 1024/3680
[A[ATraining Step: 9578  | total loss: [1m[32m0.34038[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34038 - acc: 0.8694 -- iter: 1056/3680
[A[ATraining Step: 9579  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34347 - acc: 0.8668 -- iter: 1088/3680
[A[ATraining Step: 9580  | total loss: [1m[32m0.34384[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34384 - acc: 0.8614 -- iter: 1120/3680
[A[ATraining Step: 9581  | total loss: [1m[32m0.33149[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33149 - acc: 0.8690 -- iter: 1152/3680
[A[ATraining Step: 9582  | total loss: [1m[32m0.32784[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32784 - acc: 0.8696 -- iter: 1184/3680
[A[ATraining Step: 9583  | total loss: [1m[32m0.33563[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33563 - acc: 0.8670 -- iter: 1216/3680
[A[ATraining Step: 9584  | total loss: [1m[32m0.33871[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33871 - acc: 0.8678 -- iter: 1248/3680
[A[ATraining Step: 9585  | total loss: [1m[32m0.32979[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32979 - acc: 0.8748 -- iter: 1280/3680
[A[ATraining Step: 9586  | total loss: [1m[32m0.33319[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33319 - acc: 0.8779 -- iter: 1312/3680
[A[ATraining Step: 9587  | total loss: [1m[32m0.34547[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34547 - acc: 0.8596 -- iter: 1344/3680
[A[ATraining Step: 9588  | total loss: [1m[32m0.34547[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34547 - acc: 0.8596 -- iter: 1376/3680
[A[ATraining Step: 9589  | total loss: [1m[32m0.34620[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34620 - acc: 0.8580 -- iter: 1408/3680
[A[ATraining Step: 9590  | total loss: [1m[32m0.36121[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36121 - acc: 0.8650 -- iter: 1440/3680
[A[ATraining Step: 9591  | total loss: [1m[32m0.34205[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34205 - acc: 0.8650 -- iter: 1472/3680
[A[ATraining Step: 9592  | total loss: [1m[32m0.35531[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35531 - acc: 0.8566 -- iter: 1504/3680
[A[ATraining Step: 9593  | total loss: [1m[32m0.35430[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35430 - acc: 0.8663 -- iter: 1536/3680
[A[ATraining Step: 9594  | total loss: [1m[32m0.34455[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34455 - acc: 0.8663 -- iter: 1568/3680
[A[ATraining Step: 9595  | total loss: [1m[32m0.35019[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35019 - acc: 0.8703 -- iter: 1600/3680
[A[ATraining Step: 9596  | total loss: [1m[32m0.35273[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35273 - acc: 0.8645 -- iter: 1632/3680
[A[ATraining Step: 9597  | total loss: [1m[32m0.36016[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36016 - acc: 0.8625 -- iter: 1664/3680
[A[ATraining Step: 9598  | total loss: [1m[32m0.34129[0m[0m
[2K| Adam | epoch: 084 | loss: 0.34129 - acc: 0.8762 -- iter: 1696/3680
[A[ATraining Step: 9599  | total loss: [1m[32m0.33293[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33293 - acc: 0.8667 -- iter: 1728/3680
[A[ATraining Step: 9600  | total loss: [1m[32m0.33293[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33293 - acc: 0.8707 | val_loss: 0.29510 - val_acc: 0.8947 -- iter: 1760/3680
[A[ATraining Step: 9600  | total loss: [1m[32m0.33293[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33293 - acc: 0.8707 | val_loss: 0.29510 - val_acc: 0.8947 -- iter: 1760/3680
--
Training Step: 9601  | total loss: [1m[32m0.32950[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32950 - acc: 0.8680 -- iter: 1792/3680
[A[ATraining Step: 9602  | total loss: [1m[32m0.33469[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33469 - acc: 0.8624 -- iter: 1824/3680
[A[ATraining Step: 9603  | total loss: [1m[32m0.32523[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32523 - acc: 0.8699 -- iter: 1856/3680
[A[ATraining Step: 9604  | total loss: [1m[32m0.35447[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35447 - acc: 0.8579 -- iter: 1888/3680
[A[ATraining Step: 9605  | total loss: [1m[32m0.35747[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35747 - acc: 0.8565 -- iter: 1920/3680
[A[ATraining Step: 9606  | total loss: [1m[32m0.35654[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35654 - acc: 0.8584 -- iter: 1952/3680
[A[ATraining Step: 9607  | total loss: [1m[32m0.35703[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35703 - acc: 0.8569 -- iter: 1984/3680
[A[ATraining Step: 9608  | total loss: [1m[32m0.35301[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35301 - acc: 0.8618 -- iter: 2016/3680
[A[ATraining Step: 9609  | total loss: [1m[32m0.36349[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36349 - acc: 0.8538 -- iter: 2048/3680
[A[ATraining Step: 9610  | total loss: [1m[32m0.36363[0m[0m
[2K| Adam | epoch: 084 | loss: 0.36363 - acc: 0.8590 -- iter: 2080/3680
[A[ATraining Step: 9611  | total loss: [1m[32m0.35873[0m[0m
[2K| Adam | epoch: 084 | loss: 0.35873 - acc: 0.8669 -- iter: 2112/3680
[A[ATraining Step: 9612  | total loss: [1m[32m0.33327[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33327 - acc: 0.8831 -- iter: 2144/3680
[A[ATraining Step: 9613  | total loss: [1m[32m0.33327[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33327 - acc: 0.8831 -- iter: 2176/3680
[A[ATraining Step: 9614  | total loss: [1m[32m0.31862[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31862 - acc: 0.8885 -- iter: 2208/3680
[A[ATraining Step: 9615  | total loss: [1m[32m0.30873[0m[0m
[2K| Adam | epoch: 084 | loss: 0.30873 - acc: 0.8934 -- iter: 2240/3680
[A[ATraining Step: 9616  | total loss: [1m[32m0.31133[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31133 - acc: 0.8916 -- iter: 2272/3680
[A[ATraining Step: 9617  | total loss: [1m[32m0.30716[0m[0m
[2K| Adam | epoch: 084 | loss: 0.30716 - acc: 0.8899 -- iter: 2304/3680
[A[ATraining Step: 9618  | total loss: [1m[32m0.29989[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29989 - acc: 0.8947 -- iter: 2336/3680
[A[ATraining Step: 9619  | total loss: [1m[32m0.29515[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29515 - acc: 0.8927 -- iter: 2368/3680
[A[ATraining Step: 9620  | total loss: [1m[32m0.29696[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29696 - acc: 0.8878 -- iter: 2400/3680
[A[ATraining Step: 9621  | total loss: [1m[32m0.29330[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29330 - acc: 0.8897 -- iter: 2432/3680
[A[ATraining Step: 9622  | total loss: [1m[32m0.29222[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29222 - acc: 0.8882 -- iter: 2464/3680
[A[ATraining Step: 9623  | total loss: [1m[32m0.29091[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29091 - acc: 0.8869 -- iter: 2496/3680
[A[ATraining Step: 9624  | total loss: [1m[32m0.27275[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27275 - acc: 0.8982 -- iter: 2528/3680
[A[ATraining Step: 9625  | total loss: [1m[32m0.27318[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27318 - acc: 0.8990 -- iter: 2560/3680
[A[ATraining Step: 9626  | total loss: [1m[32m0.29154[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29154 - acc: 0.8966 -- iter: 2592/3680
[A[ATraining Step: 9627  | total loss: [1m[32m0.30141[0m[0m
[2K| Adam | epoch: 084 | loss: 0.30141 - acc: 0.8882 -- iter: 2624/3680
[A[ATraining Step: 9628  | total loss: [1m[32m0.29735[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29735 - acc: 0.8869 -- iter: 2656/3680
[A[ATraining Step: 9629  | total loss: [1m[32m0.29636[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29636 - acc: 0.8826 -- iter: 2688/3680
[A[ATraining Step: 9630  | total loss: [1m[32m0.28325[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28325 - acc: 0.8912 -- iter: 2720/3680
[A[ATraining Step: 9631  | total loss: [1m[32m0.27974[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27974 - acc: 0.8927 -- iter: 2752/3680
[A[ATraining Step: 9632  | total loss: [1m[32m0.28248[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28248 - acc: 0.8878 -- iter: 2784/3680
[A[ATraining Step: 9633  | total loss: [1m[32m0.27929[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27929 - acc: 0.8865 -- iter: 2816/3680
[A[ATraining Step: 9634  | total loss: [1m[32m0.28231[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28231 - acc: 0.8822 -- iter: 2848/3680
[A[ATraining Step: 9635  | total loss: [1m[32m0.28266[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28266 - acc: 0.8784 -- iter: 2880/3680
[A[ATraining Step: 9636  | total loss: [1m[32m0.31078[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31078 - acc: 0.8749 -- iter: 2912/3680
[A[ATraining Step: 9637  | total loss: [1m[32m0.33016[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33016 - acc: 0.8624 -- iter: 2944/3680
[A[ATraining Step: 9638  | total loss: [1m[32m0.31613[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31613 - acc: 0.8731 -- iter: 2976/3680
[A[ATraining Step: 9639  | total loss: [1m[32m0.33169[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33169 - acc: 0.8670 -- iter: 3008/3680
[A[ATraining Step: 9640  | total loss: [1m[32m0.33184[0m[0m
[2K| Adam | epoch: 084 | loss: 0.33184 - acc: 0.8647 -- iter: 3040/3680
[A[ATraining Step: 9641  | total loss: [1m[32m0.31680[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31680 - acc: 0.8720 -- iter: 3072/3680
[A[ATraining Step: 9642  | total loss: [1m[32m0.32188[0m[0m
[2K| Adam | epoch: 084 | loss: 0.32188 - acc: 0.8723 -- iter: 3104/3680
[A[ATraining Step: 9643  | total loss: [1m[32m0.31497[0m[0m
[2K| Adam | epoch: 084 | loss: 0.31497 - acc: 0.8788 -- iter: 3136/3680
[A[ATraining Step: 9644  | total loss: [1m[32m0.30626[0m[0m
[2K| Adam | epoch: 084 | loss: 0.30626 - acc: 0.8837 -- iter: 3168/3680
[A[ATraining Step: 9645  | total loss: [1m[32m0.30474[0m[0m
[2K| Adam | epoch: 084 | loss: 0.30474 - acc: 0.8837 -- iter: 3200/3680
[A[ATraining Step: 9646  | total loss: [1m[32m0.29397[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29397 - acc: 0.8891 -- iter: 3232/3680
[A[ATraining Step: 9647  | total loss: [1m[32m0.28794[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28794 - acc: 0.8877 -- iter: 3264/3680
[A[ATraining Step: 9648  | total loss: [1m[32m0.28702[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28702 - acc: 0.8909 -- iter: 3296/3680
[A[ATraining Step: 9649  | total loss: [1m[32m0.28702[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28702 - acc: 0.8909 -- iter: 3328/3680
[A[ATraining Step: 9650  | total loss: [1m[32m0.27765[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27765 - acc: 0.8987 -- iter: 3360/3680
[A[ATraining Step: 9651  | total loss: [1m[32m0.29311[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29311 - acc: 0.8932 -- iter: 3392/3680
[A[ATraining Step: 9652  | total loss: [1m[32m0.27512[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27512 - acc: 0.8919 -- iter: 3424/3680
[A[ATraining Step: 9653  | total loss: [1m[32m0.28207[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28207 - acc: 0.8919 -- iter: 3456/3680
[A[ATraining Step: 9654  | total loss: [1m[32m0.27727[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27727 - acc: 0.8965 -- iter: 3488/3680
[A[ATraining Step: 9655  | total loss: [1m[32m0.27337[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27337 - acc: 0.8918 -- iter: 3520/3680
[A[ATraining Step: 9656  | total loss: [1m[32m0.27941[0m[0m
[2K| Adam | epoch: 084 | loss: 0.27941 - acc: 0.8918 -- iter: 3552/3680
[A[ATraining Step: 9657  | total loss: [1m[32m0.29459[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29459 - acc: 0.8807 -- iter: 3584/3680
[A[ATraining Step: 9658  | total loss: [1m[32m0.28079[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28079 - acc: 0.8895 -- iter: 3616/3680
[A[ATraining Step: 9659  | total loss: [1m[32m0.28018[0m[0m
[2K| Adam | epoch: 084 | loss: 0.28018 - acc: 0.8849 -- iter: 3648/3680
[A[ATraining Step: 9660  | total loss: [1m[32m0.29548[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29548 - acc: 0.8808 | val_loss: 0.28861 - val_acc: 0.8969 -- iter: 3680/3680
[A[ATraining Step: 9660  | total loss: [1m[32m0.29548[0m[0m
[2K| Adam | epoch: 084 | loss: 0.29548 - acc: 0.8808 | val_loss: 0.28861 - val_acc: 0.8969 -- iter: 3680/3680
--
Training Step: 9661  | total loss: [1m[32m0.29662[0m[0m
[2K| Adam | epoch: 085 | loss: 0.29662 - acc: 0.8834 -- iter: 0032/3680
[A[ATraining Step: 9662  | total loss: [1m[32m0.29295[0m[0m
[2K| Adam | epoch: 085 | loss: 0.29295 - acc: 0.8888 -- iter: 0064/3680
[A[ATraining Step: 9663  | total loss: [1m[32m0.29072[0m[0m
[2K| Adam | epoch: 085 | loss: 0.29072 - acc: 0.8843 -- iter: 0096/3680
[A[ATraining Step: 9664  | total loss: [1m[32m0.32576[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32576 - acc: 0.8771 -- iter: 0128/3680
[A[ATraining Step: 9665  | total loss: [1m[32m0.33676[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33676 - acc: 0.8738 -- iter: 0160/3680
[A[ATraining Step: 9666  | total loss: [1m[32m0.33084[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33084 - acc: 0.8739 -- iter: 0192/3680
[A[ATraining Step: 9667  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34347 - acc: 0.8646 -- iter: 0224/3680
[A[ATraining Step: 9668  | total loss: [1m[32m0.33906[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33906 - acc: 0.8719 -- iter: 0256/3680
[A[ATraining Step: 9669  | total loss: [1m[32m0.33861[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33861 - acc: 0.8691 -- iter: 0288/3680
[A[ATraining Step: 9670  | total loss: [1m[32m0.31466[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31466 - acc: 0.8822 -- iter: 0320/3680
[A[ATraining Step: 9671  | total loss: [1m[32m0.31604[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31604 - acc: 0.8846 -- iter: 0352/3680
[A[ATraining Step: 9672  | total loss: [1m[32m0.31052[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31052 - acc: 0.8868 -- iter: 0384/3680
[A[ATraining Step: 9673  | total loss: [1m[32m0.31483[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31483 - acc: 0.8811 -- iter: 0416/3680
[A[ATraining Step: 9674  | total loss: [1m[32m0.32639[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32639 - acc: 0.8811 -- iter: 0448/3680
[A[ATraining Step: 9675  | total loss: [1m[32m0.35152[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35152 - acc: 0.8742 -- iter: 0480/3680
[A[ATraining Step: 9676  | total loss: [1m[32m0.34359[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34359 - acc: 0.8806 -- iter: 0512/3680
[A[ATraining Step: 9677  | total loss: [1m[32m0.33543[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33543 - acc: 0.8800 -- iter: 0544/3680
[A[ATraining Step: 9678  | total loss: [1m[32m0.32884[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32884 - acc: 0.8795 -- iter: 0576/3680
[A[ATraining Step: 9679  | total loss: [1m[32m0.33790[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33790 - acc: 0.8790 -- iter: 0608/3680
[A[ATraining Step: 9680  | total loss: [1m[32m0.33058[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33058 - acc: 0.8689 -- iter: 0640/3680
[A[ATraining Step: 9681  | total loss: [1m[32m0.32952[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32952 - acc: 0.8689 -- iter: 0672/3680
[A[ATraining Step: 9682  | total loss: [1m[32m0.32952[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32952 - acc: 0.8695 -- iter: 0704/3680
[A[ATraining Step: 9683  | total loss: [1m[32m0.32792[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32792 - acc: 0.8669 -- iter: 0736/3680
[A[ATraining Step: 9684  | total loss: [1m[32m0.34302[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34302 - acc: 0.8615 -- iter: 0768/3680
[A[ATraining Step: 9685  | total loss: [1m[32m0.35571[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35571 - acc: 0.8535 -- iter: 0800/3680
[A[ATraining Step: 9686  | total loss: [1m[32m0.34874[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34874 - acc: 0.8587 -- iter: 0832/3680
[A[ATraining Step: 9687  | total loss: [1m[32m0.34887[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34887 - acc: 0.8656 -- iter: 0864/3680
[A[ATraining Step: 9688  | total loss: [1m[32m0.32620[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32620 - acc: 0.8656 -- iter: 0896/3680
[A[ATraining Step: 9689  | total loss: [1m[32m0.34019[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34019 - acc: 0.8603 -- iter: 0928/3680
[A[ATraining Step: 9690  | total loss: [1m[32m0.35008[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35008 - acc: 0.8492 -- iter: 0960/3680
[A[ATraining Step: 9691  | total loss: [1m[32m0.33988[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33988 - acc: 0.8420 -- iter: 0992/3680
[A[ATraining Step: 9692  | total loss: [1m[32m0.33988[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33988 - acc: 0.8420 -- iter: 1024/3680
[A[ATraining Step: 9693  | total loss: [1m[32m0.32438[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32438 - acc: 0.8507 -- iter: 1056/3680
[A[ATraining Step: 9694  | total loss: [1m[32m0.33055[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33055 - acc: 0.8507 -- iter: 1088/3680
[A[ATraining Step: 9695  | total loss: [1m[32m0.33920[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33920 - acc: 0.8407 -- iter: 1120/3680
[A[ATraining Step: 9696  | total loss: [1m[32m0.33371[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33371 - acc: 0.8472 -- iter: 1152/3680
[A[ATraining Step: 9697  | total loss: [1m[32m0.34454[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34454 - acc: 0.8562 -- iter: 1184/3680
[A[ATraining Step: 9698  | total loss: [1m[32m0.33841[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33841 - acc: 0.8644 -- iter: 1216/3680
[A[ATraining Step: 9699  | total loss: [1m[32m0.34201[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34201 - acc: 0.8701 -- iter: 1248/3680
[A[ATraining Step: 9700  | total loss: [1m[32m0.32345[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32345 - acc: 0.8701 | val_loss: 0.28836 - val_acc: 0.8958 -- iter: 1280/3680
[A[ATraining Step: 9700  | total loss: [1m[32m0.32345[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32345 - acc: 0.8701 | val_loss: 0.28836 - val_acc: 0.8958 -- iter: 1280/3680
--
Training Step: 9701  | total loss: [1m[32m0.32856[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32856 - acc: 0.8644 -- iter: 1312/3680
[A[ATraining Step: 9702  | total loss: [1m[32m0.32878[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32878 - acc: 0.8654 -- iter: 1344/3680
[A[ATraining Step: 9703  | total loss: [1m[32m0.32079[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32079 - acc: 0.8695 -- iter: 1376/3680
[A[ATraining Step: 9704  | total loss: [1m[32m0.31038[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31038 - acc: 0.8763 -- iter: 1408/3680
[A[ATraining Step: 9705  | total loss: [1m[32m0.31131[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31131 - acc: 0.8762 -- iter: 1440/3680
[A[ATraining Step: 9706  | total loss: [1m[32m0.30558[0m[0m
[2K| Adam | epoch: 085 | loss: 0.30558 - acc: 0.8792 -- iter: 1472/3680
[A[ATraining Step: 9707  | total loss: [1m[32m0.31325[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31325 - acc: 0.8756 -- iter: 1504/3680
[A[ATraining Step: 9708  | total loss: [1m[32m0.31364[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31364 - acc: 0.8725 -- iter: 1536/3680
[A[ATraining Step: 9709  | total loss: [1m[32m0.31827[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31827 - acc: 0.8729 -- iter: 1568/3680
[A[ATraining Step: 9710  | total loss: [1m[32m0.31470[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31470 - acc: 0.8794 -- iter: 1600/3680
[A[ATraining Step: 9711  | total loss: [1m[32m0.31470[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31470 - acc: 0.8794 -- iter: 1632/3680
[A[ATraining Step: 9712  | total loss: [1m[32m0.32013[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32013 - acc: 0.8696 -- iter: 1664/3680
[A[ATraining Step: 9713  | total loss: [1m[32m0.32779[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32779 - acc: 0.8701 -- iter: 1696/3680
[A[ATraining Step: 9714  | total loss: [1m[32m0.32863[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32863 - acc: 0.8706 -- iter: 1728/3680
[A[ATraining Step: 9715  | total loss: [1m[32m0.33031[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33031 - acc: 0.8679 -- iter: 1760/3680
[A[ATraining Step: 9716  | total loss: [1m[32m0.32696[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32696 - acc: 0.8686 -- iter: 1792/3680
[A[ATraining Step: 9717  | total loss: [1m[32m0.32093[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32093 - acc: 0.8693 -- iter: 1824/3680
[A[ATraining Step: 9718  | total loss: [1m[32m0.33687[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33687 - acc: 0.8636 -- iter: 1856/3680
[A[ATraining Step: 9719  | total loss: [1m[32m0.35043[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35043 - acc: 0.8522 -- iter: 1888/3680
[A[ATraining Step: 9720  | total loss: [1m[32m0.34614[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34614 - acc: 0.8514 -- iter: 1920/3680
[A[ATraining Step: 9721  | total loss: [1m[32m0.32916[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32916 - acc: 0.8593 -- iter: 1952/3680
[A[ATraining Step: 9722  | total loss: [1m[32m0.32916[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32916 - acc: 0.8593 -- iter: 1984/3680
[A[ATraining Step: 9723  | total loss: [1m[32m0.33894[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33894 - acc: 0.8609 -- iter: 2016/3680
[A[ATraining Step: 9724  | total loss: [1m[32m0.33574[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33574 - acc: 0.8592 -- iter: 2048/3680
[A[ATraining Step: 9725  | total loss: [1m[32m0.34826[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34826 - acc: 0.8545 -- iter: 2080/3680
[A[ATraining Step: 9726  | total loss: [1m[32m0.35211[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35211 - acc: 0.8472 -- iter: 2112/3680
[A[ATraining Step: 9727  | total loss: [1m[32m0.36028[0m[0m
[2K| Adam | epoch: 085 | loss: 0.36028 - acc: 0.8437 -- iter: 2144/3680
[A[ATraining Step: 9728  | total loss: [1m[32m0.35119[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35119 - acc: 0.8500 -- iter: 2176/3680
[A[ATraining Step: 9729  | total loss: [1m[32m0.35509[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35509 - acc: 0.8400 -- iter: 2208/3680
[A[ATraining Step: 9730  | total loss: [1m[32m0.34761[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34761 - acc: 0.8400 -- iter: 2240/3680
[A[ATraining Step: 9731  | total loss: [1m[32m0.33978[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33978 - acc: 0.8498 -- iter: 2272/3680
[A[ATraining Step: 9732  | total loss: [1m[32m0.33550[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33550 - acc: 0.8523 -- iter: 2304/3680
[A[ATraining Step: 9733  | total loss: [1m[32m0.33682[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33682 - acc: 0.8546 -- iter: 2336/3680
[A[ATraining Step: 9734  | total loss: [1m[32m0.32451[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32451 - acc: 0.8660 -- iter: 2368/3680
[A[ATraining Step: 9735  | total loss: [1m[32m0.32938[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32938 - acc: 0.8700 -- iter: 2400/3680
[A[ATraining Step: 9736  | total loss: [1m[32m0.34431[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34431 - acc: 0.8705 -- iter: 2432/3680
[A[ATraining Step: 9737  | total loss: [1m[32m0.34124[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34124 - acc: 0.8710 -- iter: 2464/3680
[A[ATraining Step: 9738  | total loss: [1m[32m0.32991[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32991 - acc: 0.8714 -- iter: 2496/3680
[A[ATraining Step: 9739  | total loss: [1m[32m0.33148[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33148 - acc: 0.8717 -- iter: 2528/3680
[A[ATraining Step: 9740  | total loss: [1m[32m0.32871[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32871 - acc: 0.8658 -- iter: 2560/3680
[A[ATraining Step: 9741  | total loss: [1m[32m0.32936[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32936 - acc: 0.8738 -- iter: 2592/3680
[A[ATraining Step: 9742  | total loss: [1m[32m0.32936[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32936 - acc: 0.8738 -- iter: 2624/3680
[A[ATraining Step: 9743  | total loss: [1m[32m0.31777[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31777 - acc: 0.8802 -- iter: 2656/3680
[A[ATraining Step: 9744  | total loss: [1m[32m0.31957[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31957 - acc: 0.8820 -- iter: 2688/3680
[A[ATraining Step: 9745  | total loss: [1m[32m0.32047[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32047 - acc: 0.8820 -- iter: 2720/3680
[A[ATraining Step: 9746  | total loss: [1m[32m0.32598[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32598 - acc: 0.8872 -- iter: 2752/3680
[A[ATraining Step: 9747  | total loss: [1m[32m0.31454[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31454 - acc: 0.8891 -- iter: 2784/3680
[A[ATraining Step: 9748  | total loss: [1m[32m0.31094[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31094 - acc: 0.8908 -- iter: 2816/3680
[A[ATraining Step: 9749  | total loss: [1m[32m0.33279[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33279 - acc: 0.8893 -- iter: 2848/3680
[A[ATraining Step: 9750  | total loss: [1m[32m0.33349[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33349 - acc: 0.8893 -- iter: 2880/3680
[A[ATraining Step: 9751  | total loss: [1m[32m0.32611[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32611 - acc: 0.8941 -- iter: 2912/3680
[A[ATraining Step: 9752  | total loss: [1m[32m0.32796[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32796 - acc: 0.8922 -- iter: 2944/3680
[A[ATraining Step: 9753  | total loss: [1m[32m0.33298[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33298 - acc: 0.8905 -- iter: 2976/3680
[A[ATraining Step: 9754  | total loss: [1m[32m0.31693[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31693 - acc: 0.8983 -- iter: 3008/3680
[A[ATraining Step: 9755  | total loss: [1m[32m0.31417[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31417 - acc: 0.8991 -- iter: 3040/3680
[A[ATraining Step: 9756  | total loss: [1m[32m0.30962[0m[0m
[2K| Adam | epoch: 085 | loss: 0.30962 - acc: 0.8967 -- iter: 3072/3680
[A[ATraining Step: 9757  | total loss: [1m[32m0.32034[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32034 - acc: 0.8851 -- iter: 3104/3680
[A[ATraining Step: 9758  | total loss: [1m[32m0.31173[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31173 - acc: 0.8904 -- iter: 3136/3680
[A[ATraining Step: 9759  | total loss: [1m[32m0.31696[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31696 - acc: 0.8920 -- iter: 3168/3680
[A[ATraining Step: 9760  | total loss: [1m[32m0.30826[0m[0m
[2K| Adam | epoch: 085 | loss: 0.30826 - acc: 0.8965 -- iter: 3200/3680
[A[ATraining Step: 9761  | total loss: [1m[32m0.29738[0m[0m
[2K| Adam | epoch: 085 | loss: 0.29738 - acc: 0.9006 -- iter: 3232/3680
[A[ATraining Step: 9762  | total loss: [1m[32m0.31009[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31009 - acc: 0.8918 -- iter: 3264/3680
[A[ATraining Step: 9763  | total loss: [1m[32m0.31335[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31335 - acc: 0.8870 -- iter: 3296/3680
[A[ATraining Step: 9764  | total loss: [1m[32m0.31753[0m[0m
[2K| Adam | epoch: 085 | loss: 0.31753 - acc: 0.8795 -- iter: 3328/3680
[A[ATraining Step: 9765  | total loss: [1m[32m0.32704[0m[0m
[2K| Adam | epoch: 085 | loss: 0.32704 - acc: 0.8728 -- iter: 3360/3680
[A[ATraining Step: 9766  | total loss: [1m[32m0.35212[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35212 - acc: 0.8574 -- iter: 3392/3680
[A[ATraining Step: 9767  | total loss: [1m[32m0.33803[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33803 - acc: 0.8686 -- iter: 3424/3680
[A[ATraining Step: 9768  | total loss: [1m[32m0.33825[0m[0m
[2K| Adam | epoch: 085 | loss: 0.33825 - acc: 0.8630 -- iter: 3456/3680
[A[ATraining Step: 9769  | total loss: [1m[32m0.34308[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34308 - acc: 0.8579 -- iter: 3488/3680
[A[ATraining Step: 9770  | total loss: [1m[32m0.34689[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34689 - acc: 0.8596 -- iter: 3520/3680
[A[ATraining Step: 9771  | total loss: [1m[32m0.35352[0m[0m
[2K| Adam | epoch: 085 | loss: 0.35352 - acc: 0.8597 -- iter: 3552/3680
[A[ATraining Step: 9772  | total loss: [1m[32m0.34969[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34969 - acc: 0.8597 -- iter: 3584/3680
[A[ATraining Step: 9773  | total loss: [1m[32m0.34908[0m[0m
[2K| Adam | epoch: 085 | loss: 0.34908 - acc: 0.8644 -- iter: 3616/3680
[A[ATraining Step: 9774  | total loss: [1m[32m0.37725[0m[0m
[2K| Adam | epoch: 085 | loss: 0.37725 - acc: 0.8529 -- iter: 3648/3680
[A[ATraining Step: 9775  | total loss: [1m[32m0.37526[0m[0m
[2K| Adam | epoch: 085 | loss: 0.37526 - acc: 0.8520 | val_loss: 0.27947 - val_acc: 0.9055 -- iter: 3680/3680
[A[ATraining Step: 9775  | total loss: [1m[32m0.37526[0m[0m
[2K| Adam | epoch: 085 | loss: 0.37526 - acc: 0.8520 | val_loss: 0.27947 - val_acc: 0.9055 -- iter: 3680/3680
--
Training Step: 9776  | total loss: [1m[32m0.37875[0m[0m
[2K| Adam | epoch: 086 | loss: 0.37875 - acc: 0.8449 -- iter: 0032/3680
[A[ATraining Step: 9777  | total loss: [1m[32m0.36314[0m[0m
[2K| Adam | epoch: 086 | loss: 0.36314 - acc: 0.8511 -- iter: 0064/3680
[A[ATraining Step: 9778  | total loss: [1m[32m0.35277[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35277 - acc: 0.8597 -- iter: 0096/3680
[A[ATraining Step: 9779  | total loss: [1m[32m0.36260[0m[0m
[2K| Adam | epoch: 086 | loss: 0.36260 - acc: 0.8425 -- iter: 0128/3680
[A[ATraining Step: 9780  | total loss: [1m[32m0.35772[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35772 - acc: 0.8457 -- iter: 0160/3680
[A[ATraining Step: 9781  | total loss: [1m[32m0.35759[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35759 - acc: 0.8455 -- iter: 0192/3680
[A[ATraining Step: 9782  | total loss: [1m[32m0.34838[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34838 - acc: 0.8568 -- iter: 0224/3680
[A[ATraining Step: 9783  | total loss: [1m[32m0.34356[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34356 - acc: 0.8568 -- iter: 0256/3680
[A[ATraining Step: 9784  | total loss: [1m[32m0.33354[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33354 - acc: 0.8617 -- iter: 0288/3680
[A[ATraining Step: 9785  | total loss: [1m[32m0.33613[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33613 - acc: 0.8568 -- iter: 0320/3680
[A[ATraining Step: 9786  | total loss: [1m[32m0.33156[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33156 - acc: 0.8586 -- iter: 0352/3680
[A[ATraining Step: 9787  | total loss: [1m[32m0.31789[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31789 - acc: 0.8665 -- iter: 0384/3680
[A[ATraining Step: 9788  | total loss: [1m[32m0.31358[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31358 - acc: 0.8705 -- iter: 0416/3680
[A[ATraining Step: 9789  | total loss: [1m[32m0.32730[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32730 - acc: 0.8616 -- iter: 0448/3680
[A[ATraining Step: 9790  | total loss: [1m[32m0.31984[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31984 - acc: 0.8700 -- iter: 0480/3680
[A[ATraining Step: 9791  | total loss: [1m[32m0.31984[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31984 - acc: 0.8700 -- iter: 0512/3680
[A[ATraining Step: 9792  | total loss: [1m[32m0.32500[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32500 - acc: 0.8705 -- iter: 0544/3680
[A[ATraining Step: 9793  | total loss: [1m[32m0.33918[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33918 - acc: 0.8679 -- iter: 0576/3680
[A[ATraining Step: 9794  | total loss: [1m[32m0.35398[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35398 - acc: 0.8592 -- iter: 0608/3680
[A[ATraining Step: 9795  | total loss: [1m[32m0.35929[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35929 - acc: 0.8577 -- iter: 0640/3680
[A[ATraining Step: 9796  | total loss: [1m[32m0.35147[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35147 - acc: 0.8531 -- iter: 0672/3680
[A[ATraining Step: 9797  | total loss: [1m[32m0.35150[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35150 - acc: 0.8664 -- iter: 0704/3680
[A[ATraining Step: 9798  | total loss: [1m[32m0.33501[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33501 - acc: 0.8664 -- iter: 0736/3680
[A[ATraining Step: 9799  | total loss: [1m[32m0.32794[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32794 - acc: 0.8771 -- iter: 0768/3680
[A[ATraining Step: 9800  | total loss: [1m[32m0.31847[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31847 - acc: 0.8771 | val_loss: 0.28841 - val_acc: 0.8958 -- iter: 0800/3680
[A[ATraining Step: 9800  | total loss: [1m[32m0.31847[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31847 - acc: 0.8771 | val_loss: 0.28841 - val_acc: 0.8958 -- iter: 0800/3680
--
Training Step: 9801  | total loss: [1m[32m0.32082[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32082 - acc: 0.8582 -- iter: 0832/3680
[A[ATraining Step: 9802  | total loss: [1m[32m0.34424[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34424 - acc: 0.8582 -- iter: 0864/3680
[A[ATraining Step: 9803  | total loss: [1m[32m0.34364[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34364 - acc: 0.8599 -- iter: 0896/3680
[A[ATraining Step: 9804  | total loss: [1m[32m0.33240[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33240 - acc: 0.8645 -- iter: 0928/3680
[A[ATraining Step: 9805  | total loss: [1m[32m0.34021[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34021 - acc: 0.8625 -- iter: 0960/3680
[A[ATraining Step: 9806  | total loss: [1m[32m0.33888[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33888 - acc: 0.8637 -- iter: 0992/3680
[A[ATraining Step: 9807  | total loss: [1m[32m0.33927[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33927 - acc: 0.8586 -- iter: 1024/3680
[A[ATraining Step: 9808  | total loss: [1m[32m0.33827[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33827 - acc: 0.8571 -- iter: 1056/3680
[A[ATraining Step: 9809  | total loss: [1m[32m0.33761[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33761 - acc: 0.8455 -- iter: 1088/3680
[A[ATraining Step: 9810  | total loss: [1m[32m0.33761[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33761 - acc: 0.8455 -- iter: 1120/3680
[A[ATraining Step: 9811  | total loss: [1m[32m0.31277[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31277 - acc: 0.8658 -- iter: 1152/3680
[A[ATraining Step: 9812  | total loss: [1m[32m0.31277[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31277 - acc: 0.8761 -- iter: 1184/3680
[A[ATraining Step: 9813  | total loss: [1m[32m0.30554[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30554 - acc: 0.8761 -- iter: 1216/3680
[A[ATraining Step: 9814  | total loss: [1m[32m0.33063[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33063 - acc: 0.8729 -- iter: 1248/3680
[A[ATraining Step: 9815  | total loss: [1m[32m0.32479[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32479 - acc: 0.8762 -- iter: 1280/3680
[A[ATraining Step: 9816  | total loss: [1m[32m0.32545[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32545 - acc: 0.8760 -- iter: 1312/3680
[A[ATraining Step: 9817  | total loss: [1m[32m0.31812[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31812 - acc: 0.8759 -- iter: 1344/3680
[A[ATraining Step: 9818  | total loss: [1m[32m0.31812[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31812 - acc: 0.8759 -- iter: 1376/3680
[A[ATraining Step: 9819  | total loss: [1m[32m0.30058[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30058 - acc: 0.8883 -- iter: 1408/3680
[A[ATraining Step: 9820  | total loss: [1m[32m0.30760[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30760 - acc: 0.8807 -- iter: 1440/3680
[A[ATraining Step: 9821  | total loss: [1m[32m0.31901[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31901 - acc: 0.8801 -- iter: 1472/3680
[A[ATraining Step: 9822  | total loss: [1m[32m0.30864[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30864 - acc: 0.8859 -- iter: 1504/3680
[A[ATraining Step: 9823  | total loss: [1m[32m0.30267[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30267 - acc: 0.8910 -- iter: 1536/3680
[A[ATraining Step: 9824  | total loss: [1m[32m0.29261[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29261 - acc: 0.8894 -- iter: 1568/3680
[A[ATraining Step: 9825  | total loss: [1m[32m0.29013[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29013 - acc: 0.8880 -- iter: 1600/3680
[A[ATraining Step: 9826  | total loss: [1m[32m0.28138[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28138 - acc: 0.8929 -- iter: 1632/3680
[A[ATraining Step: 9827  | total loss: [1m[32m0.27822[0m[0m
[2K| Adam | epoch: 086 | loss: 0.27822 - acc: 0.8943 -- iter: 1664/3680
[A[ATraining Step: 9828  | total loss: [1m[32m0.39233[0m[0m
[2K| Adam | epoch: 086 | loss: 0.39233 - acc: 0.8455 -- iter: 1696/3680
[A[ATraining Step: 9829  | total loss: [1m[32m0.37983[0m[0m
[2K| Adam | epoch: 086 | loss: 0.37983 - acc: 0.8547 -- iter: 1728/3680
[A[ATraining Step: 9830  | total loss: [1m[32m0.37250[0m[0m
[2K| Adam | epoch: 086 | loss: 0.37250 - acc: 0.8567 -- iter: 1760/3680
[A[ATraining Step: 9831  | total loss: [1m[32m0.35699[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35699 - acc: 0.8679 -- iter: 1792/3680
[A[ATraining Step: 9832  | total loss: [1m[32m0.35672[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35672 - acc: 0.8686 -- iter: 1824/3680
[A[ATraining Step: 9833  | total loss: [1m[32m0.35223[0m[0m
[2K| Adam | epoch: 086 | loss: 0.35223 - acc: 0.8724 -- iter: 1856/3680
[A[ATraining Step: 9834  | total loss: [1m[32m0.34882[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34882 - acc: 0.8758 -- iter: 1888/3680
[A[ATraining Step: 9835  | total loss: [1m[32m0.36538[0m[0m
[2K| Adam | epoch: 086 | loss: 0.36538 - acc: 0.8663 -- iter: 1920/3680
[A[ATraining Step: 9836  | total loss: [1m[32m0.34425[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34425 - acc: 0.8766 -- iter: 1952/3680
[A[ATraining Step: 9837  | total loss: [1m[32m0.37909[0m[0m
[2K| Adam | epoch: 086 | loss: 0.37909 - acc: 0.8733 -- iter: 1984/3680
[A[ATraining Step: 9838  | total loss: [1m[32m0.36423[0m[0m
[2K| Adam | epoch: 086 | loss: 0.36423 - acc: 0.8766 -- iter: 2016/3680
[A[ATraining Step: 9839  | total loss: [1m[32m0.36213[0m[0m
[2K| Adam | epoch: 086 | loss: 0.36213 - acc: 0.8733 -- iter: 2048/3680
[A[ATraining Step: 9840  | total loss: [1m[32m0.40110[0m[0m
[2K| Adam | epoch: 086 | loss: 0.40110 - acc: 0.8610 -- iter: 2080/3680
[A[ATraining Step: 9841  | total loss: [1m[32m0.38337[0m[0m
[2K| Adam | epoch: 086 | loss: 0.38337 - acc: 0.8686 -- iter: 2112/3680
[A[ATraining Step: 9842  | total loss: [1m[32m0.37208[0m[0m
[2K| Adam | epoch: 086 | loss: 0.37208 - acc: 0.8724 -- iter: 2144/3680
[A[ATraining Step: 9843  | total loss: [1m[32m0.37900[0m[0m
[2K| Adam | epoch: 086 | loss: 0.37900 - acc: 0.8695 -- iter: 2176/3680
[A[ATraining Step: 9844  | total loss: [1m[32m0.36136[0m[0m
[2K| Adam | epoch: 086 | loss: 0.36136 - acc: 0.8763 -- iter: 2208/3680
[A[ATraining Step: 9845  | total loss: [1m[32m0.34683[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34683 - acc: 0.8824 -- iter: 2240/3680
[A[ATraining Step: 9846  | total loss: [1m[32m0.33564[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33564 - acc: 0.8879 -- iter: 2272/3680
[A[ATraining Step: 9847  | total loss: [1m[32m0.33156[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33156 - acc: 0.8866 -- iter: 2304/3680
[A[ATraining Step: 9848  | total loss: [1m[32m0.34034[0m[0m
[2K| Adam | epoch: 086 | loss: 0.34034 - acc: 0.8792 -- iter: 2336/3680
[A[ATraining Step: 9849  | total loss: [1m[32m0.32282[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32282 - acc: 0.8788 -- iter: 2368/3680
[A[ATraining Step: 9850  | total loss: [1m[32m0.32583[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32583 - acc: 0.8753 -- iter: 2400/3680
[A[ATraining Step: 9851  | total loss: [1m[32m0.32142[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32142 - acc: 0.8721 -- iter: 2432/3680
[A[ATraining Step: 9852  | total loss: [1m[32m0.31224[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31224 - acc: 0.8877 -- iter: 2464/3680
[A[ATraining Step: 9853  | total loss: [1m[32m0.29913[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29913 - acc: 0.8958 -- iter: 2496/3680
[A[ATraining Step: 9854  | total loss: [1m[32m0.29913[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29913 - acc: 0.8958 -- iter: 2528/3680
[A[ATraining Step: 9855  | total loss: [1m[32m0.30783[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30783 - acc: 0.8772 -- iter: 2560/3680
[A[ATraining Step: 9856  | total loss: [1m[32m0.31748[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31748 - acc: 0.8772 -- iter: 2592/3680
[A[ATraining Step: 9857  | total loss: [1m[32m0.31388[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31388 - acc: 0.8738 -- iter: 2624/3680
[A[ATraining Step: 9858  | total loss: [1m[32m0.29271[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29271 - acc: 0.8864 -- iter: 2656/3680
[A[ATraining Step: 9859  | total loss: [1m[32m0.28411[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28411 - acc: 0.8915 -- iter: 2688/3680
[A[ATraining Step: 9860  | total loss: [1m[32m0.28375[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28375 - acc: 0.8930 -- iter: 2720/3680
[A[ATraining Step: 9861  | total loss: [1m[32m0.28236[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28236 - acc: 0.8975 -- iter: 2752/3680
[A[ATraining Step: 9862  | total loss: [1m[32m0.27202[0m[0m
[2K| Adam | epoch: 086 | loss: 0.27202 - acc: 0.9046 -- iter: 2784/3680
[A[ATraining Step: 9863  | total loss: [1m[32m0.26912[0m[0m
[2K| Adam | epoch: 086 | loss: 0.26912 - acc: 0.9016 -- iter: 2816/3680
[A[ATraining Step: 9864  | total loss: [1m[32m0.29973[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29973 - acc: 0.8975 -- iter: 2848/3680
[A[ATraining Step: 9865  | total loss: [1m[32m0.29009[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29009 - acc: 0.9015 -- iter: 2880/3680
[A[ATraining Step: 9866  | total loss: [1m[32m0.29047[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29047 - acc: 0.9015 -- iter: 2912/3680
[A[ATraining Step: 9867  | total loss: [1m[32m0.28367[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28367 - acc: 0.8989 -- iter: 2944/3680
[A[ATraining Step: 9868  | total loss: [1m[32m0.27988[0m[0m
[2K| Adam | epoch: 086 | loss: 0.27988 - acc: 0.8933 -- iter: 2976/3680
[A[ATraining Step: 9869  | total loss: [1m[32m0.28771[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28771 - acc: 0.8978 -- iter: 3008/3680
[A[ATraining Step: 9870  | total loss: [1m[32m0.29506[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29506 - acc: 0.9000 -- iter: 3040/3680
[A[ATraining Step: 9871  | total loss: [1m[32m0.29228[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29228 - acc: 0.9000 -- iter: 3072/3680
[A[ATraining Step: 9872  | total loss: [1m[32m0.28468[0m[0m
[2K| Adam | epoch: 086 | loss: 0.28468 - acc: 0.9009 -- iter: 3104/3680
[A[ATraining Step: 9873  | total loss: [1m[32m0.29811[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29811 - acc: 0.9009 -- iter: 3136/3680
[A[ATraining Step: 9874  | total loss: [1m[32m0.29296[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29296 - acc: 0.9014 -- iter: 3168/3680
[A[ATraining Step: 9875  | total loss: [1m[32m0.30187[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30187 - acc: 0.8898 -- iter: 3200/3680
[A[ATraining Step: 9876  | total loss: [1m[32m0.30187[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30187 - acc: 0.8898 -- iter: 3232/3680
[A[ATraining Step: 9877  | total loss: [1m[32m0.29098[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29098 - acc: 0.8946 -- iter: 3264/3680
[A[ATraining Step: 9878  | total loss: [1m[32m0.29537[0m[0m
[2K| Adam | epoch: 086 | loss: 0.29537 - acc: 0.8824 -- iter: 3296/3680
[A[ATraining Step: 9879  | total loss: [1m[32m0.30781[0m[0m
[2K| Adam | epoch: 086 | loss: 0.30781 - acc: 0.8824 -- iter: 3328/3680
[A[ATraining Step: 9880  | total loss: [1m[32m0.31880[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31880 - acc: 0.8723 -- iter: 3360/3680
[A[ATraining Step: 9881  | total loss: [1m[32m0.33785[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33785 - acc: 0.8570 -- iter: 3392/3680
[A[ATraining Step: 9882  | total loss: [1m[32m0.33424[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33424 - acc: 0.8588 -- iter: 3424/3680
[A[ATraining Step: 9883  | total loss: [1m[32m0.33205[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33205 - acc: 0.8573 -- iter: 3456/3680
[A[ATraining Step: 9884  | total loss: [1m[32m0.33707[0m[0m
[2K| Adam | epoch: 086 | loss: 0.33707 - acc: 0.8497 -- iter: 3488/3680
[A[ATraining Step: 9885  | total loss: [1m[32m0.32508[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32508 - acc: 0.8553 -- iter: 3520/3680
[A[ATraining Step: 9886  | total loss: [1m[32m0.31386[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31386 - acc: 0.8584 -- iter: 3552/3680
[A[ATraining Step: 9887  | total loss: [1m[32m0.32755[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32755 - acc: 0.8663 -- iter: 3584/3680
[A[ATraining Step: 9888  | total loss: [1m[32m0.31288[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31288 - acc: 0.8663 -- iter: 3616/3680
[A[ATraining Step: 9889  | total loss: [1m[32m0.32005[0m[0m
[2K| Adam | epoch: 086 | loss: 0.32005 - acc: 0.8578 -- iter: 3648/3680
[A[ATraining Step: 9890  | total loss: [1m[32m0.31570[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31570 - acc: 0.8595 | val_loss: 0.29169 - val_acc: 0.8871 -- iter: 3680/3680
[A[ATraining Step: 9890  | total loss: [1m[32m0.31570[0m[0m
[2K| Adam | epoch: 086 | loss: 0.31570 - acc: 0.8595 | val_loss: 0.29169 - val_acc: 0.8871 -- iter: 3680/3680
--
Training Step: 9891  | total loss: [1m[32m0.30414[0m[0m
[2K| Adam | epoch: 087 | loss: 0.30414 - acc: 0.8619 -- iter: 0032/3680
[A[ATraining Step: 9892  | total loss: [1m[32m0.32577[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32577 - acc: 0.8619 -- iter: 0064/3680
[A[ATraining Step: 9893  | total loss: [1m[32m0.30992[0m[0m
[2K| Adam | epoch: 087 | loss: 0.30992 - acc: 0.8725 -- iter: 0096/3680
[A[ATraining Step: 9894  | total loss: [1m[32m0.33569[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33569 - acc: 0.8572 -- iter: 0128/3680
[A[ATraining Step: 9895  | total loss: [1m[32m0.33448[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33448 - acc: 0.8558 -- iter: 0160/3680
[A[ATraining Step: 9896  | total loss: [1m[32m0.33721[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33721 - acc: 0.8577 -- iter: 0192/3680
[A[ATraining Step: 9897  | total loss: [1m[32m0.33193[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33193 - acc: 0.8595 -- iter: 0224/3680
[A[ATraining Step: 9898  | total loss: [1m[32m0.34752[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34752 - acc: 0.8548 -- iter: 0256/3680
[A[ATraining Step: 9899  | total loss: [1m[32m0.34011[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34011 - acc: 0.8677 -- iter: 0288/3680
[A[ATraining Step: 9900  | total loss: [1m[32m0.33224[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33224 - acc: 0.8677 | val_loss: 0.29110 - val_acc: 0.8936 -- iter: 0320/3680
[A[ATraining Step: 9900  | total loss: [1m[32m0.33224[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33224 - acc: 0.8677 | val_loss: 0.29110 - val_acc: 0.8936 -- iter: 0320/3680
--
Training Step: 9901  | total loss: [1m[32m0.33895[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33895 - acc: 0.8590 -- iter: 0352/3680
[A[ATraining Step: 9902  | total loss: [1m[32m0.36228[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36228 - acc: 0.8544 -- iter: 0384/3680
[A[ATraining Step: 9903  | total loss: [1m[32m0.36808[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36808 - acc: 0.8502 -- iter: 0416/3680
[A[ATraining Step: 9904  | total loss: [1m[32m0.36354[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36354 - acc: 0.8527 -- iter: 0448/3680
[A[ATraining Step: 9905  | total loss: [1m[32m0.35878[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35878 - acc: 0.8580 -- iter: 0480/3680
[A[ATraining Step: 9906  | total loss: [1m[32m0.34506[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34506 - acc: 0.8629 -- iter: 0512/3680
[A[ATraining Step: 9907  | total loss: [1m[32m0.35183[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35183 - acc: 0.8609 -- iter: 0544/3680
[A[ATraining Step: 9908  | total loss: [1m[32m0.34253[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34253 - acc: 0.8686 -- iter: 0576/3680
[A[ATraining Step: 9909  | total loss: [1m[32m0.33918[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33918 - acc: 0.8692 -- iter: 0608/3680
[A[ATraining Step: 9910  | total loss: [1m[32m0.32152[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32152 - acc: 0.8792 -- iter: 0640/3680
[A[ATraining Step: 9911  | total loss: [1m[32m0.32535[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32535 - acc: 0.8756 -- iter: 0672/3680
[A[ATraining Step: 9912  | total loss: [1m[32m0.31468[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31468 - acc: 0.8783 -- iter: 0704/3680
[A[ATraining Step: 9913  | total loss: [1m[32m0.33144[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33144 - acc: 0.8718 -- iter: 0736/3680
[A[ATraining Step: 9914  | total loss: [1m[32m0.32125[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32125 - acc: 0.8783 -- iter: 0768/3680
[A[ATraining Step: 9915  | total loss: [1m[32m0.32125[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32125 - acc: 0.8783 -- iter: 0800/3680
[A[ATraining Step: 9916  | total loss: [1m[32m0.34209[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34209 - acc: 0.8655 -- iter: 0832/3680
[A[ATraining Step: 9917  | total loss: [1m[32m0.32459[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32459 - acc: 0.8727 -- iter: 0864/3680
[A[ATraining Step: 9918  | total loss: [1m[32m0.31908[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31908 - acc: 0.8761 -- iter: 0896/3680
[A[ATraining Step: 9919  | total loss: [1m[32m0.32734[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32734 - acc: 0.8697 -- iter: 0928/3680
[A[ATraining Step: 9920  | total loss: [1m[32m0.32336[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32336 - acc: 0.8734 -- iter: 0960/3680
[A[ATraining Step: 9921  | total loss: [1m[32m0.32291[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32291 - acc: 0.8735 -- iter: 0992/3680
[A[ATraining Step: 9922  | total loss: [1m[32m0.31830[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31830 - acc: 0.8737 -- iter: 1024/3680
[A[ATraining Step: 9923  | total loss: [1m[32m0.31819[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31819 - acc: 0.8707 -- iter: 1056/3680
[A[ATraining Step: 9924  | total loss: [1m[32m0.31348[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31348 - acc: 0.8774 -- iter: 1088/3680
[A[ATraining Step: 9925  | total loss: [1m[32m0.30525[0m[0m
[2K| Adam | epoch: 087 | loss: 0.30525 - acc: 0.8771 -- iter: 1120/3680
[A[ATraining Step: 9926  | total loss: [1m[32m0.32509[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32509 - acc: 0.8644 -- iter: 1152/3680
[A[ATraining Step: 9927  | total loss: [1m[32m0.31338[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31338 - acc: 0.8717 -- iter: 1184/3680
[A[ATraining Step: 9928  | total loss: [1m[32m0.29465[0m[0m
[2K| Adam | epoch: 087 | loss: 0.29465 - acc: 0.8845 -- iter: 1216/3680
[A[ATraining Step: 9929  | total loss: [1m[32m0.31687[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31687 - acc: 0.8796 -- iter: 1248/3680
[A[ATraining Step: 9930  | total loss: [1m[32m0.30207[0m[0m
[2K| Adam | epoch: 087 | loss: 0.30207 - acc: 0.8916 -- iter: 1280/3680
[A[ATraining Step: 9931  | total loss: [1m[32m0.30207[0m[0m
[2K| Adam | epoch: 087 | loss: 0.30207 - acc: 0.8916 -- iter: 1312/3680
[A[ATraining Step: 9932  | total loss: [1m[32m0.29933[0m[0m
[2K| Adam | epoch: 087 | loss: 0.29933 - acc: 0.8962 -- iter: 1344/3680
[A[ATraining Step: 9933  | total loss: [1m[32m0.29733[0m[0m
[2K| Adam | epoch: 087 | loss: 0.29733 - acc: 0.8972 -- iter: 1376/3680
[A[ATraining Step: 9934  | total loss: [1m[32m0.28571[0m[0m
[2K| Adam | epoch: 087 | loss: 0.28571 - acc: 0.9013 -- iter: 1408/3680
[A[ATraining Step: 9935  | total loss: [1m[32m0.28320[0m[0m
[2K| Adam | epoch: 087 | loss: 0.28320 - acc: 0.9018 -- iter: 1440/3680
[A[ATraining Step: 9936  | total loss: [1m[32m0.27380[0m[0m
[2K| Adam | epoch: 087 | loss: 0.27380 - acc: 0.9085 -- iter: 1472/3680
[A[ATraining Step: 9937  | total loss: [1m[32m0.27798[0m[0m
[2K| Adam | epoch: 087 | loss: 0.27798 - acc: 0.9051 -- iter: 1504/3680
[A[ATraining Step: 9938  | total loss: [1m[32m0.28279[0m[0m
[2K| Adam | epoch: 087 | loss: 0.28279 - acc: 0.8990 -- iter: 1536/3680
[A[ATraining Step: 9939  | total loss: [1m[32m0.29991[0m[0m
[2K| Adam | epoch: 087 | loss: 0.29991 - acc: 0.8903 -- iter: 1568/3680
[A[ATraining Step: 9940  | total loss: [1m[32m0.29791[0m[0m
[2K| Adam | epoch: 087 | loss: 0.29791 - acc: 0.8888 -- iter: 1600/3680
[A[ATraining Step: 9941  | total loss: [1m[32m0.31577[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31577 - acc: 0.8805 -- iter: 1632/3680
[A[ATraining Step: 9942  | total loss: [1m[32m0.31577[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31577 - acc: 0.8805 -- iter: 1664/3680
[A[ATraining Step: 9943  | total loss: [1m[32m0.30487[0m[0m
[2K| Adam | epoch: 087 | loss: 0.30487 - acc: 0.8862 -- iter: 1696/3680
[A[ATraining Step: 9944  | total loss: [1m[32m0.41088[0m[0m
[2K| Adam | epoch: 087 | loss: 0.41088 - acc: 0.8445 -- iter: 1728/3680
[A[ATraining Step: 9945  | total loss: [1m[32m0.39415[0m[0m
[2K| Adam | epoch: 087 | loss: 0.39415 - acc: 0.8507 -- iter: 1760/3680
[A[ATraining Step: 9946  | total loss: [1m[32m0.39288[0m[0m
[2K| Adam | epoch: 087 | loss: 0.39288 - acc: 0.8437 -- iter: 1792/3680
[A[ATraining Step: 9947  | total loss: [1m[32m0.38589[0m[0m
[2K| Adam | epoch: 087 | loss: 0.38589 - acc: 0.8469 -- iter: 1824/3680
[A[ATraining Step: 9948  | total loss: [1m[32m0.37372[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37372 - acc: 0.8528 -- iter: 1856/3680
[A[ATraining Step: 9949  | total loss: [1m[32m0.35488[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35488 - acc: 0.8644 -- iter: 1888/3680
[A[ATraining Step: 9950  | total loss: [1m[32m0.33690[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33690 - acc: 0.8748 -- iter: 1920/3680
[A[ATraining Step: 9951  | total loss: [1m[32m0.33591[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33591 - acc: 0.8745 -- iter: 1952/3680
[A[ATraining Step: 9952  | total loss: [1m[32m0.33574[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33574 - acc: 0.8745 -- iter: 1984/3680
[A[ATraining Step: 9953  | total loss: [1m[32m0.33920[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33920 - acc: 0.8715 -- iter: 2016/3680
[A[ATraining Step: 9954  | total loss: [1m[32m0.33577[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33577 - acc: 0.8718 -- iter: 2048/3680
[A[ATraining Step: 9955  | total loss: [1m[32m0.33457[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33457 - acc: 0.8690 -- iter: 2080/3680
[A[ATraining Step: 9956  | total loss: [1m[32m0.32097[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32097 - acc: 0.8790 -- iter: 2112/3680
[A[ATraining Step: 9957  | total loss: [1m[32m0.31539[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31539 - acc: 0.8817 -- iter: 2144/3680
[A[ATraining Step: 9958  | total loss: [1m[32m0.31932[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31932 - acc: 0.8779 -- iter: 2176/3680
[A[ATraining Step: 9959  | total loss: [1m[32m0.31376[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31376 - acc: 0.8776 -- iter: 2208/3680
[A[ATraining Step: 9960  | total loss: [1m[32m0.31002[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31002 - acc: 0.8742 -- iter: 2240/3680
[A[ATraining Step: 9961  | total loss: [1m[32m0.31004[0m[0m
[2K| Adam | epoch: 087 | loss: 0.31004 - acc: 0.8712 -- iter: 2272/3680
[A[ATraining Step: 9962  | total loss: [1m[32m0.32614[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32614 - acc: 0.8716 -- iter: 2304/3680
[A[ATraining Step: 9963  | total loss: [1m[32m0.32838[0m[0m
[2K| Adam | epoch: 087 | loss: 0.32838 - acc: 0.8750 -- iter: 2336/3680
[A[ATraining Step: 9964  | total loss: [1m[32m0.35279[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35279 - acc: 0.8688 -- iter: 2368/3680
[A[ATraining Step: 9965  | total loss: [1m[32m0.36395[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36395 - acc: 0.8725 -- iter: 2400/3680
[A[ATraining Step: 9966  | total loss: [1m[32m0.34680[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34680 - acc: 0.8790 -- iter: 2432/3680
[A[ATraining Step: 9967  | total loss: [1m[32m0.35902[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35902 - acc: 0.8724 -- iter: 2464/3680
[A[ATraining Step: 9968  | total loss: [1m[32m0.36883[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36883 - acc: 0.8633 -- iter: 2496/3680
[A[ATraining Step: 9969  | total loss: [1m[32m0.37593[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37593 - acc: 0.8519 -- iter: 2528/3680
[A[ATraining Step: 9970  | total loss: [1m[32m0.38059[0m[0m
[2K| Adam | epoch: 087 | loss: 0.38059 - acc: 0.8511 -- iter: 2560/3680
[A[ATraining Step: 9971  | total loss: [1m[32m0.38331[0m[0m
[2K| Adam | epoch: 087 | loss: 0.38331 - acc: 0.8504 -- iter: 2592/3680
[A[ATraining Step: 9972  | total loss: [1m[32m0.41041[0m[0m
[2K| Adam | epoch: 087 | loss: 0.41041 - acc: 0.8341 -- iter: 2624/3680
[A[ATraining Step: 9973  | total loss: [1m[32m0.41128[0m[0m
[2K| Adam | epoch: 087 | loss: 0.41128 - acc: 0.8351 -- iter: 2656/3680
[A[ATraining Step: 9974  | total loss: [1m[32m0.39735[0m[0m
[2K| Adam | epoch: 087 | loss: 0.39735 - acc: 0.8391 -- iter: 2688/3680
[A[ATraining Step: 9975  | total loss: [1m[32m0.38771[0m[0m
[2K| Adam | epoch: 087 | loss: 0.38771 - acc: 0.8458 -- iter: 2720/3680
[A[ATraining Step: 9976  | total loss: [1m[32m0.38185[0m[0m
[2K| Adam | epoch: 087 | loss: 0.38185 - acc: 0.8487 -- iter: 2752/3680
[A[ATraining Step: 9977  | total loss: [1m[32m0.37924[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37924 - acc: 0.8482 -- iter: 2784/3680
[A[ATraining Step: 9978  | total loss: [1m[32m0.38024[0m[0m
[2K| Adam | epoch: 087 | loss: 0.38024 - acc: 0.8446 -- iter: 2816/3680
[A[ATraining Step: 9979  | total loss: [1m[32m0.37809[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37809 - acc: 0.8445 -- iter: 2848/3680
[A[ATraining Step: 9980  | total loss: [1m[32m0.37520[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37520 - acc: 0.8413 -- iter: 2880/3680
[A[ATraining Step: 9981  | total loss: [1m[32m0.36542[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36542 - acc: 0.8447 -- iter: 2912/3680
[A[ATraining Step: 9982  | total loss: [1m[32m0.37594[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37594 - acc: 0.8415 -- iter: 2944/3680
[A[ATraining Step: 9983  | total loss: [1m[32m0.39517[0m[0m
[2K| Adam | epoch: 087 | loss: 0.39517 - acc: 0.8261 -- iter: 2976/3680
[A[ATraining Step: 9984  | total loss: [1m[32m0.40128[0m[0m
[2K| Adam | epoch: 087 | loss: 0.40128 - acc: 0.8329 -- iter: 3008/3680
[A[ATraining Step: 9985  | total loss: [1m[32m0.39055[0m[0m
[2K| Adam | epoch: 087 | loss: 0.39055 - acc: 0.8329 -- iter: 3040/3680
[A[ATraining Step: 9986  | total loss: [1m[32m0.37807[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37807 - acc: 0.8402 -- iter: 3072/3680
[A[ATraining Step: 9987  | total loss: [1m[32m0.36661[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36661 - acc: 0.8468 -- iter: 3104/3680
[A[ATraining Step: 9988  | total loss: [1m[32m0.36330[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36330 - acc: 0.8465 -- iter: 3136/3680
[A[ATraining Step: 9989  | total loss: [1m[32m0.36009[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36009 - acc: 0.8525 -- iter: 3168/3680
[A[ATraining Step: 9990  | total loss: [1m[32m0.36581[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36581 - acc: 0.8391 -- iter: 3200/3680
[A[ATraining Step: 9991  | total loss: [1m[32m0.36153[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36153 - acc: 0.8396 -- iter: 3232/3680
[A[ATraining Step: 9992  | total loss: [1m[32m0.35257[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35257 - acc: 0.8431 -- iter: 3264/3680
[A[ATraining Step: 9993  | total loss: [1m[32m0.35099[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35099 - acc: 0.8401 -- iter: 3296/3680
[A[ATraining Step: 9994  | total loss: [1m[32m0.35632[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35632 - acc: 0.8342 -- iter: 3328/3680
[A[ATraining Step: 9995  | total loss: [1m[32m0.34367[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34367 - acc: 0.8445 -- iter: 3360/3680
[A[ATraining Step: 9996  | total loss: [1m[32m0.33820[0m[0m
[2K| Adam | epoch: 087 | loss: 0.33820 - acc: 0.8497 -- iter: 3392/3680
[A[ATraining Step: 9997  | total loss: [1m[32m0.35516[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35516 - acc: 0.8497 -- iter: 3424/3680
[A[ATraining Step: 9998  | total loss: [1m[32m0.34736[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34736 - acc: 0.8448 -- iter: 3456/3680
[A[ATraining Step: 9999  | total loss: [1m[32m0.35799[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35799 - acc: 0.8448 -- iter: 3488/3680
[A[ATraining Step: 10000  | total loss: [1m[32m0.36349[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36349 - acc: 0.8447 | val_loss: 0.40687 - val_acc: 0.8230 -- iter: 3520/3680
[A[ATraining Step: 10000  | total loss: [1m[32m0.36349[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36349 - acc: 0.8447 | val_loss: 0.40687 - val_acc: 0.8230 -- iter: 3520/3680
--
Training Step: 10001  | total loss: [1m[32m0.37664[0m[0m
[2K| Adam | epoch: 087 | loss: 0.37664 - acc: 0.8321 -- iter: 3552/3680
[A[ATraining Step: 10002  | total loss: [1m[32m0.35276[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35276 - acc: 0.8458 -- iter: 3584/3680
[A[ATraining Step: 10003  | total loss: [1m[32m0.36427[0m[0m
[2K| Adam | epoch: 087 | loss: 0.36427 - acc: 0.8393 -- iter: 3616/3680
[A[ATraining Step: 10004  | total loss: [1m[32m0.35668[0m[0m
[2K| Adam | epoch: 087 | loss: 0.35668 - acc: 0.8429 -- iter: 3648/3680
[A[ATraining Step: 10005  | total loss: [1m[32m0.34502[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34502 - acc: 0.8461 | val_loss: 0.32341 - val_acc: 0.8773 -- iter: 3680/3680
[A[ATraining Step: 10005  | total loss: [1m[32m0.34502[0m[0m
[2K| Adam | epoch: 087 | loss: 0.34502 - acc: 0.8461 | val_loss: 0.32341 - val_acc: 0.8773 -- iter: 3680/3680
--
Training Step: 10006  | total loss: [1m[32m0.34782[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34782 - acc: 0.8427 -- iter: 0032/3680
[A[ATraining Step: 10007  | total loss: [1m[32m0.34898[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34898 - acc: 0.8428 -- iter: 0064/3680
[A[ATraining Step: 10008  | total loss: [1m[32m0.34708[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34708 - acc: 0.8492 -- iter: 0096/3680
[A[ATraining Step: 10009  | total loss: [1m[32m0.33536[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33536 - acc: 0.8549 -- iter: 0128/3680
[A[ATraining Step: 10010  | total loss: [1m[32m0.32898[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32898 - acc: 0.8538 -- iter: 0160/3680
[A[ATraining Step: 10011  | total loss: [1m[32m0.31985[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31985 - acc: 0.8634 -- iter: 0192/3680
[A[ATraining Step: 10012  | total loss: [1m[32m0.31369[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31369 - acc: 0.8634 -- iter: 0224/3680
[A[ATraining Step: 10013  | total loss: [1m[32m0.35057[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35057 - acc: 0.8521 -- iter: 0256/3680
[A[ATraining Step: 10014  | total loss: [1m[32m0.37167[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37167 - acc: 0.8419 -- iter: 0288/3680
[A[ATraining Step: 10015  | total loss: [1m[32m0.37788[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37788 - acc: 0.8304 -- iter: 0320/3680
[A[ATraining Step: 10016  | total loss: [1m[32m0.37788[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37788 - acc: 0.8304 -- iter: 0352/3680
[A[ATraining Step: 10017  | total loss: [1m[32m0.37700[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37700 - acc: 0.8348 -- iter: 0384/3680
[A[ATraining Step: 10018  | total loss: [1m[32m0.37042[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37042 - acc: 0.8326 -- iter: 0416/3680
[A[ATraining Step: 10019  | total loss: [1m[32m0.35897[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35897 - acc: 0.8431 -- iter: 0448/3680
[A[ATraining Step: 10020  | total loss: [1m[32m0.36173[0m[0m
[2K| Adam | epoch: 088 | loss: 0.36173 - acc: 0.8491 -- iter: 0480/3680
[A[ATraining Step: 10021  | total loss: [1m[32m0.35151[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35151 - acc: 0.8491 -- iter: 0512/3680
[A[ATraining Step: 10022  | total loss: [1m[32m0.34786[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34786 - acc: 0.8549 -- iter: 0544/3680
[A[ATraining Step: 10023  | total loss: [1m[32m0.35396[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35396 - acc: 0.8506 -- iter: 0576/3680
[A[ATraining Step: 10024  | total loss: [1m[32m0.36723[0m[0m
[2K| Adam | epoch: 088 | loss: 0.36723 - acc: 0.8499 -- iter: 0608/3680
[A[ATraining Step: 10025  | total loss: [1m[32m0.37818[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37818 - acc: 0.8556 -- iter: 0640/3680
[A[ATraining Step: 10026  | total loss: [1m[32m0.36032[0m[0m
[2K| Adam | epoch: 088 | loss: 0.36032 - acc: 0.8669 -- iter: 0672/3680
[A[ATraining Step: 10027  | total loss: [1m[32m0.34511[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34511 - acc: 0.8739 -- iter: 0704/3680
[A[ATraining Step: 10028  | total loss: [1m[32m0.34209[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34209 - acc: 0.8741 -- iter: 0736/3680
[A[ATraining Step: 10029  | total loss: [1m[32m0.33395[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33395 - acc: 0.8741 -- iter: 0768/3680
[A[ATraining Step: 10030  | total loss: [1m[32m0.34344[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34344 - acc: 0.8652 -- iter: 0800/3680
[A[ATraining Step: 10031  | total loss: [1m[32m0.34344[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34344 - acc: 0.8652 -- iter: 0832/3680
[A[ATraining Step: 10032  | total loss: [1m[32m0.34380[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34380 - acc: 0.8600 -- iter: 0864/3680
[A[ATraining Step: 10033  | total loss: [1m[32m0.32603[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32603 - acc: 0.8708 -- iter: 0896/3680
[A[ATraining Step: 10034  | total loss: [1m[32m0.31061[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31061 - acc: 0.8806 -- iter: 0928/3680
[A[ATraining Step: 10035  | total loss: [1m[32m0.30505[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30505 - acc: 0.8832 -- iter: 0960/3680
[A[ATraining Step: 10036  | total loss: [1m[32m0.30066[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30066 - acc: 0.8824 -- iter: 0992/3680
[A[ATraining Step: 10037  | total loss: [1m[32m0.31750[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31750 - acc: 0.8691 -- iter: 1024/3680
[A[ATraining Step: 10038  | total loss: [1m[32m0.30354[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30354 - acc: 0.8760 -- iter: 1056/3680
[A[ATraining Step: 10039  | total loss: [1m[32m0.32283[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32283 - acc: 0.8642 -- iter: 1088/3680
[A[ATraining Step: 10040  | total loss: [1m[32m0.32921[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32921 - acc: 0.8642 -- iter: 1120/3680
[A[ATraining Step: 10041  | total loss: [1m[32m0.32185[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32185 - acc: 0.8653 -- iter: 1152/3680
[A[ATraining Step: 10042  | total loss: [1m[32m0.32858[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32858 - acc: 0.8632 -- iter: 1184/3680
[A[ATraining Step: 10043  | total loss: [1m[32m0.32415[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32415 - acc: 0.8675 -- iter: 1216/3680
[A[ATraining Step: 10044  | total loss: [1m[32m0.32777[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32777 - acc: 0.8682 -- iter: 1248/3680
[A[ATraining Step: 10045  | total loss: [1m[32m0.33134[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33134 - acc: 0.8673 -- iter: 1280/3680
[A[ATraining Step: 10046  | total loss: [1m[32m0.33134[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33134 - acc: 0.8673 -- iter: 1312/3680
[A[ATraining Step: 10047  | total loss: [1m[32m0.31904[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31904 - acc: 0.8743 -- iter: 1344/3680
[A[ATraining Step: 10048  | total loss: [1m[32m0.31063[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31063 - acc: 0.8807 -- iter: 1376/3680
[A[ATraining Step: 10049  | total loss: [1m[32m0.31941[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31941 - acc: 0.8801 -- iter: 1408/3680
[A[ATraining Step: 10050  | total loss: [1m[32m0.31321[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31321 - acc: 0.8827 -- iter: 1440/3680
[A[ATraining Step: 10051  | total loss: [1m[32m0.32376[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32376 - acc: 0.8757 -- iter: 1472/3680
[A[ATraining Step: 10052  | total loss: [1m[32m0.34716[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34716 - acc: 0.8694 -- iter: 1504/3680
[A[ATraining Step: 10053  | total loss: [1m[32m0.34180[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34180 - acc: 0.8637 -- iter: 1536/3680
[A[ATraining Step: 10054  | total loss: [1m[32m0.35529[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35529 - acc: 0.8523 -- iter: 1568/3680
[A[ATraining Step: 10055  | total loss: [1m[32m0.33907[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33907 - acc: 0.8640 -- iter: 1600/3680
[A[ATraining Step: 10056  | total loss: [1m[32m0.32674[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32674 - acc: 0.8744 -- iter: 1632/3680
[A[ATraining Step: 10057  | total loss: [1m[32m0.32115[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32115 - acc: 0.8776 -- iter: 1664/3680
[A[ATraining Step: 10058  | total loss: [1m[32m0.31535[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31535 - acc: 0.8805 -- iter: 1696/3680
[A[ATraining Step: 10059  | total loss: [1m[32m0.34391[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34391 - acc: 0.8643 -- iter: 1728/3680
[A[ATraining Step: 10060  | total loss: [1m[32m0.45188[0m[0m
[2K| Adam | epoch: 088 | loss: 0.45188 - acc: 0.8279 -- iter: 1760/3680
[A[ATraining Step: 10061  | total loss: [1m[32m0.42323[0m[0m
[2K| Adam | epoch: 088 | loss: 0.42323 - acc: 0.8340 -- iter: 1792/3680
[A[ATraining Step: 10062  | total loss: [1m[32m0.42323[0m[0m
[2K| Adam | epoch: 088 | loss: 0.42323 - acc: 0.8340 -- iter: 1824/3680
[A[ATraining Step: 10063  | total loss: [1m[32m0.42259[0m[0m
[2K| Adam | epoch: 088 | loss: 0.42259 - acc: 0.8287 -- iter: 1856/3680
[A[ATraining Step: 10064  | total loss: [1m[32m0.40582[0m[0m
[2K| Adam | epoch: 088 | loss: 0.40582 - acc: 0.8302 -- iter: 1888/3680
[A[ATraining Step: 10065  | total loss: [1m[32m0.42189[0m[0m
[2K| Adam | epoch: 088 | loss: 0.42189 - acc: 0.8316 -- iter: 1920/3680
[A[ATraining Step: 10066  | total loss: [1m[32m0.41151[0m[0m
[2K| Adam | epoch: 088 | loss: 0.41151 - acc: 0.8273 -- iter: 1952/3680
[A[ATraining Step: 10067  | total loss: [1m[32m0.41151[0m[0m
[2K| Adam | epoch: 088 | loss: 0.41151 - acc: 0.8273 -- iter: 1984/3680
[A[ATraining Step: 10068  | total loss: [1m[32m0.40476[0m[0m
[2K| Adam | epoch: 088 | loss: 0.40476 - acc: 0.8352 -- iter: 2016/3680
[A[ATraining Step: 10069  | total loss: [1m[32m0.40578[0m[0m
[2K| Adam | epoch: 088 | loss: 0.40578 - acc: 0.8392 -- iter: 2048/3680
[A[ATraining Step: 10070  | total loss: [1m[32m0.40564[0m[0m
[2K| Adam | epoch: 088 | loss: 0.40564 - acc: 0.8397 -- iter: 2080/3680
[A[ATraining Step: 10071  | total loss: [1m[32m0.40152[0m[0m
[2K| Adam | epoch: 088 | loss: 0.40152 - acc: 0.8369 -- iter: 2112/3680
[A[ATraining Step: 10072  | total loss: [1m[32m0.37118[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37118 - acc: 0.8501 -- iter: 2144/3680
[A[ATraining Step: 10073  | total loss: [1m[32m0.37118[0m[0m
[2K| Adam | epoch: 088 | loss: 0.37118 - acc: 0.8501 -- iter: 2176/3680
[A[ATraining Step: 10074  | total loss: [1m[32m0.36142[0m[0m
[2K| Adam | epoch: 088 | loss: 0.36142 - acc: 0.8526 -- iter: 2208/3680
[A[ATraining Step: 10075  | total loss: [1m[32m0.35392[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35392 - acc: 0.8580 -- iter: 2240/3680
[A[ATraining Step: 10076  | total loss: [1m[32m0.34549[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34549 - acc: 0.8628 -- iter: 2272/3680
[A[ATraining Step: 10077  | total loss: [1m[32m0.34145[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34145 - acc: 0.8671 -- iter: 2304/3680
[A[ATraining Step: 10078  | total loss: [1m[32m0.33303[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33303 - acc: 0.8711 -- iter: 2336/3680
[A[ATraining Step: 10079  | total loss: [1m[32m0.34202[0m[0m
[2K| Adam | epoch: 088 | loss: 0.34202 - acc: 0.8652 -- iter: 2368/3680
[A[ATraining Step: 10080  | total loss: [1m[32m0.33340[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33340 - acc: 0.8693 -- iter: 2400/3680
[A[ATraining Step: 10081  | total loss: [1m[32m0.33323[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33323 - acc: 0.8766 -- iter: 2432/3680
[A[ATraining Step: 10082  | total loss: [1m[32m0.32065[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32065 - acc: 0.8766 -- iter: 2464/3680
[A[ATraining Step: 10083  | total loss: [1m[32m0.31691[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31691 - acc: 0.8733 -- iter: 2496/3680
[A[ATraining Step: 10084  | total loss: [1m[32m0.33841[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33841 - acc: 0.8610 -- iter: 2528/3680
[A[ATraining Step: 10085  | total loss: [1m[32m0.33239[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33239 - acc: 0.8624 -- iter: 2560/3680
[A[ATraining Step: 10086  | total loss: [1m[32m0.32665[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32665 - acc: 0.8699 -- iter: 2592/3680
[A[ATraining Step: 10087  | total loss: [1m[32m0.32970[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32970 - acc: 0.8673 -- iter: 2624/3680
[A[ATraining Step: 10088  | total loss: [1m[32m0.31393[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31393 - acc: 0.8774 -- iter: 2656/3680
[A[ATraining Step: 10089  | total loss: [1m[32m0.30912[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30912 - acc: 0.8803 -- iter: 2688/3680
[A[ATraining Step: 10090  | total loss: [1m[32m0.33209[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33209 - acc: 0.8642 -- iter: 2720/3680
[A[ATraining Step: 10091  | total loss: [1m[32m0.32864[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32864 - acc: 0.8653 -- iter: 2752/3680
[A[ATraining Step: 10092  | total loss: [1m[32m0.31115[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31115 - acc: 0.8725 -- iter: 2784/3680
[A[ATraining Step: 10093  | total loss: [1m[32m0.30003[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30003 - acc: 0.8790 -- iter: 2816/3680
[A[ATraining Step: 10094  | total loss: [1m[32m0.29093[0m[0m
[2K| Adam | epoch: 088 | loss: 0.29093 - acc: 0.8817 -- iter: 2848/3680
[A[ATraining Step: 10095  | total loss: [1m[32m0.29251[0m[0m
[2K| Adam | epoch: 088 | loss: 0.29251 - acc: 0.8810 -- iter: 2880/3680
[A[ATraining Step: 10096  | total loss: [1m[32m0.28298[0m[0m
[2K| Adam | epoch: 088 | loss: 0.28298 - acc: 0.8761 -- iter: 2912/3680
[A[ATraining Step: 10097  | total loss: [1m[32m0.30965[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30965 - acc: 0.8761 -- iter: 2944/3680
[A[ATraining Step: 10098  | total loss: [1m[32m0.30133[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30133 - acc: 0.8823 -- iter: 2976/3680
[A[ATraining Step: 10099  | total loss: [1m[32m0.30742[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30742 - acc: 0.8784 -- iter: 3008/3680
[A[ATraining Step: 10100  | total loss: [1m[32m0.31997[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31997 - acc: 0.8750 | val_loss: 0.28741 - val_acc: 0.8903 -- iter: 3040/3680
[A[ATraining Step: 10100  | total loss: [1m[32m0.31997[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31997 - acc: 0.8750 | val_loss: 0.28741 - val_acc: 0.8903 -- iter: 3040/3680
--
Training Step: 10101  | total loss: [1m[32m0.30762[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30762 - acc: 0.8750 -- iter: 3072/3680
[A[ATraining Step: 10102  | total loss: [1m[32m0.32400[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32400 - acc: 0.8687 -- iter: 3104/3680
[A[ATraining Step: 10103  | total loss: [1m[32m0.31381[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31381 - acc: 0.8756 -- iter: 3136/3680
[A[ATraining Step: 10104  | total loss: [1m[32m0.30997[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30997 - acc: 0.8755 -- iter: 3168/3680
[A[ATraining Step: 10105  | total loss: [1m[32m0.30900[0m[0m
[2K| Adam | epoch: 088 | loss: 0.30900 - acc: 0.8755 -- iter: 3200/3680
[A[ATraining Step: 10106  | total loss: [1m[32m0.31563[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31563 - acc: 0.8754 -- iter: 3232/3680
[A[ATraining Step: 10107  | total loss: [1m[32m0.31421[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31421 - acc: 0.8723 -- iter: 3264/3680
[A[ATraining Step: 10108  | total loss: [1m[32m0.33258[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33258 - acc: 0.8600 -- iter: 3296/3680
[A[ATraining Step: 10109  | total loss: [1m[32m0.32911[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32911 - acc: 0.8615 -- iter: 3328/3680
[A[ATraining Step: 10110  | total loss: [1m[32m0.32871[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32871 - acc: 0.8457 -- iter: 3360/3680
[A[ATraining Step: 10111  | total loss: [1m[32m0.33844[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33844 - acc: 0.8423 -- iter: 3392/3680
[A[ATraining Step: 10112  | total loss: [1m[32m0.33844[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33844 - acc: 0.8423 -- iter: 3424/3680
[A[ATraining Step: 10113  | total loss: [1m[32m0.33587[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33587 - acc: 0.8487 -- iter: 3456/3680
[A[ATraining Step: 10114  | total loss: [1m[32m0.32228[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32228 - acc: 0.8576 -- iter: 3488/3680
[A[ATraining Step: 10115  | total loss: [1m[32m0.31334[0m[0m
[2K| Adam | epoch: 088 | loss: 0.31334 - acc: 0.8625 -- iter: 3520/3680
[A[ATraining Step: 10116  | total loss: [1m[32m0.32113[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32113 - acc: 0.8606 -- iter: 3552/3680
[A[ATraining Step: 10117  | total loss: [1m[32m0.32137[0m[0m
[2K| Adam | epoch: 088 | loss: 0.32137 - acc: 0.8620 -- iter: 3584/3680
[A[ATraining Step: 10118  | total loss: [1m[32m0.33217[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33217 - acc: 0.8540 -- iter: 3616/3680
[A[ATraining Step: 10119  | total loss: [1m[32m0.33431[0m[0m
[2K| Adam | epoch: 088 | loss: 0.33431 - acc: 0.8561 -- iter: 3648/3680
[A[ATraining Step: 10120  | total loss: [1m[32m0.35185[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35185 - acc: 0.8611 | val_loss: 0.32073 - val_acc: 0.8740 -- iter: 3680/3680
[A[ATraining Step: 10120  | total loss: [1m[32m0.35185[0m[0m
[2K| Adam | epoch: 088 | loss: 0.35185 - acc: 0.8611 | val_loss: 0.32073 - val_acc: 0.8740 -- iter: 3680/3680
--
Training Step: 10121  | total loss: [1m[32m0.34177[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34177 - acc: 0.8625 -- iter: 0032/3680
[A[ATraining Step: 10122  | total loss: [1m[32m0.32332[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32332 - acc: 0.8762 -- iter: 0064/3680
[A[ATraining Step: 10123  | total loss: [1m[32m0.32444[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32444 - acc: 0.8761 -- iter: 0096/3680
[A[ATraining Step: 10124  | total loss: [1m[32m0.31850[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31850 - acc: 0.8760 -- iter: 0128/3680
[A[ATraining Step: 10125  | total loss: [1m[32m0.30616[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30616 - acc: 0.8790 -- iter: 0160/3680
[A[ATraining Step: 10126  | total loss: [1m[32m0.29622[0m[0m
[2K| Adam | epoch: 089 | loss: 0.29622 - acc: 0.8849 -- iter: 0192/3680
[A[ATraining Step: 10127  | total loss: [1m[32m0.28294[0m[0m
[2K| Adam | epoch: 089 | loss: 0.28294 - acc: 0.8933 -- iter: 0224/3680
[A[ATraining Step: 10128  | total loss: [1m[32m0.27568[0m[0m
[2K| Adam | epoch: 089 | loss: 0.27568 - acc: 0.8977 -- iter: 0256/3680
[A[ATraining Step: 10129  | total loss: [1m[32m0.26265[0m[0m
[2K| Adam | epoch: 089 | loss: 0.26265 - acc: 0.9017 -- iter: 0288/3680
[A[ATraining Step: 10130  | total loss: [1m[32m0.27490[0m[0m
[2K| Adam | epoch: 089 | loss: 0.27490 - acc: 0.8959 -- iter: 0320/3680
[A[ATraining Step: 10131  | total loss: [1m[32m0.28344[0m[0m
[2K| Adam | epoch: 089 | loss: 0.28344 - acc: 0.8938 -- iter: 0352/3680
[A[ATraining Step: 10132  | total loss: [1m[32m0.28954[0m[0m
[2K| Adam | epoch: 089 | loss: 0.28954 - acc: 0.8888 -- iter: 0384/3680
[A[ATraining Step: 10133  | total loss: [1m[32m0.27244[0m[0m
[2K| Adam | epoch: 089 | loss: 0.27244 - acc: 0.8946 -- iter: 0416/3680
[A[ATraining Step: 10134  | total loss: [1m[32m0.27096[0m[0m
[2K| Adam | epoch: 089 | loss: 0.27096 - acc: 0.8946 -- iter: 0448/3680
[A[ATraining Step: 10135  | total loss: [1m[32m0.29627[0m[0m
[2K| Adam | epoch: 089 | loss: 0.29627 - acc: 0.8770 -- iter: 0480/3680
[A[ATraining Step: 10136  | total loss: [1m[32m0.29490[0m[0m
[2K| Adam | epoch: 089 | loss: 0.29490 - acc: 0.8799 -- iter: 0512/3680
[A[ATraining Step: 10137  | total loss: [1m[32m0.30123[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30123 - acc: 0.8759 -- iter: 0544/3680
[A[ATraining Step: 10138  | total loss: [1m[32m0.30932[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30932 - acc: 0.8759 -- iter: 0576/3680
[A[ATraining Step: 10139  | total loss: [1m[32m0.31793[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31793 - acc: 0.8758 -- iter: 0608/3680
[A[ATraining Step: 10140  | total loss: [1m[32m0.32878[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32878 - acc: 0.8757 -- iter: 0640/3680
[A[ATraining Step: 10141  | total loss: [1m[32m0.33125[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33125 - acc: 0.8725 -- iter: 0672/3680
[A[ATraining Step: 10142  | total loss: [1m[32m0.33729[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33729 - acc: 0.8665 -- iter: 0704/3680
[A[ATraining Step: 10143  | total loss: [1m[32m0.33004[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33004 - acc: 0.8705 -- iter: 0736/3680
[A[ATraining Step: 10144  | total loss: [1m[32m0.32061[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32061 - acc: 0.8745 -- iter: 0768/3680
[A[ATraining Step: 10145  | total loss: [1m[32m0.32061[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32061 - acc: 0.8745 -- iter: 0800/3680
[A[ATraining Step: 10146  | total loss: [1m[32m0.31663[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31663 - acc: 0.8776 -- iter: 0832/3680
[A[ATraining Step: 10147  | total loss: [1m[32m0.33155[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33155 - acc: 0.8743 -- iter: 0864/3680
[A[ATraining Step: 10148  | total loss: [1m[32m0.31883[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31883 - acc: 0.8806 -- iter: 0896/3680
[A[ATraining Step: 10149  | total loss: [1m[32m0.30469[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30469 - acc: 0.8863 -- iter: 0928/3680
[A[ATraining Step: 10150  | total loss: [1m[32m0.29746[0m[0m
[2K| Adam | epoch: 089 | loss: 0.29746 - acc: 0.8901 -- iter: 0960/3680
[A[ATraining Step: 10151  | total loss: [1m[32m0.29746[0m[0m
[2K| Adam | epoch: 089 | loss: 0.29746 - acc: 0.8901 -- iter: 0992/3680
[A[ATraining Step: 10152  | total loss: [1m[32m0.31304[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31304 - acc: 0.8823 -- iter: 1024/3680
[A[ATraining Step: 10153  | total loss: [1m[32m0.31053[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31053 - acc: 0.8900 -- iter: 1056/3680
[A[ATraining Step: 10154  | total loss: [1m[32m0.30549[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30549 - acc: 0.8900 -- iter: 1088/3680
[A[ATraining Step: 10155  | total loss: [1m[32m0.30726[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30726 - acc: 0.8885 -- iter: 1120/3680
[A[ATraining Step: 10156  | total loss: [1m[32m0.31053[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31053 - acc: 0.8903 -- iter: 1152/3680
[A[ATraining Step: 10157  | total loss: [1m[32m0.31196[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31196 - acc: 0.8887 -- iter: 1184/3680
[A[ATraining Step: 10158  | total loss: [1m[32m0.31215[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31215 - acc: 0.8874 -- iter: 1216/3680
[A[ATraining Step: 10159  | total loss: [1m[32m0.31838[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31838 - acc: 0.8830 -- iter: 1248/3680
[A[ATraining Step: 10160  | total loss: [1m[32m0.30885[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30885 - acc: 0.8853 -- iter: 1280/3680
[A[ATraining Step: 10161  | total loss: [1m[32m0.31190[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31190 - acc: 0.8843 -- iter: 1312/3680
[A[ATraining Step: 10162  | total loss: [1m[32m0.30835[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30835 - acc: 0.8896 -- iter: 1344/3680
[A[ATraining Step: 10163  | total loss: [1m[32m0.33119[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33119 - acc: 0.8788 -- iter: 1376/3680
[A[ATraining Step: 10164  | total loss: [1m[32m0.34238[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34238 - acc: 0.8753 -- iter: 1408/3680
[A[ATraining Step: 10165  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34347 - acc: 0.8690 -- iter: 1440/3680
[A[ATraining Step: 10166  | total loss: [1m[32m0.34347[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34347 - acc: 0.8690 -- iter: 1472/3680
[A[ATraining Step: 10167  | total loss: [1m[32m0.34863[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34863 - acc: 0.8696 -- iter: 1504/3680
[A[ATraining Step: 10168  | total loss: [1m[32m0.34010[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34010 - acc: 0.8764 -- iter: 1536/3680
[A[ATraining Step: 10169  | total loss: [1m[32m0.34805[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34805 - acc: 0.8700 -- iter: 1568/3680
[A[ATraining Step: 10170  | total loss: [1m[32m0.35740[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35740 - acc: 0.8549 -- iter: 1600/3680
[A[ATraining Step: 10171  | total loss: [1m[32m0.34868[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34868 - acc: 0.8569 -- iter: 1632/3680
[A[ATraining Step: 10172  | total loss: [1m[32m0.35591[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35591 - acc: 0.8524 -- iter: 1664/3680
[A[ATraining Step: 10173  | total loss: [1m[32m0.35808[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35808 - acc: 0.8547 -- iter: 1696/3680
[A[ATraining Step: 10174  | total loss: [1m[32m0.35669[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35669 - acc: 0.8567 -- iter: 1728/3680
[A[ATraining Step: 10175  | total loss: [1m[32m0.34972[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34972 - acc: 0.8571 -- iter: 1760/3680
[A[ATraining Step: 10176  | total loss: [1m[32m0.34230[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34230 - acc: 0.8571 -- iter: 1792/3680
[A[ATraining Step: 10177  | total loss: [1m[32m0.35023[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35023 - acc: 0.8526 -- iter: 1824/3680
[A[ATraining Step: 10178  | total loss: [1m[32m0.36828[0m[0m
[2K| Adam | epoch: 089 | loss: 0.36828 - acc: 0.8361 -- iter: 1856/3680
[A[ATraining Step: 10179  | total loss: [1m[32m0.36801[0m[0m
[2K| Adam | epoch: 089 | loss: 0.36801 - acc: 0.8431 -- iter: 1888/3680
[A[ATraining Step: 10180  | total loss: [1m[32m0.36824[0m[0m
[2K| Adam | epoch: 089 | loss: 0.36824 - acc: 0.8463 -- iter: 1920/3680
[A[ATraining Step: 10181  | total loss: [1m[32m0.35738[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35738 - acc: 0.8523 -- iter: 1952/3680
[A[ATraining Step: 10182  | total loss: [1m[32m0.35753[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35753 - acc: 0.8483 -- iter: 1984/3680
[A[ATraining Step: 10183  | total loss: [1m[32m0.36171[0m[0m
[2K| Adam | epoch: 089 | loss: 0.36171 - acc: 0.8416 -- iter: 2016/3680
[A[ATraining Step: 10184  | total loss: [1m[32m0.34831[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34831 - acc: 0.8512 -- iter: 2048/3680
[A[ATraining Step: 10185  | total loss: [1m[32m0.34850[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34850 - acc: 0.8567 -- iter: 2080/3680
[A[ATraining Step: 10186  | total loss: [1m[32m0.33950[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33950 - acc: 0.8599 -- iter: 2112/3680
[A[ATraining Step: 10187  | total loss: [1m[32m0.33950[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33950 - acc: 0.8599 -- iter: 2144/3680
[A[ATraining Step: 10188  | total loss: [1m[32m0.32858[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32858 - acc: 0.8676 -- iter: 2176/3680
[A[ATraining Step: 10189  | total loss: [1m[32m0.32367[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32367 - acc: 0.8684 -- iter: 2208/3680
[A[ATraining Step: 10190  | total loss: [1m[32m0.32733[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32733 - acc: 0.8690 -- iter: 2240/3680
[A[ATraining Step: 10191  | total loss: [1m[32m0.31872[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31872 - acc: 0.8759 -- iter: 2272/3680
[A[ATraining Step: 10192  | total loss: [1m[32m0.32879[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32879 - acc: 0.8695 -- iter: 2304/3680
[A[ATraining Step: 10193  | total loss: [1m[32m0.33128[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33128 - acc: 0.8670 -- iter: 2336/3680
[A[ATraining Step: 10194  | total loss: [1m[32m0.31974[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31974 - acc: 0.8740 -- iter: 2368/3680
[A[ATraining Step: 10195  | total loss: [1m[32m0.30528[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30528 - acc: 0.8835 -- iter: 2400/3680
[A[ATraining Step: 10196  | total loss: [1m[32m0.33813[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33813 - acc: 0.8670 -- iter: 2432/3680
[A[ATraining Step: 10197  | total loss: [1m[32m0.35249[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35249 - acc: 0.8678 -- iter: 2464/3680
[A[ATraining Step: 10198  | total loss: [1m[32m0.35321[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35321 - acc: 0.8717 -- iter: 2496/3680
[A[ATraining Step: 10199  | total loss: [1m[32m0.35884[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35884 - acc: 0.8732 -- iter: 2528/3680
[A[ATraining Step: 10200  | total loss: [1m[32m0.34435[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34435 - acc: 0.8732 | val_loss: 0.32125 - val_acc: 0.8751 -- iter: 2560/3680
[A[ATraining Step: 10200  | total loss: [1m[32m0.34435[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34435 - acc: 0.8732 | val_loss: 0.32125 - val_acc: 0.8751 -- iter: 2560/3680
--
Training Step: 10201  | total loss: [1m[32m0.34752[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34752 - acc: 0.8703 -- iter: 2592/3680
[A[ATraining Step: 10202  | total loss: [1m[32m0.35058[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35058 - acc: 0.8614 -- iter: 2624/3680
[A[ATraining Step: 10203  | total loss: [1m[32m0.35553[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35553 - acc: 0.8534 -- iter: 2656/3680
[A[ATraining Step: 10204  | total loss: [1m[32m0.34251[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34251 - acc: 0.8587 -- iter: 2688/3680
[A[ATraining Step: 10205  | total loss: [1m[32m0.33738[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33738 - acc: 0.8572 -- iter: 2720/3680
[A[ATraining Step: 10206  | total loss: [1m[32m0.33316[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33316 - acc: 0.8558 -- iter: 2752/3680
[A[ATraining Step: 10207  | total loss: [1m[32m0.33199[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33199 - acc: 0.8577 -- iter: 2784/3680
[A[ATraining Step: 10208  | total loss: [1m[32m0.30634[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30634 - acc: 0.8729 -- iter: 2816/3680
[A[ATraining Step: 10209  | total loss: [1m[32m0.30634[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30634 - acc: 0.8729 -- iter: 2848/3680
[A[ATraining Step: 10210  | total loss: [1m[32m0.30179[0m[0m
[2K| Adam | epoch: 089 | loss: 0.30179 - acc: 0.8731 -- iter: 2880/3680
[A[ATraining Step: 10211  | total loss: [1m[32m0.31785[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31785 - acc: 0.8608 -- iter: 2912/3680
[A[ATraining Step: 10212  | total loss: [1m[32m0.32304[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32304 - acc: 0.8560 -- iter: 2944/3680
[A[ATraining Step: 10213  | total loss: [1m[32m0.32586[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32586 - acc: 0.8610 -- iter: 2976/3680
[A[ATraining Step: 10214  | total loss: [1m[32m0.32667[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32667 - acc: 0.8577 -- iter: 3008/3680
[A[ATraining Step: 10215  | total loss: [1m[32m0.33413[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33413 - acc: 0.8577 -- iter: 3040/3680
[A[ATraining Step: 10216  | total loss: [1m[32m0.31636[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31636 - acc: 0.8657 -- iter: 3072/3680
[A[ATraining Step: 10217  | total loss: [1m[32m0.32841[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32841 - acc: 0.8604 -- iter: 3104/3680
[A[ATraining Step: 10218  | total loss: [1m[32m0.33423[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33423 - acc: 0.8587 -- iter: 3136/3680
[A[ATraining Step: 10219  | total loss: [1m[32m0.32511[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32511 - acc: 0.8666 -- iter: 3168/3680
[A[ATraining Step: 10220  | total loss: [1m[32m0.31765[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31765 - acc: 0.8706 -- iter: 3200/3680
[A[ATraining Step: 10221  | total loss: [1m[32m0.33226[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33226 - acc: 0.8710 -- iter: 3232/3680
[A[ATraining Step: 10222  | total loss: [1m[32m0.31966[0m[0m
[2K| Adam | epoch: 089 | loss: 0.31966 - acc: 0.8777 -- iter: 3264/3680
[A[ATraining Step: 10223  | total loss: [1m[32m0.32847[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32847 - acc: 0.8715 -- iter: 3296/3680
[A[ATraining Step: 10224  | total loss: [1m[32m0.32100[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32100 - acc: 0.8812 -- iter: 3328/3680
[A[ATraining Step: 10225  | total loss: [1m[32m0.32100[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32100 - acc: 0.8812 -- iter: 3360/3680
[A[ATraining Step: 10226  | total loss: [1m[32m0.32514[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32514 - acc: 0.8775 -- iter: 3392/3680
[A[ATraining Step: 10227  | total loss: [1m[32m0.32702[0m[0m
[2K| Adam | epoch: 089 | loss: 0.32702 - acc: 0.8741 -- iter: 3424/3680
[A[ATraining Step: 10228  | total loss: [1m[32m0.35677[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35677 - acc: 0.8648 -- iter: 3456/3680
[A[ATraining Step: 10229  | total loss: [1m[32m0.35194[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35194 - acc: 0.8659 -- iter: 3488/3680
[A[ATraining Step: 10230  | total loss: [1m[32m0.35729[0m[0m
[2K| Adam | epoch: 089 | loss: 0.35729 - acc: 0.8574 -- iter: 3520/3680
[A[ATraining Step: 10231  | total loss: [1m[32m0.34357[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34357 - acc: 0.8623 -- iter: 3552/3680
[A[ATraining Step: 10232  | total loss: [1m[32m0.33811[0m[0m
[2K| Adam | epoch: 089 | loss: 0.33811 - acc: 0.8573 -- iter: 3584/3680
[A[ATraining Step: 10233  | total loss: [1m[32m0.34916[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34916 - acc: 0.8488 -- iter: 3616/3680
[A[ATraining Step: 10234  | total loss: [1m[32m0.34916[0m[0m
[2K| Adam | epoch: 089 | loss: 0.34916 - acc: 0.8488 -- iter: 3648/3680
[A[ATraining Step: 10235  | total loss: [1m[32m0.36024[0m[0m
[2K| Adam | epoch: 089 | loss: 0.36024 - acc: 0.8420 | val_loss: 0.28634 - val_acc: 0.8969 -- iter: 3680/3680
[A[ATraining Step: 10235  | total loss: [1m[32m0.36024[0m[0m
[2K| Adam | epoch: 089 | loss: 0.36024 - acc: 0.8420 | val_loss: 0.28634 - val_acc: 0.8969 -- iter: 3680/3680
--
Training Step: 10236  | total loss: [1m[32m0.34416[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34416 - acc: 0.8516 -- iter: 0032/3680
[A[ATraining Step: 10237  | total loss: [1m[32m0.34897[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34897 - acc: 0.8477 -- iter: 0064/3680
[A[ATraining Step: 10238  | total loss: [1m[32m0.34988[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34988 - acc: 0.8535 -- iter: 0096/3680
[A[ATraining Step: 10239  | total loss: [1m[32m0.32885[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32885 - acc: 0.8682 -- iter: 0128/3680
[A[ATraining Step: 10240  | total loss: [1m[32m0.33234[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33234 - acc: 0.8689 -- iter: 0160/3680
[A[ATraining Step: 10241  | total loss: [1m[32m0.32124[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32124 - acc: 0.8663 -- iter: 0192/3680
[A[ATraining Step: 10242  | total loss: [1m[32m0.30546[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30546 - acc: 0.8766 -- iter: 0224/3680
[A[ATraining Step: 10243  | total loss: [1m[32m0.29329[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29329 - acc: 0.8885 -- iter: 0256/3680
[A[ATraining Step: 10244  | total loss: [1m[32m0.29057[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29057 - acc: 0.8903 -- iter: 0288/3680
[A[ATraining Step: 10245  | total loss: [1m[32m0.29057[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29057 - acc: 0.8903 -- iter: 0320/3680
[A[ATraining Step: 10246  | total loss: [1m[32m0.29936[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29936 - acc: 0.8919 -- iter: 0352/3680
[A[ATraining Step: 10247  | total loss: [1m[32m0.28980[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28980 - acc: 0.8995 -- iter: 0384/3680
[A[ATraining Step: 10248  | total loss: [1m[32m0.28833[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28833 - acc: 0.9002 -- iter: 0416/3680
[A[ATraining Step: 10249  | total loss: [1m[32m0.28659[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28659 - acc: 0.8946 -- iter: 0448/3680
[A[ATraining Step: 10250  | total loss: [1m[32m0.29423[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29423 - acc: 0.8895 -- iter: 0480/3680
[A[ATraining Step: 10251  | total loss: [1m[32m0.28494[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28494 - acc: 0.8880 -- iter: 0512/3680
[A[ATraining Step: 10252  | total loss: [1m[32m0.27732[0m[0m
[2K| Adam | epoch: 090 | loss: 0.27732 - acc: 0.8930 -- iter: 0544/3680
[A[ATraining Step: 10253  | total loss: [1m[32m0.28803[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28803 - acc: 0.8912 -- iter: 0576/3680
[A[ATraining Step: 10254  | total loss: [1m[32m0.28890[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28890 - acc: 0.8927 -- iter: 0608/3680
[A[ATraining Step: 10255  | total loss: [1m[32m0.29697[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29697 - acc: 0.8878 -- iter: 0640/3680
[A[ATraining Step: 10256  | total loss: [1m[32m0.29479[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29479 - acc: 0.8865 -- iter: 0672/3680
[A[ATraining Step: 10257  | total loss: [1m[32m0.31719[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31719 - acc: 0.8760 -- iter: 0704/3680
[A[ATraining Step: 10258  | total loss: [1m[32m0.31781[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31781 - acc: 0.8790 -- iter: 0736/3680
[A[ATraining Step: 10259  | total loss: [1m[32m0.31476[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31476 - acc: 0.8814 -- iter: 0768/3680
[A[ATraining Step: 10260  | total loss: [1m[32m0.31476[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31476 - acc: 0.8814 -- iter: 0800/3680
[A[ATraining Step: 10261  | total loss: [1m[32m0.31202[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31202 - acc: 0.8839 -- iter: 0832/3680
[A[ATraining Step: 10262  | total loss: [1m[32m0.31530[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31530 - acc: 0.8830 -- iter: 0864/3680
[A[ATraining Step: 10263  | total loss: [1m[32m0.30481[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30481 - acc: 0.8884 -- iter: 0896/3680
[A[ATraining Step: 10264  | total loss: [1m[32m0.28958[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28958 - acc: 0.8981 -- iter: 0928/3680
[A[ATraining Step: 10265  | total loss: [1m[32m0.28958[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28958 - acc: 0.8981 -- iter: 0960/3680
[A[ATraining Step: 10266  | total loss: [1m[32m0.28461[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28461 - acc: 0.8989 -- iter: 0992/3680
[A[ATraining Step: 10267  | total loss: [1m[32m0.28267[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28267 - acc: 0.9027 -- iter: 1024/3680
[A[ATraining Step: 10268  | total loss: [1m[32m0.28714[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28714 - acc: 0.9000 -- iter: 1056/3680
[A[ATraining Step: 10269  | total loss: [1m[32m0.30192[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30192 - acc: 0.8881 -- iter: 1088/3680
[A[ATraining Step: 10270  | total loss: [1m[32m0.30811[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30811 - acc: 0.8837 -- iter: 1120/3680
[A[ATraining Step: 10271  | total loss: [1m[32m0.29365[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29365 - acc: 0.8922 -- iter: 1152/3680
[A[ATraining Step: 10272  | total loss: [1m[32m0.29386[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29386 - acc: 0.8936 -- iter: 1184/3680
[A[ATraining Step: 10273  | total loss: [1m[32m0.30141[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30141 - acc: 0.8823 -- iter: 1216/3680
[A[ATraining Step: 10274  | total loss: [1m[32m0.30364[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30364 - acc: 0.8816 -- iter: 1248/3680
[A[ATraining Step: 10275  | total loss: [1m[32m0.30766[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30766 - acc: 0.8810 -- iter: 1280/3680
[A[ATraining Step: 10276  | total loss: [1m[32m0.30399[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30399 - acc: 0.8804 -- iter: 1312/3680
[A[ATraining Step: 10277  | total loss: [1m[32m0.29830[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29830 - acc: 0.8829 -- iter: 1344/3680
[A[ATraining Step: 10278  | total loss: [1m[32m0.30178[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30178 - acc: 0.8790 -- iter: 1376/3680
[A[ATraining Step: 10279  | total loss: [1m[32m0.31899[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31899 - acc: 0.8724 -- iter: 1408/3680
[A[ATraining Step: 10280  | total loss: [1m[32m0.32065[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32065 - acc: 0.8726 -- iter: 1440/3680
[A[ATraining Step: 10281  | total loss: [1m[32m0.32872[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32872 - acc: 0.8729 -- iter: 1472/3680
[A[ATraining Step: 10282  | total loss: [1m[32m0.31361[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31361 - acc: 0.8852 -- iter: 1504/3680
[A[ATraining Step: 10283  | total loss: [1m[32m0.31361[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31361 - acc: 0.8852 -- iter: 1536/3680
[A[ATraining Step: 10284  | total loss: [1m[32m0.30827[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30827 - acc: 0.8873 -- iter: 1568/3680
[A[ATraining Step: 10285  | total loss: [1m[32m0.30164[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30164 - acc: 0.8892 -- iter: 1600/3680
[A[ATraining Step: 10286  | total loss: [1m[32m0.29916[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29916 - acc: 0.8909 -- iter: 1632/3680
[A[ATraining Step: 10287  | total loss: [1m[32m0.28078[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28078 - acc: 0.9018 -- iter: 1664/3680
[A[ATraining Step: 10288  | total loss: [1m[32m0.28422[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28422 - acc: 0.8960 -- iter: 1696/3680
[A[ATraining Step: 10289  | total loss: [1m[32m0.30056[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30056 - acc: 0.8845 -- iter: 1728/3680
[A[ATraining Step: 10290  | total loss: [1m[32m0.29601[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29601 - acc: 0.8898 -- iter: 1760/3680
[A[ATraining Step: 10291  | total loss: [1m[32m0.29159[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29159 - acc: 0.8946 -- iter: 1792/3680
[A[ATraining Step: 10292  | total loss: [1m[32m0.36047[0m[0m
[2K| Adam | epoch: 090 | loss: 0.36047 - acc: 0.8739 -- iter: 1824/3680
[A[ATraining Step: 10293  | total loss: [1m[32m0.35699[0m[0m
[2K| Adam | epoch: 090 | loss: 0.35699 - acc: 0.8771 -- iter: 1856/3680
[A[ATraining Step: 10294  | total loss: [1m[32m0.33380[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33380 - acc: 0.8861 -- iter: 1888/3680
[A[ATraining Step: 10295  | total loss: [1m[32m0.33380[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33380 - acc: 0.8861 -- iter: 1920/3680
[A[ATraining Step: 10296  | total loss: [1m[32m0.33696[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33696 - acc: 0.8787 -- iter: 1952/3680
[A[ATraining Step: 10297  | total loss: [1m[32m0.31799[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31799 - acc: 0.8877 -- iter: 1984/3680
[A[ATraining Step: 10298  | total loss: [1m[32m0.32345[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32345 - acc: 0.8865 -- iter: 2016/3680
[A[ATraining Step: 10299  | total loss: [1m[32m0.32237[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32237 - acc: 0.8853 -- iter: 2048/3680
[A[ATraining Step: 10300  | total loss: [1m[32m0.31867[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31867 - acc: 0.8874 | val_loss: 0.29471 - val_acc: 0.8925 -- iter: 2080/3680
[A[ATraining Step: 10300  | total loss: [1m[32m0.31867[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31867 - acc: 0.8874 | val_loss: 0.29471 - val_acc: 0.8925 -- iter: 2080/3680
--
Training Step: 10301  | total loss: [1m[32m0.33131[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33131 - acc: 0.8799 -- iter: 2112/3680
[A[ATraining Step: 10302  | total loss: [1m[32m0.33562[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33562 - acc: 0.8794 -- iter: 2144/3680
[A[ATraining Step: 10303  | total loss: [1m[32m0.33580[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33580 - acc: 0.8759 -- iter: 2176/3680
[A[ATraining Step: 10304  | total loss: [1m[32m0.35956[0m[0m
[2K| Adam | epoch: 090 | loss: 0.35956 - acc: 0.8601 -- iter: 2208/3680
[A[ATraining Step: 10305  | total loss: [1m[32m0.34310[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34310 - acc: 0.8679 -- iter: 2240/3680
[A[ATraining Step: 10306  | total loss: [1m[32m0.33739[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33739 - acc: 0.8655 -- iter: 2272/3680
[A[ATraining Step: 10307  | total loss: [1m[32m0.34773[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34773 - acc: 0.8602 -- iter: 2304/3680
[A[ATraining Step: 10308  | total loss: [1m[32m0.33585[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33585 - acc: 0.8633 -- iter: 2336/3680
[A[ATraining Step: 10309  | total loss: [1m[32m0.33585[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33585 - acc: 0.8633 -- iter: 2368/3680
[A[ATraining Step: 10310  | total loss: [1m[32m0.33796[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33796 - acc: 0.8645 -- iter: 2400/3680
[A[ATraining Step: 10311  | total loss: [1m[32m0.34091[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34091 - acc: 0.8624 -- iter: 2432/3680
[A[ATraining Step: 10312  | total loss: [1m[32m0.33966[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33966 - acc: 0.8574 -- iter: 2464/3680
[A[ATraining Step: 10313  | total loss: [1m[32m0.33619[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33619 - acc: 0.8560 -- iter: 2496/3680
[A[ATraining Step: 10314  | total loss: [1m[32m0.34333[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34333 - acc: 0.8517 -- iter: 2528/3680
[A[ATraining Step: 10315  | total loss: [1m[32m0.34821[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34821 - acc: 0.8540 -- iter: 2560/3680
[A[ATraining Step: 10316  | total loss: [1m[32m0.33725[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33725 - acc: 0.8624 -- iter: 2592/3680
[A[ATraining Step: 10317  | total loss: [1m[32m0.35078[0m[0m
[2K| Adam | epoch: 090 | loss: 0.35078 - acc: 0.8511 -- iter: 2624/3680
[A[ATraining Step: 10318  | total loss: [1m[32m0.34231[0m[0m
[2K| Adam | epoch: 090 | loss: 0.34231 - acc: 0.8598 -- iter: 2656/3680
[A[ATraining Step: 10319  | total loss: [1m[32m0.33733[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33733 - acc: 0.8644 -- iter: 2688/3680
[A[ATraining Step: 10320  | total loss: [1m[32m0.33402[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33402 - acc: 0.8623 -- iter: 2720/3680
[A[ATraining Step: 10321  | total loss: [1m[32m0.33589[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33589 - acc: 0.8636 -- iter: 2752/3680
[A[ATraining Step: 10322  | total loss: [1m[32m0.33949[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33949 - acc: 0.8679 -- iter: 2784/3680
[A[ATraining Step: 10323  | total loss: [1m[32m0.33949[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33949 - acc: 0.8561 -- iter: 2816/3680
[A[ATraining Step: 10324  | total loss: [1m[32m0.33145[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33145 - acc: 0.8580 -- iter: 2848/3680
[A[ATraining Step: 10325  | total loss: [1m[32m0.32584[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32584 - acc: 0.8628 -- iter: 2880/3680
[A[ATraining Step: 10326  | total loss: [1m[32m0.30997[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30997 - acc: 0.8734 -- iter: 2912/3680
[A[ATraining Step: 10327  | total loss: [1m[32m0.29501[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29501 - acc: 0.8798 -- iter: 2944/3680
[A[ATraining Step: 10328  | total loss: [1m[32m0.29473[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29473 - acc: 0.8792 -- iter: 2976/3680
[A[ATraining Step: 10329  | total loss: [1m[32m0.29473[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29473 - acc: 0.8632 -- iter: 3008/3680
[A[ATraining Step: 10330  | total loss: [1m[32m0.32273[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32273 - acc: 0.8632 -- iter: 3040/3680
[A[ATraining Step: 10331  | total loss: [1m[32m0.33313[0m[0m
[2K| Adam | epoch: 090 | loss: 0.33313 - acc: 0.8581 -- iter: 3072/3680
[A[ATraining Step: 10332  | total loss: [1m[32m0.32143[0m[0m
[2K| Adam | epoch: 090 | loss: 0.32143 - acc: 0.8629 -- iter: 3104/3680
[A[ATraining Step: 10333  | total loss: [1m[32m0.31024[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31024 - acc: 0.8672 -- iter: 3136/3680
[A[ATraining Step: 10334  | total loss: [1m[32m0.29861[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29861 - acc: 0.8711 -- iter: 3168/3680
[A[ATraining Step: 10335  | total loss: [1m[32m0.31271[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31271 - acc: 0.8600 -- iter: 3200/3680
[A[ATraining Step: 10336  | total loss: [1m[32m0.31271[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31271 - acc: 0.8709 -- iter: 3232/3680
[A[ATraining Step: 10337  | total loss: [1m[32m0.29827[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29827 - acc: 0.8709 -- iter: 3264/3680
[A[ATraining Step: 10338  | total loss: [1m[32m0.29200[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29200 - acc: 0.8744 -- iter: 3296/3680
[A[ATraining Step: 10339  | total loss: [1m[32m0.30498[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30498 - acc: 0.8745 -- iter: 3328/3680
[A[ATraining Step: 10340  | total loss: [1m[32m0.30220[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30220 - acc: 0.8777 -- iter: 3360/3680
[A[ATraining Step: 10341  | total loss: [1m[32m0.30057[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30057 - acc: 0.8805 -- iter: 3392/3680
[A[ATraining Step: 10342  | total loss: [1m[32m0.29476[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29476 - acc: 0.8862 -- iter: 3424/3680
[A[ATraining Step: 10343  | total loss: [1m[32m0.29242[0m[0m
[2K| Adam | epoch: 090 | loss: 0.29242 - acc: 0.8851 -- iter: 3456/3680
[A[ATraining Step: 10344  | total loss: [1m[32m0.28737[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28737 - acc: 0.8872 -- iter: 3488/3680
[A[ATraining Step: 10345  | total loss: [1m[32m0.28554[0m[0m
[2K| Adam | epoch: 090 | loss: 0.28554 - acc: 0.8829 -- iter: 3520/3680
[A[ATraining Step: 10346  | total loss: [1m[32m0.30648[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30648 - acc: 0.8696 -- iter: 3552/3680
[A[ATraining Step: 10347  | total loss: [1m[32m0.30154[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30154 - acc: 0.8764 -- iter: 3584/3680
[A[ATraining Step: 10348  | total loss: [1m[32m0.31405[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31405 - acc: 0.8661 -- iter: 3616/3680
[A[ATraining Step: 10349  | total loss: [1m[32m0.31405[0m[0m
[2K| Adam | epoch: 090 | loss: 0.31405 - acc: 0.8661 -- iter: 3648/3680
[A[ATraining Step: 10350  | total loss: [1m[32m0.30698[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30698 - acc: 0.8701 | val_loss: 0.28340 - val_acc: 0.9001 -- iter: 3680/3680
[A[ATraining Step: 10350  | total loss: [1m[32m0.30698[0m[0m
[2K| Adam | epoch: 090 | loss: 0.30698 - acc: 0.8701 | val_loss: 0.28340 - val_acc: 0.9001 -- iter: 3680/3680
--
Training Step: 10351  | total loss: [1m[32m0.30722[0m[0m
[2K| Adam | epoch: 091 | loss: 0.30722 - acc: 0.8706 -- iter: 0032/3680
[A[ATraining Step: 10352  | total loss: [1m[32m0.30395[0m[0m
[2K| Adam | epoch: 091 | loss: 0.30395 - acc: 0.8710 -- iter: 0064/3680
[A[ATraining Step: 10353  | total loss: [1m[32m0.29118[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29118 - acc: 0.8777 -- iter: 0096/3680
[A[ATraining Step: 10354  | total loss: [1m[32m0.29496[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29496 - acc: 0.8774 -- iter: 0128/3680
[A[ATraining Step: 10355  | total loss: [1m[32m0.28740[0m[0m
[2K| Adam | epoch: 091 | loss: 0.28740 - acc: 0.8834 -- iter: 0160/3680
[A[ATraining Step: 10356  | total loss: [1m[32m0.27322[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27322 - acc: 0.8920 -- iter: 0192/3680
[A[ATraining Step: 10357  | total loss: [1m[32m0.30101[0m[0m
[2K| Adam | epoch: 091 | loss: 0.30101 - acc: 0.8746 -- iter: 0224/3680
[A[ATraining Step: 10358  | total loss: [1m[32m0.29657[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29657 - acc: 0.8809 -- iter: 0256/3680
[A[ATraining Step: 10359  | total loss: [1m[32m0.29441[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29441 - acc: 0.8835 -- iter: 0288/3680
[A[ATraining Step: 10360  | total loss: [1m[32m0.29265[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29265 - acc: 0.8826 -- iter: 0320/3680
[A[ATraining Step: 10361  | total loss: [1m[32m0.29973[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29973 - acc: 0.8787 -- iter: 0352/3680
[A[ATraining Step: 10362  | total loss: [1m[32m0.29471[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29471 - acc: 0.8815 -- iter: 0384/3680
[A[ATraining Step: 10363  | total loss: [1m[32m0.27846[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27846 - acc: 0.8933 -- iter: 0416/3680
[A[ATraining Step: 10364  | total loss: [1m[32m0.27937[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27937 - acc: 0.8915 -- iter: 0448/3680
[A[ATraining Step: 10365  | total loss: [1m[32m0.26342[0m[0m
[2K| Adam | epoch: 091 | loss: 0.26342 - acc: 0.9023 -- iter: 0480/3680
[A[ATraining Step: 10366  | total loss: [1m[32m0.28598[0m[0m
[2K| Adam | epoch: 091 | loss: 0.28598 - acc: 0.8871 -- iter: 0512/3680
[A[ATraining Step: 10367  | total loss: [1m[32m0.28876[0m[0m
[2K| Adam | epoch: 091 | loss: 0.28876 - acc: 0.8859 -- iter: 0544/3680
[A[ATraining Step: 10368  | total loss: [1m[32m0.28698[0m[0m
[2K| Adam | epoch: 091 | loss: 0.28698 - acc: 0.8835 -- iter: 0576/3680
[A[ATraining Step: 10369  | total loss: [1m[32m0.29026[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29026 - acc: 0.8835 -- iter: 0608/3680
[A[ATraining Step: 10370  | total loss: [1m[32m0.28619[0m[0m
[2K| Adam | epoch: 091 | loss: 0.28619 - acc: 0.8827 -- iter: 0640/3680
[A[ATraining Step: 10371  | total loss: [1m[32m0.27804[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27804 - acc: 0.8819 -- iter: 0672/3680
[A[ATraining Step: 10372  | total loss: [1m[32m0.27192[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27192 - acc: 0.8875 -- iter: 0704/3680
[A[ATraining Step: 10373  | total loss: [1m[32m0.27411[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27411 - acc: 0.8893 -- iter: 0736/3680
[A[ATraining Step: 10374  | total loss: [1m[32m0.26665[0m[0m
[2K| Adam | epoch: 091 | loss: 0.26665 - acc: 0.8942 -- iter: 0768/3680
[A[ATraining Step: 10375  | total loss: [1m[32m0.27850[0m[0m
[2K| Adam | epoch: 091 | loss: 0.27850 - acc: 0.8860 -- iter: 0800/3680
[A[ATraining Step: 10376  | total loss: [1m[32m0.26778[0m[0m
[2K| Adam | epoch: 091 | loss: 0.26778 - acc: 0.8895 -- iter: 0832/3680
[A[ATraining Step: 10377  | total loss: [1m[32m0.28205[0m[0m
[2K| Adam | epoch: 091 | loss: 0.28205 - acc: 0.8895 -- iter: 0864/3680
[A[ATraining Step: 10378  | total loss: [1m[32m0.29316[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29316 - acc: 0.8808 -- iter: 0896/3680
[A[ATraining Step: 10379  | total loss: [1m[32m0.29316[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29316 - acc: 0.8808 -- iter: 0928/3680
[A[ATraining Step: 10380  | total loss: [1m[32m0.29154[0m[0m
[2K| Adam | epoch: 091 | loss: 0.29154 - acc: 0.8802 -- iter: 0960/3680
[A[ATraining Step: 10381  | total loss: [1m[32m0.34169[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34169 - acc: 0.8671 -- iter: 0992/3680
[A[ATraining Step: 10382  | total loss: [1m[32m0.34169[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34169 - acc: 0.8671 -- iter: 1024/3680
[A[ATraining Step: 10383  | total loss: [1m[32m0.34654[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34654 - acc: 0.8554 -- iter: 1056/3680
[A[ATraining Step: 10384  | total loss: [1m[32m0.33322[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33322 - acc: 0.8685 -- iter: 1088/3680
[A[ATraining Step: 10385  | total loss: [1m[32m0.33322[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33322 - acc: 0.8685 -- iter: 1120/3680
[A[ATraining Step: 10386  | total loss: [1m[32m0.32941[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32941 - acc: 0.8691 -- iter: 1152/3680
[A[ATraining Step: 10387  | total loss: [1m[32m0.34137[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34137 - acc: 0.8666 -- iter: 1184/3680
[A[ATraining Step: 10388  | total loss: [1m[32m0.34013[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34013 - acc: 0.8643 -- iter: 1216/3680
[A[ATraining Step: 10389  | total loss: [1m[32m0.34017[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34017 - acc: 0.8654 -- iter: 1248/3680
[A[ATraining Step: 10390  | total loss: [1m[32m0.34211[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34211 - acc: 0.8601 -- iter: 1280/3680
[A[ATraining Step: 10391  | total loss: [1m[32m0.36920[0m[0m
[2K| Adam | epoch: 091 | loss: 0.36920 - acc: 0.8491 -- iter: 1312/3680
[A[ATraining Step: 10392  | total loss: [1m[32m0.37779[0m[0m
[2K| Adam | epoch: 091 | loss: 0.37779 - acc: 0.8517 -- iter: 1344/3680
[A[ATraining Step: 10393  | total loss: [1m[32m0.37329[0m[0m
[2K| Adam | epoch: 091 | loss: 0.37329 - acc: 0.8571 -- iter: 1376/3680
[A[ATraining Step: 10394  | total loss: [1m[32m0.39326[0m[0m
[2K| Adam | epoch: 091 | loss: 0.39326 - acc: 0.8558 -- iter: 1408/3680
[A[ATraining Step: 10395  | total loss: [1m[32m0.40707[0m[0m
[2K| Adam | epoch: 091 | loss: 0.40707 - acc: 0.8421 -- iter: 1440/3680
[A[ATraining Step: 10396  | total loss: [1m[32m0.39908[0m[0m
[2K| Adam | epoch: 091 | loss: 0.39908 - acc: 0.8422 -- iter: 1472/3680
[A[ATraining Step: 10397  | total loss: [1m[32m0.37820[0m[0m
[2K| Adam | epoch: 091 | loss: 0.37820 - acc: 0.8549 -- iter: 1504/3680
[A[ATraining Step: 10398  | total loss: [1m[32m0.37390[0m[0m
[2K| Adam | epoch: 091 | loss: 0.37390 - acc: 0.8507 -- iter: 1536/3680
[A[ATraining Step: 10399  | total loss: [1m[32m0.35656[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35656 - acc: 0.8593 -- iter: 1568/3680
[A[ATraining Step: 10400  | total loss: [1m[32m0.35234[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35234 - acc: 0.8609 | val_loss: 0.27767 - val_acc: 0.9077 -- iter: 1600/3680
[A[ATraining Step: 10400  | total loss: [1m[32m0.35234[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35234 - acc: 0.8609 | val_loss: 0.27767 - val_acc: 0.9077 -- iter: 1600/3680
--
Training Step: 10401  | total loss: [1m[32m0.34148[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34148 - acc: 0.8592 -- iter: 1632/3680
[A[ATraining Step: 10402  | total loss: [1m[32m0.33385[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33385 - acc: 0.8608 -- iter: 1664/3680
[A[ATraining Step: 10403  | total loss: [1m[32m0.33377[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33377 - acc: 0.8622 -- iter: 1696/3680
[A[ATraining Step: 10404  | total loss: [1m[32m0.33357[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33357 - acc: 0.8666 -- iter: 1728/3680
[A[ATraining Step: 10405  | total loss: [1m[32m0.32872[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32872 - acc: 0.8643 -- iter: 1760/3680
[A[ATraining Step: 10406  | total loss: [1m[32m0.32537[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32537 - acc: 0.8685 -- iter: 1792/3680
[A[ATraining Step: 10407  | total loss: [1m[32m0.34317[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34317 - acc: 0.8598 -- iter: 1824/3680
[A[ATraining Step: 10408  | total loss: [1m[32m0.33217[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33217 - acc: 0.8644 -- iter: 1856/3680
[A[ATraining Step: 10409  | total loss: [1m[32m0.34316[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34316 - acc: 0.8592 -- iter: 1888/3680
[A[ATraining Step: 10410  | total loss: [1m[32m0.32835[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32835 - acc: 0.8702 -- iter: 1920/3680
[A[ATraining Step: 10411  | total loss: [1m[32m0.32762[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32762 - acc: 0.8738 -- iter: 1952/3680
[A[ATraining Step: 10412  | total loss: [1m[32m0.33501[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33501 - acc: 0.8677 -- iter: 1984/3680
[A[ATraining Step: 10413  | total loss: [1m[32m0.34386[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34386 - acc: 0.8590 -- iter: 2016/3680
[A[ATraining Step: 10414  | total loss: [1m[32m0.33581[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33581 - acc: 0.8637 -- iter: 2048/3680
[A[ATraining Step: 10415  | total loss: [1m[32m0.33230[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33230 - acc: 0.8631 -- iter: 2080/3680
[A[ATraining Step: 10416  | total loss: [1m[32m0.34128[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34128 - acc: 0.8674 -- iter: 2112/3680
[A[ATraining Step: 10417  | total loss: [1m[32m0.33367[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33367 - acc: 0.8744 -- iter: 2144/3680
[A[ATraining Step: 10418  | total loss: [1m[32m0.33367[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33367 - acc: 0.8744 -- iter: 2176/3680
[A[ATraining Step: 10419  | total loss: [1m[32m0.32790[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32790 - acc: 0.8776 -- iter: 2208/3680
[A[ATraining Step: 10420  | total loss: [1m[32m0.36278[0m[0m
[2K| Adam | epoch: 091 | loss: 0.36278 - acc: 0.8523 -- iter: 2240/3680
[A[ATraining Step: 10421  | total loss: [1m[32m0.35516[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35516 - acc: 0.8515 -- iter: 2272/3680
[A[ATraining Step: 10422  | total loss: [1m[32m0.35098[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35098 - acc: 0.8538 -- iter: 2304/3680
[A[ATraining Step: 10423  | total loss: [1m[32m0.34744[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34744 - acc: 0.8591 -- iter: 2336/3680
[A[ATraining Step: 10424  | total loss: [1m[32m0.34780[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34780 - acc: 0.8575 -- iter: 2368/3680
[A[ATraining Step: 10425  | total loss: [1m[32m0.33323[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33323 - acc: 0.8687 -- iter: 2400/3680
[A[ATraining Step: 10426  | total loss: [1m[32m0.32276[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32276 - acc: 0.8755 -- iter: 2432/3680
[A[ATraining Step: 10427  | total loss: [1m[32m0.32349[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32349 - acc: 0.8786 -- iter: 2464/3680
[A[ATraining Step: 10428  | total loss: [1m[32m0.32438[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32438 - acc: 0.8814 -- iter: 2496/3680
[A[ATraining Step: 10429  | total loss: [1m[32m0.31711[0m[0m
[2K| Adam | epoch: 091 | loss: 0.31711 - acc: 0.8858 -- iter: 2528/3680
[A[ATraining Step: 10430  | total loss: [1m[32m0.31670[0m[0m
[2K| Adam | epoch: 091 | loss: 0.31670 - acc: 0.8858 -- iter: 2560/3680
[A[ATraining Step: 10431  | total loss: [1m[32m0.32746[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32746 - acc: 0.8847 -- iter: 2592/3680
[A[ATraining Step: 10432  | total loss: [1m[32m0.32832[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32832 - acc: 0.8685 -- iter: 2624/3680
[A[ATraining Step: 10433  | total loss: [1m[32m0.32883[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32883 - acc: 0.8685 -- iter: 2656/3680
[A[ATraining Step: 10434  | total loss: [1m[32m0.33356[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33356 - acc: 0.8598 -- iter: 2688/3680
[A[ATraining Step: 10435  | total loss: [1m[32m0.35191[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35191 - acc: 0.8550 -- iter: 2720/3680
[A[ATraining Step: 10436  | total loss: [1m[32m0.34535[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34535 - acc: 0.8570 -- iter: 2752/3680
[A[ATraining Step: 10437  | total loss: [1m[32m0.34988[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34988 - acc: 0.8495 -- iter: 2784/3680
[A[ATraining Step: 10438  | total loss: [1m[32m0.35320[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35320 - acc: 0.8520 -- iter: 2816/3680
[A[ATraining Step: 10439  | total loss: [1m[32m0.35874[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35874 - acc: 0.8512 -- iter: 2848/3680
[A[ATraining Step: 10440  | total loss: [1m[32m0.35873[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35873 - acc: 0.8560 -- iter: 2880/3680
[A[ATraining Step: 10441  | total loss: [1m[32m0.34612[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34612 - acc: 0.8642 -- iter: 2912/3680
[A[ATraining Step: 10442  | total loss: [1m[32m0.34612[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34612 - acc: 0.8642 -- iter: 2944/3680
[A[ATraining Step: 10443  | total loss: [1m[32m0.36370[0m[0m
[2K| Adam | epoch: 091 | loss: 0.36370 - acc: 0.8496 -- iter: 2976/3680
[A[ATraining Step: 10444  | total loss: [1m[32m0.36221[0m[0m
[2K| Adam | epoch: 091 | loss: 0.36221 - acc: 0.8459 -- iter: 3008/3680
[A[ATraining Step: 10445  | total loss: [1m[32m0.35546[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35546 - acc: 0.8519 -- iter: 3040/3680
[A[ATraining Step: 10446  | total loss: [1m[32m0.34117[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34117 - acc: 0.8560 -- iter: 3072/3680
[A[ATraining Step: 10447  | total loss: [1m[32m0.34117[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34117 - acc: 0.8560 -- iter: 3104/3680
[A[ATraining Step: 10448  | total loss: [1m[32m0.33722[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33722 - acc: 0.8579 -- iter: 3136/3680
[A[ATraining Step: 10449  | total loss: [1m[32m0.33187[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33187 - acc: 0.8596 -- iter: 3168/3680
[A[ATraining Step: 10450  | total loss: [1m[32m0.33793[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33793 - acc: 0.8612 -- iter: 3200/3680
[A[ATraining Step: 10451  | total loss: [1m[32m0.33355[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33355 - acc: 0.8625 -- iter: 3232/3680
[A[ATraining Step: 10452  | total loss: [1m[32m0.32142[0m[0m
[2K| Adam | epoch: 091 | loss: 0.32142 - acc: 0.8669 -- iter: 3264/3680
[A[ATraining Step: 10453  | total loss: [1m[32m0.33921[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33921 - acc: 0.8552 -- iter: 3296/3680
[A[ATraining Step: 10454  | total loss: [1m[32m0.33866[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33866 - acc: 0.8572 -- iter: 3328/3680
[A[ATraining Step: 10455  | total loss: [1m[32m0.33745[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33745 - acc: 0.8527 -- iter: 3360/3680
[A[ATraining Step: 10456  | total loss: [1m[32m0.33755[0m[0m
[2K| Adam | epoch: 091 | loss: 0.33755 - acc: 0.8510 -- iter: 3392/3680
[A[ATraining Step: 10457  | total loss: [1m[32m0.34568[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34568 - acc: 0.8597 -- iter: 3424/3680
[A[ATraining Step: 10458  | total loss: [1m[32m0.34225[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34225 - acc: 0.8597 -- iter: 3456/3680
[A[ATraining Step: 10459  | total loss: [1m[32m0.34095[0m[0m
[2K| Adam | epoch: 091 | loss: 0.34095 - acc: 0.8643 -- iter: 3488/3680
[A[ATraining Step: 10460  | total loss: [1m[32m0.38005[0m[0m
[2K| Adam | epoch: 091 | loss: 0.38005 - acc: 0.8404 -- iter: 3520/3680
[A[ATraining Step: 10461  | total loss: [1m[32m0.37673[0m[0m
[2K| Adam | epoch: 091 | loss: 0.37673 - acc: 0.8407 -- iter: 3552/3680
[A[ATraining Step: 10462  | total loss: [1m[32m0.39276[0m[0m
[2K| Adam | epoch: 091 | loss: 0.39276 - acc: 0.8317 -- iter: 3584/3680
[A[ATraining Step: 10463  | total loss: [1m[32m0.37212[0m[0m
[2K| Adam | epoch: 091 | loss: 0.37212 - acc: 0.8454 -- iter: 3616/3680
[A[ATraining Step: 10464  | total loss: [1m[32m0.35108[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35108 - acc: 0.8608 -- iter: 3648/3680
[A[ATraining Step: 10465  | total loss: [1m[32m0.35210[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35210 - acc: 0.8560 | val_loss: 0.33075 - val_acc: 0.8686 -- iter: 3680/3680
[A[ATraining Step: 10465  | total loss: [1m[32m0.35210[0m[0m
[2K| Adam | epoch: 091 | loss: 0.35210 - acc: 0.8560 | val_loss: 0.33075 - val_acc: 0.8686 -- iter: 3680/3680
--
Training Step: 10466  | total loss: [1m[32m0.34354[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34354 - acc: 0.8548 -- iter: 0032/3680
[A[ATraining Step: 10467  | total loss: [1m[32m0.34130[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34130 - acc: 0.8537 -- iter: 0064/3680
[A[ATraining Step: 10468  | total loss: [1m[32m0.35852[0m[0m
[2K| Adam | epoch: 092 | loss: 0.35852 - acc: 0.8433 -- iter: 0096/3680
[A[ATraining Step: 10469  | total loss: [1m[32m0.35493[0m[0m
[2K| Adam | epoch: 092 | loss: 0.35493 - acc: 0.8496 -- iter: 0128/3680
[A[ATraining Step: 10470  | total loss: [1m[32m0.35654[0m[0m
[2K| Adam | epoch: 092 | loss: 0.35654 - acc: 0.8428 -- iter: 0160/3680
[A[ATraining Step: 10471  | total loss: [1m[32m0.36211[0m[0m
[2K| Adam | epoch: 092 | loss: 0.36211 - acc: 0.8366 -- iter: 0192/3680
[A[ATraining Step: 10472  | total loss: [1m[32m0.36813[0m[0m
[2K| Adam | epoch: 092 | loss: 0.36813 - acc: 0.8342 -- iter: 0224/3680
[A[ATraining Step: 10473  | total loss: [1m[32m0.35192[0m[0m
[2K| Adam | epoch: 092 | loss: 0.35192 - acc: 0.8445 -- iter: 0256/3680
[A[ATraining Step: 10474  | total loss: [1m[32m0.33940[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33940 - acc: 0.8507 -- iter: 0288/3680
[A[ATraining Step: 10475  | total loss: [1m[32m0.34482[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34482 - acc: 0.8531 -- iter: 0320/3680
[A[ATraining Step: 10476  | total loss: [1m[32m0.34752[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34752 - acc: 0.8459 -- iter: 0352/3680
[A[ATraining Step: 10477  | total loss: [1m[32m0.33890[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33890 - acc: 0.8546 -- iter: 0384/3680
[A[ATraining Step: 10478  | total loss: [1m[32m0.33890[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33890 - acc: 0.8546 -- iter: 0416/3680
[A[ATraining Step: 10479  | total loss: [1m[32m0.34125[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34125 - acc: 0.8504 -- iter: 0448/3680
[A[ATraining Step: 10480  | total loss: [1m[32m0.32667[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32667 - acc: 0.8591 -- iter: 0480/3680
[A[ATraining Step: 10481  | total loss: [1m[32m0.31541[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31541 - acc: 0.8669 -- iter: 0512/3680
[A[ATraining Step: 10482  | total loss: [1m[32m0.31714[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31714 - acc: 0.8685 -- iter: 0544/3680
[A[ATraining Step: 10483  | total loss: [1m[32m0.31714[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31714 - acc: 0.8691 -- iter: 0576/3680
[A[ATraining Step: 10484  | total loss: [1m[32m0.31731[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31731 - acc: 0.8691 -- iter: 0608/3680
[A[ATraining Step: 10485  | total loss: [1m[32m0.30672[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30672 - acc: 0.8728 -- iter: 0640/3680
[A[ATraining Step: 10486  | total loss: [1m[32m0.32116[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32116 - acc: 0.8605 -- iter: 0672/3680
[A[ATraining Step: 10487  | total loss: [1m[32m0.32734[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32734 - acc: 0.8620 -- iter: 0704/3680
[A[ATraining Step: 10488  | total loss: [1m[32m0.33001[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33001 - acc: 0.8633 -- iter: 0736/3680
[A[ATraining Step: 10489  | total loss: [1m[32m0.31678[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31678 - acc: 0.8707 -- iter: 0768/3680
[A[ATraining Step: 10490  | total loss: [1m[32m0.31814[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31814 - acc: 0.8680 -- iter: 0800/3680
[A[ATraining Step: 10491  | total loss: [1m[32m0.32247[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32247 - acc: 0.8656 -- iter: 0832/3680
[A[ATraining Step: 10492  | total loss: [1m[32m0.32066[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32066 - acc: 0.8728 -- iter: 0864/3680
[A[ATraining Step: 10493  | total loss: [1m[32m0.31780[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31780 - acc: 0.8730 -- iter: 0896/3680
[A[ATraining Step: 10494  | total loss: [1m[32m0.32814[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32814 - acc: 0.8703 -- iter: 0928/3680
[A[ATraining Step: 10495  | total loss: [1m[32m0.32814[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32814 - acc: 0.8703 -- iter: 0960/3680
[A[ATraining Step: 10496  | total loss: [1m[32m0.31319[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31319 - acc: 0.8770 -- iter: 0992/3680
[A[ATraining Step: 10497  | total loss: [1m[32m0.34457[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34457 - acc: 0.8549 -- iter: 1024/3680
[A[ATraining Step: 10498  | total loss: [1m[32m0.32647[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32647 - acc: 0.8632 -- iter: 1056/3680
[A[ATraining Step: 10499  | total loss: [1m[32m0.32473[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32473 - acc: 0.8644 -- iter: 1088/3680
[A[ATraining Step: 10500  | total loss: [1m[32m0.33308[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33308 - acc: 0.8529 | val_loss: 0.29617 - val_acc: 0.8947 -- iter: 1120/3680
[A[ATraining Step: 10500  | total loss: [1m[32m0.33308[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33308 - acc: 0.8529 | val_loss: 0.29617 - val_acc: 0.8947 -- iter: 1120/3680
--
Training Step: 10501  | total loss: [1m[32m0.33590[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33590 - acc: 0.8489 -- iter: 1152/3680
[A[ATraining Step: 10502  | total loss: [1m[32m0.32912[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32912 - acc: 0.8484 -- iter: 1184/3680
[A[ATraining Step: 10503  | total loss: [1m[32m0.31760[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31760 - acc: 0.8542 -- iter: 1216/3680
[A[ATraining Step: 10504  | total loss: [1m[32m0.31867[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31867 - acc: 0.8562 -- iter: 1248/3680
[A[ATraining Step: 10505  | total loss: [1m[32m0.31958[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31958 - acc: 0.8519 -- iter: 1280/3680
[A[ATraining Step: 10506  | total loss: [1m[32m0.32644[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32644 - acc: 0.8511 -- iter: 1312/3680
[A[ATraining Step: 10507  | total loss: [1m[32m0.32315[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32315 - acc: 0.8503 -- iter: 1344/3680
[A[ATraining Step: 10508  | total loss: [1m[32m0.30909[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30909 - acc: 0.8622 -- iter: 1376/3680
[A[ATraining Step: 10509  | total loss: [1m[32m0.31418[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31418 - acc: 0.8612 -- iter: 1408/3680
[A[ATraining Step: 10510  | total loss: [1m[32m0.31418[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31418 - acc: 0.8657 -- iter: 1440/3680
[A[ATraining Step: 10511  | total loss: [1m[32m0.30276[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30276 - acc: 0.8729 -- iter: 1472/3680
[A[ATraining Step: 10512  | total loss: [1m[32m0.30671[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30671 - acc: 0.8729 -- iter: 1504/3680
[A[ATraining Step: 10513  | total loss: [1m[32m0.31867[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31867 - acc: 0.8668 -- iter: 1536/3680
[A[ATraining Step: 10514  | total loss: [1m[32m0.31691[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31691 - acc: 0.8676 -- iter: 1568/3680
[A[ATraining Step: 10515  | total loss: [1m[32m0.31074[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31074 - acc: 0.8715 -- iter: 1600/3680
[A[ATraining Step: 10516  | total loss: [1m[32m0.29819[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29819 - acc: 0.8812 -- iter: 1632/3680
[A[ATraining Step: 10517  | total loss: [1m[32m0.30052[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30052 - acc: 0.8775 -- iter: 1664/3680
[A[ATraining Step: 10518  | total loss: [1m[32m0.28995[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28995 - acc: 0.8804 -- iter: 1696/3680
[A[ATraining Step: 10519  | total loss: [1m[32m0.28327[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28327 - acc: 0.8861 -- iter: 1728/3680
[A[ATraining Step: 10520  | total loss: [1m[32m0.27754[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27754 - acc: 0.8912 -- iter: 1760/3680
[A[ATraining Step: 10521  | total loss: [1m[32m0.27505[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27505 - acc: 0.8896 -- iter: 1792/3680
[A[ATraining Step: 10522  | total loss: [1m[32m0.27571[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27571 - acc: 0.8913 -- iter: 1824/3680
[A[ATraining Step: 10523  | total loss: [1m[32m0.28670[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28670 - acc: 0.8865 -- iter: 1856/3680
[A[ATraining Step: 10524  | total loss: [1m[32m0.27339[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27339 - acc: 0.8916 -- iter: 1888/3680
[A[ATraining Step: 10525  | total loss: [1m[32m0.27623[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27623 - acc: 0.8899 -- iter: 1920/3680
[A[ATraining Step: 10526  | total loss: [1m[32m0.27853[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27853 - acc: 0.8885 -- iter: 1952/3680
[A[ATraining Step: 10527  | total loss: [1m[32m0.28748[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28748 - acc: 0.8777 -- iter: 1984/3680
[A[ATraining Step: 10528  | total loss: [1m[32m0.28152[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28152 - acc: 0.8868 -- iter: 2016/3680
[A[ATraining Step: 10529  | total loss: [1m[32m0.28741[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28741 - acc: 0.8852 -- iter: 2048/3680
[A[ATraining Step: 10530  | total loss: [1m[32m0.27751[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27751 - acc: 0.8852 -- iter: 2080/3680
[A[ATraining Step: 10531  | total loss: [1m[32m0.28412[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28412 - acc: 0.8811 -- iter: 2112/3680
[A[ATraining Step: 10532  | total loss: [1m[32m0.29398[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29398 - acc: 0.8677 -- iter: 2144/3680
[A[ATraining Step: 10533  | total loss: [1m[32m0.29716[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29716 - acc: 0.8677 -- iter: 2176/3680
[A[ATraining Step: 10534  | total loss: [1m[32m0.28927[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28927 - acc: 0.8653 -- iter: 2208/3680
[A[ATraining Step: 10535  | total loss: [1m[32m0.28643[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28643 - acc: 0.8663 -- iter: 2240/3680
[A[ATraining Step: 10536  | total loss: [1m[32m0.28969[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28969 - acc: 0.8703 -- iter: 2272/3680
[A[ATraining Step: 10537  | total loss: [1m[32m0.29565[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29565 - acc: 0.8676 -- iter: 2304/3680
[A[ATraining Step: 10538  | total loss: [1m[32m0.28666[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28666 - acc: 0.8777 -- iter: 2336/3680
[A[ATraining Step: 10539  | total loss: [1m[32m0.27901[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27901 - acc: 0.8868 -- iter: 2368/3680
[A[ATraining Step: 10540  | total loss: [1m[32m0.28584[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28584 - acc: 0.8852 -- iter: 2400/3680
[A[ATraining Step: 10541  | total loss: [1m[32m0.27595[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27595 - acc: 0.8852 -- iter: 2432/3680
[A[ATraining Step: 10542  | total loss: [1m[32m0.29395[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29395 - acc: 0.8779 -- iter: 2464/3680
[A[ATraining Step: 10543  | total loss: [1m[32m0.28612[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28612 - acc: 0.8839 -- iter: 2496/3680
[A[ATraining Step: 10544  | total loss: [1m[32m0.29223[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29223 - acc: 0.8799 -- iter: 2528/3680
[A[ATraining Step: 10545  | total loss: [1m[32m0.27909[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27909 - acc: 0.8919 -- iter: 2560/3680
[A[ATraining Step: 10546  | total loss: [1m[32m0.27252[0m[0m
[2K| Adam | epoch: 092 | loss: 0.27252 - acc: 0.8965 -- iter: 2592/3680
[A[ATraining Step: 10547  | total loss: [1m[32m0.28562[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28562 - acc: 0.8943 -- iter: 2624/3680
[A[ATraining Step: 10548  | total loss: [1m[32m0.29014[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29014 - acc: 0.8924 -- iter: 2656/3680
[A[ATraining Step: 10549  | total loss: [1m[32m0.29702[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29702 - acc: 0.8831 -- iter: 2688/3680
[A[ATraining Step: 10550  | total loss: [1m[32m0.29702[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29702 - acc: 0.8831 -- iter: 2720/3680
[A[ATraining Step: 10551  | total loss: [1m[32m0.31122[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31122 - acc: 0.8698 -- iter: 2752/3680
[A[ATraining Step: 10552  | total loss: [1m[32m0.30843[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30843 - acc: 0.8672 -- iter: 2784/3680
[A[ATraining Step: 10553  | total loss: [1m[32m0.29707[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29707 - acc: 0.8774 -- iter: 2816/3680
[A[ATraining Step: 10554  | total loss: [1m[32m0.30452[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30452 - acc: 0.8709 -- iter: 2848/3680
[A[ATraining Step: 10555  | total loss: [1m[32m0.30778[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30778 - acc: 0.8807 -- iter: 2880/3680
[A[ATraining Step: 10556  | total loss: [1m[32m0.29212[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29212 - acc: 0.8807 -- iter: 2912/3680
[A[ATraining Step: 10557  | total loss: [1m[32m0.35152[0m[0m
[2K| Adam | epoch: 092 | loss: 0.35152 - acc: 0.8833 -- iter: 2944/3680
[A[ATraining Step: 10558  | total loss: [1m[32m0.35889[0m[0m
[2K| Adam | epoch: 092 | loss: 0.35889 - acc: 0.8762 -- iter: 2976/3680
[A[ATraining Step: 10559  | total loss: [1m[32m0.34273[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34273 - acc: 0.8792 -- iter: 3008/3680
[A[ATraining Step: 10560  | total loss: [1m[32m0.34174[0m[0m
[2K| Adam | epoch: 092 | loss: 0.34174 - acc: 0.8788 -- iter: 3040/3680
[A[ATraining Step: 10561  | total loss: [1m[32m0.33697[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33697 - acc: 0.8753 -- iter: 3072/3680
[A[ATraining Step: 10562  | total loss: [1m[32m0.33322[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33322 - acc: 0.8784 -- iter: 3104/3680
[A[ATraining Step: 10563  | total loss: [1m[32m0.31638[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31638 - acc: 0.8843 -- iter: 3136/3680
[A[ATraining Step: 10564  | total loss: [1m[32m0.31480[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31480 - acc: 0.8865 -- iter: 3168/3680
[A[ATraining Step: 10565  | total loss: [1m[32m0.31214[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31214 - acc: 0.8874 -- iter: 3200/3680
[A[ATraining Step: 10566  | total loss: [1m[32m0.31214[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31214 - acc: 0.8924 -- iter: 3232/3680
[A[ATraining Step: 10567  | total loss: [1m[32m0.30070[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30070 - acc: 0.8924 -- iter: 3264/3680
[A[ATraining Step: 10568  | total loss: [1m[32m0.30923[0m[0m
[2K| Adam | epoch: 092 | loss: 0.30923 - acc: 0.8876 -- iter: 3296/3680
[A[ATraining Step: 10569  | total loss: [1m[32m0.32277[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32277 - acc: 0.8801 -- iter: 3328/3680
[A[ATraining Step: 10570  | total loss: [1m[32m0.32185[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32185 - acc: 0.8827 -- iter: 3360/3680
[A[ATraining Step: 10571  | total loss: [1m[32m0.32614[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32614 - acc: 0.8819 -- iter: 3392/3680
[A[ATraining Step: 10572  | total loss: [1m[32m0.33314[0m[0m
[2K| Adam | epoch: 092 | loss: 0.33314 - acc: 0.8875 -- iter: 3424/3680
[A[ATraining Step: 10573  | total loss: [1m[32m0.31893[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31893 - acc: 0.8873 -- iter: 3456/3680
[A[ATraining Step: 10574  | total loss: [1m[32m0.31893[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31893 - acc: 0.8873 -- iter: 3488/3680
[A[ATraining Step: 10575  | total loss: [1m[32m0.32033[0m[0m
[2K| Adam | epoch: 092 | loss: 0.32033 - acc: 0.8798 -- iter: 3520/3680
[A[ATraining Step: 10576  | total loss: [1m[32m0.31765[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31765 - acc: 0.8825 -- iter: 3552/3680
[A[ATraining Step: 10577  | total loss: [1m[32m0.31780[0m[0m
[2K| Adam | epoch: 092 | loss: 0.31780 - acc: 0.8786 -- iter: 3584/3680
[A[ATraining Step: 10578  | total loss: [1m[32m0.29794[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29794 - acc: 0.8907 -- iter: 3616/3680
[A[ATraining Step: 10579  | total loss: [1m[32m0.28972[0m[0m
[2K| Adam | epoch: 092 | loss: 0.28972 - acc: 0.8923 -- iter: 3648/3680
[A[ATraining Step: 10580  | total loss: [1m[32m0.29861[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29861 - acc: 0.8843 | val_loss: 0.33312 - val_acc: 0.8686 -- iter: 3680/3680
[A[ATraining Step: 10580  | total loss: [1m[32m0.29861[0m[0m
[2K| Adam | epoch: 092 | loss: 0.29861 - acc: 0.8843 | val_loss: 0.33312 - val_acc: 0.8686 -- iter: 3680/3680
--
Training Step: 10581  | total loss: [1m[32m0.32165[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32165 - acc: 0.8802 -- iter: 0032/3680
[A[ATraining Step: 10582  | total loss: [1m[32m0.31863[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31863 - acc: 0.8797 -- iter: 0064/3680
[A[ATraining Step: 10583  | total loss: [1m[32m0.30795[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30795 - acc: 0.8824 -- iter: 0096/3680
[A[ATraining Step: 10584  | total loss: [1m[32m0.32183[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32183 - acc: 0.8694 -- iter: 0128/3680
[A[ATraining Step: 10585  | total loss: [1m[32m0.33082[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33082 - acc: 0.8694 -- iter: 0160/3680
[A[ATraining Step: 10586  | total loss: [1m[32m0.32626[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32626 - acc: 0.8668 -- iter: 0192/3680
[A[ATraining Step: 10587  | total loss: [1m[32m0.33022[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33022 - acc: 0.8645 -- iter: 0224/3680
[A[ATraining Step: 10588  | total loss: [1m[32m0.31914[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31914 - acc: 0.8718 -- iter: 0256/3680
[A[ATraining Step: 10589  | total loss: [1m[32m0.30652[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30652 - acc: 0.8874 -- iter: 0288/3680
[A[ATraining Step: 10590  | total loss: [1m[32m0.29420[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29420 - acc: 0.8874 -- iter: 0320/3680
[A[ATraining Step: 10591  | total loss: [1m[32m0.30646[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30646 - acc: 0.8701 -- iter: 0352/3680
[A[ATraining Step: 10592  | total loss: [1m[32m0.31453[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31453 - acc: 0.8701 -- iter: 0384/3680
[A[ATraining Step: 10593  | total loss: [1m[32m0.31432[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31432 - acc: 0.8674 -- iter: 0416/3680
[A[ATraining Step: 10594  | total loss: [1m[32m0.30111[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30111 - acc: 0.8776 -- iter: 0448/3680
[A[ATraining Step: 10595  | total loss: [1m[32m0.30747[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30747 - acc: 0.8742 -- iter: 0480/3680
[A[ATraining Step: 10596  | total loss: [1m[32m0.29307[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29307 - acc: 0.8836 -- iter: 0512/3680
[A[ATraining Step: 10597  | total loss: [1m[32m0.29301[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29301 - acc: 0.8890 -- iter: 0544/3680
[A[ATraining Step: 10598  | total loss: [1m[32m0.29961[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29961 - acc: 0.8908 -- iter: 0576/3680
[A[ATraining Step: 10599  | total loss: [1m[32m0.29291[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29291 - acc: 0.8923 -- iter: 0608/3680
[A[ATraining Step: 10600  | total loss: [1m[32m0.29033[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29033 - acc: 0.8906 | val_loss: 0.00000 - val_acc: 0.0000 -- iter: 0640/3680
[A[ATraining Step: 10600  | total loss: [1m[32m0.29033[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29033 - acc: 0.8906 | val_loss: 0.00000 - val_acc: 0.0000 -- iter: 0640/3680
--
Training Step: 10601  | total loss: [1m[32m0.28454[0m[0m
[2K| Adam | epoch: 093 | loss: 0.28454 - acc: 0.8967 -- iter: 0672/3680
[A[ATraining Step: 10602  | total loss: [1m[32m0.27723[0m[0m
[2K| Adam | epoch: 093 | loss: 0.27723 - acc: 0.8967 -- iter: 0704/3680
[A[ATraining Step: 10603  | total loss: [1m[32m0.27822[0m[0m
[2K| Adam | epoch: 093 | loss: 0.27822 - acc: 0.8914 -- iter: 0736/3680
[A[ATraining Step: 10604  | total loss: [1m[32m0.27651[0m[0m
[2K| Adam | epoch: 093 | loss: 0.27651 - acc: 0.8929 -- iter: 0768/3680
[A[ATraining Step: 10605  | total loss: [1m[32m0.26812[0m[0m
[2K| Adam | epoch: 093 | loss: 0.26812 - acc: 0.9036 -- iter: 0800/3680
[A[ATraining Step: 10606  | total loss: [1m[32m0.27146[0m[0m
[2K| Adam | epoch: 093 | loss: 0.27146 - acc: 0.8945 -- iter: 0832/3680
[A[ATraining Step: 10607  | total loss: [1m[32m0.28128[0m[0m
[2K| Adam | epoch: 093 | loss: 0.28128 - acc: 0.8925 -- iter: 0864/3680
[A[ATraining Step: 10608  | total loss: [1m[32m0.29225[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29225 - acc: 0.8876 -- iter: 0896/3680
[A[ATraining Step: 10609  | total loss: [1m[32m0.29827[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29827 - acc: 0.8874 -- iter: 0928/3680
[A[ATraining Step: 10610  | total loss: [1m[32m0.29827[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29827 - acc: 0.8831 -- iter: 0960/3680
[A[ATraining Step: 10611  | total loss: [1m[32m0.29623[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29623 - acc: 0.8831 -- iter: 0992/3680
[A[ATraining Step: 10612  | total loss: [1m[32m0.31688[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31688 - acc: 0.8791 -- iter: 1024/3680
[A[ATraining Step: 10613  | total loss: [1m[32m0.31119[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31119 - acc: 0.8787 -- iter: 1056/3680
[A[ATraining Step: 10614  | total loss: [1m[32m0.30441[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30441 - acc: 0.8902 -- iter: 1088/3680
[A[ATraining Step: 10615  | total loss: [1m[32m0.29092[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29092 - acc: 0.8902 -- iter: 1120/3680
[A[ATraining Step: 10616  | total loss: [1m[32m0.32093[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32093 - acc: 0.8793 -- iter: 1152/3680
[A[ATraining Step: 10617  | total loss: [1m[32m0.33135[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33135 - acc: 0.8726 -- iter: 1184/3680
[A[ATraining Step: 10618  | total loss: [1m[32m0.34525[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34525 - acc: 0.8697 -- iter: 1216/3680
[A[ATraining Step: 10619  | total loss: [1m[32m0.34802[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34802 - acc: 0.8609 -- iter: 1248/3680
[A[ATraining Step: 10620  | total loss: [1m[32m0.33897[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33897 - acc: 0.8654 -- iter: 1280/3680
[A[ATraining Step: 10621  | total loss: [1m[32m0.33835[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33835 - acc: 0.8669 -- iter: 1312/3680
[A[ATraining Step: 10622  | total loss: [1m[32m0.35097[0m[0m
[2K| Adam | epoch: 093 | loss: 0.35097 - acc: 0.8669 -- iter: 1344/3680
[A[ATraining Step: 10623  | total loss: [1m[32m0.33992[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33992 - acc: 0.8709 -- iter: 1376/3680
[A[ATraining Step: 10624  | total loss: [1m[32m0.33010[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33010 - acc: 0.8775 -- iter: 1408/3680
[A[ATraining Step: 10625  | total loss: [1m[32m0.32491[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32491 - acc: 0.8804 -- iter: 1440/3680
[A[ATraining Step: 10626  | total loss: [1m[32m0.31208[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31208 - acc: 0.8892 -- iter: 1472/3680
[A[ATraining Step: 10627  | total loss: [1m[32m0.31125[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31125 - acc: 0.8878 -- iter: 1504/3680
[A[ATraining Step: 10628  | total loss: [1m[32m0.30800[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30800 - acc: 0.8897 -- iter: 1536/3680
[A[ATraining Step: 10629  | total loss: [1m[32m0.29575[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29575 - acc: 0.8944 -- iter: 1568/3680
[A[ATraining Step: 10630  | total loss: [1m[32m0.29637[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29637 - acc: 0.8862 -- iter: 1600/3680
[A[ATraining Step: 10631  | total loss: [1m[32m0.29322[0m[0m
[2K| Adam | epoch: 093 | loss: 0.29322 - acc: 0.8963 -- iter: 1632/3680
[A[ATraining Step: 10632  | total loss: [1m[32m0.28300[0m[0m
[2K| Adam | epoch: 093 | loss: 0.28300 - acc: 0.8963 -- iter: 1664/3680
[A[ATraining Step: 10633  | total loss: [1m[32m0.31339[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31339 - acc: 0.8785 -- iter: 1696/3680
[A[ATraining Step: 10634  | total loss: [1m[32m0.32132[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32132 - acc: 0.8813 -- iter: 1728/3680
[A[ATraining Step: 10635  | total loss: [1m[32m0.30834[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30834 - acc: 0.8813 -- iter: 1760/3680
[A[ATraining Step: 10636  | total loss: [1m[32m0.31437[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31437 - acc: 0.8776 -- iter: 1792/3680
[A[ATraining Step: 10637  | total loss: [1m[32m0.30021[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30021 - acc: 0.8802 -- iter: 1824/3680
[A[ATraining Step: 10638  | total loss: [1m[32m0.30021[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30021 - acc: 0.8802 -- iter: 1856/3680
[A[ATraining Step: 10639  | total loss: [1m[32m0.30232[0m[0m
[2K| Adam | epoch: 093 | loss: 0.30232 - acc: 0.8797 -- iter: 1888/3680
[A[ATraining Step: 10640  | total loss: [1m[32m0.41520[0m[0m
[2K| Adam | epoch: 093 | loss: 0.41520 - acc: 0.8261 -- iter: 1920/3680
[A[ATraining Step: 10641  | total loss: [1m[32m0.40687[0m[0m
[2K| Adam | epoch: 093 | loss: 0.40687 - acc: 0.8310 -- iter: 1952/3680
[A[ATraining Step: 10642  | total loss: [1m[32m0.37369[0m[0m
[2K| Adam | epoch: 093 | loss: 0.37369 - acc: 0.8453 -- iter: 1984/3680
[A[ATraining Step: 10643  | total loss: [1m[32m0.36023[0m[0m
[2K| Adam | epoch: 093 | loss: 0.36023 - acc: 0.8482 -- iter: 2016/3680
[A[ATraining Step: 10644  | total loss: [1m[32m0.36023[0m[0m
[2K| Adam | epoch: 093 | loss: 0.36023 - acc: 0.8482 -- iter: 2048/3680
[A[ATraining Step: 10645  | total loss: [1m[32m0.34896[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34896 - acc: 0.8540 -- iter: 2080/3680
[A[ATraining Step: 10646  | total loss: [1m[32m0.34380[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34380 - acc: 0.8530 -- iter: 2112/3680
[A[ATraining Step: 10647  | total loss: [1m[32m0.33565[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33565 - acc: 0.8615 -- iter: 2144/3680
[A[ATraining Step: 10648  | total loss: [1m[32m0.31967[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31967 - acc: 0.8691 -- iter: 2176/3680
[A[ATraining Step: 10649  | total loss: [1m[32m0.31937[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31937 - acc: 0.8697 -- iter: 2208/3680
[A[ATraining Step: 10650  | total loss: [1m[32m0.32552[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32552 - acc: 0.8682 -- iter: 2240/3680
[A[ATraining Step: 10651  | total loss: [1m[32m0.31722[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31722 - acc: 0.8682 -- iter: 2272/3680
[A[ATraining Step: 10652  | total loss: [1m[32m0.32005[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32005 - acc: 0.8689 -- iter: 2304/3680
[A[ATraining Step: 10653  | total loss: [1m[32m0.33473[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33473 - acc: 0.8663 -- iter: 2336/3680
[A[ATraining Step: 10654  | total loss: [1m[32m0.33312[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33312 - acc: 0.8672 -- iter: 2368/3680
[A[ATraining Step: 10655  | total loss: [1m[32m0.32322[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32322 - acc: 0.8721 -- iter: 2400/3680
[A[ATraining Step: 10656  | total loss: [1m[32m0.32322[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32322 - acc: 0.8721 -- iter: 2432/3680
[A[ATraining Step: 10657  | total loss: [1m[32m0.33149[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33149 - acc: 0.8724 -- iter: 2464/3680
[A[ATraining Step: 10658  | total loss: [1m[32m0.32166[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32166 - acc: 0.8789 -- iter: 2496/3680
[A[ATraining Step: 10659  | total loss: [1m[32m0.31302[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31302 - acc: 0.8817 -- iter: 2528/3680
[A[ATraining Step: 10660  | total loss: [1m[32m0.31166[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31166 - acc: 0.8616 -- iter: 2560/3680
[A[ATraining Step: 10661  | total loss: [1m[32m0.33385[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33385 - acc: 0.8616 -- iter: 2592/3680
[A[ATraining Step: 10662  | total loss: [1m[32m0.33354[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33354 - acc: 0.8630 -- iter: 2624/3680
[A[ATraining Step: 10663  | total loss: [1m[32m0.34057[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34057 - acc: 0.8579 -- iter: 2656/3680
[A[ATraining Step: 10664  | total loss: [1m[32m0.34407[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34407 - acc: 0.8596 -- iter: 2688/3680
[A[ATraining Step: 10665  | total loss: [1m[32m0.36681[0m[0m
[2K| Adam | epoch: 093 | loss: 0.36681 - acc: 0.8487 -- iter: 2720/3680
[A[ATraining Step: 10666  | total loss: [1m[32m0.35267[0m[0m
[2K| Adam | epoch: 093 | loss: 0.35267 - acc: 0.8624 -- iter: 2752/3680
[A[ATraining Step: 10667  | total loss: [1m[32m0.34118[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34118 - acc: 0.8624 -- iter: 2784/3680
[A[ATraining Step: 10668  | total loss: [1m[32m0.33635[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33635 - acc: 0.8668 -- iter: 2816/3680
[A[ATraining Step: 10669  | total loss: [1m[32m0.36003[0m[0m
[2K| Adam | epoch: 093 | loss: 0.36003 - acc: 0.8583 -- iter: 2848/3680
[A[ATraining Step: 10670  | total loss: [1m[32m0.34619[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34619 - acc: 0.8631 -- iter: 2880/3680
[A[ATraining Step: 10671  | total loss: [1m[32m0.34994[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34994 - acc: 0.8580 -- iter: 2912/3680
[A[ATraining Step: 10672  | total loss: [1m[32m0.34255[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34255 - acc: 0.8597 -- iter: 2944/3680
[A[ATraining Step: 10673  | total loss: [1m[32m0.34655[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34655 - acc: 0.8581 -- iter: 2976/3680
[A[ATraining Step: 10674  | total loss: [1m[32m0.34184[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34184 - acc: 0.8629 -- iter: 3008/3680
[A[ATraining Step: 10675  | total loss: [1m[32m0.32375[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32375 - acc: 0.8774 -- iter: 3040/3680
[A[ATraining Step: 10676  | total loss: [1m[32m0.32375[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32375 - acc: 0.8774 -- iter: 3072/3680
[A[ATraining Step: 10677  | total loss: [1m[32m0.33085[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33085 - acc: 0.8647 -- iter: 3104/3680
[A[ATraining Step: 10678  | total loss: [1m[32m0.33255[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33255 - acc: 0.8657 -- iter: 3136/3680
[A[ATraining Step: 10679  | total loss: [1m[32m0.33973[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33973 - acc: 0.8604 -- iter: 3168/3680
[A[ATraining Step: 10680  | total loss: [1m[32m0.33743[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33743 - acc: 0.8650 -- iter: 3200/3680
[A[ATraining Step: 10681  | total loss: [1m[32m0.31938[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31938 - acc: 0.8722 -- iter: 3232/3680
[A[ATraining Step: 10682  | total loss: [1m[32m0.33100[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33100 - acc: 0.8725 -- iter: 3264/3680
[A[ATraining Step: 10683  | total loss: [1m[32m0.32846[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32846 - acc: 0.8727 -- iter: 3296/3680
[A[ATraining Step: 10684  | total loss: [1m[32m0.32680[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32680 - acc: 0.8698 -- iter: 3328/3680
[A[ATraining Step: 10685  | total loss: [1m[32m0.33091[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33091 - acc: 0.8704 -- iter: 3360/3680
[A[ATraining Step: 10686  | total loss: [1m[32m0.33602[0m[0m
[2K| Adam | epoch: 093 | loss: 0.33602 - acc: 0.8614 -- iter: 3392/3680
[A[ATraining Step: 10687  | total loss: [1m[32m0.34864[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34864 - acc: 0.8646 -- iter: 3424/3680
[A[ATraining Step: 10688  | total loss: [1m[32m0.34864[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34864 - acc: 0.8646 -- iter: 3456/3680
[A[ATraining Step: 10689  | total loss: [1m[32m0.35351[0m[0m
[2K| Adam | epoch: 093 | loss: 0.35351 - acc: 0.8594 -- iter: 3488/3680
[A[ATraining Step: 10690  | total loss: [1m[32m0.34940[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34940 - acc: 0.8641 -- iter: 3520/3680
[A[ATraining Step: 10691  | total loss: [1m[32m0.35344[0m[0m
[2K| Adam | epoch: 093 | loss: 0.35344 - acc: 0.8652 -- iter: 3552/3680
[A[ATraining Step: 10692  | total loss: [1m[32m0.34601[0m[0m
[2K| Adam | epoch: 093 | loss: 0.34601 - acc: 0.8724 -- iter: 3584/3680
[A[ATraining Step: 10693  | total loss: [1m[32m0.32824[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32824 - acc: 0.8821 -- iter: 3616/3680
[A[ATraining Step: 10694  | total loss: [1m[32m0.32083[0m[0m
[2K| Adam | epoch: 093 | loss: 0.32083 - acc: 0.8845 -- iter: 3648/3680
[A[ATraining Step: 10695  | total loss: [1m[32m0.31539[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31539 - acc: 0.8835 | val_loss: 0.27889 - val_acc: 0.9055 -- iter: 3680/3680
[A[ATraining Step: 10695  | total loss: [1m[32m0.31539[0m[0m
[2K| Adam | epoch: 093 | loss: 0.31539 - acc: 0.8835 | val_loss: 0.27889 - val_acc: 0.9055 -- iter: 3680/3680
--
Training Step: 10696  | total loss: [1m[32m0.31455[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31455 - acc: 0.8827 -- iter: 0032/3680
[A[ATraining Step: 10697  | total loss: [1m[32m0.31276[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31276 - acc: 0.8850 -- iter: 0064/3680
[A[ATraining Step: 10698  | total loss: [1m[32m0.32677[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32677 - acc: 0.8778 -- iter: 0096/3680
[A[ATraining Step: 10699  | total loss: [1m[32m0.32061[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32061 - acc: 0.8775 -- iter: 0128/3680
[A[ATraining Step: 10700  | total loss: [1m[32m0.32114[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32114 - acc: 0.8773 | val_loss: 0.28355 - val_acc: 0.9001 -- iter: 0160/3680
[A[ATraining Step: 10700  | total loss: [1m[32m0.32114[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32114 - acc: 0.8773 | val_loss: 0.28355 - val_acc: 0.9001 -- iter: 0160/3680
--
Training Step: 10701  | total loss: [1m[32m0.40030[0m[0m
[2K| Adam | epoch: 094 | loss: 0.40030 - acc: 0.8645 -- iter: 0192/3680
[A[ATraining Step: 10702  | total loss: [1m[32m0.39258[0m[0m
[2K| Adam | epoch: 094 | loss: 0.39258 - acc: 0.8656 -- iter: 0224/3680
[A[ATraining Step: 10703  | total loss: [1m[32m0.39492[0m[0m
[2K| Adam | epoch: 094 | loss: 0.39492 - acc: 0.8665 -- iter: 0256/3680
[A[ATraining Step: 10704  | total loss: [1m[32m0.37513[0m[0m
[2K| Adam | epoch: 094 | loss: 0.37513 - acc: 0.8736 -- iter: 0288/3680
[A[ATraining Step: 10705  | total loss: [1m[32m0.36486[0m[0m
[2K| Adam | epoch: 094 | loss: 0.36486 - acc: 0.8738 -- iter: 0320/3680
[A[ATraining Step: 10706  | total loss: [1m[32m0.36341[0m[0m
[2K| Adam | epoch: 094 | loss: 0.36341 - acc: 0.8708 -- iter: 0352/3680
[A[ATraining Step: 10707  | total loss: [1m[32m0.36644[0m[0m
[2K| Adam | epoch: 094 | loss: 0.36644 - acc: 0.8681 -- iter: 0384/3680
[A[ATraining Step: 10708  | total loss: [1m[32m0.36508[0m[0m
[2K| Adam | epoch: 094 | loss: 0.36508 - acc: 0.8625 -- iter: 0416/3680
[A[ATraining Step: 10709  | total loss: [1m[32m0.34406[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34406 - acc: 0.8708 -- iter: 0448/3680
[A[ATraining Step: 10710  | total loss: [1m[32m0.34406[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34406 - acc: 0.8708 -- iter: 0480/3680
[A[ATraining Step: 10711  | total loss: [1m[32m0.33614[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33614 - acc: 0.8807 -- iter: 0512/3680
[A[ATraining Step: 10712  | total loss: [1m[32m0.33129[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33129 - acc: 0.8832 -- iter: 0544/3680
[A[ATraining Step: 10713  | total loss: [1m[32m0.32898[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32898 - acc: 0.8832 -- iter: 0576/3680
[A[ATraining Step: 10714  | total loss: [1m[32m0.31730[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31730 - acc: 0.8887 -- iter: 0608/3680
[A[ATraining Step: 10715  | total loss: [1m[32m0.32890[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32890 - acc: 0.8873 -- iter: 0640/3680
[A[ATraining Step: 10716  | total loss: [1m[32m0.32643[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32643 - acc: 0.8861 -- iter: 0672/3680
[A[ATraining Step: 10717  | total loss: [1m[32m0.34005[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34005 - acc: 0.8752 -- iter: 0704/3680
[A[ATraining Step: 10718  | total loss: [1m[32m0.34003[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34003 - acc: 0.8689 -- iter: 0736/3680
[A[ATraining Step: 10719  | total loss: [1m[32m0.35501[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35501 - acc: 0.8689 -- iter: 0768/3680
[A[ATraining Step: 10720  | total loss: [1m[32m0.34793[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34793 - acc: 0.8664 -- iter: 0800/3680
[A[ATraining Step: 10721  | total loss: [1m[32m0.32627[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32627 - acc: 0.8798 -- iter: 0832/3680
[A[ATraining Step: 10722  | total loss: [1m[32m0.31053[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31053 - acc: 0.8918 -- iter: 0864/3680
[A[ATraining Step: 10723  | total loss: [1m[32m0.32526[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32526 - acc: 0.8839 -- iter: 0896/3680
[A[ATraining Step: 10724  | total loss: [1m[32m0.33031[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33031 - acc: 0.8799 -- iter: 0928/3680
[A[ATraining Step: 10725  | total loss: [1m[32m0.31976[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31976 - acc: 0.8887 -- iter: 0960/3680
[A[ATraining Step: 10726  | total loss: [1m[32m0.31455[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31455 - acc: 0.8936 -- iter: 0992/3680
[A[ATraining Step: 10727  | total loss: [1m[32m0.30756[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30756 - acc: 0.8873 -- iter: 1024/3680
[A[ATraining Step: 10728  | total loss: [1m[32m0.30468[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30468 - acc: 0.8829 -- iter: 1056/3680
[A[ATraining Step: 10729  | total loss: [1m[32m0.30468[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30468 - acc: 0.8829 -- iter: 1088/3680
[A[ATraining Step: 10730  | total loss: [1m[32m0.31279[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31279 - acc: 0.8759 -- iter: 1120/3680
[A[ATraining Step: 10731  | total loss: [1m[32m0.33124[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33124 - acc: 0.8727 -- iter: 1152/3680
[A[ATraining Step: 10732  | total loss: [1m[32m0.34193[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34193 - acc: 0.8666 -- iter: 1184/3680
[A[ATraining Step: 10733  | total loss: [1m[32m0.33304[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33304 - acc: 0.8737 -- iter: 1216/3680
[A[ATraining Step: 10734  | total loss: [1m[32m0.31665[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31665 - acc: 0.8832 -- iter: 1248/3680
[A[ATraining Step: 10735  | total loss: [1m[32m0.32150[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32150 - acc: 0.8824 -- iter: 1280/3680
[A[ATraining Step: 10736  | total loss: [1m[32m0.34061[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34061 - acc: 0.8723 -- iter: 1312/3680
[A[ATraining Step: 10737  | total loss: [1m[32m0.34572[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34572 - acc: 0.8663 -- iter: 1344/3680
[A[ATraining Step: 10738  | total loss: [1m[32m0.37654[0m[0m
[2K| Adam | epoch: 094 | loss: 0.37654 - acc: 0.8547 -- iter: 1376/3680
[A[ATraining Step: 10739  | total loss: [1m[32m0.35601[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35601 - acc: 0.8630 -- iter: 1408/3680
[A[ATraining Step: 10740  | total loss: [1m[32m0.34024[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34024 - acc: 0.8673 -- iter: 1440/3680
[A[ATraining Step: 10741  | total loss: [1m[32m0.33467[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33467 - acc: 0.8712 -- iter: 1472/3680
[A[ATraining Step: 10742  | total loss: [1m[32m0.34639[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34639 - acc: 0.8622 -- iter: 1504/3680
[A[ATraining Step: 10743  | total loss: [1m[32m0.34400[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34400 - acc: 0.8666 -- iter: 1536/3680
[A[ATraining Step: 10744  | total loss: [1m[32m0.32661[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32661 - acc: 0.8768 -- iter: 1568/3680
[A[ATraining Step: 10745  | total loss: [1m[32m0.32160[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32160 - acc: 0.8766 -- iter: 1600/3680
[A[ATraining Step: 10746  | total loss: [1m[32m0.31155[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31155 - acc: 0.8827 -- iter: 1632/3680
[A[ATraining Step: 10747  | total loss: [1m[32m0.30874[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30874 - acc: 0.8819 -- iter: 1664/3680
[A[ATraining Step: 10748  | total loss: [1m[32m0.30021[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30021 - acc: 0.8875 -- iter: 1696/3680
[A[ATraining Step: 10749  | total loss: [1m[32m0.30393[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30393 - acc: 0.8831 -- iter: 1728/3680
[A[ATraining Step: 10750  | total loss: [1m[32m0.29176[0m[0m
[2K| Adam | epoch: 094 | loss: 0.29176 - acc: 0.8886 -- iter: 1760/3680
[A[ATraining Step: 10751  | total loss: [1m[32m0.28328[0m[0m
[2K| Adam | epoch: 094 | loss: 0.28328 - acc: 0.8966 -- iter: 1792/3680
[A[ATraining Step: 10752  | total loss: [1m[32m0.28306[0m[0m
[2K| Adam | epoch: 094 | loss: 0.28306 - acc: 0.8944 -- iter: 1824/3680
[A[ATraining Step: 10753  | total loss: [1m[32m0.30106[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30106 - acc: 0.8862 -- iter: 1856/3680
[A[ATraining Step: 10754  | total loss: [1m[32m0.29955[0m[0m
[2K| Adam | epoch: 094 | loss: 0.29955 - acc: 0.8882 -- iter: 1888/3680
[A[ATraining Step: 10755  | total loss: [1m[32m0.30871[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30871 - acc: 0.8900 -- iter: 1920/3680
[A[ATraining Step: 10756  | total loss: [1m[32m0.31381[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31381 - acc: 0.8854 -- iter: 1952/3680
[A[ATraining Step: 10757  | total loss: [1m[32m0.30506[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30506 - acc: 0.8875 -- iter: 1984/3680
[A[ATraining Step: 10758  | total loss: [1m[32m0.30320[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30320 - acc: 0.8831 -- iter: 2016/3680
[A[ATraining Step: 10759  | total loss: [1m[32m0.30109[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30109 - acc: 0.8792 -- iter: 2048/3680
[A[ATraining Step: 10760  | total loss: [1m[32m0.28631[0m[0m
[2K| Adam | epoch: 094 | loss: 0.28631 - acc: 0.8881 -- iter: 2080/3680
[A[ATraining Step: 10761  | total loss: [1m[32m0.29539[0m[0m
[2K| Adam | epoch: 094 | loss: 0.29539 - acc: 0.8806 -- iter: 2112/3680
[A[ATraining Step: 10762  | total loss: [1m[32m0.31011[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31011 - acc: 0.8738 -- iter: 2144/3680
[A[ATraining Step: 10763  | total loss: [1m[32m0.31944[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31944 - acc: 0.8739 -- iter: 2176/3680
[A[ATraining Step: 10764  | total loss: [1m[32m0.31823[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31823 - acc: 0.8709 -- iter: 2208/3680
[A[ATraining Step: 10765  | total loss: [1m[32m0.32703[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32703 - acc: 0.8720 -- iter: 2240/3680
[A[ATraining Step: 10766  | total loss: [1m[32m0.32703[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32703 - acc: 0.8720 -- iter: 2272/3680
[A[ATraining Step: 10767  | total loss: [1m[32m0.31699[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31699 - acc: 0.8785 -- iter: 2304/3680
[A[ATraining Step: 10768  | total loss: [1m[32m0.32731[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32731 - acc: 0.8807 -- iter: 2336/3680
[A[ATraining Step: 10769  | total loss: [1m[32m0.39725[0m[0m
[2K| Adam | epoch: 094 | loss: 0.39725 - acc: 0.8807 -- iter: 2368/3680
[A[ATraining Step: 10770  | total loss: [1m[32m0.46276[0m[0m
[2K| Adam | epoch: 094 | loss: 0.46276 - acc: 0.8645 -- iter: 2400/3680
[A[ATraining Step: 10771  | total loss: [1m[32m0.46086[0m[0m
[2K| Adam | epoch: 094 | loss: 0.46086 - acc: 0.8624 -- iter: 2432/3680
[A[ATraining Step: 10772  | total loss: [1m[32m0.43716[0m[0m
[2K| Adam | epoch: 094 | loss: 0.43716 - acc: 0.8668 -- iter: 2464/3680
[A[ATraining Step: 10773  | total loss: [1m[32m0.41702[0m[0m
[2K| Adam | epoch: 094 | loss: 0.41702 - acc: 0.8739 -- iter: 2496/3680
[A[ATraining Step: 10774  | total loss: [1m[32m0.40919[0m[0m
[2K| Adam | epoch: 094 | loss: 0.40919 - acc: 0.8771 -- iter: 2528/3680
[A[ATraining Step: 10775  | total loss: [1m[32m0.42481[0m[0m
[2K| Adam | epoch: 094 | loss: 0.42481 - acc: 0.8738 -- iter: 2560/3680
[A[ATraining Step: 10776  | total loss: [1m[32m0.39987[0m[0m
[2K| Adam | epoch: 094 | loss: 0.39987 - acc: 0.8801 -- iter: 2592/3680
[A[ATraining Step: 10777  | total loss: [1m[32m0.37750[0m[0m
[2K| Adam | epoch: 094 | loss: 0.37750 - acc: 0.8785 -- iter: 2624/3680
[A[ATraining Step: 10778  | total loss: [1m[32m0.37868[0m[0m
[2K| Adam | epoch: 094 | loss: 0.37868 - acc: 0.8785 -- iter: 2656/3680
[A[ATraining Step: 10779  | total loss: [1m[32m0.38033[0m[0m
[2K| Adam | epoch: 094 | loss: 0.38033 - acc: 0.8719 -- iter: 2688/3680
[A[ATraining Step: 10780  | total loss: [1m[32m0.37075[0m[0m
[2K| Adam | epoch: 094 | loss: 0.37075 - acc: 0.8754 -- iter: 2720/3680
[A[ATraining Step: 10781  | total loss: [1m[32m0.35075[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35075 - acc: 0.8847 -- iter: 2752/3680
[A[ATraining Step: 10782  | total loss: [1m[32m0.34356[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34356 - acc: 0.8797 -- iter: 2784/3680
[A[ATraining Step: 10783  | total loss: [1m[32m0.35065[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35065 - acc: 0.8797 -- iter: 2816/3680
[A[ATraining Step: 10784  | total loss: [1m[32m0.33966[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33966 - acc: 0.8855 -- iter: 2848/3680
[A[ATraining Step: 10785  | total loss: [1m[32m0.34089[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34089 - acc: 0.8845 -- iter: 2880/3680
[A[ATraining Step: 10786  | total loss: [1m[32m0.33625[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33625 - acc: 0.8804 -- iter: 2912/3680
[A[ATraining Step: 10787  | total loss: [1m[32m0.32390[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32390 - acc: 0.8861 -- iter: 2944/3680
[A[ATraining Step: 10788  | total loss: [1m[32m0.32773[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32773 - acc: 0.8787 -- iter: 2976/3680
[A[ATraining Step: 10789  | total loss: [1m[32m0.32864[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32864 - acc: 0.8784 -- iter: 3008/3680
[A[ATraining Step: 10790  | total loss: [1m[32m0.33730[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33730 - acc: 0.8687 -- iter: 3040/3680
[A[ATraining Step: 10791  | total loss: [1m[32m0.34979[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34979 - acc: 0.8630 -- iter: 3072/3680
[A[ATraining Step: 10792  | total loss: [1m[32m0.35559[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35559 - acc: 0.8580 -- iter: 3104/3680
[A[ATraining Step: 10793  | total loss: [1m[32m0.36863[0m[0m
[2K| Adam | epoch: 094 | loss: 0.36863 - acc: 0.8566 -- iter: 3136/3680
[A[ATraining Step: 10794  | total loss: [1m[32m0.35835[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35835 - acc: 0.8615 -- iter: 3168/3680
[A[ATraining Step: 10795  | total loss: [1m[32m0.35200[0m[0m
[2K| Adam | epoch: 094 | loss: 0.35200 - acc: 0.8629 -- iter: 3200/3680
[A[ATraining Step: 10796  | total loss: [1m[32m0.33536[0m[0m
[2K| Adam | epoch: 094 | loss: 0.33536 - acc: 0.8672 -- iter: 3232/3680
[A[ATraining Step: 10797  | total loss: [1m[32m0.31957[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31957 - acc: 0.8742 -- iter: 3264/3680
[A[ATraining Step: 10798  | total loss: [1m[32m0.31030[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31030 - acc: 0.8806 -- iter: 3296/3680
[A[ATraining Step: 10799  | total loss: [1m[32m0.30753[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30753 - acc: 0.8831 -- iter: 3328/3680
[A[ATraining Step: 10800  | total loss: [1m[32m0.31680[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31680 - acc: 0.8819 | val_loss: 0.28739 - val_acc: 0.8903 -- iter: 3360/3680
[A[ATraining Step: 10800  | total loss: [1m[32m0.31680[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31680 - acc: 0.8819 | val_loss: 0.28739 - val_acc: 0.8903 -- iter: 3360/3680
--
Training Step: 10801  | total loss: [1m[32m0.30992[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30992 - acc: 0.8819 -- iter: 3392/3680
[A[ATraining Step: 10802  | total loss: [1m[32m0.29982[0m[0m
[2K| Adam | epoch: 094 | loss: 0.29982 - acc: 0.8843 -- iter: 3424/3680
[A[ATraining Step: 10803  | total loss: [1m[32m0.29766[0m[0m
[2K| Adam | epoch: 094 | loss: 0.29766 - acc: 0.8834 -- iter: 3456/3680
[A[ATraining Step: 10804  | total loss: [1m[32m0.30186[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30186 - acc: 0.8794 -- iter: 3488/3680
[A[ATraining Step: 10805  | total loss: [1m[32m0.30960[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30960 - acc: 0.8759 -- iter: 3520/3680
[A[ATraining Step: 10806  | total loss: [1m[32m0.30421[0m[0m
[2K| Adam | epoch: 094 | loss: 0.30421 - acc: 0.8820 -- iter: 3552/3680
[A[ATraining Step: 10807  | total loss: [1m[32m0.31742[0m[0m
[2K| Adam | epoch: 094 | loss: 0.31742 - acc: 0.8782 -- iter: 3584/3680
[A[ATraining Step: 10808  | total loss: [1m[32m0.32694[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32694 - acc: 0.8716 -- iter: 3616/3680
[A[ATraining Step: 10809  | total loss: [1m[32m0.32119[0m[0m
[2K| Adam | epoch: 094 | loss: 0.32119 - acc: 0.8751 -- iter: 3648/3680
[A[ATraining Step: 10810  | total loss: [1m[32m0.34731[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34731 - acc: 0.8688 | val_loss: 0.27437 - val_acc: 0.9131 -- iter: 3680/3680
[A[ATraining Step: 10810  | total loss: [1m[32m0.34731[0m[0m
[2K| Adam | epoch: 094 | loss: 0.34731 - acc: 0.8688 | val_loss: 0.27437 - val_acc: 0.9131 -- iter: 3680/3680
--
Training Step: 10811  | total loss: [1m[32m0.34273[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34273 - acc: 0.8695 -- iter: 0032/3680
[A[ATraining Step: 10812  | total loss: [1m[32m0.34877[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34877 - acc: 0.8669 -- iter: 0064/3680
[A[ATraining Step: 10813  | total loss: [1m[32m0.34863[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34863 - acc: 0.8614 -- iter: 0096/3680
[A[ATraining Step: 10814  | total loss: [1m[32m0.34921[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34921 - acc: 0.8628 -- iter: 0128/3680
[A[ATraining Step: 10815  | total loss: [1m[32m0.34048[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34048 - acc: 0.8671 -- iter: 0160/3680
[A[ATraining Step: 10816  | total loss: [1m[32m0.34458[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34458 - acc: 0.8648 -- iter: 0192/3680
[A[ATraining Step: 10817  | total loss: [1m[32m0.33590[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33590 - acc: 0.8689 -- iter: 0224/3680
[A[ATraining Step: 10818  | total loss: [1m[32m0.32201[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32201 - acc: 0.8727 -- iter: 0256/3680
[A[ATraining Step: 10819  | total loss: [1m[32m0.32646[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32646 - acc: 0.8667 -- iter: 0288/3680
[A[ATraining Step: 10820  | total loss: [1m[32m0.33397[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33397 - acc: 0.8581 -- iter: 0320/3680
[A[ATraining Step: 10821  | total loss: [1m[32m0.32120[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32120 - acc: 0.8661 -- iter: 0352/3680
[A[ATraining Step: 10822  | total loss: [1m[32m0.32207[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32207 - acc: 0.8670 -- iter: 0384/3680
[A[ATraining Step: 10823  | total loss: [1m[32m0.31831[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31831 - acc: 0.8740 -- iter: 0416/3680
[A[ATraining Step: 10824  | total loss: [1m[32m0.34279[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34279 - acc: 0.8616 -- iter: 0448/3680
[A[ATraining Step: 10825  | total loss: [1m[32m0.30976[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30976 - acc: 0.8817 -- iter: 0480/3680
[A[ATraining Step: 10826  | total loss: [1m[32m0.30976[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30976 - acc: 0.8817 -- iter: 0512/3680
[A[ATraining Step: 10827  | total loss: [1m[32m0.32521[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32521 - acc: 0.8747 -- iter: 0544/3680
[A[ATraining Step: 10828  | total loss: [1m[32m0.32521[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32521 - acc: 0.8779 -- iter: 0576/3680
[A[ATraining Step: 10829  | total loss: [1m[32m0.33143[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33143 - acc: 0.8713 -- iter: 0608/3680
[A[ATraining Step: 10830  | total loss: [1m[32m0.31953[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31953 - acc: 0.8811 -- iter: 0640/3680
[A[ATraining Step: 10831  | total loss: [1m[32m0.31656[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31656 - acc: 0.8774 -- iter: 0672/3680
[A[ATraining Step: 10832  | total loss: [1m[32m0.31273[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31273 - acc: 0.8740 -- iter: 0704/3680
[A[ATraining Step: 10833  | total loss: [1m[32m0.28668[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28668 - acc: 0.8836 -- iter: 0736/3680
[A[ATraining Step: 10834  | total loss: [1m[32m0.28668[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28668 - acc: 0.8836 -- iter: 0768/3680
[A[ATraining Step: 10835  | total loss: [1m[32m0.29042[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29042 - acc: 0.8858 -- iter: 0800/3680
[A[ATraining Step: 10836  | total loss: [1m[32m0.29220[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29220 - acc: 0.8847 -- iter: 0832/3680
[A[ATraining Step: 10837  | total loss: [1m[32m0.29745[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29745 - acc: 0.8806 -- iter: 0864/3680
[A[ATraining Step: 10838  | total loss: [1m[32m0.30927[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30927 - acc: 0.8832 -- iter: 0896/3680
[A[ATraining Step: 10839  | total loss: [1m[32m0.29370[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29370 - acc: 0.8918 -- iter: 0928/3680
[A[ATraining Step: 10840  | total loss: [1m[32m0.29831[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29831 - acc: 0.8851 -- iter: 0960/3680
[A[ATraining Step: 10841  | total loss: [1m[32m0.29831[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29831 - acc: 0.8851 -- iter: 0992/3680
[A[ATraining Step: 10842  | total loss: [1m[32m0.29516[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29516 - acc: 0.8904 -- iter: 1024/3680
[A[ATraining Step: 10843  | total loss: [1m[32m0.29006[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29006 - acc: 0.8920 -- iter: 1056/3680
[A[ATraining Step: 10844  | total loss: [1m[32m0.28919[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28919 - acc: 0.8934 -- iter: 1088/3680
[A[ATraining Step: 10845  | total loss: [1m[32m0.31126[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31126 - acc: 0.8777 -- iter: 1120/3680
[A[ATraining Step: 10846  | total loss: [1m[32m0.31126[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31126 - acc: 0.8777 -- iter: 1152/3680
[A[ATraining Step: 10847  | total loss: [1m[32m0.35072[0m[0m
[2K| Adam | epoch: 095 | loss: 0.35072 - acc: 0.8556 -- iter: 1184/3680
[A[ATraining Step: 10848  | total loss: [1m[32m0.34360[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34360 - acc: 0.8669 -- iter: 1216/3680
[A[ATraining Step: 10849  | total loss: [1m[32m0.32885[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32885 - acc: 0.8771 -- iter: 1248/3680
[A[ATraining Step: 10850  | total loss: [1m[32m0.32082[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32082 - acc: 0.8800 -- iter: 1280/3680
[A[ATraining Step: 10851  | total loss: [1m[32m0.31358[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31358 - acc: 0.8795 -- iter: 1312/3680
[A[ATraining Step: 10852  | total loss: [1m[32m0.32568[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32568 - acc: 0.8759 -- iter: 1344/3680
[A[ATraining Step: 10853  | total loss: [1m[32m0.35384[0m[0m
[2K| Adam | epoch: 095 | loss: 0.35384 - acc: 0.8539 -- iter: 1376/3680
[A[ATraining Step: 10854  | total loss: [1m[32m0.35643[0m[0m
[2K| Adam | epoch: 095 | loss: 0.35643 - acc: 0.8467 -- iter: 1408/3680
[A[ATraining Step: 10855  | total loss: [1m[32m0.36138[0m[0m
[2K| Adam | epoch: 095 | loss: 0.36138 - acc: 0.8495 -- iter: 1440/3680
[A[ATraining Step: 10856  | total loss: [1m[32m0.35070[0m[0m
[2K| Adam | epoch: 095 | loss: 0.35070 - acc: 0.8552 -- iter: 1472/3680
[A[ATraining Step: 10857  | total loss: [1m[32m0.33960[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33960 - acc: 0.8603 -- iter: 1504/3680
[A[ATraining Step: 10858  | total loss: [1m[32m0.33771[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33771 - acc: 0.8680 -- iter: 1536/3680
[A[ATraining Step: 10859  | total loss: [1m[32m0.33451[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33451 - acc: 0.8656 -- iter: 1568/3680
[A[ATraining Step: 10860  | total loss: [1m[32m0.32183[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32183 - acc: 0.8665 -- iter: 1600/3680
[A[ATraining Step: 10861  | total loss: [1m[32m0.31356[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31356 - acc: 0.8716 -- iter: 1632/3680
[A[ATraining Step: 10862  | total loss: [1m[32m0.30136[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30136 - acc: 0.8716 -- iter: 1664/3680
[A[ATraining Step: 10863  | total loss: [1m[32m0.29798[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29798 - acc: 0.8688 -- iter: 1696/3680
[A[ATraining Step: 10864  | total loss: [1m[32m0.29895[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29895 - acc: 0.8688 -- iter: 1728/3680
[A[ATraining Step: 10865  | total loss: [1m[32m0.30439[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30439 - acc: 0.8663 -- iter: 1760/3680
[A[ATraining Step: 10866  | total loss: [1m[32m0.32298[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32298 - acc: 0.8609 -- iter: 1792/3680
[A[ATraining Step: 10867  | total loss: [1m[32m0.31616[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31616 - acc: 0.8623 -- iter: 1824/3680
[A[ATraining Step: 10868  | total loss: [1m[32m0.32481[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32481 - acc: 0.8667 -- iter: 1856/3680
[A[ATraining Step: 10869  | total loss: [1m[32m0.33405[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33405 - acc: 0.8675 -- iter: 1888/3680
[A[ATraining Step: 10870  | total loss: [1m[32m0.33589[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33589 - acc: 0.8620 -- iter: 1920/3680
[A[ATraining Step: 10871  | total loss: [1m[32m0.34890[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34890 - acc: 0.8540 -- iter: 1952/3680
[A[ATraining Step: 10872  | total loss: [1m[32m0.34589[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34589 - acc: 0.8561 -- iter: 1984/3680
[A[ATraining Step: 10873  | total loss: [1m[32m0.37342[0m[0m
[2K| Adam | epoch: 095 | loss: 0.37342 - acc: 0.8298 -- iter: 2016/3680
[A[ATraining Step: 10874  | total loss: [1m[32m0.37325[0m[0m
[2K| Adam | epoch: 095 | loss: 0.37325 - acc: 0.8343 -- iter: 2048/3680
[A[ATraining Step: 10875  | total loss: [1m[32m0.36732[0m[0m
[2K| Adam | epoch: 095 | loss: 0.36732 - acc: 0.8389 -- iter: 2080/3680
[A[ATraining Step: 10876  | total loss: [1m[32m0.36120[0m[0m
[2K| Adam | epoch: 095 | loss: 0.36120 - acc: 0.8389 -- iter: 2112/3680
[A[ATraining Step: 10877  | total loss: [1m[32m0.35792[0m[0m
[2K| Adam | epoch: 095 | loss: 0.35792 - acc: 0.8363 -- iter: 2144/3680
[A[ATraining Step: 10878  | total loss: [1m[32m0.36415[0m[0m
[2K| Adam | epoch: 095 | loss: 0.36415 - acc: 0.8370 -- iter: 2176/3680
[A[ATraining Step: 10879  | total loss: [1m[32m0.34931[0m[0m
[2K| Adam | epoch: 095 | loss: 0.34931 - acc: 0.8471 -- iter: 2208/3680
[A[ATraining Step: 10880  | total loss: [1m[32m0.32999[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32999 - acc: 0.8593 -- iter: 2240/3680
[A[ATraining Step: 10881  | total loss: [1m[32m0.33197[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33197 - acc: 0.8640 -- iter: 2272/3680
[A[ATraining Step: 10882  | total loss: [1m[32m0.32180[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32180 - acc: 0.8713 -- iter: 2304/3680
[A[ATraining Step: 10883  | total loss: [1m[32m0.31719[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31719 - acc: 0.8779 -- iter: 2336/3680
[A[ATraining Step: 10884  | total loss: [1m[32m0.31613[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31613 - acc: 0.8779 -- iter: 2368/3680
[A[ATraining Step: 10885  | total loss: [1m[32m0.31738[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31738 - acc: 0.8714 -- iter: 2400/3680
[A[ATraining Step: 10886  | total loss: [1m[32m0.32578[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32578 - acc: 0.8686 -- iter: 2432/3680
[A[ATraining Step: 10887  | total loss: [1m[32m0.31727[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31727 - acc: 0.8724 -- iter: 2464/3680
[A[ATraining Step: 10888  | total loss: [1m[32m0.30508[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30508 - acc: 0.8820 -- iter: 2496/3680
[A[ATraining Step: 10889  | total loss: [1m[32m0.28760[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28760 - acc: 0.8938 -- iter: 2528/3680
[A[ATraining Step: 10890  | total loss: [1m[32m0.30743[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30743 - acc: 0.8809 -- iter: 2560/3680
[A[ATraining Step: 10891  | total loss: [1m[32m0.30743[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30743 - acc: 0.8809 -- iter: 2592/3680
[A[ATraining Step: 10892  | total loss: [1m[32m0.30309[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30309 - acc: 0.8803 -- iter: 2624/3680
[A[ATraining Step: 10893  | total loss: [1m[32m0.29078[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29078 - acc: 0.8829 -- iter: 2656/3680
[A[ATraining Step: 10894  | total loss: [1m[32m0.28427[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28427 - acc: 0.8821 -- iter: 2688/3680
[A[ATraining Step: 10895  | total loss: [1m[32m0.27993[0m[0m
[2K| Adam | epoch: 095 | loss: 0.27993 - acc: 0.8783 -- iter: 2720/3680
[A[ATraining Step: 10896  | total loss: [1m[32m0.27993[0m[0m
[2K| Adam | epoch: 095 | loss: 0.27993 - acc: 0.8842 -- iter: 2752/3680
[A[ATraining Step: 10897  | total loss: [1m[32m0.28526[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28526 - acc: 0.8884 -- iter: 2784/3680
[A[ATraining Step: 10898  | total loss: [1m[32m0.27773[0m[0m
[2K| Adam | epoch: 095 | loss: 0.27773 - acc: 0.8884 -- iter: 2816/3680
[A[ATraining Step: 10899  | total loss: [1m[32m0.29687[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29687 - acc: 0.8768 -- iter: 2848/3680
[A[ATraining Step: 10900  | total loss: [1m[32m0.30460[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30460 - acc: 0.8797 | val_loss: 0.30112 - val_acc: 0.8827 -- iter: 2880/3680
[A[ATraining Step: 10900  | total loss: [1m[32m0.30460[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30460 - acc: 0.8797 | val_loss: 0.30112 - val_acc: 0.8827 -- iter: 2880/3680
--
Training Step: 10901  | total loss: [1m[32m0.30460[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30460 - acc: 0.8797 -- iter: 2912/3680
[A[ATraining Step: 10902  | total loss: [1m[32m0.31814[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31814 - acc: 0.8667 -- iter: 2944/3680
[A[ATraining Step: 10903  | total loss: [1m[32m0.32490[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32490 - acc: 0.8661 -- iter: 2976/3680
[A[ATraining Step: 10904  | total loss: [1m[32m0.32426[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32426 - acc: 0.8661 -- iter: 3008/3680
[A[ATraining Step: 10905  | total loss: [1m[32m0.31606[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31606 - acc: 0.8733 -- iter: 3040/3680
[A[ATraining Step: 10906  | total loss: [1m[32m0.32048[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32048 - acc: 0.8703 -- iter: 3072/3680
[A[ATraining Step: 10907  | total loss: [1m[32m0.32109[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32109 - acc: 0.8708 -- iter: 3104/3680
[A[ATraining Step: 10908  | total loss: [1m[32m0.33935[0m[0m
[2K| Adam | epoch: 095 | loss: 0.33935 - acc: 0.8650 -- iter: 3136/3680
[A[ATraining Step: 10909  | total loss: [1m[32m0.32410[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32410 - acc: 0.8753 -- iter: 3168/3680
[A[ATraining Step: 10910  | total loss: [1m[32m0.31856[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31856 - acc: 0.8753 -- iter: 3200/3680
[A[ATraining Step: 10911  | total loss: [1m[32m0.31197[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31197 - acc: 0.8753 -- iter: 3232/3680
[A[ATraining Step: 10912  | total loss: [1m[32m0.31360[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31360 - acc: 0.8690 -- iter: 3264/3680
[A[ATraining Step: 10913  | total loss: [1m[32m0.31322[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31322 - acc: 0.8696 -- iter: 3296/3680
[A[ATraining Step: 10914  | total loss: [1m[32m0.30873[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30873 - acc: 0.8701 -- iter: 3328/3680
[A[ATraining Step: 10915  | total loss: [1m[32m0.30645[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30645 - acc: 0.8737 -- iter: 3360/3680
[A[ATraining Step: 10916  | total loss: [1m[32m0.31191[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31191 - acc: 0.8740 -- iter: 3392/3680
[A[ATraining Step: 10917  | total loss: [1m[32m0.29566[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29566 - acc: 0.8866 -- iter: 3424/3680
[A[ATraining Step: 10918  | total loss: [1m[32m0.29566[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29566 - acc: 0.8866 -- iter: 3456/3680
[A[ATraining Step: 10919  | total loss: [1m[32m0.28680[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28680 - acc: 0.8917 -- iter: 3488/3680
[A[ATraining Step: 10920  | total loss: [1m[32m0.29245[0m[0m
[2K| Adam | epoch: 095 | loss: 0.29245 - acc: 0.8838 -- iter: 3520/3680
[A[ATraining Step: 10921  | total loss: [1m[32m0.28185[0m[0m
[2K| Adam | epoch: 095 | loss: 0.28185 - acc: 0.8860 -- iter: 3552/3680
[A[ATraining Step: 10922  | total loss: [1m[32m0.30127[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30127 - acc: 0.8755 -- iter: 3584/3680
[A[ATraining Step: 10923  | total loss: [1m[32m0.30732[0m[0m
[2K| Adam | epoch: 095 | loss: 0.30732 - acc: 0.8692 -- iter: 3616/3680
[A[ATraining Step: 10924  | total loss: [1m[32m0.32189[0m[0m
[2K| Adam | epoch: 095 | loss: 0.32189 - acc: 0.8636 -- iter: 3648/3680
[A[ATraining Step: 10925  | total loss: [1m[32m0.31065[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31065 - acc: 0.8741 | val_loss: 0.27875 - val_acc: 0.9034 -- iter: 3680/3680
[A[ATraining Step: 10925  | total loss: [1m[32m0.31065[0m[0m
[2K| Adam | epoch: 095 | loss: 0.31065 - acc: 0.8741 | val_loss: 0.27875 - val_acc: 0.9034 -- iter: 3680/3680
--
Training Step: 10926  | total loss: [1m[32m0.30290[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30290 - acc: 0.8773 -- iter: 0032/3680
[A[ATraining Step: 10927  | total loss: [1m[32m0.29561[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29561 - acc: 0.8802 -- iter: 0064/3680
[A[ATraining Step: 10928  | total loss: [1m[32m0.30437[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30437 - acc: 0.8734 -- iter: 0096/3680
[A[ATraining Step: 10929  | total loss: [1m[32m0.32407[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32407 - acc: 0.8736 -- iter: 0128/3680
[A[ATraining Step: 10930  | total loss: [1m[32m0.32800[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32800 - acc: 0.8706 -- iter: 0160/3680
[A[ATraining Step: 10931  | total loss: [1m[32m0.33443[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33443 - acc: 0.8648 -- iter: 0192/3680
[A[ATraining Step: 10932  | total loss: [1m[32m0.33276[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33276 - acc: 0.8695 -- iter: 0224/3680
[A[ATraining Step: 10933  | total loss: [1m[32m0.32692[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32692 - acc: 0.8695 -- iter: 0256/3680
[A[ATraining Step: 10934  | total loss: [1m[32m0.32837[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32837 - acc: 0.8670 -- iter: 0288/3680
[A[ATraining Step: 10935  | total loss: [1m[32m0.31469[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31469 - acc: 0.8740 -- iter: 0320/3680
[A[ATraining Step: 10936  | total loss: [1m[32m0.32440[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32440 - acc: 0.8679 -- iter: 0352/3680
[A[ATraining Step: 10937  | total loss: [1m[32m0.33738[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33738 - acc: 0.8623 -- iter: 0384/3680
[A[ATraining Step: 10938  | total loss: [1m[32m0.35815[0m[0m
[2K| Adam | epoch: 096 | loss: 0.35815 - acc: 0.8511 -- iter: 0416/3680
[A[ATraining Step: 10939  | total loss: [1m[32m0.37210[0m[0m
[2K| Adam | epoch: 096 | loss: 0.37210 - acc: 0.8375 -- iter: 0448/3680
[A[ATraining Step: 10940  | total loss: [1m[32m0.38264[0m[0m
[2K| Adam | epoch: 096 | loss: 0.38264 - acc: 0.8375 -- iter: 0480/3680
[A[ATraining Step: 10941  | total loss: [1m[32m0.37610[0m[0m
[2K| Adam | epoch: 096 | loss: 0.37610 - acc: 0.8413 -- iter: 0512/3680
[A[ATraining Step: 10942  | total loss: [1m[32m0.39123[0m[0m
[2K| Adam | epoch: 096 | loss: 0.39123 - acc: 0.8384 -- iter: 0544/3680
[A[ATraining Step: 10943  | total loss: [1m[32m0.37717[0m[0m
[2K| Adam | epoch: 096 | loss: 0.37717 - acc: 0.8452 -- iter: 0576/3680
[A[ATraining Step: 10944  | total loss: [1m[32m0.36170[0m[0m
[2K| Adam | epoch: 096 | loss: 0.36170 - acc: 0.8513 -- iter: 0608/3680
[A[ATraining Step: 10945  | total loss: [1m[32m0.35231[0m[0m
[2K| Adam | epoch: 096 | loss: 0.35231 - acc: 0.8568 -- iter: 0640/3680
[A[ATraining Step: 10946  | total loss: [1m[32m0.35792[0m[0m
[2K| Adam | epoch: 096 | loss: 0.35792 - acc: 0.8555 -- iter: 0672/3680
[A[ATraining Step: 10947  | total loss: [1m[32m0.34467[0m[0m
[2K| Adam | epoch: 096 | loss: 0.34467 - acc: 0.8742 -- iter: 0704/3680
[A[ATraining Step: 10948  | total loss: [1m[32m0.32933[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32933 - acc: 0.8742 -- iter: 0736/3680
[A[ATraining Step: 10949  | total loss: [1m[32m0.32714[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32714 - acc: 0.8836 -- iter: 0768/3680
[A[ATraining Step: 10950  | total loss: [1m[32m0.32606[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32606 - acc: 0.8859 -- iter: 0800/3680
[A[ATraining Step: 10951  | total loss: [1m[32m0.32102[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32102 - acc: 0.8898 -- iter: 0832/3680
[A[ATraining Step: 10952  | total loss: [1m[32m0.31397[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31397 - acc: 0.8898 -- iter: 0864/3680
[A[ATraining Step: 10953  | total loss: [1m[32m0.31932[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31932 - acc: 0.8914 -- iter: 0896/3680
[A[ATraining Step: 10954  | total loss: [1m[32m0.31705[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31705 - acc: 0.8866 -- iter: 0928/3680
[A[ATraining Step: 10955  | total loss: [1m[32m0.31403[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31403 - acc: 0.8855 -- iter: 0960/3680
[A[ATraining Step: 10956  | total loss: [1m[32m0.31338[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31338 - acc: 0.8813 -- iter: 0992/3680
[A[ATraining Step: 10957  | total loss: [1m[32m0.30302[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30302 - acc: 0.8901 -- iter: 1024/3680
[A[ATraining Step: 10958  | total loss: [1m[32m0.30376[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30376 - acc: 0.8885 -- iter: 1056/3680
[A[ATraining Step: 10959  | total loss: [1m[32m0.29150[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29150 - acc: 0.8966 -- iter: 1088/3680
[A[ATraining Step: 10960  | total loss: [1m[32m0.28095[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28095 - acc: 0.9007 -- iter: 1120/3680
[A[ATraining Step: 10961  | total loss: [1m[32m0.27671[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27671 - acc: 0.8933 -- iter: 1152/3680
[A[ATraining Step: 10962  | total loss: [1m[32m0.28231[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28231 - acc: 0.8883 -- iter: 1184/3680
[A[ATraining Step: 10963  | total loss: [1m[32m0.28231[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28231 - acc: 0.8883 -- iter: 1216/3680
[A[ATraining Step: 10964  | total loss: [1m[32m0.30450[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30450 - acc: 0.8776 -- iter: 1248/3680
[A[ATraining Step: 10965  | total loss: [1m[32m0.28835[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28835 - acc: 0.8915 -- iter: 1280/3680
[A[ATraining Step: 10966  | total loss: [1m[32m0.30547[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30547 - acc: 0.8915 -- iter: 1312/3680
[A[ATraining Step: 10967  | total loss: [1m[32m0.31410[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31410 - acc: 0.8961 -- iter: 1344/3680
[A[ATraining Step: 10968  | total loss: [1m[32m0.30659[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30659 - acc: 0.8940 -- iter: 1376/3680
[A[ATraining Step: 10969  | total loss: [1m[32m0.31361[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31361 - acc: 0.8827 -- iter: 1408/3680
[A[ATraining Step: 10970  | total loss: [1m[32m0.32601[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32601 - acc: 0.8851 -- iter: 1440/3680
[A[ATraining Step: 10971  | total loss: [1m[32m0.31762[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31762 - acc: 0.8872 -- iter: 1472/3680
[A[ATraining Step: 10972  | total loss: [1m[32m0.31723[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31723 - acc: 0.8828 -- iter: 1504/3680
[A[ATraining Step: 10973  | total loss: [1m[32m0.33934[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33934 - acc: 0.8696 -- iter: 1536/3680
[A[ATraining Step: 10974  | total loss: [1m[32m0.33955[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33955 - acc: 0.8764 -- iter: 1568/3680
[A[ATraining Step: 10975  | total loss: [1m[32m0.33123[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33123 - acc: 0.8793 -- iter: 1600/3680
[A[ATraining Step: 10976  | total loss: [1m[32m0.31497[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31497 - acc: 0.8852 -- iter: 1632/3680
[A[ATraining Step: 10977  | total loss: [1m[32m0.34089[0m[0m
[2K| Adam | epoch: 096 | loss: 0.34089 - acc: 0.8748 -- iter: 1664/3680
[A[ATraining Step: 10978  | total loss: [1m[32m0.33154[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33154 - acc: 0.8779 -- iter: 1696/3680
[A[ATraining Step: 10979  | total loss: [1m[32m0.31583[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31583 - acc: 0.8870 -- iter: 1728/3680
[A[ATraining Step: 10980  | total loss: [1m[32m0.31015[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31015 - acc: 0.8920 -- iter: 1760/3680
[A[ATraining Step: 10981  | total loss: [1m[32m0.32786[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32786 - acc: 0.8841 -- iter: 1792/3680
[A[ATraining Step: 10982  | total loss: [1m[32m0.32756[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32756 - acc: 0.8801 -- iter: 1824/3680
[A[ATraining Step: 10983  | total loss: [1m[32m0.32199[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32199 - acc: 0.8827 -- iter: 1856/3680
[A[ATraining Step: 10984  | total loss: [1m[32m0.30263[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30263 - acc: 0.8865 -- iter: 1888/3680
[A[ATraining Step: 10985  | total loss: [1m[32m0.30265[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30265 - acc: 0.8865 -- iter: 1920/3680
[A[ATraining Step: 10986  | total loss: [1m[32m0.30214[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30214 - acc: 0.8847 -- iter: 1952/3680
[A[ATraining Step: 10987  | total loss: [1m[32m0.30214[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30214 - acc: 0.8847 -- iter: 1984/3680
[A[ATraining Step: 10988  | total loss: [1m[32m0.31453[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31453 - acc: 0.8712 -- iter: 2016/3680
[A[ATraining Step: 10989  | total loss: [1m[32m0.31138[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31138 - acc: 0.8750 -- iter: 2048/3680
[A[ATraining Step: 10990  | total loss: [1m[32m0.30476[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30476 - acc: 0.8750 -- iter: 2080/3680
[A[ATraining Step: 10991  | total loss: [1m[32m0.31132[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31132 - acc: 0.8719 -- iter: 2112/3680
[A[ATraining Step: 10992  | total loss: [1m[32m0.32037[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32037 - acc: 0.8753 -- iter: 2144/3680
[A[ATraining Step: 10993  | total loss: [1m[32m0.33113[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33113 - acc: 0.8753 -- iter: 2176/3680
[A[ATraining Step: 10994  | total loss: [1m[32m0.33654[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33654 - acc: 0.8722 -- iter: 2208/3680
[A[ATraining Step: 10995  | total loss: [1m[32m0.34101[0m[0m
[2K| Adam | epoch: 096 | loss: 0.34101 - acc: 0.8755 -- iter: 2240/3680
[A[ATraining Step: 10996  | total loss: [1m[32m0.34101[0m[0m
[2K| Adam | epoch: 096 | loss: 0.34101 - acc: 0.8755 -- iter: 2272/3680
[A[ATraining Step: 10997  | total loss: [1m[32m0.32820[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32820 - acc: 0.8755 -- iter: 2304/3680
[A[ATraining Step: 10998  | total loss: [1m[32m0.31758[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31758 - acc: 0.8848 -- iter: 2336/3680
[A[ATraining Step: 10999  | total loss: [1m[32m0.33800[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33800 - acc: 0.8682 -- iter: 2368/3680
[A[ATraining Step: 11000  | total loss: [1m[32m0.33757[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33757 - acc: 0.8689 | val_loss: 0.28177 - val_acc: 0.9023 -- iter: 2400/3680
[A[ATraining Step: 11000  | total loss: [1m[32m0.33757[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33757 - acc: 0.8689 | val_loss: 0.28177 - val_acc: 0.9023 -- iter: 2400/3680
--
Training Step: 11001  | total loss: [1m[32m0.35166[0m[0m
[2K| Adam | epoch: 096 | loss: 0.35166 - acc: 0.8601 -- iter: 2432/3680
[A[ATraining Step: 11002  | total loss: [1m[32m0.35152[0m[0m
[2K| Adam | epoch: 096 | loss: 0.35152 - acc: 0.8553 -- iter: 2464/3680
[A[ATraining Step: 11003  | total loss: [1m[32m0.33480[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33480 - acc: 0.8636 -- iter: 2496/3680
[A[ATraining Step: 11004  | total loss: [1m[32m0.31567[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31567 - acc: 0.8741 -- iter: 2528/3680
[A[ATraining Step: 11005  | total loss: [1m[32m0.31865[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31865 - acc: 0.8742 -- iter: 2560/3680
[A[ATraining Step: 11006  | total loss: [1m[32m0.33161[0m[0m
[2K| Adam | epoch: 096 | loss: 0.33161 - acc: 0.8680 -- iter: 2592/3680
[A[ATraining Step: 11007  | total loss: [1m[32m0.31607[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31607 - acc: 0.8718 -- iter: 2624/3680
[A[ATraining Step: 11008  | total loss: [1m[32m0.32053[0m[0m
[2K| Adam | epoch: 096 | loss: 0.32053 - acc: 0.8721 -- iter: 2656/3680
[A[ATraining Step: 11009  | total loss: [1m[32m0.30022[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30022 - acc: 0.8814 -- iter: 2688/3680
[A[ATraining Step: 11010  | total loss: [1m[32m0.30022[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30022 - acc: 0.8814 -- iter: 2720/3680
[A[ATraining Step: 11011  | total loss: [1m[32m0.29197[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29197 - acc: 0.8870 -- iter: 2752/3680
[A[ATraining Step: 11012  | total loss: [1m[32m0.29316[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29316 - acc: 0.8890 -- iter: 2784/3680
[A[ATraining Step: 11013  | total loss: [1m[32m0.30128[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30128 - acc: 0.8844 -- iter: 2816/3680
[A[ATraining Step: 11014  | total loss: [1m[32m0.30172[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30172 - acc: 0.8804 -- iter: 2848/3680
[A[ATraining Step: 11015  | total loss: [1m[32m0.30195[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30195 - acc: 0.8798 -- iter: 2880/3680
[A[ATraining Step: 11016  | total loss: [1m[32m0.29975[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29975 - acc: 0.8794 -- iter: 2912/3680
[A[ATraining Step: 11017  | total loss: [1m[32m0.30743[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30743 - acc: 0.8789 -- iter: 2944/3680
[A[ATraining Step: 11018  | total loss: [1m[32m0.29279[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29279 - acc: 0.8807 -- iter: 2976/3680
[A[ATraining Step: 11019  | total loss: [1m[32m0.29536[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29536 - acc: 0.8807 -- iter: 3008/3680
[A[ATraining Step: 11020  | total loss: [1m[32m0.28010[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28010 - acc: 0.8895 -- iter: 3040/3680
[A[ATraining Step: 11021  | total loss: [1m[32m0.27082[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27082 - acc: 0.8943 -- iter: 3072/3680
[A[ATraining Step: 11022  | total loss: [1m[32m0.26928[0m[0m
[2K| Adam | epoch: 096 | loss: 0.26928 - acc: 0.8955 -- iter: 3104/3680
[A[ATraining Step: 11023  | total loss: [1m[32m0.26740[0m[0m
[2K| Adam | epoch: 096 | loss: 0.26740 - acc: 0.8966 -- iter: 3136/3680
[A[ATraining Step: 11024  | total loss: [1m[32m0.28576[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28576 - acc: 0.8850 -- iter: 3168/3680
[A[ATraining Step: 11025  | total loss: [1m[32m0.27888[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27888 - acc: 0.8703 -- iter: 3200/3680
[A[ATraining Step: 11026  | total loss: [1m[32m0.31467[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31467 - acc: 0.8703 -- iter: 3232/3680
[A[ATraining Step: 11027  | total loss: [1m[32m0.31282[0m[0m
[2K| Adam | epoch: 096 | loss: 0.31282 - acc: 0.8708 -- iter: 3264/3680
[A[ATraining Step: 11028  | total loss: [1m[32m0.30960[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30960 - acc: 0.8712 -- iter: 3296/3680
[A[ATraining Step: 11029  | total loss: [1m[32m0.29754[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29754 - acc: 0.8778 -- iter: 3328/3680
[A[ATraining Step: 11030  | total loss: [1m[32m0.30670[0m[0m
[2K| Adam | epoch: 096 | loss: 0.30670 - acc: 0.8744 -- iter: 3360/3680
[A[ATraining Step: 11031  | total loss: [1m[32m0.29499[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29499 - acc: 0.8839 -- iter: 3392/3680
[A[ATraining Step: 11032  | total loss: [1m[32m0.29240[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29240 - acc: 0.8861 -- iter: 3424/3680
[A[ATraining Step: 11033  | total loss: [1m[32m0.29194[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29194 - acc: 0.8912 -- iter: 3456/3680
[A[ATraining Step: 11034  | total loss: [1m[32m0.28934[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28934 - acc: 0.8959 -- iter: 3488/3680
[A[ATraining Step: 11035  | total loss: [1m[32m0.28875[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28875 - acc: 0.8938 -- iter: 3520/3680
[A[ATraining Step: 11036  | total loss: [1m[32m0.29191[0m[0m
[2K| Adam | epoch: 096 | loss: 0.29191 - acc: 0.8919 -- iter: 3552/3680
[A[ATraining Step: 11037  | total loss: [1m[32m0.28068[0m[0m
[2K| Adam | epoch: 096 | loss: 0.28068 - acc: 0.8933 -- iter: 3584/3680
[A[ATraining Step: 11038  | total loss: [1m[32m0.27553[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27553 - acc: 0.8977 -- iter: 3616/3680
[A[ATraining Step: 11039  | total loss: [1m[32m0.27521[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27521 - acc: 0.9017 -- iter: 3648/3680
[A[ATraining Step: 11040  | total loss: [1m[32m0.27959[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27959 - acc: 0.8991 | val_loss: 0.27945 - val_acc: 0.9023 -- iter: 3680/3680
[A[ATraining Step: 11040  | total loss: [1m[32m0.27959[0m[0m
[2K| Adam | epoch: 096 | loss: 0.27959 - acc: 0.8991 | val_loss: 0.27945 - val_acc: 0.9023 -- iter: 3680/3680
--
Training Step: 11041  | total loss: [1m[32m0.27075[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27075 - acc: 0.9060 -- iter: 0032/3680
[A[ATraining Step: 11042  | total loss: [1m[32m0.28408[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28408 - acc: 0.8973 -- iter: 0064/3680
[A[ATraining Step: 11043  | total loss: [1m[32m0.28944[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28944 - acc: 0.8973 -- iter: 0096/3680
[A[ATraining Step: 11044  | total loss: [1m[32m0.27751[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27751 - acc: 0.9013 -- iter: 0128/3680
[A[ATraining Step: 11045  | total loss: [1m[32m0.28226[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28226 - acc: 0.8987 -- iter: 0160/3680
[A[ATraining Step: 11046  | total loss: [1m[32m0.26586[0m[0m
[2K| Adam | epoch: 097 | loss: 0.26586 - acc: 0.9088 -- iter: 0192/3680
[A[ATraining Step: 11047  | total loss: [1m[32m0.27414[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27414 - acc: 0.9023 -- iter: 0224/3680
[A[ATraining Step: 11048  | total loss: [1m[32m0.27418[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27418 - acc: 0.8996 -- iter: 0256/3680
[A[ATraining Step: 11049  | total loss: [1m[32m0.28627[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28627 - acc: 0.8940 -- iter: 0288/3680
[A[ATraining Step: 11050  | total loss: [1m[32m0.31314[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31314 - acc: 0.8859 -- iter: 0320/3680
[A[ATraining Step: 11051  | total loss: [1m[32m0.31567[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31567 - acc: 0.8754 -- iter: 0352/3680
[A[ATraining Step: 11052  | total loss: [1m[32m0.33411[0m[0m
[2K| Adam | epoch: 097 | loss: 0.33411 - acc: 0.8722 -- iter: 0384/3680
[A[ATraining Step: 11053  | total loss: [1m[32m0.33426[0m[0m
[2K| Adam | epoch: 097 | loss: 0.33426 - acc: 0.8694 -- iter: 0416/3680
[A[ATraining Step: 11054  | total loss: [1m[32m0.32601[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32601 - acc: 0.8699 -- iter: 0448/3680
[A[ATraining Step: 11055  | total loss: [1m[32m0.32823[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32823 - acc: 0.8704 -- iter: 0480/3680
[A[ATraining Step: 11056  | total loss: [1m[32m0.30055[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30055 - acc: 0.8835 -- iter: 0512/3680
[A[ATraining Step: 11057  | total loss: [1m[32m0.30055[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30055 - acc: 0.8835 -- iter: 0544/3680
[A[ATraining Step: 11058  | total loss: [1m[32m0.29792[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29792 - acc: 0.8889 -- iter: 0576/3680
[A[ATraining Step: 11059  | total loss: [1m[32m0.29630[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29630 - acc: 0.8906 -- iter: 0608/3680
[A[ATraining Step: 11060  | total loss: [1m[32m0.30390[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30390 - acc: 0.8891 -- iter: 0640/3680
[A[ATraining Step: 11061  | total loss: [1m[32m0.30467[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30467 - acc: 0.8845 -- iter: 0672/3680
[A[ATraining Step: 11062  | total loss: [1m[32m0.30975[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30975 - acc: 0.8836 -- iter: 0704/3680
[A[ATraining Step: 11063  | total loss: [1m[32m0.32147[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32147 - acc: 0.8734 -- iter: 0736/3680
[A[ATraining Step: 11064  | total loss: [1m[32m0.30452[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30452 - acc: 0.8798 -- iter: 0768/3680
[A[ATraining Step: 11065  | total loss: [1m[32m0.31355[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31355 - acc: 0.8793 -- iter: 0800/3680
[A[ATraining Step: 11066  | total loss: [1m[32m0.31590[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31590 - acc: 0.8851 -- iter: 0832/3680
[A[ATraining Step: 11067  | total loss: [1m[32m0.30133[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30133 - acc: 0.8935 -- iter: 0864/3680
[A[ATraining Step: 11068  | total loss: [1m[32m0.29587[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29587 - acc: 0.8979 -- iter: 0896/3680
[A[ATraining Step: 11069  | total loss: [1m[32m0.28899[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28899 - acc: 0.9050 -- iter: 0928/3680
[A[ATraining Step: 11070  | total loss: [1m[32m0.31706[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31706 - acc: 0.9020 -- iter: 0960/3680
[A[ATraining Step: 11071  | total loss: [1m[32m0.31015[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31015 - acc: 0.9024 -- iter: 0992/3680
[A[ATraining Step: 11072  | total loss: [1m[32m0.30139[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30139 - acc: 0.9059 -- iter: 1024/3680
[A[ATraining Step: 11073  | total loss: [1m[32m0.30058[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30058 - acc: 0.9059 -- iter: 1056/3680
[A[ATraining Step: 11074  | total loss: [1m[32m0.28028[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28028 - acc: 0.9116 -- iter: 1088/3680
[A[ATraining Step: 11075  | total loss: [1m[32m0.28028[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28028 - acc: 0.9116 -- iter: 1120/3680
[A[ATraining Step: 11076  | total loss: [1m[32m0.29019[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29019 - acc: 0.9111 -- iter: 1152/3680
[A[ATraining Step: 11077  | total loss: [1m[32m0.28759[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28759 - acc: 0.9106 -- iter: 1184/3680
[A[ATraining Step: 11078  | total loss: [1m[32m0.28659[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28659 - acc: 0.9070 -- iter: 1216/3680
[A[ATraining Step: 11079  | total loss: [1m[32m0.28199[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28199 - acc: 0.9070 -- iter: 1248/3680
[A[ATraining Step: 11080  | total loss: [1m[32m0.27595[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27595 - acc: 0.9069 -- iter: 1280/3680
[A[ATraining Step: 11081  | total loss: [1m[32m0.28408[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28408 - acc: 0.9037 -- iter: 1312/3680
[A[ATraining Step: 11082  | total loss: [1m[32m0.30004[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30004 - acc: 0.8977 -- iter: 1344/3680
[A[ATraining Step: 11083  | total loss: [1m[32m0.30746[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30746 - acc: 0.8954 -- iter: 1376/3680
[A[ATraining Step: 11084  | total loss: [1m[32m0.30730[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30730 - acc: 0.8996 -- iter: 1408/3680
[A[ATraining Step: 11085  | total loss: [1m[32m0.29876[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29876 - acc: 0.9066 -- iter: 1440/3680
[A[ATraining Step: 11086  | total loss: [1m[32m0.29164[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29164 - acc: 0.9065 -- iter: 1472/3680
[A[ATraining Step: 11087  | total loss: [1m[32m0.30919[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30919 - acc: 0.8877 -- iter: 1504/3680
[A[ATraining Step: 11088  | total loss: [1m[32m0.30686[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30686 - acc: 0.8927 -- iter: 1536/3680
[A[ATraining Step: 11089  | total loss: [1m[32m0.29895[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29895 - acc: 0.8987 -- iter: 1568/3680
[A[ATraining Step: 11090  | total loss: [1m[32m0.28735[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28735 - acc: 0.8987 -- iter: 1600/3680
[A[ATraining Step: 11091  | total loss: [1m[32m0.27994[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27994 - acc: 0.8995 -- iter: 1632/3680
[A[ATraining Step: 11092  | total loss: [1m[32m0.28332[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28332 - acc: 0.8939 -- iter: 1664/3680
[A[ATraining Step: 11093  | total loss: [1m[32m0.29101[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29101 - acc: 0.8889 -- iter: 1696/3680
[A[ATraining Step: 11094  | total loss: [1m[32m0.29344[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29344 - acc: 0.8844 -- iter: 1728/3680
[A[ATraining Step: 11095  | total loss: [1m[32m0.31137[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31137 - acc: 0.8741 -- iter: 1760/3680
[A[ATraining Step: 11096  | total loss: [1m[32m0.31866[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31866 - acc: 0.8773 -- iter: 1792/3680
[A[ATraining Step: 11097  | total loss: [1m[32m0.31670[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31670 - acc: 0.8771 -- iter: 1824/3680
[A[ATraining Step: 11098  | total loss: [1m[32m0.31943[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31943 - acc: 0.8769 -- iter: 1856/3680
[A[ATraining Step: 11099  | total loss: [1m[32m0.31721[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31721 - acc: 0.8735 -- iter: 1888/3680
[A[ATraining Step: 11100  | total loss: [1m[32m0.31879[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31879 - acc: 0.8737 | val_loss: 0.29214 - val_acc: 0.8893 -- iter: 1920/3680
[A[ATraining Step: 11100  | total loss: [1m[32m0.31879[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31879 - acc: 0.8737 | val_loss: 0.29214 - val_acc: 0.8893 -- iter: 1920/3680
--
Training Step: 11101  | total loss: [1m[32m0.31447[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31447 - acc: 0.8707 -- iter: 1952/3680
[A[ATraining Step: 11102  | total loss: [1m[32m0.31236[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31236 - acc: 0.8711 -- iter: 1984/3680
[A[ATraining Step: 11103  | total loss: [1m[32m0.31290[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31290 - acc: 0.8715 -- iter: 2016/3680
[A[ATraining Step: 11104  | total loss: [1m[32m0.30809[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30809 - acc: 0.8697 -- iter: 2048/3680
[A[ATraining Step: 11105  | total loss: [1m[32m0.30809[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30809 - acc: 0.8697 -- iter: 2080/3680
[A[ATraining Step: 11106  | total loss: [1m[32m0.31357[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31357 - acc: 0.8702 -- iter: 2112/3680
[A[ATraining Step: 11107  | total loss: [1m[32m0.30919[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30919 - acc: 0.8707 -- iter: 2144/3680
[A[ATraining Step: 11108  | total loss: [1m[32m0.29949[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29949 - acc: 0.8805 -- iter: 2176/3680
[A[ATraining Step: 11109  | total loss: [1m[32m0.29461[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29461 - acc: 0.8831 -- iter: 2208/3680
[A[ATraining Step: 11110  | total loss: [1m[32m0.28701[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28701 - acc: 0.8885 -- iter: 2240/3680
[A[ATraining Step: 11111  | total loss: [1m[32m0.28040[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28040 - acc: 0.8903 -- iter: 2272/3680
[A[ATraining Step: 11112  | total loss: [1m[32m0.26980[0m[0m
[2K| Adam | epoch: 097 | loss: 0.26980 - acc: 0.8981 -- iter: 2304/3680
[A[ATraining Step: 11113  | total loss: [1m[32m0.26841[0m[0m
[2K| Adam | epoch: 097 | loss: 0.26841 - acc: 0.9021 -- iter: 2336/3680
[A[ATraining Step: 11114  | total loss: [1m[32m0.26622[0m[0m
[2K| Adam | epoch: 097 | loss: 0.26622 - acc: 0.9056 -- iter: 2368/3680
[A[ATraining Step: 11115  | total loss: [1m[32m0.27233[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27233 - acc: 0.8994 -- iter: 2400/3680
[A[ATraining Step: 11116  | total loss: [1m[32m0.27315[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27315 - acc: 0.9001 -- iter: 2432/3680
[A[ATraining Step: 11117  | total loss: [1m[32m0.27267[0m[0m
[2K| Adam | epoch: 097 | loss: 0.27267 - acc: 0.8976 -- iter: 2464/3680
[A[ATraining Step: 11118  | total loss: [1m[32m0.28485[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28485 - acc: 0.8922 -- iter: 2496/3680
[A[ATraining Step: 11119  | total loss: [1m[32m0.28585[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28585 - acc: 0.8936 -- iter: 2528/3680
[A[ATraining Step: 11120  | total loss: [1m[32m0.29771[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29771 - acc: 0.8886 -- iter: 2560/3680
[A[ATraining Step: 11121  | total loss: [1m[32m0.30952[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30952 - acc: 0.8810 -- iter: 2592/3680
[A[ATraining Step: 11122  | total loss: [1m[32m0.31220[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31220 - acc: 0.8773 -- iter: 2624/3680
[A[ATraining Step: 11123  | total loss: [1m[32m0.30722[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30722 - acc: 0.8771 -- iter: 2656/3680
[A[ATraining Step: 11124  | total loss: [1m[32m0.30993[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30993 - acc: 0.8769 -- iter: 2688/3680
[A[ATraining Step: 11125  | total loss: [1m[32m0.30875[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30875 - acc: 0.8798 -- iter: 2720/3680
[A[ATraining Step: 11126  | total loss: [1m[32m0.28962[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28962 - acc: 0.8887 -- iter: 2752/3680
[A[ATraining Step: 11127  | total loss: [1m[32m0.29477[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29477 - acc: 0.8842 -- iter: 2784/3680
[A[ATraining Step: 11128  | total loss: [1m[32m0.29337[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29337 - acc: 0.8864 -- iter: 2816/3680
[A[ATraining Step: 11129  | total loss: [1m[32m0.30437[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30437 - acc: 0.8853 -- iter: 2848/3680
[A[ATraining Step: 11130  | total loss: [1m[32m0.29819[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29819 - acc: 0.8905 -- iter: 2880/3680
[A[ATraining Step: 11131  | total loss: [1m[32m0.30159[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30159 - acc: 0.8858 -- iter: 2912/3680
[A[ATraining Step: 11132  | total loss: [1m[32m0.30450[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30450 - acc: 0.8816 -- iter: 2944/3680
[A[ATraining Step: 11133  | total loss: [1m[32m0.30406[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30406 - acc: 0.8872 -- iter: 2976/3680
[A[ATraining Step: 11134  | total loss: [1m[32m0.29663[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29663 - acc: 0.8922 -- iter: 3008/3680
[A[ATraining Step: 11135  | total loss: [1m[32m0.29626[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29626 - acc: 0.8905 -- iter: 3040/3680
[A[ATraining Step: 11136  | total loss: [1m[32m0.30565[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30565 - acc: 0.8827 -- iter: 3072/3680
[A[ATraining Step: 11137  | total loss: [1m[32m0.30798[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30798 - acc: 0.8788 -- iter: 3104/3680
[A[ATraining Step: 11138  | total loss: [1m[32m0.31914[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31914 - acc: 0.8753 -- iter: 3136/3680
[A[ATraining Step: 11139  | total loss: [1m[32m0.32418[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32418 - acc: 0.8721 -- iter: 3168/3680
[A[ATraining Step: 11140  | total loss: [1m[32m0.31315[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31315 - acc: 0.8787 -- iter: 3200/3680
[A[ATraining Step: 11141  | total loss: [1m[32m0.32147[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32147 - acc: 0.8752 -- iter: 3232/3680
[A[ATraining Step: 11142  | total loss: [1m[32m0.31077[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31077 - acc: 0.8783 -- iter: 3264/3680
[A[ATraining Step: 11143  | total loss: [1m[32m0.30047[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30047 - acc: 0.8873 -- iter: 3296/3680
[A[ATraining Step: 11144  | total loss: [1m[32m0.29900[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29900 - acc: 0.8892 -- iter: 3328/3680
[A[ATraining Step: 11145  | total loss: [1m[32m0.29067[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29067 - acc: 0.8972 -- iter: 3360/3680
[A[ATraining Step: 11146  | total loss: [1m[32m0.28024[0m[0m
[2K| Adam | epoch: 097 | loss: 0.28024 - acc: 0.8986 -- iter: 3392/3680
[A[ATraining Step: 11147  | total loss: [1m[32m0.29142[0m[0m
[2K| Adam | epoch: 097 | loss: 0.29142 - acc: 0.8986 -- iter: 3424/3680
[A[ATraining Step: 11148  | total loss: [1m[32m0.30708[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30708 - acc: 0.8922 -- iter: 3456/3680
[A[ATraining Step: 11149  | total loss: [1m[32m0.30708[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30708 - acc: 0.8780 -- iter: 3488/3680
[A[ATraining Step: 11150  | total loss: [1m[32m0.32878[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32878 - acc: 0.8780 -- iter: 3520/3680
[A[ATraining Step: 11151  | total loss: [1m[32m0.32702[0m[0m
[2K| Adam | epoch: 097 | loss: 0.32702 - acc: 0.8777 -- iter: 3552/3680
[A[ATraining Step: 11152  | total loss: [1m[32m0.30886[0m[0m
[2K| Adam | epoch: 097 | loss: 0.30886 - acc: 0.8837 -- iter: 3584/3680
[A[ATraining Step: 11153  | total loss: [1m[32m0.31432[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31432 - acc: 0.8797 -- iter: 3616/3680
[A[ATraining Step: 11154  | total loss: [1m[32m0.31239[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31239 - acc: 0.8886 -- iter: 3648/3680
[A[ATraining Step: 11155  | total loss: [1m[32m0.31396[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31396 - acc: 0.8872 | val_loss: 0.26566 - val_acc: 0.9099 -- iter: 3680/3680
[A[ATraining Step: 11155  | total loss: [1m[32m0.31396[0m[0m
[2K| Adam | epoch: 097 | loss: 0.31396 - acc: 0.8872 | val_loss: 0.26566 - val_acc: 0.9099 -- iter: 3680/3680
--
Training Step: 11156  | total loss: [1m[32m0.31678[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31678 - acc: 0.8860 -- iter: 0032/3680
[A[ATraining Step: 11157  | total loss: [1m[32m0.32427[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32427 - acc: 0.8755 -- iter: 0064/3680
[A[ATraining Step: 11158  | total loss: [1m[32m0.31334[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31334 - acc: 0.8786 -- iter: 0096/3680
[A[ATraining Step: 11159  | total loss: [1m[32m0.31051[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31051 - acc: 0.8751 -- iter: 0128/3680
[A[ATraining Step: 11160  | total loss: [1m[32m0.30628[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30628 - acc: 0.8782 -- iter: 0160/3680
[A[ATraining Step: 11161  | total loss: [1m[32m0.29549[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29549 - acc: 0.8739 -- iter: 0192/3680
[A[ATraining Step: 11162  | total loss: [1m[32m0.31553[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31553 - acc: 0.8739 -- iter: 0224/3680
[A[ATraining Step: 11163  | total loss: [1m[32m0.31151[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31151 - acc: 0.8771 -- iter: 0256/3680
[A[ATraining Step: 11164  | total loss: [1m[32m0.31823[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31823 - acc: 0.8769 -- iter: 0288/3680
[A[ATraining Step: 11165  | total loss: [1m[32m0.33549[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33549 - acc: 0.8548 -- iter: 0320/3680
[A[ATraining Step: 11166  | total loss: [1m[32m0.32883[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32883 - acc: 0.8569 -- iter: 0352/3680
[A[ATraining Step: 11167  | total loss: [1m[32m0.33003[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33003 - acc: 0.8587 -- iter: 0384/3680
[A[ATraining Step: 11168  | total loss: [1m[32m0.35228[0m[0m
[2K| Adam | epoch: 098 | loss: 0.35228 - acc: 0.8478 -- iter: 0416/3680
[A[ATraining Step: 11169  | total loss: [1m[32m0.34292[0m[0m
[2K| Adam | epoch: 098 | loss: 0.34292 - acc: 0.8505 -- iter: 0448/3680
[A[ATraining Step: 11170  | total loss: [1m[32m0.32766[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32766 - acc: 0.8623 -- iter: 0480/3680
[A[ATraining Step: 11171  | total loss: [1m[32m0.31851[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31851 - acc: 0.8699 -- iter: 0512/3680
[A[ATraining Step: 11172  | total loss: [1m[32m0.32085[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32085 - acc: 0.8766 -- iter: 0544/3680
[A[ATraining Step: 11173  | total loss: [1m[32m0.32666[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32666 - acc: 0.8702 -- iter: 0576/3680
[A[ATraining Step: 11174  | total loss: [1m[32m0.32428[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32428 - acc: 0.8707 -- iter: 0608/3680
[A[ATraining Step: 11175  | total loss: [1m[32m0.30707[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30707 - acc: 0.8805 -- iter: 0640/3680
[A[ATraining Step: 11176  | total loss: [1m[32m0.32142[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32142 - acc: 0.8706 -- iter: 0672/3680
[A[ATraining Step: 11177  | total loss: [1m[32m0.31778[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31778 - acc: 0.8648 -- iter: 0704/3680
[A[ATraining Step: 11178  | total loss: [1m[32m0.34984[0m[0m
[2K| Adam | epoch: 098 | loss: 0.34984 - acc: 0.8408 -- iter: 0736/3680
[A[ATraining Step: 11179  | total loss: [1m[32m0.35680[0m[0m
[2K| Adam | epoch: 098 | loss: 0.35680 - acc: 0.8348 -- iter: 0768/3680
[A[ATraining Step: 11180  | total loss: [1m[32m0.34031[0m[0m
[2K| Adam | epoch: 098 | loss: 0.34031 - acc: 0.8451 -- iter: 0800/3680
[A[ATraining Step: 11181  | total loss: [1m[32m0.33942[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33942 - acc: 0.8450 -- iter: 0832/3680
[A[ATraining Step: 11182  | total loss: [1m[32m0.34217[0m[0m
[2K| Adam | epoch: 098 | loss: 0.34217 - acc: 0.8448 -- iter: 0864/3680
[A[ATraining Step: 11183  | total loss: [1m[32m0.33548[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33548 - acc: 0.8510 -- iter: 0896/3680
[A[ATraining Step: 11184  | total loss: [1m[32m0.33657[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33657 - acc: 0.8503 -- iter: 0928/3680
[A[ATraining Step: 11185  | total loss: [1m[32m0.33800[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33800 - acc: 0.8527 -- iter: 0960/3680
[A[ATraining Step: 11186  | total loss: [1m[32m0.33202[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33202 - acc: 0.8581 -- iter: 0992/3680
[A[ATraining Step: 11187  | total loss: [1m[32m0.32326[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32326 - acc: 0.8629 -- iter: 1024/3680
[A[ATraining Step: 11188  | total loss: [1m[32m0.32711[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32711 - acc: 0.8579 -- iter: 1056/3680
[A[ATraining Step: 11189  | total loss: [1m[32m0.32242[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32242 - acc: 0.8627 -- iter: 1088/3680
[A[ATraining Step: 11190  | total loss: [1m[32m0.32033[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32033 - acc: 0.8608 -- iter: 1120/3680
[A[ATraining Step: 11191  | total loss: [1m[32m0.33171[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33171 - acc: 0.8529 -- iter: 1152/3680
[A[ATraining Step: 11192  | total loss: [1m[32m0.33163[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33163 - acc: 0.8551 -- iter: 1184/3680
[A[ATraining Step: 11193  | total loss: [1m[32m0.32758[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32758 - acc: 0.8571 -- iter: 1216/3680
[A[ATraining Step: 11194  | total loss: [1m[32m0.31898[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31898 - acc: 0.8651 -- iter: 1248/3680
[A[ATraining Step: 11195  | total loss: [1m[32m0.29936[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29936 - acc: 0.8755 -- iter: 1280/3680
[A[ATraining Step: 11196  | total loss: [1m[32m0.29653[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29653 - acc: 0.8754 -- iter: 1312/3680
[A[ATraining Step: 11197  | total loss: [1m[32m0.30478[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30478 - acc: 0.8754 -- iter: 1344/3680
[A[ATraining Step: 11198  | total loss: [1m[32m0.30549[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30549 - acc: 0.8691 -- iter: 1376/3680
[A[ATraining Step: 11199  | total loss: [1m[32m0.29816[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29816 - acc: 0.8728 -- iter: 1408/3680
[A[ATraining Step: 11200  | total loss: [1m[32m0.30856[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30856 - acc: 0.8668 | val_loss: 0.27884 - val_acc: 0.9034 -- iter: 1440/3680
[A[ATraining Step: 11200  | total loss: [1m[32m0.30856[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30856 - acc: 0.8668 | val_loss: 0.27884 - val_acc: 0.9034 -- iter: 1440/3680
--
Training Step: 11201  | total loss: [1m[32m0.30842[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30842 - acc: 0.8676 -- iter: 1472/3680
[A[ATraining Step: 11202  | total loss: [1m[32m0.30436[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30436 - acc: 0.8683 -- iter: 1504/3680
[A[ATraining Step: 11203  | total loss: [1m[32m0.30075[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30075 - acc: 0.8721 -- iter: 1536/3680
[A[ATraining Step: 11204  | total loss: [1m[32m0.30642[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30642 - acc: 0.8693 -- iter: 1568/3680
[A[ATraining Step: 11205  | total loss: [1m[32m0.29412[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29412 - acc: 0.8730 -- iter: 1600/3680
[A[ATraining Step: 11206  | total loss: [1m[32m0.29337[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29337 - acc: 0.8763 -- iter: 1632/3680
[A[ATraining Step: 11207  | total loss: [1m[32m0.29701[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29701 - acc: 0.8699 -- iter: 1664/3680
[A[ATraining Step: 11208  | total loss: [1m[32m0.29343[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29343 - acc: 0.8642 -- iter: 1696/3680
[A[ATraining Step: 11209  | total loss: [1m[32m0.28231[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28231 - acc: 0.8747 -- iter: 1728/3680
[A[ATraining Step: 11210  | total loss: [1m[32m0.28273[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28273 - acc: 0.8716 -- iter: 1760/3680
[A[ATraining Step: 11211  | total loss: [1m[32m0.28273[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28273 - acc: 0.8716 -- iter: 1792/3680
[A[ATraining Step: 11212  | total loss: [1m[32m0.28963[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28963 - acc: 0.8719 -- iter: 1824/3680
[A[ATraining Step: 11213  | total loss: [1m[32m0.28480[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28480 - acc: 0.8754 -- iter: 1856/3680
[A[ATraining Step: 11214  | total loss: [1m[32m0.30735[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30735 - acc: 0.8691 -- iter: 1888/3680
[A[ATraining Step: 11215  | total loss: [1m[32m0.31035[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31035 - acc: 0.8728 -- iter: 1920/3680
[A[ATraining Step: 11216  | total loss: [1m[32m0.31342[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31342 - acc: 0.8668 -- iter: 1952/3680
[A[ATraining Step: 11217  | total loss: [1m[32m0.31293[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31293 - acc: 0.8645 -- iter: 1984/3680
[A[ATraining Step: 11218  | total loss: [1m[32m0.32417[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32417 - acc: 0.8499 -- iter: 2016/3680
[A[ATraining Step: 11219  | total loss: [1m[32m0.33247[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33247 - acc: 0.8493 -- iter: 2048/3680
[A[ATraining Step: 11220  | total loss: [1m[32m0.33413[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33413 - acc: 0.8518 -- iter: 2080/3680
[A[ATraining Step: 11221  | total loss: [1m[32m0.32146[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32146 - acc: 0.8573 -- iter: 2112/3680
[A[ATraining Step: 11222  | total loss: [1m[32m0.31143[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31143 - acc: 0.8622 -- iter: 2144/3680
[A[ATraining Step: 11223  | total loss: [1m[32m0.30842[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30842 - acc: 0.8635 -- iter: 2176/3680
[A[ATraining Step: 11224  | total loss: [1m[32m0.30110[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30110 - acc: 0.8677 -- iter: 2208/3680
[A[ATraining Step: 11225  | total loss: [1m[32m0.30535[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30535 - acc: 0.8653 -- iter: 2240/3680
[A[ATraining Step: 11226  | total loss: [1m[32m0.30161[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30161 - acc: 0.8663 -- iter: 2272/3680
[A[ATraining Step: 11227  | total loss: [1m[32m0.31821[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31821 - acc: 0.8641 -- iter: 2304/3680
[A[ATraining Step: 11228  | total loss: [1m[32m0.35506[0m[0m
[2K| Adam | epoch: 098 | loss: 0.35506 - acc: 0.8620 -- iter: 2336/3680
[A[ATraining Step: 11229  | total loss: [1m[32m0.35687[0m[0m
[2K| Adam | epoch: 098 | loss: 0.35687 - acc: 0.8602 -- iter: 2368/3680
[A[ATraining Step: 11230  | total loss: [1m[32m0.36593[0m[0m
[2K| Adam | epoch: 098 | loss: 0.36593 - acc: 0.8586 -- iter: 2400/3680
[A[ATraining Step: 11231  | total loss: [1m[32m0.35799[0m[0m
[2K| Adam | epoch: 098 | loss: 0.35799 - acc: 0.8602 -- iter: 2432/3680
[A[ATraining Step: 11232  | total loss: [1m[32m0.33607[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33607 - acc: 0.8711 -- iter: 2464/3680
[A[ATraining Step: 11233  | total loss: [1m[32m0.31515[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31515 - acc: 0.8808 -- iter: 2496/3680
[A[ATraining Step: 11234  | total loss: [1m[32m0.32311[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32311 - acc: 0.8771 -- iter: 2528/3680
[A[ATraining Step: 11235  | total loss: [1m[32m0.31082[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31082 - acc: 0.8832 -- iter: 2560/3680
[A[ATraining Step: 11236  | total loss: [1m[32m0.32888[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32888 - acc: 0.8698 -- iter: 2592/3680
[A[ATraining Step: 11237  | total loss: [1m[32m0.32804[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32804 - acc: 0.8641 -- iter: 2624/3680
[A[ATraining Step: 11238  | total loss: [1m[32m0.31671[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31671 - acc: 0.8683 -- iter: 2656/3680
[A[ATraining Step: 11239  | total loss: [1m[32m0.31100[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31100 - acc: 0.8690 -- iter: 2688/3680
[A[ATraining Step: 11240  | total loss: [1m[32m0.30743[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30743 - acc: 0.8733 -- iter: 2720/3680
[A[ATraining Step: 11241  | total loss: [1m[32m0.30361[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30361 - acc: 0.8733 -- iter: 2752/3680
[A[ATraining Step: 11242  | total loss: [1m[32m0.29787[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29787 - acc: 0.8734 -- iter: 2784/3680
[A[ATraining Step: 11243  | total loss: [1m[32m0.31672[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31672 - acc: 0.8673 -- iter: 2816/3680
[A[ATraining Step: 11244  | total loss: [1m[32m0.31390[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31390 - acc: 0.8744 -- iter: 2848/3680
[A[ATraining Step: 11245  | total loss: [1m[32m0.30826[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30826 - acc: 0.8744 -- iter: 2880/3680
[A[ATraining Step: 11246  | total loss: [1m[32m0.33992[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33992 - acc: 0.8620 -- iter: 2912/3680
[A[ATraining Step: 11247  | total loss: [1m[32m0.33922[0m[0m
[2K| Adam | epoch: 098 | loss: 0.33922 - acc: 0.8633 -- iter: 2944/3680
[A[ATraining Step: 11248  | total loss: [1m[32m0.32756[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32756 - acc: 0.8676 -- iter: 2976/3680
[A[ATraining Step: 11249  | total loss: [1m[32m0.32415[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32415 - acc: 0.8690 -- iter: 3008/3680
[A[ATraining Step: 11250  | total loss: [1m[32m0.30842[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30842 - acc: 0.8790 -- iter: 3040/3680
[A[ATraining Step: 11251  | total loss: [1m[32m0.30842[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30842 - acc: 0.8790 -- iter: 3072/3680
[A[ATraining Step: 11252  | total loss: [1m[32m0.30837[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30837 - acc: 0.8848 -- iter: 3104/3680
[A[ATraining Step: 11253  | total loss: [1m[32m0.29914[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29914 - acc: 0.8932 -- iter: 3136/3680
[A[ATraining Step: 11254  | total loss: [1m[32m0.28151[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28151 - acc: 0.9039 -- iter: 3168/3680
[A[ATraining Step: 11255  | total loss: [1m[32m0.27666[0m[0m
[2K| Adam | epoch: 098 | loss: 0.27666 - acc: 0.9040 -- iter: 3200/3680
[A[ATraining Step: 11256  | total loss: [1m[32m0.27666[0m[0m
[2K| Adam | epoch: 098 | loss: 0.27666 - acc: 0.9040 -- iter: 3232/3680
[A[ATraining Step: 11257  | total loss: [1m[32m0.26939[0m[0m
[2K| Adam | epoch: 098 | loss: 0.26939 - acc: 0.9074 -- iter: 3264/3680
[A[ATraining Step: 11258  | total loss: [1m[32m0.27891[0m[0m
[2K| Adam | epoch: 098 | loss: 0.27891 - acc: 0.9040 -- iter: 3296/3680
[A[ATraining Step: 11259  | total loss: [1m[32m0.27891[0m[0m
[2K| Adam | epoch: 098 | loss: 0.27891 - acc: 0.9040 -- iter: 3328/3680
[A[ATraining Step: 11260  | total loss: [1m[32m0.28963[0m[0m
[2K| Adam | epoch: 098 | loss: 0.28963 - acc: 0.9011 -- iter: 3360/3680
[A[ATraining Step: 11261  | total loss: [1m[32m0.29602[0m[0m
[2K| Adam | epoch: 098 | loss: 0.29602 - acc: 0.8985 -- iter: 3392/3680
[A[ATraining Step: 11262  | total loss: [1m[32m0.30657[0m[0m
[2K| Adam | epoch: 098 | loss: 0.30657 - acc: 0.8868 -- iter: 3424/3680
[A[ATraining Step: 11263  | total loss: [1m[32m0.31545[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31545 - acc: 0.8825 -- iter: 3456/3680
[A[ATraining Step: 11264  | total loss: [1m[32m0.31765[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31765 - acc: 0.8817 -- iter: 3488/3680
[A[ATraining Step: 11265  | total loss: [1m[32m0.32576[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32576 - acc: 0.8686 -- iter: 3520/3680
[A[ATraining Step: 11266  | total loss: [1m[32m0.32419[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32419 - acc: 0.8661 -- iter: 3552/3680
[A[ATraining Step: 11267  | total loss: [1m[32m0.31086[0m[0m
[2K| Adam | epoch: 098 | loss: 0.31086 - acc: 0.8732 -- iter: 3584/3680
[A[ATraining Step: 11268  | total loss: [1m[32m0.32984[0m[0m
[2K| Adam | epoch: 098 | loss: 0.32984 - acc: 0.8640 -- iter: 3616/3680
[A[ATraining Step: 11269  | total loss: [1m[32m0.37874[0m[0m
[2K| Adam | epoch: 098 | loss: 0.37874 - acc: 0.8620 -- iter: 3648/3680
[A[ATraining Step: 11270  | total loss: [1m[32m0.37107[0m[0m
[2K| Adam | epoch: 098 | loss: 0.37107 - acc: 0.8633 | val_loss: 0.31366 - val_acc: 0.8773 -- iter: 3680/3680
[A[ATraining Step: 11270  | total loss: [1m[32m0.37107[0m[0m
[2K| Adam | epoch: 098 | loss: 0.37107 - acc: 0.8633 | val_loss: 0.31366 - val_acc: 0.8773 -- iter: 3680/3680
--
Training Step: 11271  | total loss: [1m[32m0.37257[0m[0m
[2K| Adam | epoch: 099 | loss: 0.37257 - acc: 0.8613 -- iter: 0032/3680
[A[ATraining Step: 11272  | total loss: [1m[32m0.38011[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38011 - acc: 0.8533 -- iter: 0064/3680
[A[ATraining Step: 11273  | total loss: [1m[32m0.36519[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36519 - acc: 0.8586 -- iter: 0096/3680
[A[ATraining Step: 11274  | total loss: [1m[32m0.34973[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34973 - acc: 0.8634 -- iter: 0128/3680
[A[ATraining Step: 11275  | total loss: [1m[32m0.33705[0m[0m
[2K| Adam | epoch: 099 | loss: 0.33705 - acc: 0.8677 -- iter: 0160/3680
[A[ATraining Step: 11276  | total loss: [1m[32m0.33668[0m[0m
[2K| Adam | epoch: 099 | loss: 0.33668 - acc: 0.8653 -- iter: 0192/3680
[A[ATraining Step: 11277  | total loss: [1m[32m0.34679[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34679 - acc: 0.8600 -- iter: 0224/3680
[A[ATraining Step: 11278  | total loss: [1m[32m0.36592[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36592 - acc: 0.8521 -- iter: 0256/3680
[A[ATraining Step: 11279  | total loss: [1m[32m0.36621[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36621 - acc: 0.8575 -- iter: 0288/3680
[A[ATraining Step: 11280  | total loss: [1m[32m0.36383[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36383 - acc: 0.8609 -- iter: 0320/3680
[A[ATraining Step: 11281  | total loss: [1m[32m0.36383[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36383 - acc: 0.8609 -- iter: 0352/3680
[A[ATraining Step: 11282  | total loss: [1m[32m0.35549[0m[0m
[2K| Adam | epoch: 099 | loss: 0.35549 - acc: 0.8604 -- iter: 0384/3680
[A[ATraining Step: 11283  | total loss: [1m[32m0.35557[0m[0m
[2K| Adam | epoch: 099 | loss: 0.35557 - acc: 0.8556 -- iter: 0416/3680
[A[ATraining Step: 11284  | total loss: [1m[32m0.35557[0m[0m
[2K| Adam | epoch: 099 | loss: 0.35557 - acc: 0.8638 -- iter: 0448/3680
[A[ATraining Step: 11285  | total loss: [1m[32m0.34626[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34626 - acc: 0.8638 -- iter: 0480/3680
[A[ATraining Step: 11286  | total loss: [1m[32m0.34313[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34313 - acc: 0.8618 -- iter: 0512/3680
[A[ATraining Step: 11287  | total loss: [1m[32m0.35578[0m[0m
[2K| Adam | epoch: 099 | loss: 0.35578 - acc: 0.8538 -- iter: 0544/3680
[A[ATraining Step: 11288  | total loss: [1m[32m0.36314[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36314 - acc: 0.8496 -- iter: 0576/3680
[A[ATraining Step: 11289  | total loss: [1m[32m0.38534[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38534 - acc: 0.8426 -- iter: 0608/3680
[A[ATraining Step: 11290  | total loss: [1m[32m0.38534[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38534 - acc: 0.8426 -- iter: 0640/3680
[A[ATraining Step: 11291  | total loss: [1m[32m0.36903[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36903 - acc: 0.8521 -- iter: 0672/3680
[A[ATraining Step: 11292  | total loss: [1m[32m0.37240[0m[0m
[2K| Adam | epoch: 099 | loss: 0.37240 - acc: 0.8481 -- iter: 0704/3680
[A[ATraining Step: 11293  | total loss: [1m[32m0.38980[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38980 - acc: 0.8352 -- iter: 0736/3680
[A[ATraining Step: 11294  | total loss: [1m[32m0.38136[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38136 - acc: 0.8423 -- iter: 0768/3680
[A[ATraining Step: 11295  | total loss: [1m[32m0.37584[0m[0m
[2K| Adam | epoch: 099 | loss: 0.37584 - acc: 0.8456 -- iter: 0800/3680
[A[ATraining Step: 11296  | total loss: [1m[32m0.38174[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38174 - acc: 0.8485 -- iter: 0832/3680
[A[ATraining Step: 11297  | total loss: [1m[32m0.38107[0m[0m
[2K| Adam | epoch: 099 | loss: 0.38107 - acc: 0.8476 -- iter: 0864/3680
[A[ATraining Step: 11298  | total loss: [1m[32m0.37617[0m[0m
[2K| Adam | epoch: 099 | loss: 0.37617 - acc: 0.8476 -- iter: 0896/3680
[A[ATraining Step: 11299  | total loss: [1m[32m0.36075[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36075 - acc: 0.8566 -- iter: 0928/3680
[A[ATraining Step: 11300  | total loss: [1m[32m0.37141[0m[0m
[2K| Adam | epoch: 099 | loss: 0.37141 - acc: 0.8522 | val_loss: 0.30034 - val_acc: 0.8893 -- iter: 0960/3680
[A[ATraining Step: 11300  | total loss: [1m[32m0.37141[0m[0m
[2K| Adam | epoch: 099 | loss: 0.37141 - acc: 0.8522 | val_loss: 0.30034 - val_acc: 0.8893 -- iter: 0960/3680
--
Training Step: 11301  | total loss: [1m[32m0.36233[0m[0m
[2K| Adam | epoch: 099 | loss: 0.36233 - acc: 0.8545 -- iter: 0992/3680
[A[ATraining Step: 11302  | total loss: [1m[32m0.35277[0m[0m
[2K| Adam | epoch: 099 | loss: 0.35277 - acc: 0.8534 -- iter: 1024/3680
[A[ATraining Step: 11303  | total loss: [1m[32m0.34071[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34071 - acc: 0.8587 -- iter: 1056/3680
[A[ATraining Step: 11304  | total loss: [1m[32m0.34545[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34545 - acc: 0.8572 -- iter: 1088/3680
[A[ATraining Step: 11305  | total loss: [1m[32m0.33313[0m[0m
[2K| Adam | epoch: 099 | loss: 0.33313 - acc: 0.8603 -- iter: 1120/3680
[A[ATraining Step: 11306  | total loss: [1m[32m0.33313[0m[0m
[2K| Adam | epoch: 099 | loss: 0.33313 - acc: 0.8603 -- iter: 1152/3680
[A[ATraining Step: 11307  | total loss: [1m[32m0.31770[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31770 - acc: 0.8680 -- iter: 1184/3680
[A[ATraining Step: 11308  | total loss: [1m[32m0.32899[0m[0m
[2K| Adam | epoch: 099 | loss: 0.32899 - acc: 0.8656 -- iter: 1216/3680
[A[ATraining Step: 11309  | total loss: [1m[32m0.30647[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30647 - acc: 0.8761 -- iter: 1248/3680
[A[ATraining Step: 11310  | total loss: [1m[32m0.30647[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30647 - acc: 0.8761 -- iter: 1280/3680
[A[ATraining Step: 11311  | total loss: [1m[32m0.31943[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31943 - acc: 0.8709 -- iter: 1312/3680
[A[ATraining Step: 11312  | total loss: [1m[32m0.30113[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30113 - acc: 0.8709 -- iter: 1344/3680
[A[ATraining Step: 11313  | total loss: [1m[32m0.30457[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30457 - acc: 0.8713 -- iter: 1376/3680
[A[ATraining Step: 11314  | total loss: [1m[32m0.29185[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29185 - acc: 0.8748 -- iter: 1408/3680
[A[ATraining Step: 11315  | total loss: [1m[32m0.28600[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28600 - acc: 0.8811 -- iter: 1440/3680
[A[ATraining Step: 11316  | total loss: [1m[32m0.28018[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28018 - acc: 0.8867 -- iter: 1472/3680
[A[ATraining Step: 11317  | total loss: [1m[32m0.27168[0m[0m
[2K| Adam | epoch: 099 | loss: 0.27168 - acc: 0.8887 -- iter: 1504/3680
[A[ATraining Step: 11318  | total loss: [1m[32m0.26615[0m[0m
[2K| Adam | epoch: 099 | loss: 0.26615 - acc: 0.8904 -- iter: 1536/3680
[A[ATraining Step: 11319  | total loss: [1m[32m0.27119[0m[0m
[2K| Adam | epoch: 099 | loss: 0.27119 - acc: 0.8858 -- iter: 1568/3680
[A[ATraining Step: 11320  | total loss: [1m[32m0.27517[0m[0m
[2K| Adam | epoch: 099 | loss: 0.27517 - acc: 0.8878 -- iter: 1600/3680
[A[ATraining Step: 11321  | total loss: [1m[32m0.28302[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28302 - acc: 0.8803 -- iter: 1632/3680
[A[ATraining Step: 11322  | total loss: [1m[32m0.29511[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29511 - acc: 0.8704 -- iter: 1664/3680
[A[ATraining Step: 11323  | total loss: [1m[32m0.28704[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28704 - acc: 0.8740 -- iter: 1696/3680
[A[ATraining Step: 11324  | total loss: [1m[32m0.31274[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31274 - acc: 0.8678 -- iter: 1728/3680
[A[ATraining Step: 11325  | total loss: [1m[32m0.30802[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30802 - acc: 0.8654 -- iter: 1760/3680
[A[ATraining Step: 11326  | total loss: [1m[32m0.29252[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29252 - acc: 0.8757 -- iter: 1792/3680
[A[ATraining Step: 11327  | total loss: [1m[32m0.29301[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29301 - acc: 0.8815 -- iter: 1824/3680
[A[ATraining Step: 11328  | total loss: [1m[32m0.29301[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29301 - acc: 0.8815 -- iter: 1856/3680
[A[ATraining Step: 11329  | total loss: [1m[32m0.31302[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31302 - acc: 0.8778 -- iter: 1888/3680
[A[ATraining Step: 11330  | total loss: [1m[32m0.29958[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29958 - acc: 0.8837 -- iter: 1920/3680
[A[ATraining Step: 11331  | total loss: [1m[32m0.29382[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29382 - acc: 0.8860 -- iter: 1952/3680
[A[ATraining Step: 11332  | total loss: [1m[32m0.28151[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28151 - acc: 0.8923 -- iter: 1984/3680
[A[ATraining Step: 11333  | total loss: [1m[32m0.29054[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29054 - acc: 0.8923 -- iter: 2016/3680
[A[ATraining Step: 11334  | total loss: [1m[32m0.29204[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29204 - acc: 0.8937 -- iter: 2048/3680
[A[ATraining Step: 11335  | total loss: [1m[32m0.29486[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29486 - acc: 0.8981 -- iter: 2080/3680
[A[ATraining Step: 11336  | total loss: [1m[32m0.30598[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30598 - acc: 0.8895 -- iter: 2112/3680
[A[ATraining Step: 11337  | total loss: [1m[32m0.29773[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29773 - acc: 0.8912 -- iter: 2144/3680
[A[ATraining Step: 11338  | total loss: [1m[32m0.28396[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28396 - acc: 0.8975 -- iter: 2176/3680
[A[ATraining Step: 11339  | total loss: [1m[32m0.28396[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28396 - acc: 0.8890 -- iter: 2208/3680
[A[ATraining Step: 11340  | total loss: [1m[32m0.28915[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28915 - acc: 0.8890 -- iter: 2240/3680
[A[ATraining Step: 11341  | total loss: [1m[32m0.31945[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31945 - acc: 0.8845 -- iter: 2272/3680
[A[ATraining Step: 11342  | total loss: [1m[32m0.30744[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30744 - acc: 0.8898 -- iter: 2304/3680
[A[ATraining Step: 11343  | total loss: [1m[32m0.30401[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30401 - acc: 0.8946 -- iter: 2336/3680
[A[ATraining Step: 11344  | total loss: [1m[32m0.30244[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30244 - acc: 0.8863 -- iter: 2368/3680
[A[ATraining Step: 11345  | total loss: [1m[32m0.30271[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30271 - acc: 0.8814 -- iter: 2400/3680
[A[ATraining Step: 11346  | total loss: [1m[32m0.30271[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30271 - acc: 0.8814 -- iter: 2432/3680
[A[ATraining Step: 11347  | total loss: [1m[32m0.29604[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29604 - acc: 0.8830 -- iter: 2464/3680
[A[ATraining Step: 11348  | total loss: [1m[32m0.29604[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29604 - acc: 0.8830 -- iter: 2496/3680
[A[ATraining Step: 11349  | total loss: [1m[32m0.29038[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29038 - acc: 0.8884 -- iter: 2528/3680
[A[ATraining Step: 11350  | total loss: [1m[32m0.29275[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29275 - acc: 0.8840 -- iter: 2560/3680
[A[ATraining Step: 11351  | total loss: [1m[32m0.28964[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28964 - acc: 0.8831 -- iter: 2592/3680
[A[ATraining Step: 11352  | total loss: [1m[32m0.29473[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29473 - acc: 0.8729 -- iter: 2624/3680
[A[ATraining Step: 11353  | total loss: [1m[32m0.30555[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30555 - acc: 0.8700 -- iter: 2656/3680
[A[ATraining Step: 11354  | total loss: [1m[32m0.31696[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31696 - acc: 0.8674 -- iter: 2688/3680
[A[ATraining Step: 11355  | total loss: [1m[32m0.31941[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31941 - acc: 0.8681 -- iter: 2720/3680
[A[ATraining Step: 11356  | total loss: [1m[32m0.32987[0m[0m
[2K| Adam | epoch: 099 | loss: 0.32987 - acc: 0.8657 -- iter: 2752/3680
[A[ATraining Step: 11357  | total loss: [1m[32m0.32329[0m[0m
[2K| Adam | epoch: 099 | loss: 0.32329 - acc: 0.8666 -- iter: 2784/3680
[A[ATraining Step: 11358  | total loss: [1m[32m0.32049[0m[0m
[2K| Adam | epoch: 099 | loss: 0.32049 - acc: 0.8612 -- iter: 2816/3680
[A[ATraining Step: 11359  | total loss: [1m[32m0.30266[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30266 - acc: 0.8720 -- iter: 2848/3680
[A[ATraining Step: 11360  | total loss: [1m[32m0.31361[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31361 - acc: 0.8691 -- iter: 2880/3680
[A[ATraining Step: 11361  | total loss: [1m[32m0.30370[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30370 - acc: 0.8697 -- iter: 2912/3680
[A[ATraining Step: 11362  | total loss: [1m[32m0.31064[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31064 - acc: 0.8671 -- iter: 2944/3680
[A[ATraining Step: 11363  | total loss: [1m[32m0.31721[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31721 - acc: 0.8585 -- iter: 2976/3680
[A[ATraining Step: 11364  | total loss: [1m[32m0.33854[0m[0m
[2K| Adam | epoch: 099 | loss: 0.33854 - acc: 0.8539 -- iter: 3008/3680
[A[ATraining Step: 11365  | total loss: [1m[32m0.34759[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34759 - acc: 0.8529 -- iter: 3040/3680
[A[ATraining Step: 11366  | total loss: [1m[32m0.34144[0m[0m
[2K| Adam | epoch: 099 | loss: 0.34144 - acc: 0.8551 -- iter: 3072/3680
[A[ATraining Step: 11367  | total loss: [1m[32m0.33220[0m[0m
[2K| Adam | epoch: 099 | loss: 0.33220 - acc: 0.8634 -- iter: 3104/3680
[A[ATraining Step: 11368  | total loss: [1m[32m0.32123[0m[0m
[2K| Adam | epoch: 099 | loss: 0.32123 - acc: 0.8708 -- iter: 3136/3680
[A[ATraining Step: 11369  | total loss: [1m[32m0.31141[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31141 - acc: 0.8806 -- iter: 3168/3680
[A[ATraining Step: 11370  | total loss: [1m[32m0.30770[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30770 - acc: 0.8800 -- iter: 3200/3680
[A[ATraining Step: 11371  | total loss: [1m[32m0.29798[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29798 - acc: 0.8858 -- iter: 3232/3680
[A[ATraining Step: 11372  | total loss: [1m[32m0.30918[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30918 - acc: 0.8718 -- iter: 3264/3680
[A[ATraining Step: 11373  | total loss: [1m[32m0.30918[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30918 - acc: 0.8718 -- iter: 3296/3680
[A[ATraining Step: 11374  | total loss: [1m[32m0.30292[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30292 - acc: 0.8784 -- iter: 3328/3680
[A[ATraining Step: 11375  | total loss: [1m[32m0.30629[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30629 - acc: 0.8781 -- iter: 3360/3680
[A[ATraining Step: 11376  | total loss: [1m[32m0.30633[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30633 - acc: 0.8778 -- iter: 3392/3680
[A[ATraining Step: 11377  | total loss: [1m[32m0.30551[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30551 - acc: 0.8838 -- iter: 3424/3680
[A[ATraining Step: 11378  | total loss: [1m[32m0.29572[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29572 - acc: 0.8838 -- iter: 3456/3680
[A[ATraining Step: 11379  | total loss: [1m[32m0.29240[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29240 - acc: 0.8860 -- iter: 3488/3680
[A[ATraining Step: 11380  | total loss: [1m[32m0.28557[0m[0m
[2K| Adam | epoch: 099 | loss: 0.28557 - acc: 0.8849 -- iter: 3520/3680
[A[ATraining Step: 11381  | total loss: [1m[32m0.29404[0m[0m
[2K| Adam | epoch: 099 | loss: 0.29404 - acc: 0.8839 -- iter: 3552/3680
[A[ATraining Step: 11382  | total loss: [1m[32m0.30924[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30924 - acc: 0.8768 -- iter: 3584/3680
[A[ATraining Step: 11383  | total loss: [1m[32m0.31303[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31303 - acc: 0.8766 -- iter: 3616/3680
[A[ATraining Step: 11384  | total loss: [1m[32m0.31714[0m[0m
[2K| Adam | epoch: 099 | loss: 0.31714 - acc: 0.8702 -- iter: 3648/3680
[A[ATraining Step: 11385  | total loss: [1m[32m0.30706[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30706 - acc: 0.8769 | val_loss: 0.28176 - val_acc: 0.9066 -- iter: 3680/3680
[A[ATraining Step: 11385  | total loss: [1m[32m0.30706[0m[0m
[2K| Adam | epoch: 099 | loss: 0.30706 - acc: 0.8769 | val_loss: 0.28176 - val_acc: 0.9066 -- iter: 3680/3680
--
Training Step: 11386  | total loss: [1m[32m0.30712[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30712 - acc: 0.8767 -- iter: 0032/3680
[A[ATraining Step: 11387  | total loss: [1m[32m0.31479[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31479 - acc: 0.8703 -- iter: 0064/3680
[A[ATraining Step: 11388  | total loss: [1m[32m0.31392[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31392 - acc: 0.8708 -- iter: 0096/3680
[A[ATraining Step: 11389  | total loss: [1m[32m0.31382[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31382 - acc: 0.8712 -- iter: 0128/3680
[A[ATraining Step: 11390  | total loss: [1m[32m0.30860[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30860 - acc: 0.8685 -- iter: 0160/3680
[A[ATraining Step: 11391  | total loss: [1m[32m0.32227[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32227 - acc: 0.8660 -- iter: 0192/3680
[A[ATraining Step: 11392  | total loss: [1m[32m0.33233[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33233 - acc: 0.8606 -- iter: 0224/3680
[A[ATraining Step: 11393  | total loss: [1m[32m0.33220[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33220 - acc: 0.8590 -- iter: 0256/3680
[A[ATraining Step: 11394  | total loss: [1m[32m0.33261[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33261 - acc: 0.8589 -- iter: 0288/3680
[A[ATraining Step: 11395  | total loss: [1m[32m0.34029[0m[0m
[2K| Adam | epoch: 100 | loss: 0.34029 - acc: 0.8574 -- iter: 0320/3680
[A[ATraining Step: 11396  | total loss: [1m[32m0.34029[0m[0m
[2K| Adam | epoch: 100 | loss: 0.34029 - acc: 0.8574 -- iter: 0352/3680
[A[ATraining Step: 11397  | total loss: [1m[32m0.33613[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33613 - acc: 0.8654 -- iter: 0384/3680
[A[ATraining Step: 11398  | total loss: [1m[32m0.33745[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33745 - acc: 0.8663 -- iter: 0416/3680
[A[ATraining Step: 11399  | total loss: [1m[32m0.32026[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32026 - acc: 0.8766 -- iter: 0448/3680
[A[ATraining Step: 11400  | total loss: [1m[32m0.32082[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32082 - acc: 0.8764 | val_loss: 0.28279 - val_acc: 0.9012 -- iter: 0480/3680
[A[ATraining Step: 11400  | total loss: [1m[32m0.32082[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32082 - acc: 0.8764 | val_loss: 0.28279 - val_acc: 0.9012 -- iter: 0480/3680
--
Training Step: 11401  | total loss: [1m[32m0.31155[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31155 - acc: 0.8857 -- iter: 0512/3680
[A[ATraining Step: 11402  | total loss: [1m[32m0.33679[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33679 - acc: 0.8815 -- iter: 0544/3680
[A[ATraining Step: 11403  | total loss: [1m[32m0.32113[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32113 - acc: 0.8902 -- iter: 0576/3680
[A[ATraining Step: 11404  | total loss: [1m[32m0.32392[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32392 - acc: 0.8918 -- iter: 0608/3680
[A[ATraining Step: 11405  | total loss: [1m[32m0.31623[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31623 - acc: 0.8901 -- iter: 0640/3680
[A[ATraining Step: 11406  | total loss: [1m[32m0.32833[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32833 - acc: 0.8855 -- iter: 0672/3680
[A[ATraining Step: 11407  | total loss: [1m[32m0.31137[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31137 - acc: 0.8891 -- iter: 0704/3680
[A[ATraining Step: 11408  | total loss: [1m[32m0.31137[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31137 - acc: 0.8891 -- iter: 0736/3680
[A[ATraining Step: 11409  | total loss: [1m[32m0.30784[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30784 - acc: 0.8908 -- iter: 0768/3680
[A[ATraining Step: 11410  | total loss: [1m[32m0.29993[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29993 - acc: 0.8906 -- iter: 0800/3680
[A[ATraining Step: 11411  | total loss: [1m[32m0.30227[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30227 - acc: 0.8906 -- iter: 0832/3680
[A[ATraining Step: 11412  | total loss: [1m[32m0.30053[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30053 - acc: 0.8859 -- iter: 0864/3680
[A[ATraining Step: 11413  | total loss: [1m[32m0.29362[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29362 - acc: 0.8880 -- iter: 0896/3680
[A[ATraining Step: 11414  | total loss: [1m[32m0.29802[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29802 - acc: 0.8836 -- iter: 0928/3680
[A[ATraining Step: 11415  | total loss: [1m[32m0.28110[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28110 - acc: 0.8921 -- iter: 0960/3680
[A[ATraining Step: 11416  | total loss: [1m[32m0.27763[0m[0m
[2K| Adam | epoch: 100 | loss: 0.27763 - acc: 0.8966 -- iter: 0992/3680
[A[ATraining Step: 11417  | total loss: [1m[32m0.27227[0m[0m
[2K| Adam | epoch: 100 | loss: 0.27227 - acc: 0.9007 -- iter: 1024/3680
[A[ATraining Step: 11418  | total loss: [1m[32m0.28481[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28481 - acc: 0.8888 -- iter: 1056/3680
[A[ATraining Step: 11419  | total loss: [1m[32m0.28791[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28791 - acc: 0.8874 -- iter: 1088/3680
[A[ATraining Step: 11420  | total loss: [1m[32m0.29120[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29120 - acc: 0.8861 -- iter: 1120/3680
[A[ATraining Step: 11421  | total loss: [1m[32m0.29725[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29725 - acc: 0.8850 -- iter: 1152/3680
[A[ATraining Step: 11422  | total loss: [1m[32m0.31050[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31050 - acc: 0.8715 -- iter: 1184/3680
[A[ATraining Step: 11423  | total loss: [1m[32m0.29793[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29793 - acc: 0.8781 -- iter: 1216/3680
[A[ATraining Step: 11424  | total loss: [1m[32m0.30044[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30044 - acc: 0.8778 -- iter: 1248/3680
[A[ATraining Step: 11425  | total loss: [1m[32m0.28902[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28902 - acc: 0.8869 -- iter: 1280/3680
[A[ATraining Step: 11426  | total loss: [1m[32m0.28095[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28095 - acc: 0.8920 -- iter: 1312/3680
[A[ATraining Step: 11427  | total loss: [1m[32m0.27823[0m[0m
[2K| Adam | epoch: 100 | loss: 0.27823 - acc: 0.8934 -- iter: 1344/3680
[A[ATraining Step: 11428  | total loss: [1m[32m0.28391[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28391 - acc: 0.8836 -- iter: 1376/3680
[A[ATraining Step: 11429  | total loss: [1m[32m0.31632[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31632 - acc: 0.8836 -- iter: 1408/3680
[A[ATraining Step: 11430  | total loss: [1m[32m0.31772[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31772 - acc: 0.8765 -- iter: 1440/3680
[A[ATraining Step: 11431  | total loss: [1m[32m0.31329[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31329 - acc: 0.8795 -- iter: 1472/3680
[A[ATraining Step: 11432  | total loss: [1m[32m0.31739[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31739 - acc: 0.8791 -- iter: 1504/3680
[A[ATraining Step: 11433  | total loss: [1m[32m0.30434[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30434 - acc: 0.8849 -- iter: 1536/3680
[A[ATraining Step: 11434  | total loss: [1m[32m0.30406[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30406 - acc: 0.8808 -- iter: 1568/3680
[A[ATraining Step: 11435  | total loss: [1m[32m0.28672[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28672 - acc: 0.8896 -- iter: 1600/3680
[A[ATraining Step: 11436  | total loss: [1m[32m0.28575[0m[0m
[2K| Adam | epoch: 100 | loss: 0.28575 - acc: 0.8881 -- iter: 1632/3680
[A[ATraining Step: 11437  | total loss: [1m[32m0.27565[0m[0m
[2K| Adam | epoch: 100 | loss: 0.27565 - acc: 0.8931 -- iter: 1664/3680
[A[ATraining Step: 11438  | total loss: [1m[32m0.29523[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29523 - acc: 0.8881 -- iter: 1696/3680
[A[ATraining Step: 11439  | total loss: [1m[32m0.30962[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30962 - acc: 0.8868 -- iter: 1728/3680
[A[ATraining Step: 11440  | total loss: [1m[32m0.31365[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31365 - acc: 0.8825 -- iter: 1760/3680
[A[ATraining Step: 11441  | total loss: [1m[32m0.30596[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30596 - acc: 0.8911 -- iter: 1792/3680
[A[ATraining Step: 11442  | total loss: [1m[32m0.34155[0m[0m
[2K| Adam | epoch: 100 | loss: 0.34155 - acc: 0.8799 -- iter: 1824/3680
[A[ATraining Step: 11443  | total loss: [1m[32m0.33018[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33018 - acc: 0.8799 -- iter: 1856/3680
[A[ATraining Step: 11444  | total loss: [1m[32m0.33115[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33115 - acc: 0.8794 -- iter: 1888/3680
[A[ATraining Step: 11445  | total loss: [1m[32m0.32566[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32566 - acc: 0.8790 -- iter: 1920/3680
[A[ATraining Step: 11446  | total loss: [1m[32m0.32547[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32547 - acc: 0.8786 -- iter: 1952/3680
[A[ATraining Step: 11447  | total loss: [1m[32m0.31436[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31436 - acc: 0.8898 -- iter: 1984/3680
[A[ATraining Step: 11448  | total loss: [1m[32m0.33465[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33465 - acc: 0.8898 -- iter: 2016/3680
[A[ATraining Step: 11449  | total loss: [1m[32m0.33465[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33465 - acc: 0.8758 -- iter: 2048/3680
[A[ATraining Step: 11450  | total loss: [1m[32m0.31715[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31715 - acc: 0.8882 -- iter: 2080/3680
[A[ATraining Step: 11451  | total loss: [1m[32m0.32000[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32000 - acc: 0.8869 -- iter: 2112/3680
[A[ATraining Step: 11452  | total loss: [1m[32m0.31649[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31649 - acc: 0.8888 -- iter: 2144/3680
[A[ATraining Step: 11453  | total loss: [1m[32m0.33002[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33002 - acc: 0.8812 -- iter: 2176/3680
[A[ATraining Step: 11454  | total loss: [1m[32m0.32198[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32198 - acc: 0.8794 -- iter: 2208/3680
[A[ATraining Step: 11455  | total loss: [1m[32m0.32042[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32042 - acc: 0.8794 -- iter: 2240/3680
[A[ATraining Step: 11456  | total loss: [1m[32m0.31788[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31788 - acc: 0.8790 -- iter: 2272/3680
[A[ATraining Step: 11457  | total loss: [1m[32m0.31619[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31619 - acc: 0.8817 -- iter: 2304/3680
[A[ATraining Step: 11458  | total loss: [1m[32m0.31774[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31774 - acc: 0.8779 -- iter: 2336/3680
[A[ATraining Step: 11459  | total loss: [1m[32m0.31360[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31360 - acc: 0.8745 -- iter: 2368/3680
[A[ATraining Step: 11460  | total loss: [1m[32m0.31446[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31446 - acc: 0.8777 -- iter: 2400/3680
[A[ATraining Step: 11461  | total loss: [1m[32m0.32240[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32240 - acc: 0.8711 -- iter: 2432/3680
[A[ATraining Step: 11462  | total loss: [1m[32m0.32256[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32256 - acc: 0.8684 -- iter: 2464/3680
[A[ATraining Step: 11463  | total loss: [1m[32m0.31319[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31319 - acc: 0.8753 -- iter: 2496/3680
[A[ATraining Step: 11464  | total loss: [1m[32m0.31815[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31815 - acc: 0.8722 -- iter: 2528/3680
[A[ATraining Step: 11465  | total loss: [1m[32m0.30165[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30165 - acc: 0.8849 -- iter: 2560/3680
[A[ATraining Step: 11466  | total loss: [1m[32m0.29573[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29573 - acc: 0.8871 -- iter: 2592/3680
[A[ATraining Step: 11467  | total loss: [1m[32m0.31580[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31580 - acc: 0.8765 -- iter: 2624/3680
[A[ATraining Step: 11468  | total loss: [1m[32m0.31219[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31219 - acc: 0.8763 -- iter: 2656/3680
[A[ATraining Step: 11469  | total loss: [1m[32m0.33450[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33450 - acc: 0.8700 -- iter: 2688/3680
[A[ATraining Step: 11470  | total loss: [1m[32m0.32952[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32952 - acc: 0.8705 -- iter: 2720/3680
[A[ATraining Step: 11471  | total loss: [1m[32m0.33397[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33397 - acc: 0.8566 -- iter: 2752/3680
[A[ATraining Step: 11472  | total loss: [1m[32m0.33397[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33397 - acc: 0.8566 -- iter: 2784/3680
[A[ATraining Step: 11473  | total loss: [1m[32m0.31970[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31970 - acc: 0.8616 -- iter: 2816/3680
[A[ATraining Step: 11474  | total loss: [1m[32m0.32186[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32186 - acc: 0.8629 -- iter: 2848/3680
[A[ATraining Step: 11475  | total loss: [1m[32m0.31051[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31051 - acc: 0.8673 -- iter: 2880/3680
[A[ATraining Step: 11476  | total loss: [1m[32m0.33591[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33591 - acc: 0.8587 -- iter: 2912/3680
[A[ATraining Step: 11477  | total loss: [1m[32m0.33446[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33446 - acc: 0.8572 -- iter: 2944/3680
[A[ATraining Step: 11478  | total loss: [1m[32m0.33846[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33846 - acc: 0.8621 -- iter: 2976/3680
[A[ATraining Step: 11479  | total loss: [1m[32m0.32094[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32094 - acc: 0.8702 -- iter: 3008/3680
[A[ATraining Step: 11480  | total loss: [1m[32m0.31999[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31999 - acc: 0.8702 -- iter: 3040/3680
[A[ATraining Step: 11481  | total loss: [1m[32m0.31283[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31283 - acc: 0.8738 -- iter: 3072/3680
[A[ATraining Step: 11482  | total loss: [1m[32m0.31635[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31635 - acc: 0.8739 -- iter: 3104/3680
[A[ATraining Step: 11483  | total loss: [1m[32m0.32310[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32310 - acc: 0.8771 -- iter: 3136/3680
[A[ATraining Step: 11484  | total loss: [1m[32m0.32071[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32071 - acc: 0.8800 -- iter: 3168/3680
[A[ATraining Step: 11485  | total loss: [1m[32m0.32940[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32940 - acc: 0.8670 -- iter: 3200/3680
[A[ATraining Step: 11486  | total loss: [1m[32m0.31505[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31505 - acc: 0.8772 -- iter: 3232/3680
[A[ATraining Step: 11487  | total loss: [1m[32m0.31689[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31689 - acc: 0.8676 -- iter: 3264/3680
[A[ATraining Step: 11488  | total loss: [1m[32m0.31093[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31093 - acc: 0.8715 -- iter: 3296/3680
[A[ATraining Step: 11489  | total loss: [1m[32m0.31065[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31065 - acc: 0.8687 -- iter: 3328/3680
[A[ATraining Step: 11490  | total loss: [1m[32m0.31619[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31619 - acc: 0.8600 -- iter: 3360/3680
[A[ATraining Step: 11491  | total loss: [1m[32m0.32899[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32899 - acc: 0.8583 -- iter: 3392/3680
[A[ATraining Step: 11492  | total loss: [1m[32m0.33709[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33709 - acc: 0.8538 -- iter: 3424/3680
[A[ATraining Step: 11493  | total loss: [1m[32m0.33172[0m[0m
[2K| Adam | epoch: 100 | loss: 0.33172 - acc: 0.8496 -- iter: 3456/3680
[A[ATraining Step: 11494  | total loss: [1m[32m0.32154[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32154 - acc: 0.8584 -- iter: 3488/3680
[A[ATraining Step: 11495  | total loss: [1m[32m0.32719[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32719 - acc: 0.8538 -- iter: 3520/3680
[A[ATraining Step: 11496  | total loss: [1m[32m0.31432[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31432 - acc: 0.8622 -- iter: 3552/3680
[A[ATraining Step: 11497  | total loss: [1m[32m0.31520[0m[0m
[2K| Adam | epoch: 100 | loss: 0.31520 - acc: 0.8603 -- iter: 3584/3680
[A[ATraining Step: 11498  | total loss: [1m[32m0.29433[0m[0m
[2K| Adam | epoch: 100 | loss: 0.29433 - acc: 0.8743 -- iter: 3616/3680
[A[ATraining Step: 11499  | total loss: [1m[32m0.30016[0m[0m
[2K| Adam | epoch: 100 | loss: 0.30016 - acc: 0.8713 -- iter: 3648/3680
[A[ATraining Step: 11500  | total loss: [1m[32m0.32908[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32908 - acc: 0.8654 | val_loss: 0.28754 - val_acc: 0.8990 -- iter: 3680/3680
[A[ATraining Step: 11500  | total loss: [1m[32m0.32908[0m[0m
[2K| Adam | epoch: 100 | loss: 0.32908 - acc: 0.8654 | val_loss: 0.28754 - val_acc: 0.8990 -- iter: 3680/3680
--
[B[B[B[?12;25h[[0.17467495799064636, 0.825325071811676]]
